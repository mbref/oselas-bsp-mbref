diff -purN --exclude=.git linux-2.6.31.12/arch/alpha/mm/init.c linux-2.6.31.12-petalinux/arch/alpha/mm/init.c
--- linux-2.6.31.12/arch/alpha/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/alpha/mm/init.c	2010-08-08 17:40:15.843755287 +0200
@@ -299,7 +299,7 @@ printk_memory_info(void)
 	initsize =  (unsigned long) &__init_end - (unsigned long) &__init_begin;
 
 	printk("Memory: %luk/%luk available (%luk kernel code, %luk reserved, %luk data, %luk init)\n",
-	       (unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+	       nr_free_pages() << (PAGE_SHIFT-10),
 	       max_mapnr << (PAGE_SHIFT-10),
 	       codesize >> 10,
 	       reservedpages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/arch/alpha/mm/numa.c linux-2.6.31.12-petalinux/arch/alpha/mm/numa.c
--- linux-2.6.31.12/arch/alpha/mm/numa.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/alpha/mm/numa.c	2010-08-08 17:40:15.843755287 +0200
@@ -349,7 +349,7 @@ void __init mem_init(void)
 
 	printk("Memory: %luk/%luk available (%luk kernel code, %luk reserved, "
 	       "%luk data, %luk init)\n",
-	       (unsigned long)nr_free_pages() << (PAGE_SHIFT-10),
+	       nr_free_pages() << (PAGE_SHIFT-10),
 	       num_physpages << (PAGE_SHIFT-10),
 	       codesize >> 10,
 	       reservedpages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/arch/arm/mm/init.c linux-2.6.31.12-petalinux/arch/arm/mm/init.c
--- linux-2.6.31.12/arch/arm/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/arm/mm/init.c	2010-08-08 17:40:15.849523897 +0200
@@ -564,8 +564,8 @@ void __init mem_init(void)
 
 	printk(KERN_NOTICE "Memory: %luKB available (%dK code, "
 		"%dK data, %dK init, %luK highmem)\n",
-		(unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
-		codesize >> 10, datasize >> 10, initsize >> 10,
+		nr_free_pages() << (PAGE_SHIFT-10), codesize >> 10,
+		datasize >> 10, initsize >> 10,
 		(unsigned long) (totalhigh_pages << (PAGE_SHIFT-10)));
 
 	if (PAGE_SIZE >= 16384 && num_physpages <= 128) {
diff -purN --exclude=.git linux-2.6.31.12/arch/avr32/mm/init.c linux-2.6.31.12-petalinux/arch/avr32/mm/init.c
--- linux-2.6.31.12/arch/avr32/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/avr32/mm/init.c	2010-08-08 17:40:15.849523897 +0200
@@ -141,7 +141,7 @@ void __init mem_init(void)
 
 	printk ("Memory: %luk/%luk available (%dk kernel code, "
 		"%dk reserved, %dk data, %dk init)\n",
-		(unsigned long)nr_free_pages() << (PAGE_SHIFT - 10),
+		nr_free_pages() << (PAGE_SHIFT - 10),
 		totalram_pages << (PAGE_SHIFT - 10),
 		codesize >> 10,
 		reservedpages << (PAGE_SHIFT - 10),
diff -purN --exclude=.git linux-2.6.31.12/arch/cris/mm/init.c linux-2.6.31.12-petalinux/arch/cris/mm/init.c
--- linux-2.6.31.12/arch/cris/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/cris/mm/init.c	2010-08-08 17:40:15.849523897 +0200
@@ -54,7 +54,7 @@ mem_init(void)
         printk(KERN_INFO
                "Memory: %luk/%luk available (%dk kernel code, %dk reserved, %dk data, "
 	       "%dk init)\n" ,
-	       (unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+	       nr_free_pages() << (PAGE_SHIFT-10),
 	       max_mapnr << (PAGE_SHIFT-10),
 	       codesize >> 10,
 	       reservedpages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/arch/h8300/kernel/ptrace.c linux-2.6.31.12-petalinux/arch/h8300/kernel/ptrace.c
--- linux-2.6.31.12/arch/h8300/kernel/ptrace.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/h8300/kernel/ptrace.c	2010-08-08 17:40:15.849523897 +0200
@@ -42,14 +42,6 @@ extern void h8300_enable_trace(struct ta
  * in exit.c or in signal.c.
  */
 
-inline
-static int read_long(struct task_struct * tsk, unsigned long addr,
-	unsigned long * result)
-{
-	*result = *(unsigned long *)addr;
-	return 0;
-}
-
 void ptrace_disable(struct task_struct *child)
 {
 	h8300_disable_trace(child);
@@ -60,17 +52,6 @@ long arch_ptrace(struct task_struct *chi
 	int ret;
 
 	switch (request) {
-		case PTRACE_PEEKTEXT: /* read word at location addr. */ 
-		case PTRACE_PEEKDATA: {
-			unsigned long tmp;
-
-			ret = read_long(child, addr, &tmp);
-			if (ret < 0)
-				break ;
-			ret = put_user(tmp, (unsigned long *) data);
-			break ;
-		}
-
 	/* read the word at location addr in the USER area. */
 		case PTRACE_PEEKUSR: {
 			unsigned long tmp = 0;
@@ -109,11 +90,6 @@ long arch_ptrace(struct task_struct *chi
 		}
 
       /* when I and D space are separate, this will have to be fixed. */
-		case PTRACE_POKETEXT: /* write the word at location addr. */
-		case PTRACE_POKEDATA:
-			ret = generic_ptrace_pokedata(child, addr, data);
-			break;
-
 		case PTRACE_POKEUSR: /* write the word at location addr in the USER area */
 			if ((addr & 3) || addr < 0 || addr >= sizeof(struct user)) {
 				ret = -EIO;
@@ -175,10 +151,6 @@ long arch_ptrace(struct task_struct *chi
 			break;
 		}
 
-		case PTRACE_DETACH:	/* detach a process that was attached. */
-			ret = ptrace_detach(child, data);
-			break;
-
 		case PTRACE_GETREGS: { /* Get all gp regs from the child. */
 		  	int i;
 			unsigned long tmp;
@@ -210,7 +182,7 @@ long arch_ptrace(struct task_struct *chi
 		}
 
 		default:
-			ret = -EIO;
+			ret = ptrace_request(child, request, addr, data);
 			break;
 	}
 	return ret;
diff -purN --exclude=.git linux-2.6.31.12/arch/ia64/mm/init.c linux-2.6.31.12-petalinux/arch/ia64/mm/init.c
--- linux-2.6.31.12/arch/ia64/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/ia64/mm/init.c	2010-08-08 17:40:15.849523897 +0200
@@ -655,7 +655,7 @@ mem_init (void)
 	initsize =  (unsigned long) __init_end - (unsigned long) __init_begin;
 
 	printk(KERN_INFO "Memory: %luk/%luk available (%luk code, %luk reserved, "
-	       "%luk data, %luk init)\n", (unsigned long) nr_free_pages() << (PAGE_SHIFT - 10),
+	       "%luk data, %luk init)\n", nr_free_pages() << (PAGE_SHIFT - 10),
 	       num_physpages << (PAGE_SHIFT - 10), codesize >> 10,
 	       reserved_pages << (PAGE_SHIFT - 10), datasize >> 10, initsize >> 10);
 
diff -purN --exclude=.git linux-2.6.31.12/arch/m32r/mm/init.c linux-2.6.31.12-petalinux/arch/m32r/mm/init.c
--- linux-2.6.31.12/arch/m32r/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/m32r/mm/init.c	2010-08-08 17:40:15.849523897 +0200
@@ -171,7 +171,7 @@ void __init mem_init(void)
 
 	printk(KERN_INFO "Memory: %luk/%luk available (%dk kernel code, "
 		"%dk reserved, %dk data, %dk init)\n",
-		(unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+		nr_free_pages() << (PAGE_SHIFT-10),
 		num_physpages << (PAGE_SHIFT-10),
 		codesize >> 10,
 		reservedpages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/arch/m68k/mm/init.c linux-2.6.31.12-petalinux/arch/m68k/mm/init.c
--- linux-2.6.31.12/arch/m68k/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/m68k/mm/init.c	2010-08-08 17:40:15.849523897 +0200
@@ -126,7 +126,7 @@ void __init mem_init(void)
 #endif
 
 	printk("Memory: %luk/%luk available (%dk kernel code, %dk data, %dk init)\n",
-	       (unsigned long)nr_free_pages() << (PAGE_SHIFT-10),
+	       nr_free_pages() << (PAGE_SHIFT-10),
 	       totalram_pages << (PAGE_SHIFT-10),
 	       codepages << (PAGE_SHIFT-10),
 	       datapages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/arch/m68knommu/kernel/ptrace.c linux-2.6.31.12-petalinux/arch/m68knommu/kernel/ptrace.c
--- linux-2.6.31.12/arch/m68knommu/kernel/ptrace.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/m68knommu/kernel/ptrace.c	2010-08-08 17:40:15.849523897 +0200
@@ -104,12 +104,6 @@ long arch_ptrace(struct task_struct *chi
 	int ret;
 
 	switch (request) {
-		/* when I and D space are separate, these will need to be fixed. */
-		case PTRACE_PEEKTEXT: /* read word at location addr. */ 
-		case PTRACE_PEEKDATA:
-			ret = generic_ptrace_peekdata(child, addr, data);
-			break;
-
 		/* read the word at location addr in the USER area. */
 		case PTRACE_PEEKUSR: {
 			unsigned long tmp;
@@ -148,12 +142,6 @@ long arch_ptrace(struct task_struct *chi
 			break;
 		}
 
-		/* when I and D space are separate, this will have to be fixed. */
-		case PTRACE_POKETEXT: /* write the word at location addr. */
-		case PTRACE_POKEDATA:
-			ret = generic_ptrace_pokedata(child, addr, data);
-			break;
-
 		case PTRACE_POKEUSR: /* write the word at location addr in the USER area */
 			ret = -EIO;
 			if ((addr & 3) || addr < 0 ||
@@ -246,10 +234,6 @@ long arch_ptrace(struct task_struct *chi
 			break;
 		}
 
-		case PTRACE_DETACH:	/* detach a process that was attached. */
-			ret = ptrace_detach(child, data);
-			break;
-
 		case PTRACE_GETREGS: { /* Get all gp regs from the child. */
 		  	int i;
 			unsigned long tmp;
@@ -308,7 +292,7 @@ long arch_ptrace(struct task_struct *chi
 #endif
 
 		default:
-			ret = -EIO;
+			ret = ptrace_request(child, request, addr, data);
 			break;
 	}
 	return ret;
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/boot/dts/system.dts linux-2.6.31.12-petalinux/arch/microblaze/boot/dts/system.dts
--- linux-2.6.31.12/arch/microblaze/boot/dts/system.dts	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/boot/dts/system.dts	2010-08-08 17:22:50.597038242 +0200
@@ -0,0 +1,364 @@
+/*
+ * Device Tree Generator version: 1.1
+ *
+ * (C) Copyright 2007-2008 Xilinx, Inc.
+ * (C) Copyright 2007-2009 Michal Simek
+ *
+ * Michal SIMEK <monstr@monstr.eu>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston,
+ * MA 02111-1307 USA
+ *
+ * CAUTION: This file is automatically generated by libgen.
+ * Version: Xilinx EDK 10.1.03 EDK_K_SP3.6
+ *
+ * XPS project directory: Xilinx-ML505-ll_temac-sgdma-MMU-FDT-edk101
+ */
+
+/dts-v1/;
+/ {
+	#address-cells = <1>;
+	#size-cells = <1>;
+	compatible = "xlnx,microblaze";
+	hard-reset-gpios = <&LEDs_8Bit 2 1>;
+	model = "testing";
+	DDR2_SDRAM: memory@90000000 {
+		device_type = "memory";
+		reg = < 0x90000000 0x10000000 >;
+	} ;
+	aliases {
+		ethernet0 = &Hard_Ethernet_MAC;
+		serial0 = &RS232_Uart_1;
+	} ;
+	chosen {
+		bootargs = "console=ttyUL0,115200 highres=on";
+		linux,stdout-path = "/plb@0/serial@84000000";
+	} ;
+	cpus {
+		#address-cells = <1>;
+		#cpus = <0x1>;
+		#size-cells = <0>;
+		microblaze_0: cpu@0 {
+			clock-frequency = <125000000>;
+			compatible = "xlnx,microblaze-7.10.d";
+			d-cache-baseaddr = <0x90000000>;
+			d-cache-highaddr = <0x9fffffff>;
+			d-cache-line-size = <0x10>;
+			d-cache-size = <0x2000>;
+			device_type = "cpu";
+			i-cache-baseaddr = <0x90000000>;
+			i-cache-highaddr = <0x9fffffff>;
+			i-cache-line-size = <0x10>;
+			i-cache-size = <0x2000>;
+			model = "microblaze,7.10.d";
+			reg = <0>;
+			timebase-frequency = <125000000>;
+			xlnx,addr-tag-bits = <0xf>;
+			xlnx,allow-dcache-wr = <0x1>;
+			xlnx,allow-icache-wr = <0x1>;
+			xlnx,area-optimized = <0x0>;
+			xlnx,cache-byte-size = <0x2000>;
+			xlnx,d-lmb = <0x1>;
+			xlnx,d-opb = <0x0>;
+			xlnx,d-plb = <0x1>;
+			xlnx,data-size = <0x20>;
+			xlnx,dcache-addr-tag = <0xf>;
+			xlnx,dcache-always-used = <0x1>;
+			xlnx,dcache-byte-size = <0x2000>;
+			xlnx,dcache-line-len = <0x4>;
+			xlnx,dcache-use-fsl = <0x1>;
+			xlnx,debug-enabled = <0x1>;
+			xlnx,div-zero-exception = <0x1>;
+			xlnx,dopb-bus-exception = <0x0>;
+			xlnx,dynamic-bus-sizing = <0x1>;
+			xlnx,edge-is-positive = <0x1>;
+			xlnx,family = "virtex5";
+			xlnx,fpu-exception = <0x1>;
+			xlnx,fsl-data-size = <0x20>;
+			xlnx,fsl-exception = <0x0>;
+			xlnx,fsl-links = <0x0>;
+			xlnx,i-lmb = <0x1>;
+			xlnx,i-opb = <0x0>;
+			xlnx,i-plb = <0x1>;
+			xlnx,icache-always-used = <0x1>;
+			xlnx,icache-line-len = <0x4>;
+			xlnx,icache-use-fsl = <0x1>;
+			xlnx,ill-opcode-exception = <0x1>;
+			xlnx,instance = "microblaze_0";
+			xlnx,interconnect = <0x1>;
+			xlnx,interrupt-is-edge = <0x0>;
+			xlnx,iopb-bus-exception = <0x0>;
+			xlnx,mmu-dtlb-size = <0x4>;
+			xlnx,mmu-itlb-size = <0x2>;
+			xlnx,mmu-tlb-access = <0x3>;
+			xlnx,mmu-zones = <0x10>;
+			xlnx,number-of-pc-brk = <0x1>;
+			xlnx,number-of-rd-addr-brk = <0x0>;
+			xlnx,number-of-wr-addr-brk = <0x0>;
+			xlnx,opcode-0x0-illegal = <0x1>;
+			xlnx,pvr = <0x2>;
+			xlnx,pvr-user1 = <0x0>;
+			xlnx,pvr-user2 = <0x0>;
+			xlnx,reset-msr = <0x0>;
+			xlnx,sco = <0x0>;
+			xlnx,unaligned-exceptions = <0x1>;
+			xlnx,use-barrel = <0x1>;
+			xlnx,use-dcache = <0x1>;
+			xlnx,use-div = <0x1>;
+			xlnx,use-ext-brk = <0x1>;
+			xlnx,use-ext-nm-brk = <0x1>;
+			xlnx,use-extended-fsl-instr = <0x0>;
+			xlnx,use-fpu = <0x2>;
+			xlnx,use-hw-mul = <0x2>;
+			xlnx,use-icache = <0x1>;
+			xlnx,use-interrupt = <0x1>;
+			xlnx,use-mmu = <0x3>;
+			xlnx,use-msr-instr = <0x1>;
+			xlnx,use-pcmp-instr = <0x1>;
+		} ;
+	} ;
+	mb_plb: plb@0 {
+		#address-cells = <1>;
+		#size-cells = <1>;
+		compatible = "xlnx,plb-v46-1.03.a", "xlnx,plb-v46-1.00.a", "simple-bus";
+		ranges ;
+		FLASH: flash@a0000000 {
+			bank-width = <2>;
+			compatible = "xlnx,xps-mch-emc-2.00.a", "cfi-flash";
+			reg = < 0xa0000000 0x2000000 >;
+			xlnx,family = "virtex5";
+			xlnx,include-datawidth-matching-0 = <0x1>;
+			xlnx,include-datawidth-matching-1 = <0x0>;
+			xlnx,include-datawidth-matching-2 = <0x0>;
+			xlnx,include-datawidth-matching-3 = <0x0>;
+			xlnx,include-negedge-ioregs = <0x0>;
+			xlnx,include-plb-ipif = <0x1>;
+			xlnx,include-wrbuf = <0x1>;
+			xlnx,max-mem-width = <0x10>;
+			xlnx,mch-native-dwidth = <0x20>;
+			xlnx,mch-plb-clk-period-ps = <0x1f40>;
+			xlnx,mch-splb-awidth = <0x20>;
+			xlnx,mch0-accessbuf-depth = <0x10>;
+			xlnx,mch0-protocol = <0x0>;
+			xlnx,mch0-rddatabuf-depth = <0x10>;
+			xlnx,mch1-accessbuf-depth = <0x10>;
+			xlnx,mch1-protocol = <0x0>;
+			xlnx,mch1-rddatabuf-depth = <0x10>;
+			xlnx,mch2-accessbuf-depth = <0x10>;
+			xlnx,mch2-protocol = <0x0>;
+			xlnx,mch2-rddatabuf-depth = <0x10>;
+			xlnx,mch3-accessbuf-depth = <0x10>;
+			xlnx,mch3-protocol = <0x0>;
+			xlnx,mch3-rddatabuf-depth = <0x10>;
+			xlnx,mem0-width = <0x10>;
+			xlnx,mem1-width = <0x20>;
+			xlnx,mem2-width = <0x20>;
+			xlnx,mem3-width = <0x20>;
+			xlnx,num-banks-mem = <0x1>;
+			xlnx,num-channels = <0x0>;
+			xlnx,priority-mode = <0x0>;
+			xlnx,synch-mem-0 = <0x0>;
+			xlnx,synch-mem-1 = <0x0>;
+			xlnx,synch-mem-2 = <0x0>;
+			xlnx,synch-mem-3 = <0x0>;
+			xlnx,synch-pipedelay-0 = <0x2>;
+			xlnx,synch-pipedelay-1 = <0x2>;
+			xlnx,synch-pipedelay-2 = <0x2>;
+			xlnx,synch-pipedelay-3 = <0x2>;
+			xlnx,tavdv-ps-mem-0 = <0x1adb0>;
+			xlnx,tavdv-ps-mem-1 = <0x3a98>;
+			xlnx,tavdv-ps-mem-2 = <0x3a98>;
+			xlnx,tavdv-ps-mem-3 = <0x3a98>;
+			xlnx,tcedv-ps-mem-0 = <0x1adb0>;
+			xlnx,tcedv-ps-mem-1 = <0x3a98>;
+			xlnx,tcedv-ps-mem-2 = <0x3a98>;
+			xlnx,tcedv-ps-mem-3 = <0x3a98>;
+			xlnx,thzce-ps-mem-0 = <0x88b8>;
+			xlnx,thzce-ps-mem-1 = <0x1b58>;
+			xlnx,thzce-ps-mem-2 = <0x1b58>;
+			xlnx,thzce-ps-mem-3 = <0x1b58>;
+			xlnx,thzoe-ps-mem-0 = <0x1b58>;
+			xlnx,thzoe-ps-mem-1 = <0x1b58>;
+			xlnx,thzoe-ps-mem-2 = <0x1b58>;
+			xlnx,thzoe-ps-mem-3 = <0x1b58>;
+			xlnx,tlzwe-ps-mem-0 = <0x88b8>;
+			xlnx,tlzwe-ps-mem-1 = <0x0>;
+			xlnx,tlzwe-ps-mem-2 = <0x0>;
+			xlnx,tlzwe-ps-mem-3 = <0x0>;
+			xlnx,twc-ps-mem-0 = <0x2af8>;
+			xlnx,twc-ps-mem-1 = <0x3a98>;
+			xlnx,twc-ps-mem-2 = <0x3a98>;
+			xlnx,twc-ps-mem-3 = <0x3a98>;
+			xlnx,twp-ps-mem-0 = <0x11170>;
+			xlnx,twp-ps-mem-1 = <0x2ee0>;
+			xlnx,twp-ps-mem-2 = <0x2ee0>;
+			xlnx,twp-ps-mem-3 = <0x2ee0>;
+			xlnx,xcl0-linesize = <0x4>;
+			xlnx,xcl0-writexfer = <0x1>;
+			xlnx,xcl1-linesize = <0x4>;
+			xlnx,xcl1-writexfer = <0x1>;
+			xlnx,xcl2-linesize = <0x4>;
+			xlnx,xcl2-writexfer = <0x1>;
+			xlnx,xcl3-linesize = <0x4>;
+			xlnx,xcl3-writexfer = <0x1>;
+		} ;
+		Hard_Ethernet_MAC: xps-ll-temac@81c00000 {
+			#address-cells = <1>;
+			#size-cells = <1>;
+			compatible = "xlnx,compound";
+			ethernet@81c00000 {
+				compatible = "xlnx,xps-ll-temac-1.01.b", "xlnx,xps-ll-temac-1.00.a";
+				device_type = "network";
+				interrupt-parent = <&xps_intc_0>;
+				interrupts = < 5 2 >;
+				llink-connected = <&PIM3>;
+				local-mac-address = [ 00 0a 35 00 00 00 ];
+				reg = < 0x81c00000 0x40 >;
+				xlnx,bus2core-clk-ratio = <0x1>;
+				xlnx,phy-type = <0x1>;
+				xlnx,phyaddr = <0x1>;
+				xlnx,rxcsum = <0x0>;
+				xlnx,rxfifo = <0x1000>;
+				xlnx,temac-type = <0x0>;
+				xlnx,txcsum = <0x0>;
+				xlnx,txfifo = <0x1000>;
+			} ;
+		} ;
+		IIC_EEPROM: i2c@81600000 {
+			compatible = "xlnx,xps-iic-2.00.a";
+			interrupt-parent = <&xps_intc_0>;
+			interrupts = < 6 2 >;
+			reg = < 0x81600000 0x10000 >;
+			xlnx,clk-freq = <0x7735940>;
+			xlnx,family = "virtex5";
+			xlnx,gpo-width = <0x1>;
+			xlnx,iic-freq = <0x186a0>;
+			xlnx,scl-inertial-delay = <0x0>;
+			xlnx,sda-inertial-delay = <0x0>;
+			xlnx,ten-bit-adr = <0x0>;
+		} ;
+		LEDs_8Bit: gpio@81400000 {
+			compatible = "xlnx,xps-gpio-1.00.a";
+			interrupt-parent = <&xps_intc_0>;
+			interrupts = < 7 2 >;
+			reg = < 0x81400000 0x10000 >;
+			xlnx,all-inputs = <0x0>;
+			xlnx,all-inputs-2 = <0x0>;
+			xlnx,dout-default = <0x0>;
+			xlnx,dout-default-2 = <0x0>;
+			xlnx,family = "virtex5";
+			xlnx,gpio-width = <0x8>;
+			xlnx,interrupt-present = <0x1>;
+			xlnx,is-bidir = <0x1>;
+			xlnx,is-bidir-2 = <0x1>;
+			xlnx,is-dual = <0x0>;
+			xlnx,tri-default = <0xffffffff>;
+			xlnx,tri-default-2 = <0xffffffff>;
+			#gpio-cells = <2>;
+			gpio-controller;
+		} ;
+
+		gpio-leds {
+			compatible = "gpio-leds";
+
+			heartbeat {
+				label = "Heartbeat";
+				gpios = <&LEDs_8Bit 4 1>;
+				linux,default-trigger = "heartbeat";
+			};
+
+			yellow {
+				label = "Yellow";
+				gpios = <&LEDs_8Bit 5 1>;
+			};
+
+			red {
+				label = "Red";
+				gpios = <&LEDs_8Bit 6 1>;
+			};
+
+			green {
+				label = "Green";
+				gpios = <&LEDs_8Bit 7 1>;
+			};
+		} ;
+		RS232_Uart_1: serial@84000000 {
+			clock-frequency = <125000000>;
+			compatible = "xlnx,xps-uartlite-1.00.a";
+			current-speed = <115200>;
+			device_type = "serial";
+			interrupt-parent = <&xps_intc_0>;
+			interrupts = < 8 0 >;
+			port-number = <0>;
+			reg = < 0x84000000 0x10000 >;
+			xlnx,baudrate = <0x1c200>;
+			xlnx,data-bits = <0x8>;
+			xlnx,family = "virtex5";
+			xlnx,odd-parity = <0x0>;
+			xlnx,use-parity = <0x0>;
+		} ;
+		SysACE_CompactFlash: sysace@83600000 {
+			compatible = "xlnx,xps-sysace-1.00.a";
+			interrupt-parent = <&xps_intc_0>;
+			interrupts = < 4 2 >;
+			reg = < 0x83600000 0x10000 >;
+			xlnx,family = "virtex5";
+			xlnx,mem-width = <0x10>;
+		} ;
+		debug_module: debug@84400000 {
+			compatible = "xlnx,mdm-1.00.d";
+			reg = < 0x84400000 0x10000 >;
+			xlnx,family = "virtex5";
+			xlnx,interconnect = <0x1>;
+			xlnx,jtag-chain = <0x2>;
+			xlnx,mb-dbg-ports = <0x1>;
+			xlnx,uart-width = <0x8>;
+			xlnx,use-uart = <0x1>;
+			xlnx,write-fsl-ports = <0x0>;
+		} ;
+		mpmc@90000000 {
+			#address-cells = <1>;
+			#size-cells = <1>;
+			compatible = "xlnx,mpmc-4.02.a";
+			PIM3: sdma@84600180 {
+				compatible = "xlnx,ll-dma-1.00.a";
+				interrupt-parent = <&xps_intc_0>;
+				interrupts = < 2 2 1 2 >;
+				reg = < 0x84600180 0x80 >;
+			} ;
+		} ;
+		xps_intc_0: interrupt-controller@81800000 {
+			#interrupt-cells = <0x2>;
+			compatible = "xlnx,xps-intc-1.00.a";
+			interrupt-controller ;
+			reg = < 0x81800000 0x10000 >;
+			xlnx,kind-of-intr = <0x100>;
+			xlnx,num-intr-inputs = <0x9>;
+		} ;
+		xps_timer_1: timer@83c00000 {
+			compatible = "xlnx,xps-timer-1.00.a";
+			interrupt-parent = <&xps_intc_0>;
+			interrupts = < 3 2 >;
+			reg = < 0x83c00000 0x10000 >;
+			xlnx,count-width = <0x20>;
+			xlnx,family = "virtex5";
+			xlnx,gen0-assert = <0x1>;
+			xlnx,gen1-assert = <0x1>;
+			xlnx,one-timer-only = <0x0>;
+			xlnx,trig0-assert = <0x1>;
+			xlnx,trig1-assert = <0x1>;
+		} ;
+	} ;
+}  ;
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/boot/linked_dtb.S linux-2.6.31.12-petalinux/arch/microblaze/boot/linked_dtb.S
--- linux-2.6.31.12/arch/microblaze/boot/linked_dtb.S	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/boot/linked_dtb.S	2010-08-08 17:22:50.535773472 +0200
@@ -0,0 +1,3 @@
+.section __fdt_blob,"a"
+.incbin "arch/microblaze/boot/system.dtb"
+
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/boot/Makefile linux-2.6.31.12-petalinux/arch/microblaze/boot/Makefile
--- linux-2.6.31.12/arch/microblaze/boot/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/boot/Makefile	2010-08-08 17:40:15.849523897 +0200
@@ -2,18 +2,66 @@
 # arch/microblaze/boot/Makefile
 #
 
-targets := linux.bin linux.bin.gz
+MKIMAGE := $(srctree)/scripts/mkuboot.sh
 
-OBJCOPYFLAGS_linux.bin  := -O binary
+obj-y += linked_dtb.o
+
+targets := linux.bin linux.bin.gz simpleImage.%
+
+OBJCOPYFLAGS := -O binary
+
+# Where the DTS files live
+dtstree         := $(srctree)/$(src)/dts
+
+# Ensure system.dtb exists
+$(obj)/linked_dtb.o: $(obj)/system.dtb
+
+# Generate system.dtb from $(DTB).dtb
+ifneq ($(DTB),system)
+$(obj)/system.dtb: $(obj)/$(DTB).dtb
+	$(call if_changed,cp)
+endif
 
 $(obj)/linux.bin: vmlinux FORCE
 	[ -n $(CONFIG_INITRAMFS_SOURCE) ] && [ ! -e $(CONFIG_INITRAMFS_SOURCE) ] && \
 	touch $(CONFIG_INITRAMFS_SOURCE) || echo "No CPIO image"
 	$(call if_changed,objcopy)
+	$(call if_changed,uimage)
 	@echo 'Kernel: $@ is ready' ' (#'`cat .version`')'
 
 $(obj)/linux.bin.gz: $(obj)/linux.bin FORCE
 	$(call if_changed,gzip)
 	@echo 'Kernel: $@ is ready' ' (#'`cat .version`')'
 
-clean-kernel += linux.bin linux.bin.gz
+quiet_cmd_cp = CP      $< $@$2
+	cmd_cp = cat $< >$@$2 || (rm -f $@ && echo false)
+
+quiet_cmd_strip = STRIP   $@
+      cmd_strip = $(STRIP) -K _start -K _end -K __log_buf -K _fdt_start vmlinux -o $@
+
+quiet_cmd_uimage = UIMAGE  $@.ub
+      cmd_uimage = $(CONFIG_SHELL) $(MKIMAGE) -A microblaze -O linux -T kernel \
+                   -C none -n 'Linux-$(KERNELRELEASE)' \
+                   -a $(CONFIG_KERNEL_BASE_ADDR) -e $(CONFIG_KERNEL_BASE_ADDR) \
+                   -d $@ $@.ub
+
+$(obj)/simpleImage.%: vmlinux FORCE
+	$(call if_changed,cp,.unstrip)
+	$(call if_changed,objcopy)
+	$(call if_changed,uimage)
+	$(call if_changed,strip)
+	@echo 'Kernel: $@ is ready' ' (#'`cat .version`')'
+
+# Rule to build device tree blobs
+DTC = $(objtree)/scripts/dtc/dtc
+
+# Rule to build device tree blobs
+quiet_cmd_dtc = DTC     $@
+	cmd_dtc = $(DTC) -O dtb -o $(obj)/$*.dtb -b 0 -p 1024 $(dtstree)/$*.dts
+
+$(obj)/%.dtb: $(dtstree)/%.dts FORCE
+	$(call if_changed,dtc)
+
+clean-kernel += linux.bin linux.bin.gz simpleImage.*
+
+clean-files += *.dtb simpleImage.*.unstrip linux.bin.ub
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/configs/mmu_defconfig linux-2.6.31.12-petalinux/arch/microblaze/configs/mmu_defconfig
--- linux-2.6.31.12/arch/microblaze/configs/mmu_defconfig	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/configs/mmu_defconfig	2010-08-08 17:26:16.585335359 +0200
@@ -34,10 +34,12 @@ CONFIG_LOCALVERSION=""
 CONFIG_LOCALVERSION_AUTO=y
 CONFIG_SYSVIPC=y
 CONFIG_SYSVIPC_SYSCTL=y
-# CONFIG_POSIX_MQUEUE is not set
-# CONFIG_BSD_PROCESS_ACCT is not set
+CONFIG_POSIX_MQUEUE=y
+CONFIG_POSIX_MQUEUE_SYSCTL=y
+CONFIG_BSD_PROCESS_ACCT=y
+CONFIG_BSD_PROCESS_ACCT_V3=y
 # CONFIG_TASKSTATS is not set
-# CONFIG_AUDIT is not set
+CONFIG_AUDIT=y
 
 #
 # RCU Subsystem
@@ -80,12 +82,12 @@ CONFIG_PRINTK=y
 CONFIG_BUG=y
 CONFIG_ELF_CORE=y
 # CONFIG_BASE_FULL is not set
-# CONFIG_FUTEX is not set
-# CONFIG_EPOLL is not set
-# CONFIG_SIGNALFD is not set
+CONFIG_FUTEX=y
+CONFIG_EPOLL=y
+CONFIG_SIGNALFD=y
 CONFIG_TIMERFD=y
 CONFIG_EVENTFD=y
-# CONFIG_SHMEM is not set
+CONFIG_SHMEM=y
 CONFIG_AIO=y
 
 #
@@ -106,6 +108,7 @@ CONFIG_SLAB=y
 # CONFIG_SLOW_WORK is not set
 # CONFIG_HAVE_GENERIC_DMA_COHERENT is not set
 CONFIG_SLABINFO=y
+CONFIG_RT_MUTEXES=y
 CONFIG_BASE_SMALL=1
 CONFIG_MODULES=y
 # CONFIG_MODULE_FORCE_LOAD is not set
@@ -358,6 +361,10 @@ CONFIG_NET_ETHERNET=y
 # CONFIG_IBM_NEW_EMAC_MAL_COMMON_ERR is not set
 # CONFIG_KS8842 is not set
 CONFIG_NETDEV_1000=y
+CONFIG_XILINX_LLTEMAC=y
+# CONFIG_XILINX_LLTEMAC_MARVELL_88E1111_RGMII is not set
+CONFIG_XILINX_LLTEMAC_MARVELL_88E1111_GMII=y
+# CONFIG_XILINX_LLTEMAC_MARVELL_88E1111_MII is not set
 CONFIG_NETDEV_10000=y
 
 #
@@ -466,6 +473,11 @@ CONFIG_ARCH_WANT_OPTIONAL_GPIOLIB=y
 # CONFIG_ACCESSIBILITY is not set
 # CONFIG_RTC_CLASS is not set
 # CONFIG_AUXDISPLAY is not set
+CONFIG_XILINX_EDK=y
+# CONFIG_XILINX_LLDMA_USE_DCR is not set
+CONFIG_XILINX_DRIVERS=y
+CONFIG_NEED_XILINX_LLDMA=y
+CONFIG_NEED_XILINX_IPIF=y
 # CONFIG_UIO is not set
 
 #
@@ -659,6 +671,8 @@ CONFIG_SCHED_DEBUG=y
 # CONFIG_DEBUG_OBJECTS is not set
 CONFIG_DEBUG_SLAB=y
 # CONFIG_DEBUG_SLAB_LEAK is not set
+# CONFIG_DEBUG_RT_MUTEXES is not set
+# CONFIG_RT_MUTEX_TESTER is not set
 CONFIG_DEBUG_SPINLOCK=y
 # CONFIG_DEBUG_MUTEXES is not set
 # CONFIG_DEBUG_SPINLOCK_SLEEP is not set
@@ -792,6 +806,7 @@ CONFIG_GENERIC_FIND_LAST_BIT=y
 CONFIG_CRC32=y
 # CONFIG_CRC7 is not set
 # CONFIG_LIBCRC32C is not set
+CONFIG_AUDIT_GENERIC=y
 CONFIG_ZLIB_INFLATE=y
 CONFIG_DECOMPRESS_GZIP=y
 CONFIG_HAS_IOMEM=y
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/asm-compat.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/asm-compat.h
--- linux-2.6.31.12/arch/microblaze/include/asm/asm-compat.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/asm-compat.h	2010-08-08 17:22:50.540980768 +0200
@@ -0,0 +1,17 @@
+#ifndef _ASM_MICROBLAZE_ASM_COMPAT_H
+#define _ASM_MICROBLAZE_ASM_COMPAT_H
+
+#include <asm/types.h>
+
+#ifdef __ASSEMBLY__
+#  define stringify_in_c(...)	__VA_ARGS__
+#  define ASM_CONST(x)		x
+#else
+/* This version of stringify will deal with commas... */
+#  define __stringify_in_c(...)	#__VA_ARGS__
+#  define stringify_in_c(...)	__stringify_in_c(__VA_ARGS__) " "
+#  define __ASM_CONST(x)	x##UL
+#  define ASM_CONST(x)		__ASM_CONST(x)
+#endif
+
+#endif /* _ASM_MICROBLAZE_ASM_COMPAT_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/cacheflush.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/cacheflush.h
--- linux-2.6.31.12/arch/microblaze/include/asm/cacheflush.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/cacheflush.h	2010-08-08 17:40:15.849523897 +0200
@@ -18,6 +18,8 @@
 /* Somebody depends on this; sigh... */
 #include <linux/mm.h>
 
+/* Look at Documentation/cachetlb.txt */
+
 /*
  * Cache handling functions.
  * Microblaze has a write-through data cache, meaning that the data cache
@@ -27,77 +29,89 @@
  * instruction cache to make sure we don't fetch old, bad code.
  */
 
-/* FIXME for LL-temac driver */
-#define invalidate_dcache_range(start, end) \
-			__invalidate_dcache_range(start, end)
+/* struct cache, d=dcache, i=icache, fl = flush, iv = invalidate,
+ * suffix r = range */
+struct scache {
+	/* icache */
+	void (*ie)(void); /* enable */
+	void (*id)(void); /* disable */
+	void (*ifl)(void); /* flush */
+	void (*iflr)(unsigned long a, unsigned long b);
+	void (*iin)(void); /* invalidate */
+	void (*iinr)(unsigned long a, unsigned long b);
+	/* dcache */
+	void (*de)(void); /* enable */
+	void (*dd)(void); /* disable */
+	void (*dfl)(void); /* flush */
+	void (*dflr)(unsigned long a, unsigned long b);
+	void (*din)(void); /* invalidate */
+	void (*dinr)(unsigned long a, unsigned long b);
+};
+
+/* microblaze cache */
+extern struct scache *mbc;
+
+void microblaze_cache_init(void);
+
+#define enable_icache()					mbc->ie();
+#define disable_icache()				mbc->id();
+#define flush_icache()					mbc->ifl();
+#define flush_icache_range(start, end)			mbc->iflr(start, end);
+#define invalidate_icache()				mbc->iin();
+#define invalidate_icache_range(start, end)		mbc->iinr(start, end);
 
-#define flush_cache_all()			__invalidate_cache_all()
-#define flush_cache_mm(mm)			do { } while (0)
-#define flush_cache_range(vma, start, end)	__invalidate_cache_all()
-#define flush_cache_page(vma, vmaddr, pfn)	do { } while (0)
 
-#define flush_dcache_range(start, end)	__invalidate_dcache_range(start, end)
+#define flush_icache_user_range(vma, pg, adr, len)	flush_icache();
+#define flush_icache_page(vma, pg)			do { } while (0)
+
+#define enable_dcache()					mbc->de();
+#define disable_dcache()				mbc->dd();
+/* FIXME for LL-temac driver */
+#define invalidate_dcache()				mbc->din();
+#define invalidate_dcache_range(start, end)		mbc->dinr(start, end);
+#define flush_dcache()					mbc->dfl();
+#define flush_dcache_range(start, end)			mbc->dflr(start, end);
+
+#define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 0
+/* D-cache aliasing problem can't happen - cache is between MMU and ram */
 #define flush_dcache_page(page)			do { } while (0)
 #define flush_dcache_mmap_lock(mapping)		do { } while (0)
 #define flush_dcache_mmap_unlock(mapping)	do { } while (0)
 
-#define flush_icache_range(start, len)	__invalidate_icache_range(start, len)
-#define flush_icache_page(vma, pg)		do { } while (0)
-
-#ifndef CONFIG_MMU
-# define flush_icache_user_range(start, len)	do { } while (0)
-#else
-# define flush_icache_user_range(vma, pg, adr, len) __invalidate_icache_all()
 
-# define flush_page_to_ram(page)		do { } while (0)
-
-# define flush_icache()			__invalidate_icache_all()
-# define flush_cache_sigtramp(vaddr) \
-			__invalidate_icache_range(vaddr, vaddr + 8)
+#define flush_cache_dup_mm(mm)				do { } while (0)
+#define flush_cache_vmap(start, end)			do { } while (0)
+#define flush_cache_vunmap(start, end)			do { } while (0)
+#define flush_cache_mm(mm)			do { } while (0)
 
-# define flush_dcache_mmap_lock(mapping)	do { } while (0)
-# define flush_dcache_mmap_unlock(mapping)	do { } while (0)
+#define flush_cache_page(vma, vmaddr, pfn) \
+	flush_dcache_range(pfn << PAGE_SHIFT, (pfn << PAGE_SHIFT) + PAGE_SIZE);
 
-# define flush_cache_dup_mm(mm)			do { } while (0)
+/* MS: kgdb code use this macro, wrong len with FLASH */
+#if 0
+#define flush_cache_range(vma, start, len)	{	\
+	flush_icache_range((unsigned) (start), (unsigned) (start) + (len)); \
+	flush_dcache_range((unsigned) (start), (unsigned) (start) + (len)); \
+}
 #endif
 
-#define flush_cache_vmap(start, end)		do { } while (0)
-#define flush_cache_vunmap(start, end)		do { } while (0)
+#define flush_cache_range(vma, start, len) do { } while (0)
 
-struct page;
-struct mm_struct;
-struct vm_area_struct;
-
-/* see arch/microblaze/kernel/cache.c */
-extern void __invalidate_icache_all(void);
-extern void __invalidate_icache_range(unsigned long start, unsigned long end);
-extern void __invalidate_icache_page(struct vm_area_struct *vma,
-				struct page *page);
-extern void __invalidate_icache_user_range(struct vm_area_struct *vma,
-				struct page *page,
-				unsigned long adr, int len);
-extern void __invalidate_cache_sigtramp(unsigned long addr);
-
-extern void __invalidate_dcache_all(void);
-extern void __invalidate_dcache_range(unsigned long start, unsigned long end);
-extern void __invalidate_dcache_page(struct vm_area_struct *vma,
-				struct page *page);
-extern void __invalidate_dcache_user_range(struct vm_area_struct *vma,
-				struct page *page,
-				unsigned long adr, int len);
-
-extern inline void __invalidate_cache_all(void)
-{
-	__invalidate_icache_all();
-	__invalidate_dcache_all();
-}
-
-#define copy_to_user_page(vma, page, vaddr, dst, src, len) \
-do { memcpy((dst), (src), (len)); \
-	flush_icache_range((unsigned) (dst), (unsigned) (dst) + (len)); \
+#define copy_to_user_page(vma, page, vaddr, dst, src, len)		\
+do {									\
+	u32 addr = virt_to_phys(dst);					\
+	memcpy((dst), (src), (len));					\
+	if (vma->vm_flags & VM_EXEC) {					\
+		invalidate_icache_range((unsigned) (addr),		\
+					(unsigned) (addr) + PAGE_SIZE);	\
+		flush_dcache_range((unsigned) (addr),			\
+					(unsigned) (addr) + PAGE_SIZE);	\
+	}								\
 } while (0)
 
-#define copy_from_user_page(vma, page, vaddr, dst, src, len) \
-	memcpy((dst), (src), (len))
+#define copy_from_user_page(vma, page, vaddr, dst, src, len)		\
+do {									\
+	memcpy((dst), (src), (len));					\
+} while (0)
 
 #endif /* _ASM_MICROBLAZE_CACHEFLUSH_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/cache.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/cache.h
--- linux-2.6.31.12/arch/microblaze/include/asm/cache.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/cache.h	2010-08-08 17:40:15.849523897 +0200
@@ -15,26 +15,10 @@
 
 #include <asm/registers.h>
 
-#define L1_CACHE_SHIFT	2
+#define L1_CACHE_SHIFT 5
 /* word-granular cache in microblaze */
 #define L1_CACHE_BYTES	(1 << L1_CACHE_SHIFT)
 
 #define SMP_CACHE_BYTES	L1_CACHE_BYTES
 
-void _enable_icache(void);
-void _disable_icache(void);
-void _invalidate_icache(unsigned int addr);
-
-#define __enable_icache()		_enable_icache()
-#define __disable_icache()		_disable_icache()
-#define __invalidate_icache(addr)	_invalidate_icache(addr)
-
-void _enable_dcache(void);
-void _disable_dcache(void);
-void _invalidate_dcache(unsigned int addr);
-
-#define __enable_dcache()		_enable_dcache()
-#define __disable_dcache()		_disable_dcache()
-#define __invalidate_dcache(addr)	_invalidate_dcache(addr)
-
 #endif /* _ASM_MICROBLAZE_CACHE_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/cpuinfo.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/cpuinfo.h
--- linux-2.6.31.12/arch/microblaze/include/asm/cpuinfo.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/cpuinfo.h	2010-08-08 17:22:50.540980768 +0200
@@ -43,7 +43,7 @@ struct cpuinfo {
 	u32 use_icache;
 	u32 icache_tagbits;
 	u32 icache_write;
-	u32 icache_line;
+	u32 icache_line_length;
 	u32 icache_size;
 	unsigned long icache_base;
 	unsigned long icache_high;
@@ -51,8 +51,9 @@ struct cpuinfo {
 	u32 use_dcache;
 	u32 dcache_tagbits;
 	u32 dcache_write;
-	u32 dcache_line;
+	u32 dcache_line_length;
 	u32 dcache_size;
+	u32 dcache_wb;
 	unsigned long dcache_base;
 	unsigned long dcache_high;
 
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/device.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/device.h
--- linux-2.6.31.12/arch/microblaze/include/asm/device.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/device.h	2010-08-08 17:40:15.849523897 +0200
@@ -14,8 +14,24 @@ struct device_node;
 struct dev_archdata {
 	/* Optional pointer to an OF device node */
 	struct device_node	*of_node;
+
+	/* DMA operations on that device */
+	struct dma_map_ops	*dma_ops;
+	void                    *dma_data;
 };
 
+static inline void dev_archdata_set_node(struct dev_archdata *ad,
+					 struct device_node *np)
+{
+	ad->of_node = np;
+}
+
+static inline struct device_node *
+dev_archdata_get_node(const struct dev_archdata *ad)
+{
+	return ad->of_node;
+}
+
 #endif /* _ASM_MICROBLAZE_DEVICE_H */
 
 
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/dma-mapping.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/dma-mapping.h
--- linux-2.6.31.12/arch/microblaze/include/asm/dma-mapping.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/dma-mapping.h	2010-08-08 17:40:15.849523897 +0200
@@ -1 +1,154 @@
-#include <asm-generic/dma-mapping-broken.h>
+/*
+ * Implements the generic device dma API for microblaze and the pci
+ *
+ * Copyright (C) 2009-2010 Michal Simek <monstr@monstr.eu>
+ * Copyright (C) 2009-2010 PetaLogix
+ *
+ * This file is subject to the terms and conditions of the GNU General
+ * Public License. See the file COPYING in the main directory of this
+ * archive for more details.
+ *
+ * This file is base on powerpc and x86 dma-mapping.h versions
+ * Copyright (C) 2004 IBM
+ */
+
+#ifndef _ASM_MICROBLAZE_DMA_MAPPING_H
+#define _ASM_MICROBLAZE_DMA_MAPPING_H
+
+/*
+ * See Documentation/PCI/PCI-DMA-mapping.txt and
+ * Documentation/DMA-API.txt for documentation.
+ */
+
+#include <linux/types.h>
+#include <linux/cache.h>
+#include <linux/mm.h>
+#include <linux/scatterlist.h>
+#include <linux/dma-debug.h>
+#include <linux/dma-attrs.h>
+#include <asm/io.h>
+#include <asm-generic/dma-coherent.h>
+
+#define DMA_ERROR_CODE		(~(dma_addr_t)0x0)
+
+#define __dma_alloc_coherent(dev, gfp, size, handle)	NULL
+#define __dma_free_coherent(size, addr)		((void)0)
+#define __dma_sync(addr, size, rw)		((void)0)
+
+static inline unsigned long device_to_mask(struct device *dev)
+{
+	if (dev->dma_mask && *dev->dma_mask)
+		return *dev->dma_mask;
+	/* Assume devices without mask can take 32 bit addresses */
+	return 0xfffffffful;
+}
+
+extern struct dma_map_ops *dma_ops;
+
+/*
+ * Available generic sets of operations
+ */
+extern struct dma_map_ops dma_direct_ops;
+
+static inline struct dma_map_ops *get_dma_ops(struct device *dev)
+{
+	/* We don't handle the NULL dev case for ISA for now. We could
+	 * do it via an out of line call but it is not needed for now. The
+	 * only ISA DMA device we support is the floppy and we have a hack
+	 * in the floppy driver directly to get a device for us.
+	 */
+	if (unlikely(!dev) || !dev->archdata.dma_ops)
+		return NULL;
+
+	return dev->archdata.dma_ops;
+}
+
+static inline void set_dma_ops(struct device *dev, struct dma_map_ops *ops)
+{
+	dev->archdata.dma_ops = ops;
+}
+
+static inline int dma_supported(struct device *dev, u64 mask)
+{
+	struct dma_map_ops *ops = get_dma_ops(dev);
+
+	if (unlikely(!ops))
+		return 0;
+	if (!ops->dma_supported)
+		return 1;
+	return ops->dma_supported(dev, mask);
+}
+
+#ifdef CONFIG_PCI
+/* We have our own implementation of pci_set_dma_mask() */
+#define HAVE_ARCH_PCI_SET_DMA_MASK
+
+#endif
+
+static inline int dma_set_mask(struct device *dev, u64 dma_mask)
+{
+	struct dma_map_ops *ops = get_dma_ops(dev);
+
+	if (unlikely(ops == NULL))
+		return -EIO;
+/* FIXME this is remove in latest code */
+//	if (ops->set_dma_mask)
+//		return ops->set_dma_mask(dev, dma_mask);
+	if (!dev->dma_mask || !dma_supported(dev, dma_mask))
+		return -EIO;
+	*dev->dma_mask = dma_mask;
+	return 0;
+}
+
+#include <asm-generic/dma-mapping-common.h>
+
+static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
+{
+	struct dma_map_ops *ops = get_dma_ops(dev);
+	if (ops->mapping_error)
+		return ops->mapping_error(dev, dma_addr);
+
+	return (dma_addr == DMA_ERROR_CODE);
+}
+
+#define dma_alloc_noncoherent(d, s, h, f) dma_alloc_coherent(d, s, h, f)
+#define dma_free_noncoherent(d, s, v, h) dma_free_coherent(d, s, v, h)
+#define dma_is_consistent(d, h)	(1)
+
+static inline void *dma_alloc_coherent(struct device *dev, size_t size,
+					dma_addr_t *dma_handle, gfp_t flag)
+{
+	struct dma_map_ops *ops = get_dma_ops(dev);
+	void *memory;
+
+	BUG_ON(!ops);
+
+	memory = ops->alloc_coherent(dev, size, dma_handle, flag);
+
+	debug_dma_alloc_coherent(dev, size, *dma_handle, memory);
+	return memory;
+}
+
+static inline void dma_free_coherent(struct device *dev, size_t size,
+				     void *cpu_addr, dma_addr_t dma_handle)
+{
+	struct dma_map_ops *ops = get_dma_ops(dev);
+
+	BUG_ON(!ops);
+	debug_dma_free_coherent(dev, size, cpu_addr, dma_handle);
+	ops->free_coherent(dev, size, cpu_addr, dma_handle);
+}
+
+static inline int dma_get_cache_alignment(void)
+{
+	return L1_CACHE_BYTES;
+}
+
+static inline void dma_cache_sync(struct device *dev, void *vaddr, size_t size,
+		enum dma_data_direction direction)
+{
+	BUG_ON(direction == DMA_NONE);
+	__dma_sync(vaddr, size, (int)direction);
+}
+
+#endif	/* _ASM_MICROBLAZE_DMA_MAPPING_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/exceptions.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/exceptions.h
--- linux-2.6.31.12/arch/microblaze/include/asm/exceptions.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/exceptions.h	2010-08-08 17:40:15.849523897 +0200
@@ -64,12 +64,6 @@ asmlinkage void full_exception(struct pt
 void die(const char *str, struct pt_regs *fp, long err);
 void _exception(int signr, struct pt_regs *regs, int code, unsigned long addr);
 
-#ifdef CONFIG_MMU
-void __bug(const char *file, int line, void *data);
-int bad_trap(int trap_num, struct pt_regs *regs);
-int debug_trap(struct pt_regs *regs);
-#endif /* CONFIG_MMU */
-
 #if defined(CONFIG_KGDB)
 void (*debugger)(struct pt_regs *regs);
 int (*debugger_bpt)(struct pt_regs *regs);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/ftrace.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/ftrace.h
--- linux-2.6.31.12/arch/microblaze/include/asm/ftrace.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/ftrace.h	2010-08-08 17:40:15.849523897 +0200
@@ -1 +1,26 @@
+#ifndef _ASM_MICROBLAZE_FTRACE
+#define _ASM_MICROBLAZE_FTRACE
 
+#ifdef CONFIG_FUNCTION_TRACER
+
+#define MCOUNT_ADDR		((long)(_mcount))
+#define MCOUNT_INSN_SIZE	8 /* sizeof mcount call */
+
+#ifndef __ASSEMBLY__
+extern void _mcount(void);
+extern void ftrace_call_graph(void);
+#endif
+
+#ifdef CONFIG_DYNAMIC_FTRACE
+/* reloction of mcount call site is the same as the address */
+static inline unsigned long ftrace_call_adjust(unsigned long addr)
+{
+	return addr;
+}
+
+struct dyn_arch_ftrace {
+};
+#endif /* CONFIG_DYNAMIC_FTRACE */
+
+#endif /* CONFIG_FUNCTION_TRACER */
+#endif /* _ASM_MICROBLAZE_FTRACE */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/futex.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/futex.h
--- linux-2.6.31.12/arch/microblaze/include/asm/futex.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/futex.h	2010-08-08 17:40:15.849523897 +0200
@@ -1 +1,126 @@
-#include <asm-generic/futex.h>
+#ifndef _ASM_MICROBLAZE_FUTEX_H
+#define _ASM_MICROBLAZE_FUTEX_H
+
+#ifdef __KERNEL__
+
+#include <linux/futex.h>
+#include <linux/uaccess.h>
+#include <asm/errno.h>
+
+#define __futex_atomic_op(insn, ret, oldval, uaddr, oparg) \
+({									\
+	__asm__ __volatile__ (						\
+			"1:	lwx	%0, %2, r0; "			\
+				insn					\
+			"2:	swx	%1, %2, r0;			\
+				addic	%1, r0, 0;			\
+				bnei	%1, 1b;				\
+			3:						\
+			.section .fixup,\"ax\";				\
+			4:	brid	3b;				\
+				addik	%1, r0, %3;			\
+			.previous;					\
+			.section __ex_table,\"a\";			\
+			.word	1b,4b,2b,4b;				\
+			.previous;"					\
+	: "=&r" (oldval), "=&r" (ret)					\
+	: "b" (uaddr), "i" (-EFAULT), "r" (oparg)			\
+	);								\
+})
+
+static inline int
+futex_atomic_op_inuser(int encoded_op, int __user *uaddr)
+{
+	int op = (encoded_op >> 28) & 7;
+	int cmp = (encoded_op >> 24) & 15;
+	int oparg = (encoded_op << 8) >> 20;
+	int cmparg = (encoded_op << 20) >> 20;
+	int oldval = 0, ret;
+	if (encoded_op & (FUTEX_OP_OPARG_SHIFT << 28))
+		oparg = 1 << oparg;
+
+	if (!access_ok(VERIFY_WRITE, uaddr, sizeof(int)))
+		return -EFAULT;
+
+	pagefault_disable();
+
+	switch (op) {
+	case FUTEX_OP_SET:
+		__futex_atomic_op("or %1,%4,%4;", ret, oldval, uaddr, oparg);
+		break;
+	case FUTEX_OP_ADD:
+		__futex_atomic_op("add %1,%0,%4;", ret, oldval, uaddr, oparg);
+		break;
+	case FUTEX_OP_OR:
+		__futex_atomic_op("or %1,%0,%4;", ret, oldval, uaddr, oparg);
+		break;
+	case FUTEX_OP_ANDN:
+		__futex_atomic_op("andn %1,%0,%4;", ret, oldval, uaddr, oparg);
+		break;
+	case FUTEX_OP_XOR:
+		__futex_atomic_op("xor %1,%0,%4;", ret, oldval, uaddr, oparg);
+		break;
+	default:
+		ret = -ENOSYS;
+	}
+
+	pagefault_enable();
+
+	if (!ret) {
+		switch (cmp) {
+		case FUTEX_OP_CMP_EQ:
+			ret = (oldval == cmparg);
+			break;
+		case FUTEX_OP_CMP_NE:
+			ret = (oldval != cmparg);
+			break;
+		case FUTEX_OP_CMP_LT:
+			ret = (oldval < cmparg);
+			break;
+		case FUTEX_OP_CMP_GE:
+			ret = (oldval >= cmparg);
+			break;
+		case FUTEX_OP_CMP_LE:
+			ret = (oldval <= cmparg);
+			break;
+		case FUTEX_OP_CMP_GT:
+			ret = (oldval > cmparg);
+			break;
+		default:
+			ret = -ENOSYS;
+		}
+	}
+	return ret;
+}
+
+static inline int
+futex_atomic_cmpxchg_inatomic(int __user *uaddr, int oldval, int newval)
+{
+	int prev, cmp;
+
+	if (!access_ok(VERIFY_WRITE, uaddr, sizeof(int)))
+		return -EFAULT;
+
+	__asm__ __volatile__ ("1:	lwx	%0, %2, r0;		\
+					cmp	%1, %0, %3;		\
+					beqi	%1, 3f;			\
+				2:	swx	%4, %2, r0;		\
+					addic	%1, r0, 0;		\
+					bnei	%1, 1b;			\
+				3:					\
+				.section .fixup,\"ax\";			\
+				4:	brid	3b;			\
+					addik	%0, r0, %5;		\
+				.previous;				\
+				.section __ex_table,\"a\";		\
+				.word	1b,4b,2b,4b;			\
+				.previous;"				\
+		: "=&r" (prev), "=&r"(cmp)				\
+		: "r" (uaddr), "r" (oldval), "r" (newval), "i" (-EFAULT));
+
+	return prev;
+}
+
+#endif /* __KERNEL__ */
+
+#endif
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/io.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/io.h
--- linux-2.6.31.12/arch/microblaze/include/asm/io.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/io.h	2010-08-08 17:40:15.849523897 +0200
@@ -15,10 +15,30 @@
 #include <asm/page.h>
 #include <linux/types.h>
 #include <linux/mm.h>          /* Get struct page {...} */
+#include <asm-generic/iomap.h>
 
+#ifndef CONFIG_PCI
+#define _IO_BASE	0
+#define _ISA_MEM_BASE	0
+#define PCI_DRAM_OFFSET	0
+#else
+#define _IO_BASE	isa_io_base
+#define _ISA_MEM_BASE	isa_mem_base
+#define PCI_DRAM_OFFSET	pci_dram_offset
+#endif
+
+extern unsigned long isa_io_base;
+extern unsigned long pci_io_base;
+extern unsigned long pci_dram_offset;
+
+extern resource_size_t isa_mem_base;
 
 #define IO_SPACE_LIMIT (0xFFFFFFFF)
 
+/* the following is needed to support PCI with some drivers */
+
+#define mmiowb()
+
 static inline unsigned char __raw_readb(const volatile void __iomem *addr)
 {
 	return *(volatile unsigned char __force *)addr;
@@ -118,15 +138,10 @@ static inline void writel(unsigned int v
 
 #ifdef CONFIG_MMU
 
-#define mm_ptov(addr)		((void *)__phys_to_virt(addr))
-#define mm_vtop(addr)		((unsigned long)__virt_to_phys(addr))
 #define phys_to_virt(addr)	((void *)__phys_to_virt(addr))
 #define virt_to_phys(addr)	((unsigned long)__virt_to_phys(addr))
 #define virt_to_bus(addr)	((unsigned long)__virt_to_phys(addr))
 
-#define __page_address(page) \
-		(PAGE_OFFSET + (((page) - mem_map) << PAGE_SHIFT))
-#define page_to_phys(page)	virt_to_phys((void *)__page_address(page))
 #define page_to_bus(page)	(page_to_phys(page))
 #define bus_to_virt(addr)	(phys_to_virt(addr))
 
@@ -210,11 +225,14 @@ static inline void __iomem *__ioremap(ph
 #define in_be32(a) __raw_readl((const void __iomem __force *)(a))
 #define in_be16(a) __raw_readw(a)
 
+#define writel_be(v, a)	out_be32((__force unsigned *)a, v)
+#define readl_be(a)	in_be32((__force unsigned *)a)
+
 /*
  * Little endian
  */
 
-#define out_le32(a, v) __raw_writel(__cpu_to_le32(v), (a));
+#define out_le32(a, v) __raw_writel(__cpu_to_le32(v), (a))
 #define out_le16(a, v) __raw_writew(__cpu_to_le16(v), (a))
 
 #define in_le32(a) __le32_to_cpu(__raw_readl(a))
@@ -224,15 +242,7 @@ static inline void __iomem *__ioremap(ph
 #define out_8(a, v) __raw_writeb((v), (a))
 #define in_8(a) __raw_readb(a)
 
-/* FIXME */
-static inline void __iomem *ioport_map(unsigned long port, unsigned int len)
-{
-	return (void __iomem *) (port);
-}
-
-static inline void ioport_unmap(void __iomem *addr)
-{
-	/* Nothing to do */
-}
+#define ioport_map(port, nr)	((void __iomem*)(port))
+#define ioport_unmap(addr)
 
 #endif /* _ASM_MICROBLAZE_IO_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/ipc.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/ipc.h
--- linux-2.6.31.12/arch/microblaze/include/asm/ipc.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/ipc.h	1970-01-01 01:00:00.000000000 +0100
@@ -1 +0,0 @@
-#include <asm-generic/ipc.h>
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/irqflags.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/irqflags.h
--- linux-2.6.31.12/arch/microblaze/include/asm/irqflags.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/irqflags.h	2010-08-08 17:22:50.551792059 +0200
@@ -10,78 +10,73 @@
 #define _ASM_MICROBLAZE_IRQFLAGS_H
 
 #include <linux/irqflags.h>
+#include <asm/registers.h>
 
 # if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
 
-# define local_irq_save(flags)				\
+# define raw_local_irq_save(flags)			\
 	do {						\
-		asm volatile ("# local_irq_save	\n\t"	\
-				"msrclr %0, %1	\n\t"	\
-				"nop	\n\t"		\
+		asm volatile ("	msrclr %0, %1;		\
+				nop;"			\
 				: "=r"(flags)		\
 				: "i"(MSR_IE)		\
 				: "memory");		\
 	} while (0)
 
-# define local_irq_disable()					\
-	do {							\
-		asm volatile ("# local_irq_disable \n\t"	\
-				"msrclr r0, %0 \n\t"		\
-				"nop	\n\t"			\
-				:				\
-				: "i"(MSR_IE)			\
-				: "memory");			\
+# define raw_local_irq_disable()			\
+	do {						\
+		asm volatile ("	msrclr r0, %0;		\
+				nop;"			\
+				:			\
+				: "i"(MSR_IE)		\
+				: "memory");		\
 	} while (0)
 
-# define local_irq_enable()					\
-	do {							\
-		asm volatile ("# local_irq_enable \n\t"		\
-				"msrset	r0, %0 \n\t"		\
-				"nop	\n\t"			\
-				:				\
-				: "i"(MSR_IE)			\
-				: "memory");			\
+# define raw_local_irq_enable()				\
+	do {						\
+		asm volatile ("	msrset	r0, %0;		\
+				nop;"			\
+				:			\
+				: "i"(MSR_IE)		\
+				: "memory");		\
 	} while (0)
 
 # else /* CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR == 0 */
 
-# define local_irq_save(flags)					\
+# define raw_local_irq_save(flags)				\
 	do {							\
 		register unsigned tmp;				\
-		asm volatile ("# local_irq_save	\n\t"		\
-				"mfs	%0, rmsr \n\t"		\
-				"nop \n\t"			\
-				"andi	%1, %0, %2 \n\t"	\
-				"mts	rmsr, %1 \n\t"		\
-				"nop \n\t"			\
+		asm volatile ("	mfs	%0, rmsr;		\
+				nop;				\
+				andi	%1, %0, %2;		\
+				mts	rmsr, %1;		\
+				nop;"				\
 				: "=r"(flags), "=r" (tmp)	\
 				: "i"(~MSR_IE)			\
 				: "memory");			\
 	} while (0)
 
-# define local_irq_disable()					\
+# define raw_local_irq_disable()				\
 	do {							\
 		register unsigned tmp;				\
-		asm volatile ("# local_irq_disable \n\t"	\
-				"mfs	%0, rmsr \n\t"		\
-				"nop \n\t"			\
-				"andi	%0, %0, %1 \n\t"	\
-				"mts	rmsr, %0 \n\t"		\
-				"nop \n\t"			\
+		asm volatile ("	mfs	%0, rmsr;		\
+				nop;				\
+				andi	%0, %0, %1;		\
+				mts	rmsr, %0;		\
+				nop;"			\
 				: "=r"(tmp)			\
 				: "i"(~MSR_IE)			\
 				: "memory");			\
 	} while (0)
 
-# define local_irq_enable()					\
+# define raw_local_irq_enable()					\
 	do {							\
 		register unsigned tmp;				\
-		asm volatile ("# local_irq_enable \n\t"		\
-				"mfs	%0, rmsr \n\t"		\
-				"nop \n\t"			\
-				"ori	%0, %0, %1 \n\t"	\
-				"mts	rmsr, %0 \n\t"		\
-				"nop \n\t"			\
+		asm volatile ("	mfs	%0, rmsr;		\
+				nop;				\
+				ori	%0, %0, %1;		\
+				mts	rmsr, %0;		\
+				nop;"				\
 				: "=r"(tmp)			\
 				: "i"(MSR_IE)			\
 				: "memory");			\
@@ -89,35 +84,28 @@
 
 # endif /* CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR */
 
-#define local_save_flags(flags)					\
+#define raw_local_irq_restore(flags)				\
 	do {							\
-		asm volatile ("# local_save_flags \n\t"		\
-				"mfs	%0, rmsr \n\t"		\
-				"nop	\n\t"			\
-				: "=r"(flags)			\
+		asm volatile ("	mts	rmsr, %0;		\
+				nop;"				\
 				:				\
+				: "r"(flags)			\
 				: "memory");			\
 	} while (0)
 
-#define local_irq_restore(flags)			\
-	do {						\
-		asm volatile ("# local_irq_restore \n\t"\
-				"mts	rmsr, %0 \n\t"	\
-				"nop	\n\t"		\
-				:			\
-				: "r"(flags)		\
-				: "memory");		\
-	} while (0)
-
-static inline int irqs_disabled(void)
+static inline unsigned long get_msr(void)
 {
 	unsigned long flags;
-
-	local_save_flags(flags);
-	return ((flags & MSR_IE) == 0);
+	asm volatile ("	mfs	%0, rmsr;	\
+			nop;"			\
+			: "=r"(flags)		\
+			:			\
+			: "memory");		\
+	return flags;
 }
 
-#define raw_irqs_disabled irqs_disabled
-#define raw_irqs_disabled_flags(flags)	((flags) == 0)
+#define raw_local_save_flags(flags)	((flags) = get_msr())
+#define raw_irqs_disabled()		((get_msr() & MSR_IE) == 0)
+#define raw_irqs_disabled_flags(flags)	((flags & MSR_IE) == 0)
 
 #endif /* _ASM_MICROBLAZE_IRQFLAGS_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/irq.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/irq.h
--- linux-2.6.31.12/arch/microblaze/include/asm/irq.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/irq.h	2010-08-08 17:40:15.849523897 +0200
@@ -14,6 +14,12 @@
 
 #include <linux/interrupt.h>
 
+/* This type is the placeholder for a hardware interrupt number. It has to
+ * be big enough to enclose whatever representation is used by a given
+ * platform.
+ */
+typedef unsigned long irq_hw_number_t;
+
 extern unsigned int nr_irq;
 
 #define NO_IRQ (-1)
@@ -21,7 +27,8 @@ extern unsigned int nr_irq;
 struct pt_regs;
 extern void do_IRQ(struct pt_regs *regs);
 
-/* irq_of_parse_and_map - Parse and Map an interrupt into linux virq space
+/**
+ * irq_of_parse_and_map - Parse and Map an interrupt into linux virq space
  * @device: Device node of the device whose interrupt is to be mapped
  * @index: Index of the interrupt to map
  *
@@ -40,4 +47,32 @@ static inline void irq_dispose_mapping(u
 	return;
 }
 
+struct irq_host;
+
+/**
+ * irq_create_mapping - Map a hardware interrupt into linux virq space
+ * @host: host owning this hardware interrupt or NULL for default host
+ * @hwirq: hardware irq number in that host space
+ *
+ * Only one mapping per hardware interrupt is permitted. Returns a linux
+ * virq number.
+ * If the sense/trigger is to be specified, set_irq_type() should be called
+ * on the number returned from that call.
+ */
+extern unsigned int irq_create_mapping(struct irq_host *host,
+					irq_hw_number_t hwirq);
+
+/**
+ * irq_create_of_mapping - Map a hardware interrupt into linux virq space
+ * @controller: Device node of the interrupt controller
+ * @inspec: Interrupt specifier from the device-tree
+ * @intsize: Size of the interrupt specifier from the device-tree
+ *
+ * This function is identical to irq_create_mapping except that it takes
+ * as input informations straight from the device-tree (typically the results
+ * of the of_irq_map_*() functions.
+ */
+extern unsigned int irq_create_of_mapping(struct device_node *controller,
+					u32 *intspec, unsigned int intsize);
+
 #endif /* _ASM_MICROBLAZE_IRQ_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/page.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/page.h
--- linux-2.6.31.12/arch/microblaze/include/asm/page.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/page.h	2010-08-08 17:40:15.853537674 +0200
@@ -17,6 +17,7 @@
 
 #include <linux/pfn.h>
 #include <asm/setup.h>
+#include <asm/asm-compat.h>
 #include <linux/const.h>
 
 #ifdef __KERNEL__
@@ -26,8 +27,13 @@
 #define PAGE_SIZE	(_AC(1, UL) << PAGE_SHIFT)
 #define PAGE_MASK	(~(PAGE_SIZE-1))
 
+#define LOAD_OFFSET	ASM_CONST((CONFIG_KERNEL_START-CONFIG_KERNEL_BASE_ADDR))
+
 #ifndef __ASSEMBLY__
 
+/* MS be sure that SLAB allocates aligned objects */
+#define ARCH_KMALLOC_MINALIGN	L1_CACHE_BYTES
+
 #define PAGE_UP(addr)	(((addr)+((PAGE_SIZE)-1))&(~((PAGE_SIZE)-1)))
 #define PAGE_DOWN(addr)	((addr)&(~((PAGE_SIZE)-1)))
 
@@ -59,12 +65,6 @@ extern unsigned int __page_offset;
 #define PAGE_OFFSET	CONFIG_KERNEL_START
 
 /*
- * MAP_NR -- given an address, calculate the index of the page struct which
- * points to the address's page.
- */
-#define MAP_NR(addr) (((unsigned long)(addr) - PAGE_OFFSET) >> PAGE_SHIFT)
-
-/*
  * The basic type of a PTE - 32 bit physical addressing.
  */
 typedef unsigned long pte_basic_t;
@@ -73,14 +73,7 @@ typedef unsigned long pte_basic_t;
 
 #endif /* CONFIG_MMU */
 
-#  ifndef CONFIG_MMU
-#  define copy_page(to, from)			memcpy((to), (from), PAGE_SIZE)
-#  define get_user_page(vaddr)			__get_free_page(GFP_KERNEL)
-#  define free_user_page(page, addr)		free_page(addr)
-#  else /* CONFIG_MMU */
-extern void copy_page(void *to, void *from);
-#  endif /* CONFIG_MMU */
-
+# define copy_page(to, from)			memcpy((to), (from), PAGE_SIZE)
 # define clear_page(pgaddr)			memset((pgaddr), 0, PAGE_SIZE)
 
 # define clear_user_page(pgaddr, vaddr, page)	memset((pgaddr), 0, PAGE_SIZE)
@@ -151,7 +144,11 @@ extern int page_is_ram(unsigned long pfn
 # define pfn_to_virt(pfn)	__va(pfn_to_phys((pfn)))
 
 #  ifdef CONFIG_MMU
-#  define virt_to_page(kaddr) 	(mem_map +  MAP_NR(kaddr))
+
+#  define virt_to_page(kaddr)	(pfn_to_page(__pa(kaddr) >> PAGE_SHIFT))
+#  define page_to_virt(page)   __va(page_to_pfn(page) << PAGE_SHIFT)
+#  define page_to_phys(page)     (page_to_pfn(page) << PAGE_SHIFT)
+
 #  else /* CONFIG_MMU */
 #  define virt_to_page(vaddr)	(pfn_to_page(virt_to_pfn(vaddr)))
 #  define page_to_virt(page)	(pfn_to_virt(page_to_pfn(page)))
@@ -161,7 +158,8 @@ extern int page_is_ram(unsigned long pfn
 #  endif /* CONFIG_MMU */
 
 #  ifndef CONFIG_MMU
-#  define pfn_valid(pfn)	((pfn) >= min_low_pfn && (pfn) <= max_mapnr)
+#  define pfn_valid(pfn)	(((pfn) >= min_low_pfn) && \
+				((pfn) <= (min_low_pfn + max_mapnr)))
 #  define ARCH_PFN_OFFSET	(PAGE_OFFSET >> PAGE_SHIFT)
 #  else /* CONFIG_MMU */
 #  define ARCH_PFN_OFFSET	(memory_start >> PAGE_SHIFT)
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/pci-bridge.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/pci-bridge.h
--- linux-2.6.31.12/arch/microblaze/include/asm/pci-bridge.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/pci-bridge.h	2010-08-08 17:40:15.853537674 +0200
@@ -1 +1,196 @@
+#ifndef _ASM_MICROBLAZE_PCI_BRIDGE_H
+#define _ASM_MICROBLAZE_PCI_BRIDGE_H
+#ifdef __KERNEL__
+/*
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
 #include <linux/pci.h>
+#include <linux/list.h>
+#include <linux/ioport.h>
+
+struct device_node;
+
+enum {
+	/* Force re-assigning all resources (ignore firmware
+	 * setup completely)
+	 */
+	PCI_REASSIGN_ALL_RSRC	= 0x00000001,
+
+	/* Re-assign all bus numbers */
+	PCI_REASSIGN_ALL_BUS	= 0x00000002,
+
+	/* Do not try to assign, just use existing setup */
+	PCI_PROBE_ONLY		= 0x00000004,
+
+	/* Don't bother with ISA alignment unless the bridge has
+	 * ISA forwarding enabled
+	 */
+	PCI_CAN_SKIP_ISA_ALIGN	= 0x00000008,
+
+	/* Enable domain numbers in /proc */
+	PCI_ENABLE_PROC_DOMAINS	= 0x00000010,
+	/* ... except for domain 0 */
+	PCI_COMPAT_DOMAIN_0		= 0x00000020,
+};
+
+/*
+ * Structure of a PCI controller (host bridge)
+ */
+struct pci_controller {
+	struct pci_bus *bus;
+	char is_dynamic;
+	struct device_node *dn;
+	struct list_head list_node;
+	struct device *parent;
+
+	int first_busno;
+	int last_busno;
+
+	int self_busno;
+
+	void __iomem *io_base_virt;
+	resource_size_t io_base_phys;
+
+	resource_size_t pci_io_size;
+
+	/* Some machines (PReP) have a non 1:1 mapping of
+	 * the PCI memory space in the CPU bus space
+	 */
+	resource_size_t pci_mem_offset;
+
+	/* Some machines have a special region to forward the ISA
+	 * "memory" cycles such as VGA memory regions. Left to 0
+	 * if unsupported
+	 */
+	resource_size_t isa_mem_phys;
+	resource_size_t isa_mem_size;
+
+	struct pci_ops *ops;
+	unsigned int __iomem *cfg_addr;
+	void __iomem *cfg_data;
+
+	/*
+	 * Used for variants of PCI indirect handling and possible quirks:
+	 *  SET_CFG_TYPE - used on 4xx or any PHB that does explicit type0/1
+	 *  EXT_REG - provides access to PCI-e extended registers
+	 *  SURPRESS_PRIMARY_BUS - we surpress the setting of PCI_PRIMARY_BUS
+	 *   on Freescale PCI-e controllers since they used the PCI_PRIMARY_BUS
+	 *   to determine which bus number to match on when generating type0
+	 *   config cycles
+	 *  NO_PCIE_LINK - the Freescale PCI-e controllers have issues with
+	 *   hanging if we don't have link and try to do config cycles to
+	 *   anything but the PHB.  Only allow talking to the PHB if this is
+	 *   set.
+	 *  BIG_ENDIAN - cfg_addr is a big endian register
+	 *  BROKEN_MRM - the 440EPx/GRx chips have an errata that causes hangs
+	 *   on the PLB4.  Effectively disable MRM commands by setting this.
+	 */
+#define INDIRECT_TYPE_SET_CFG_TYPE		0x00000001
+#define INDIRECT_TYPE_EXT_REG		0x00000002
+#define INDIRECT_TYPE_SURPRESS_PRIMARY_BUS	0x00000004
+#define INDIRECT_TYPE_NO_PCIE_LINK		0x00000008
+#define INDIRECT_TYPE_BIG_ENDIAN		0x00000010
+#define INDIRECT_TYPE_BROKEN_MRM		0x00000020
+	u32 indirect_type;
+
+	/* Currently, we limit ourselves to 1 IO range and 3 mem
+	 * ranges since the common pci_bus structure can't handle more
+	 */
+	struct resource io_resource;
+	struct resource mem_resources[3];
+	int global_number;	/* PCI domain number */
+};
+
+static inline struct pci_controller *pci_bus_to_host(const struct pci_bus *bus)
+{
+	return bus->sysdata;
+}
+
+static inline int isa_vaddr_is_ioport(void __iomem *address)
+{
+	/* No specific ISA handling on ppc32 at this stage, it
+	 * all goes through PCI
+	 */
+	return 0;
+}
+
+/* These are used for config access before all the PCI probing
+   has been done. */
+extern int early_read_config_byte(struct pci_controller *hose, int bus,
+			int dev_fn, int where, u8 *val);
+extern int early_read_config_word(struct pci_controller *hose, int bus,
+			int dev_fn, int where, u16 *val);
+extern int early_read_config_dword(struct pci_controller *hose, int bus,
+			int dev_fn, int where, u32 *val);
+extern int early_write_config_byte(struct pci_controller *hose, int bus,
+			int dev_fn, int where, u8 val);
+extern int early_write_config_word(struct pci_controller *hose, int bus,
+			int dev_fn, int where, u16 val);
+extern int early_write_config_dword(struct pci_controller *hose, int bus,
+			int dev_fn, int where, u32 val);
+
+extern int early_find_capability(struct pci_controller *hose, int bus,
+				 int dev_fn, int cap);
+
+extern void setup_indirect_pci(struct pci_controller *hose,
+			       resource_size_t cfg_addr,
+			       resource_size_t cfg_data, u32 flags);
+
+/* Get the PCI host controller for an OF device */
+extern struct pci_controller *pci_find_hose_for_OF_device(
+			struct device_node *node);
+
+/* Fill up host controller resources from the OF node */
+extern void pci_process_bridge_OF_ranges(struct pci_controller *hose,
+			struct device_node *dev, int primary);
+
+/* Allocate & free a PCI host bridge structure */
+extern struct pci_controller *pcibios_alloc_controller(struct device_node *dev);
+extern void pcibios_free_controller(struct pci_controller *phb);
+extern void pcibios_setup_phb_resources(struct pci_controller *hose);
+
+#ifdef CONFIG_PCI
+extern unsigned int pci_flags;
+
+static inline void pci_set_flags(int flags)
+{
+	pci_flags = flags;
+}
+
+static inline void pci_add_flags(int flags)
+{
+	pci_flags |= flags;
+}
+
+static inline int pci_has_flag(int flag)
+{
+	return (pci_flags & flag);
+}
+
+extern struct list_head hose_list;
+
+extern unsigned long pci_address_to_pio(phys_addr_t address);
+extern int pcibios_vaddr_is_ioport(void __iomem *address);
+#else
+static inline unsigned long pci_address_to_pio(phys_addr_t address)
+{
+	return (unsigned long)-1;
+}
+static inline int pcibios_vaddr_is_ioport(void __iomem *address)
+{
+	return 0;
+}
+
+static inline void pci_set_flags(int flags) { }
+static inline void pci_add_flags(int flags) { }
+static inline int pci_has_flag(int flag)
+{
+	return 0;
+}
+#endif	/* CONFIG_PCI */
+
+#endif	/* __KERNEL__ */
+#endif	/* _ASM_MICROBLAZE_PCI_BRIDGE_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/pci.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/pci.h
--- linux-2.6.31.12/arch/microblaze/include/asm/pci.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/pci.h	2010-08-08 17:40:15.853537674 +0200
@@ -1 +1,179 @@
-#include <asm-generic/pci.h>
+/*
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ *
+ * Based on powerpc version
+ */
+
+#ifndef __ASM_MICROBLAZE_PCI_H
+#define __ASM_MICROBLAZE_PCI_H
+#ifdef __KERNEL__
+
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/dma-mapping.h>
+#include <linux/pci.h>
+
+#include <asm/scatterlist.h>
+#include <asm/io.h>
+#include <asm/prom.h>
+#include <asm/pci-bridge.h>
+
+#include <asm-generic/pci-dma-compat.h>
+
+#define PCIBIOS_MIN_IO		0x1000
+#define PCIBIOS_MIN_MEM		0x10000000
+
+struct pci_dev;
+
+/* Values for the `which' argument to sys_pciconfig_iobase syscall.  */
+#define IOBASE_BRIDGE_NUMBER	0
+#define IOBASE_MEMORY		1
+#define IOBASE_IO		2
+#define IOBASE_ISA_IO		3
+#define IOBASE_ISA_MEM		4
+
+#define pcibios_scan_all_fns(a, b)	0
+
+/*
+ * Set this to 1 if you want the kernel to re-assign all PCI
+ * bus numbers (don't do that on ppc64 yet !)
+ */
+#define pcibios_assign_all_busses() \
+	(pci_has_flag(PCI_REASSIGN_ALL_BUS))
+
+static inline void pcibios_set_master(struct pci_dev *dev)
+{
+	/* No special bus mastering setup handling */
+}
+
+static inline void pcibios_penalize_isa_irq(int irq, int active)
+{
+	/* We don't do dynamic PCI IRQ allocation */
+}
+
+#ifdef CONFIG_PCI
+extern void set_pci_dma_ops(struct dma_map_ops *dma_ops);
+extern struct dma_map_ops *get_pci_dma_ops(void);
+#else	/* CONFIG_PCI */
+#define set_pci_dma_ops(d)
+#define get_pci_dma_ops()	NULL
+#endif
+
+#ifdef CONFIG_PCI
+static inline void pci_dma_burst_advice(struct pci_dev *pdev,
+					enum pci_dma_burst_strategy *strat,
+					unsigned long *strategy_parameter)
+{
+	*strat = PCI_DMA_BURST_INFINITY;
+	*strategy_parameter = ~0UL;
+}
+#endif
+
+extern int pci_domain_nr(struct pci_bus *bus);
+
+/* Decide whether to display the domain number in /proc */
+extern int pci_proc_domain(struct pci_bus *bus);
+
+struct vm_area_struct;
+/* Map a range of PCI memory or I/O space for a device into user space */
+int pci_mmap_page_range(struct pci_dev *pdev, struct vm_area_struct *vma,
+			enum pci_mmap_state mmap_state, int write_combine);
+
+/* Tell drivers/pci/proc.c that we have pci_mmap_page_range() */
+#define HAVE_PCI_MMAP	1
+
+extern int pci_legacy_read(struct pci_bus *bus, loff_t port, u32 *val,
+			   size_t count);
+extern int pci_legacy_write(struct pci_bus *bus, loff_t port, u32 val,
+			   size_t count);
+extern int pci_mmap_legacy_page_range(struct pci_bus *bus,
+				      struct vm_area_struct *vma,
+				      enum pci_mmap_state mmap_state);
+
+#define HAVE_PCI_LEGACY	1
+
+/* pci_unmap_{page,single} is a nop so... */
+#define DECLARE_PCI_UNMAP_ADDR(ADDR_NAME)
+#define DECLARE_PCI_UNMAP_LEN(LEN_NAME)
+#define pci_unmap_addr(PTR, ADDR_NAME)		(0)
+#define pci_unmap_addr_set(PTR, ADDR_NAME, VAL)	do { } while (0)
+#define pci_unmap_len(PTR, LEN_NAME)		(0)
+#define pci_unmap_len_set(PTR, LEN_NAME, VAL)	do { } while (0)
+
+/* The PCI address space does equal the physical memory
+ * address space (no IOMMU).  The IDE and SCSI device layers use
+ * this boolean for bounce buffer decisions.
+ */
+#define PCI_DMA_BUS_IS_PHYS     (1)
+
+extern void pcibios_resource_to_bus(struct pci_dev *dev,
+			struct pci_bus_region *region,
+			struct resource *res);
+
+extern void pcibios_bus_to_resource(struct pci_dev *dev,
+			struct resource *res,
+			struct pci_bus_region *region);
+
+static inline struct resource *pcibios_select_root(struct pci_dev *pdev,
+			struct resource *res)
+{
+	struct resource *root = NULL;
+
+	if (res->flags & IORESOURCE_IO)
+		root = &ioport_resource;
+	if (res->flags & IORESOURCE_MEM)
+		root = &iomem_resource;
+
+	return root;
+}
+
+extern void pcibios_claim_one_bus(struct pci_bus *b);
+
+extern void pcibios_finish_adding_to_bus(struct pci_bus *bus);
+
+extern void pcibios_resource_survey(void);
+
+extern struct pci_controller *init_phb_dynamic(struct device_node *dn);
+extern int remove_phb_dynamic(struct pci_controller *phb);
+
+extern struct pci_dev *of_create_pci_dev(struct device_node *node,
+					struct pci_bus *bus, int devfn);
+
+extern void of_scan_pci_bridge(struct device_node *node,
+				struct pci_dev *dev);
+
+extern void of_scan_bus(struct device_node *node, struct pci_bus *bus);
+extern void of_rescan_bus(struct device_node *node, struct pci_bus *bus);
+
+extern int pci_read_irq_line(struct pci_dev *dev);
+
+extern int pci_bus_find_capability(struct pci_bus *bus,
+						unsigned int devfn, int cap);
+
+struct file;
+extern pgprot_t	pci_phys_mem_access_prot(struct file *file,
+					 unsigned long pfn,
+					 unsigned long size,
+					 pgprot_t prot);
+
+#define HAVE_ARCH_PCI_RESOURCE_TO_USER
+extern void pci_resource_to_user(const struct pci_dev *dev, int bar,
+				 const struct resource *rsrc,
+				 resource_size_t *start, resource_size_t *end);
+
+extern void pcibios_setup_bus_devices(struct pci_bus *bus);
+extern void pcibios_setup_bus_self(struct pci_bus *bus);
+
+/* This part of code was originaly in xilinx-pci.h */
+#ifdef CONFIG_PCI_XILINX
+extern void __init xilinx_pci_init(void);
+#else
+static inline void __init xilinx_pci_init(void) { return; }
+#endif
+
+#endif	/* __KERNEL__ */
+#endif /* __ASM_MICROBLAZE_PCI_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/pgalloc.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/pgalloc.h
--- linux-2.6.31.12/arch/microblaze/include/asm/pgalloc.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/pgalloc.h	2010-08-08 17:40:15.853537674 +0200
@@ -19,6 +19,7 @@
 #include <asm/io.h>
 #include <asm/page.h>
 #include <asm/cache.h>
+#include <asm/pgtable.h>
 
 #define PGDIR_ORDER	0
 
@@ -106,26 +107,8 @@ extern inline void free_pgd_slow(pgd_t *
  */
 #define pmd_alloc_one_fast(mm, address)	({ BUG(); ((pmd_t *)1); })
 #define pmd_alloc_one(mm, address)	({ BUG(); ((pmd_t *)2); })
-/* FIXME two definition - look below */
-#define pmd_free(mm, x)			do { } while (0)
-#define pgd_populate(mm, pmd, pte)	BUG()
 
-static inline pte_t *pte_alloc_one_kernel(struct mm_struct *mm,
-		unsigned long address)
-{
-	pte_t *pte;
-	extern int mem_init_done;
-	extern void *early_get_page(void);
-	if (mem_init_done) {
-		pte = (pte_t *)__get_free_page(GFP_KERNEL |
-					__GFP_REPEAT | __GFP_ZERO);
-	} else {
-		pte = (pte_t *)early_get_page();
-		if (pte)
-			clear_page(pte);
-	}
-	return pte;
-}
+extern pte_t *pte_alloc_one_kernel(struct mm_struct *mm, unsigned long addr);
 
 static inline struct page *pte_alloc_one(struct mm_struct *mm,
 		unsigned long address)
@@ -192,14 +175,14 @@ extern inline void pte_free(struct mm_st
  * the pgd will always be present..
  */
 #define pmd_alloc_one(mm, address)	({ BUG(); ((pmd_t *)2); })
-/*#define pmd_free(mm, x)			do { } while (0)*/
-#define __pmd_free_tlb(tlb, x, addr)	do { } while (0)
+#define pmd_free(mm, x)			do { } while (0)
+#define __pmd_free_tlb(tlb, x, addr)	pmd_free((tlb)->mm, x)
 #define pgd_populate(mm, pmd, pte)	BUG()
 
 extern int do_check_pgt_cache(int, int);
 
 #endif /* CONFIG_MMU */
 
-#define check_pgt_cache()	do {} while (0)
+#define check_pgt_cache()		do { } while (0)
 
 #endif /* _ASM_MICROBLAZE_PGALLOC_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/pgtable.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/pgtable.h
--- linux-2.6.31.12/arch/microblaze/include/asm/pgtable.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/pgtable.h	2010-08-08 17:40:15.853537674 +0200
@@ -16,6 +16,10 @@
 #define io_remap_pfn_range(vma, vaddr, pfn, size, prot)		\
 		remap_pfn_range(vma, vaddr, pfn, size, prot)
 
+#ifndef __ASSEMBLY__
+extern int mem_init_done;
+#endif
+
 #ifndef CONFIG_MMU
 
 #define pgd_present(pgd)	(1) /* pages are always present on non MMU */
@@ -51,6 +55,8 @@ static inline int pte_file(pte_t pte) { 
 
 #define arch_enter_lazy_cpu_mode()	do {} while (0)
 
+#define pgprot_noncached_wc(prot)	prot
+
 #else /* CONFIG_MMU */
 
 #include <asm-generic/4level-fixup.h>
@@ -68,7 +74,6 @@ static inline int pte_file(pte_t pte) { 
 
 extern unsigned long va_to_phys(unsigned long address);
 extern pte_t *va_to_pte(unsigned long address);
-extern unsigned long ioremap_bot, ioremap_base;
 
 /*
  * The following only work if pte_present() is true.
@@ -85,11 +90,25 @@ static inline pte_t pte_mkspecial(pte_t 
 #define VMALLOC_START	(CONFIG_KERNEL_START + \
 				max(32 * 1024 * 1024UL, memory_size))
 #define VMALLOC_END	ioremap_bot
-#define VMALLOC_VMADDR(x) ((unsigned long)(x))
 
 #endif /* __ASSEMBLY__ */
 
 /*
+ * Macro to mark a page protection value as "uncacheable".
+ */
+
+#define _PAGE_CACHE_CTL	(_PAGE_GUARDED | _PAGE_NO_CACHE | \
+							_PAGE_WRITETHRU)
+
+#define pgprot_noncached(prot) \
+			(__pgprot((pgprot_val(prot) & ~_PAGE_CACHE_CTL) | \
+					_PAGE_NO_CACHE | _PAGE_GUARDED))
+
+#define pgprot_noncached_wc(prot) \
+			 (__pgprot((pgprot_val(prot) & ~_PAGE_CACHE_CTL) | \
+							_PAGE_NO_CACHE))
+
+/*
  * The MicroBlaze MMU is identical to the PPC-40x MMU, and uses a hash
  * table containing PTEs, together with a set of 16 segment registers, to
  * define the virtual to physical address mapping.
@@ -397,7 +416,7 @@ static inline unsigned long pte_update(p
 	mts     rmsr, %2\n\
 	nop"
 	: "=&r" (old), "=&r" (tmp), "=&r" (msr), "=m" (*p)
-	: "r" ((unsigned long)(p+1) - 4), "r" (clr), "r" (set), "m" (*p)
+	: "r" ((unsigned long)(p + 1) - 4), "r" (clr), "r" (set), "m" (*p)
 	: "cc");
 
 	return old;
@@ -493,15 +512,6 @@ static inline pmd_t *pmd_offset(pgd_t *d
 extern pgd_t swapper_pg_dir[PTRS_PER_PGD];
 
 /*
- * When flushing the tlb entry for a page, we also need to flush the hash
- * table entry.  flush_hash_page is assembler (for speed) in hashtable.S.
- */
-extern int flush_hash_page(unsigned context, unsigned long va, pte_t *ptep);
-
-/* Add an HPTE to the hash table */
-extern void add_hash_page(unsigned context, unsigned long va, pte_t *ptep);
-
-/*
  * Encode and decode a swap entry.
  * Note that the bits we use in a PTE for representing a swap entry
  * must not include the _PAGE_PRESENT bit, or the _PAGE_HASHPTE bit
@@ -514,15 +524,7 @@ extern void add_hash_page(unsigned conte
 #define __pte_to_swp_entry(pte)	((swp_entry_t) { pte_val(pte) >> 2 })
 #define __swp_entry_to_pte(x)	((pte_t) { (x).val << 2 })
 
-
-/* CONFIG_APUS */
-/* For virtual address to physical address conversion */
-extern void cache_clear(__u32 addr, int length);
-extern void cache_push(__u32 addr, int length);
-extern int mm_end_of_chunk(unsigned long addr, int len);
 extern unsigned long iopa(unsigned long addr);
-/* extern unsigned long mm_ptov(unsigned long addr) \
-	__attribute__ ((const)); TBD */
 
 /* Values for nocacheflag and cmode */
 /* These are not used by the APUS kernel_map, but prevents
@@ -533,18 +535,6 @@ extern unsigned long iopa(unsigned long 
 #define	IOMAP_NOCACHE_NONSER	2
 #define	IOMAP_NO_COPYBACK	3
 
-/*
- * Map some physical address range into the kernel address space.
- */
-extern unsigned long kernel_map(unsigned long paddr, unsigned long size,
-				int nocacheflag, unsigned long *memavailp);
-
-/*
- * Set cache mode of (kernel space) address range.
- */
-extern void kernel_set_cachemode(unsigned long address, unsigned long size,
-				unsigned int cmode);
-
 /* Needs to be defined here and not in linux/mm.h, as it is arch dependent */
 #define kern_addr_valid(addr)	(1)
 
@@ -558,26 +548,15 @@ extern void kernel_set_cachemode(unsigne
 void do_page_fault(struct pt_regs *regs, unsigned long address,
 		   unsigned long error_code);
 
-void __init io_block_mapping(unsigned long virt, phys_addr_t phys,
-			     unsigned int size, int flags);
-
-void __init adjust_total_lowmem(void);
 void mapin_ram(void);
 int map_page(unsigned long va, phys_addr_t pa, int flags);
 
 extern int mem_init_done;
-extern unsigned long ioremap_base;
-extern unsigned long ioremap_bot;
 
 asmlinkage void __init mmu_init(void);
 
 void __init *early_get_page(void);
 
-void *consistent_alloc(int gfp, size_t size, dma_addr_t *dma_handle);
-void consistent_free(void *vaddr);
-void consistent_sync(void *vaddr, size_t size, int direction);
-void consistent_sync_page(struct page *page, unsigned long offset,
-	size_t size, int direction);
 #endif /* __ASSEMBLY__ */
 #endif /* __KERNEL__ */
 
@@ -586,6 +565,14 @@ void consistent_sync_page(struct page *p
 #ifndef __ASSEMBLY__
 #include <asm-generic/pgtable.h>
 
+extern unsigned long ioremap_bot, ioremap_base;
+
+void *consistent_alloc(int gfp, size_t size, dma_addr_t *dma_handle);
+void consistent_free(size_t size, void *vaddr);
+void consistent_sync(void *vaddr, size_t size, int direction);
+void consistent_sync_page(struct page *page, unsigned long offset,
+	size_t size, int direction);
+
 void setup_memory(void);
 #endif /* __ASSEMBLY__ */
 
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/processor.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/processor.h
--- linux-2.6.31.12/arch/microblaze/include/asm/processor.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/processor.h	2010-08-08 17:40:15.853537674 +0200
@@ -14,7 +14,6 @@
 #include <asm/ptrace.h>
 #include <asm/setup.h>
 #include <asm/registers.h>
-#include <asm/segment.h>
 #include <asm/entry.h>
 #include <asm/current.h>
 
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/prom.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/prom.h
--- linux-2.6.31.12/arch/microblaze/include/asm/prom.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/prom.h	2010-08-08 17:40:15.853537674 +0200
@@ -158,6 +158,21 @@ extern int prom_update_property(struct d
 				struct property *newprop,
 				struct property *oldprop);
 
+#ifdef CONFIG_PCI
+/*
+ * PCI <-> OF matching functions
+ * (XXX should these be here?)
+ */
+struct pci_bus;
+struct pci_dev;
+extern int pci_device_from_OF_node(struct device_node *node,
+					u8 *bus, u8 *devfn);
+extern struct device_node *pci_busdev_to_OF_node(struct pci_bus *bus,
+							int devfn);
+extern struct device_node *pci_device_to_OF_node(struct pci_dev *dev);
+extern void pci_create_OF_bus_map(void);
+#endif
+
 extern struct resource *request_OF_resource(struct device_node *node,
 				int index, const char *name_postfix);
 extern int release_OF_resource(struct device_node *node, int index);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/ptrace.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/ptrace.h
--- linux-2.6.31.12/arch/microblaze/include/asm/ptrace.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/ptrace.h	2010-08-08 17:40:15.853537674 +0200
@@ -54,6 +54,7 @@ struct pt_regs {
 	int pt_mode;
 };
 
+#ifdef __KERNEL__
 #define kernel_mode(regs)		((regs)->pt_mode)
 #define user_mode(regs)			(!kernel_mode(regs))
 
@@ -62,6 +63,19 @@ struct pt_regs {
 
 void show_regs(struct pt_regs *);
 
+#else /* __KERNEL__ */
+
+/* pt_regs offsets used by gdbserver etc in ptrace syscalls */
+#define PT_GPR(n)       ((n) * sizeof(microblaze_reg_t))
+#define PT_PC           (32 * sizeof(microblaze_reg_t))
+#define PT_MSR          (33 * sizeof(microblaze_reg_t))
+#define PT_EAR          (34 * sizeof(microblaze_reg_t))
+#define PT_ESR          (35 * sizeof(microblaze_reg_t))
+#define PT_FSR          (36 * sizeof(microblaze_reg_t))
+#define PT_KERNEL_MODE  (37 * sizeof(microblaze_reg_t))
+
+#endif /* __KERNEL */
+
 #endif /* __ASSEMBLY__ */
 
 #endif /* _ASM_MICROBLAZE_PTRACE_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/pvr.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/pvr.h
--- linux-2.6.31.12/arch/microblaze/include/asm/pvr.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/pvr.h	2010-08-08 17:22:50.557036231 +0200
@@ -76,20 +76,23 @@ struct pvr_s {
 #define PVR3_FSL_LINKS_MASK		0x00000380
 
 /* ICache config PVR masks */
-#define PVR4_USE_ICACHE_MASK		0x80000000
-#define PVR4_ICACHE_ADDR_TAG_BITS_MASK	0x7C000000
-#define PVR4_ICACHE_USE_FSL_MASK	0x02000000
-#define PVR4_ICACHE_ALLOW_WR_MASK	0x01000000
-#define PVR4_ICACHE_LINE_LEN_MASK	0x00E00000
-#define PVR4_ICACHE_BYTE_SIZE_MASK	0x001F0000
+#define PVR4_USE_ICACHE_MASK		0x80000000 /* ICU */
+#define PVR4_ICACHE_ADDR_TAG_BITS_MASK	0x7C000000 /* ICTS */
+#define PVR4_ICACHE_ALLOW_WR_MASK	0x01000000 /* ICW */
+#define PVR4_ICACHE_LINE_LEN_MASK	0x00E00000 /* ICLL */
+#define PVR4_ICACHE_BYTE_SIZE_MASK	0x001F0000 /* ICBS */
+#define PVR4_ICACHE_ALWAYS_USED		0x00008000 /* IAU */
+#define PVR4_ICACHE_INTERFACE		0x00002000 /* ICI */
 
 /* DCache config PVR masks */
-#define PVR5_USE_DCACHE_MASK		0x80000000
-#define PVR5_DCACHE_ADDR_TAG_BITS_MASK	0x7C000000
-#define PVR5_DCACHE_USE_FSL_MASK	0x02000000
-#define PVR5_DCACHE_ALLOW_WR_MASK	0x01000000
-#define PVR5_DCACHE_LINE_LEN_MASK	0x00E00000
-#define PVR5_DCACHE_BYTE_SIZE_MASK	0x001F0000
+#define PVR5_USE_DCACHE_MASK		0x80000000 /* DCU */
+#define PVR5_DCACHE_ADDR_TAG_BITS_MASK	0x7C000000 /* DCTS */
+#define PVR5_DCACHE_ALLOW_WR_MASK	0x01000000 /* DCW */
+#define PVR5_DCACHE_LINE_LEN_MASK	0x00E00000 /* DCLL */
+#define PVR5_DCACHE_BYTE_SIZE_MASK	0x001F0000 /* DCBS */
+#define PVR5_DCACHE_ALWAYS_USED		0x00008000 /* DAU */
+#define PVR5_DCACHE_USE_WRITEBACK	0x00004000 /* DWB */
+#define PVR5_DCACHE_INTERFACE		0x00002000 /* DCI */
 
 /* ICache base address PVR mask */
 #define PVR6_ICACHE_BASEADDR_MASK	0xFFFFFFFF
@@ -178,11 +181,14 @@ struct pvr_s {
 			((pvr.pvr[5] & PVR5_DCACHE_ADDR_TAG_BITS_MASK) >> 26)
 #define PVR_DCACHE_USE_FSL(pvr)		(pvr.pvr[5] & PVR5_DCACHE_USE_FSL_MASK)
 #define PVR_DCACHE_ALLOW_WR(pvr)	(pvr.pvr[5] & PVR5_DCACHE_ALLOW_WR_MASK)
+/* FIXME two shifts on one line needs any comment */
 #define PVR_DCACHE_LINE_LEN(pvr) \
 			(1 << ((pvr.pvr[5] & PVR5_DCACHE_LINE_LEN_MASK) >> 21))
 #define PVR_DCACHE_BYTE_SIZE(pvr) \
 			(1 << ((pvr.pvr[5] & PVR5_DCACHE_BYTE_SIZE_MASK) >> 16))
 
+#define PVR_DCACHE_USE_WRITEBACK(pvr) \
+			((pvr.pvr[5] & PVR5_DCACHE_USE_WRITEBACK) >> 14)
 
 #define PVR_ICACHE_BASEADDR(pvr)	(pvr.pvr[6] & PVR6_ICACHE_BASEADDR_MASK)
 #define PVR_ICACHE_HIGHADDR(pvr)	(pvr.pvr[7] & PVR7_ICACHE_HIGHADDR_MASK)
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/segment.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/segment.h
--- linux-2.6.31.12/arch/microblaze/include/asm/segment.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/segment.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,49 +0,0 @@
-/*
- * Copyright (C) 2008-2009 Michal Simek <monstr@monstr.eu>
- * Copyright (C) 2008-2009 PetaLogix
- * Copyright (C) 2006 Atmark Techno, Inc.
- *
- * This file is subject to the terms and conditions of the GNU General Public
- * License. See the file "COPYING" in the main directory of this archive
- * for more details.
- */
-
-#ifndef _ASM_MICROBLAZE_SEGMENT_H
-#define _ASM_MICROBLAZE_SEGMENT_H
-
-# ifndef __ASSEMBLY__
-
-typedef struct {
-	unsigned long seg;
-} mm_segment_t;
-
-/*
- * On Microblaze the fs value is actually the top of the corresponding
- * address space.
- *
- * The fs value determines whether argument validity checking should be
- * performed or not. If get_fs() == USER_DS, checking is performed, with
- * get_fs() == KERNEL_DS, checking is bypassed.
- *
- * For historical reasons, these macros are grossly misnamed.
- *
- * For non-MMU arch like Microblaze, KERNEL_DS and USER_DS is equal.
- */
-# define MAKE_MM_SEG(s)       ((mm_segment_t) { (s) })
-
-#  ifndef CONFIG_MMU
-#  define KERNEL_DS	MAKE_MM_SEG(0)
-#  define USER_DS	KERNEL_DS
-#  else
-#  define KERNEL_DS	MAKE_MM_SEG(0xFFFFFFFF)
-#  define USER_DS	MAKE_MM_SEG(TASK_SIZE - 1)
-#  endif
-
-# define get_ds()	(KERNEL_DS)
-# define get_fs()	(current_thread_info()->addr_limit)
-# define set_fs(val)	(current_thread_info()->addr_limit = (val))
-
-# define segment_eq(a, b)	((a).seg == (b).seg)
-
-# endif /* __ASSEMBLY__ */
-#endif /* _ASM_MICROBLAZE_SEGMENT_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/setup.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/setup.h
--- linux-2.6.31.12/arch/microblaze/include/asm/setup.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/setup.h	2010-08-08 17:40:15.853537674 +0200
@@ -35,10 +35,13 @@ extern void mmu_reset(void);
 extern void early_console_reg_tlb_alloc(unsigned int addr);
 #   endif /* CONFIG_MMU */
 
+extern void of_platform_reset_gpio_probe(void);
+
 void time_init(void);
 void init_IRQ(void);
 void machine_early_init(const char *cmdline, unsigned int ram,
-						unsigned int fdt);
+		unsigned int fdt, unsigned int msr, unsigned int tlb0,
+		unsigned int tlb1);
 
 void machine_restart(char *cmd);
 void machine_shutdown(void);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/syscall.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/syscall.h
--- linux-2.6.31.12/arch/microblaze/include/asm/syscall.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/syscall.h	2010-08-08 17:22:50.557036231 +0200
@@ -0,0 +1,99 @@
+#ifndef __ASM_MICROBLAZE_SYSCALL_H
+#define __ASM_MICROBLAZE_SYSCALL_H
+
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <asm/ptrace.h>
+
+/* The system call number is given by the user in R12 */
+static inline long syscall_get_nr(struct task_struct *task,
+				  struct pt_regs *regs)
+{
+	return regs->r12;
+}
+
+static inline void syscall_rollback(struct task_struct *task,
+				    struct pt_regs *regs)
+{
+	/* TODO.  */
+}
+
+static inline long syscall_get_error(struct task_struct *task,
+				     struct pt_regs *regs)
+{
+	return IS_ERR_VALUE(regs->r3) ? regs->r3 : 0;
+}
+
+static inline long syscall_get_return_value(struct task_struct *task,
+					    struct pt_regs *regs)
+{
+	return regs->r3;
+}
+
+static inline void syscall_set_return_value(struct task_struct *task,
+					    struct pt_regs *regs,
+					    int error, long val)
+{
+	if (error)
+		regs->r3 = -error;
+	else
+		regs->r3 = val;
+}
+
+static inline microblaze_reg_t microblaze_get_syscall_arg(struct pt_regs *regs,
+							  unsigned int n)
+{
+	switch (n) {
+	case 5: return regs->r10;
+	case 4: return regs->r9;
+	case 3: return regs->r8;
+	case 2: return regs->r7;
+	case 1: return regs->r6;
+	case 0: return regs->r5;
+	default:
+		BUG();
+	}
+	return ~0;
+}
+
+static inline void microblaze_set_syscall_arg(struct pt_regs *regs,
+					      unsigned int n,
+					      unsigned long val)
+{
+	switch (n) {
+	case 5:
+		regs->r10 = val;
+	case 4:
+		regs->r9 = val;
+	case 3:
+		regs->r8 = val;
+	case 2:
+		regs->r7 = val;
+	case 1:
+		regs->r6 = val;
+	case 0:
+		regs->r5 = val;
+	default:
+		BUG();
+	}
+}
+
+static inline void syscall_get_arguments(struct task_struct *task,
+					 struct pt_regs *regs,
+					 unsigned int i, unsigned int n,
+					 unsigned long *args)
+{
+	while (n--)
+		*args++ = microblaze_get_syscall_arg(regs, i++);
+}
+
+static inline void syscall_set_arguments(struct task_struct *task,
+					 struct pt_regs *regs,
+					 unsigned int i, unsigned int n,
+					 const unsigned long *args)
+{
+	while (n--)
+		microblaze_set_syscall_arg(regs, i++, *args++);
+}
+
+#endif /* __ASM_MICROBLAZE_SYSCALL_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/system.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/system.h
--- linux-2.6.31.12/arch/microblaze/include/asm/system.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/system.h	2010-08-08 17:40:15.853537674 +0200
@@ -12,10 +12,13 @@
 #include <asm/registers.h>
 #include <asm/setup.h>
 #include <asm/irqflags.h>
+#include <asm/cache.h>
 
 #include <asm-generic/cmpxchg.h>
 #include <asm-generic/cmpxchg-local.h>
 
+#define __ARCH_WANT_INTERRUPTS_ON_CTXSW
+
 struct task_struct;
 struct thread_info;
 
@@ -83,12 +86,26 @@ void default_idle(void);
 void free_init_pages(char *what, unsigned long begin, unsigned long end);
 void free_initmem(void);
 extern char *klimit;
+extern unsigned long kernel_tlb;
 extern void ret_from_fork(void);
 
+extern void *alloc_maybe_bootmem(size_t size, gfp_t mask);
+extern void *zalloc_maybe_bootmem(size_t size, gfp_t mask);
+
 #ifdef CONFIG_DEBUG_FS
 extern struct dentry *of_debugfs_root;
 #endif
 
 #define arch_align_stack(x) (x)
 
+/*
+ * MicroBlaze doesn't handle unaligned accesses in hardware.
+ *
+ * Based on this we force the IP header alignment in network drivers.
+ * We also modify NET_SKB_PAD to be a cacheline in size, thus maintaining
+ * cacheline alignment of buffers.
+ */
+#define NET_IP_ALIGN	2
+#define NET_SKB_PAD	L1_CACHE_BYTES
+
 #endif /* _ASM_MICROBLAZE_SYSTEM_H */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/thread_info.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/thread_info.h
--- linux-2.6.31.12/arch/microblaze/include/asm/thread_info.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/thread_info.h	2010-08-08 17:40:15.853537674 +0200
@@ -19,7 +19,6 @@
 #ifndef __ASSEMBLY__
 # include <linux/types.h>
 # include <asm/processor.h>
-# include <asm/segment.h>
 
 /*
  * low level task data that entry.S needs immediate access to
@@ -60,6 +59,10 @@ struct cpu_context {
 	__u32	fsr;
 };
 
+typedef struct {
+	unsigned long seg;
+} mm_segment_t;
+
 struct thread_info {
 	struct task_struct	*task; /* main task structure */
 	struct exec_domain	*exec_domain; /* execution domain */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/tlbflush.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/tlbflush.h
--- linux-2.6.31.12/arch/microblaze/include/asm/tlbflush.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/tlbflush.h	2010-08-08 17:40:15.853537674 +0200
@@ -23,7 +23,8 @@
 extern void _tlbie(unsigned long address);
 extern void _tlbia(void);
 
-#define __tlbia()	_tlbia()
+#define __tlbia()	{ preempt_disable(); _tlbia(); preempt_enable(); }
+#define __tlbie(x)	{ _tlbie(x); }
 
 static inline void local_flush_tlb_all(void)
 	{ __tlbia(); }
@@ -31,7 +32,7 @@ static inline void local_flush_tlb_mm(st
 	{ __tlbia(); }
 static inline void local_flush_tlb_page(struct vm_area_struct *vma,
 				unsigned long vmaddr)
-	{ _tlbie(vmaddr); }
+	{ __tlbie(vmaddr); }
 static inline void local_flush_tlb_range(struct vm_area_struct *vma,
 		unsigned long start, unsigned long end)
 	{ __tlbia(); }
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/uaccess.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/uaccess.h
--- linux-2.6.31.12/arch/microblaze/include/asm/uaccess.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/uaccess.h	2010-08-08 17:40:15.853537674 +0200
@@ -22,101 +22,73 @@
 #include <asm/mmu.h>
 #include <asm/page.h>
 #include <asm/pgtable.h>
-#include <asm/segment.h>
 #include <linux/string.h>
 
 #define VERIFY_READ	0
 #define VERIFY_WRITE	1
 
-#define __clear_user(addr, n)	(memset((void *)(addr), 0, (n)), 0)
-
-#ifndef CONFIG_MMU
-
-extern int ___range_ok(unsigned long addr, unsigned long size);
-
-#define __range_ok(addr, size) \
-		___range_ok((unsigned long)(addr), (unsigned long)(size))
-
-#define access_ok(type, addr, size) (__range_ok((addr), (size)) == 0)
-#define __access_ok(add, size) (__range_ok((addr), (size)) == 0)
-
-/* Undefined function to trigger linker error */
-extern int bad_user_access_length(void);
+/*
+ * On Microblaze the fs value is actually the top of the corresponding
+ * address space.
+ *
+ * The fs value determines whether argument validity checking should be
+ * performed or not. If get_fs() == USER_DS, checking is performed, with
+ * get_fs() == KERNEL_DS, checking is bypassed.
+ *
+ * For historical reasons, these macros are grossly misnamed.
+ *
+ * For non-MMU arch like Microblaze, KERNEL_DS and USER_DS is equal.
+ */
+# define MAKE_MM_SEG(s)       ((mm_segment_t) { (s) })
 
-/* FIXME this is function for optimalization -> memcpy */
-#define __get_user(var, ptr)				\
-({							\
-	int __gu_err = 0;				\
-	switch (sizeof(*(ptr))) {			\
-	case 1:						\
-	case 2:						\
-	case 4:						\
-		(var) = *(ptr);				\
-		break;					\
-	case 8:						\
-		memcpy((void *) &(var), (ptr), 8);	\
-		break;					\
-	default:					\
-		(var) = 0;				\
-		__gu_err = __get_user_bad();		\
-		break;					\
-	}						\
-	__gu_err;					\
-})
+#  ifndef CONFIG_MMU
+#  define KERNEL_DS	MAKE_MM_SEG(0)
+#  define USER_DS	KERNEL_DS
+#  else
+#  define KERNEL_DS	MAKE_MM_SEG(0xFFFFFFFF)
+#  define USER_DS	MAKE_MM_SEG(TASK_SIZE - 1)
+#  endif
+
+# define get_ds()	(KERNEL_DS)
+# define get_fs()	(current_thread_info()->addr_limit)
+# define set_fs(val)	(current_thread_info()->addr_limit = (val))
 
-#define __get_user_bad()	(bad_user_access_length(), (-EFAULT))
+# define segment_eq(a, b)	((a).seg == (b).seg)
 
-/* FIXME is not there defined __pu_val */
-#define __put_user(var, ptr)					\
-({								\
-	int __pu_err = 0;					\
-	switch (sizeof(*(ptr))) {				\
-	case 1:							\
-	case 2:							\
-	case 4:							\
-		*(ptr) = (var);					\
-		break;						\
-	case 8: {						\
-		typeof(*(ptr)) __pu_val = (var);		\
-		memcpy(ptr, &__pu_val, sizeof(__pu_val));	\
-		}						\
-		break;						\
-	default:						\
-		__pu_err = __put_user_bad();			\
-		break;						\
-	}							\
-	__pu_err;						\
-})
-
-#define __put_user_bad()	(bad_user_access_length(), (-EFAULT))
-
-#define put_user(x, ptr)	__put_user((x), (ptr))
-#define get_user(x, ptr)	__get_user((x), (ptr))
+/*
+ * The exception table consists of pairs of addresses: the first is the
+ * address of an instruction that is allowed to fault, and the second is
+ * the address at which the program should continue. No registers are
+ * modified, so it is entirely up to the continuation code to figure out
+ * what to do.
+ *
+ * All the routines below use bits of fixup code that are out of line
+ * with the main instruction path. This means when everything is well,
+ * we don't even have to jump over them. Further, they do not intrude
+ * on our cache or tlb entries.
+ */
+struct exception_table_entry {
+	unsigned long insn, fixup;
+};
 
-#define copy_to_user(to, from, n)	(memcpy((to), (from), (n)), 0)
-#define copy_from_user(to, from, n)	(memcpy((to), (from), (n)), 0)
+/* Returns 0 if exception not found and fixup otherwise.  */
+extern unsigned long search_exception_table(unsigned long);
 
-#define __copy_to_user(to, from, n)	(copy_to_user((to), (from), (n)))
-#define __copy_from_user(to, from, n)	(copy_from_user((to), (from), (n)))
-#define __copy_to_user_inatomic(to, from, n) \
-			(__copy_to_user((to), (from), (n)))
-#define __copy_from_user_inatomic(to, from, n) \
-			(__copy_from_user((to), (from), (n)))
+#ifndef CONFIG_MMU
 
-static inline unsigned long clear_user(void *addr, unsigned long size)
+/* Check against bounds of physical memory */
+static inline int ___range_ok(unsigned long addr, unsigned long size)
 {
-	if (access_ok(VERIFY_WRITE, addr, size))
-		size = __clear_user(addr, size);
-	return size;
+	return ((addr < memory_start) ||
+		((addr + size) > memory_end));
 }
 
-/* Returns 0 if exception not found and fixup otherwise.  */
-extern unsigned long search_exception_table(unsigned long);
+#define __range_ok(addr, size) \
+		___range_ok((unsigned long)(addr), (unsigned long)(size))
 
-extern long strncpy_from_user(char *dst, const char *src, long count);
-extern long strnlen_user(const char *src, long count);
+#define access_ok(type, addr, size) (__range_ok((addr), (size)) == 0)
 
-#else /* CONFIG_MMU */
+#else
 
 /*
  * Address is valid if:
@@ -129,22 +101,119 @@ extern long strnlen_user(const char *src
 /* || printk("access_ok failed for %s at 0x%08lx (size %d), seg 0x%08x\n",
  type?"WRITE":"READ",addr,size,get_fs().seg)) */
 
-/*
- * All the __XXX versions macros/functions below do not perform
- * access checking. It is assumed that the necessary checks have been
- * already performed before the finction (macro) is called.
- */
+#endif
 
-#define get_user(x, ptr)						\
-({									\
-	access_ok(VERIFY_READ, (ptr), sizeof(*(ptr)))			\
-		? __get_user((x), (ptr)) : -EFAULT;			\
+#ifdef CONFIG_MMU
+# define __FIXUP_SECTION	".section .fixup,\"ax\"\n"
+# define __EX_TABLE_SECTION	".section __ex_table,\"a\"\n"
+#else
+# define __FIXUP_SECTION	".section .discard,\"ax\"\n"
+# define __EX_TABLE_SECTION	".section .discard,\"a\"\n"
+#endif
+
+extern unsigned long __copy_tofrom_user(void __user *to,
+		const void __user *from, unsigned long size);
+
+/* Return: number of not copied bytes, i.e. 0 if OK or non-zero if fail. */
+static inline unsigned long __must_check __clear_user(void __user *to,
+							unsigned long n)
+{
+	/* normal memset with two words to __ex_table */
+	__asm__ __volatile__ (				\
+			"1:	sb	r0, %2, r0;"	\
+			"	addik	%0, %0, -1;"	\
+			"	bneid	%0, 1b;"	\
+			"	addik	%2, %2, 1;"	\
+			"2:			"	\
+			__EX_TABLE_SECTION		\
+			".word	1b,2b;"			\
+			".previous;"			\
+		: "=r"(n)				\
+		: "0"(n), "r"(to)
+	);
+	return n;
+}
+
+static inline unsigned long __must_check clear_user(void __user *to,
+							unsigned long n)
+{
+	might_sleep();
+	if (unlikely(!access_ok(VERIFY_WRITE, to, n)))
+		return n;
+
+	return __clear_user(to, n);
+}
+
+/* put_user and get_user macros */
+extern long __user_bad(void);
+
+#define __get_user_asm(insn, __gu_ptr, __gu_val, __gu_err)	\
+({								\
+	__asm__ __volatile__ (					\
+			"1:"	insn	" %1, %2, r0;"		\
+			"	addk	%0, r0, r0;"		\
+			"2:			"		\
+			__FIXUP_SECTION				\
+			"3:	brid	2b;"			\
+			"	addik	%0, r0, %3;"		\
+			".previous;"				\
+			__EX_TABLE_SECTION			\
+			".word	1b,3b;"				\
+			".previous;"				\
+		: "=&r"(__gu_err), "=r"(__gu_val)		\
+		: "r"(__gu_ptr), "i"(-EFAULT)			\
+	);							\
 })
 
-#define put_user(x, ptr)						\
+/**
+ * get_user: - Get a simple variable from user space.
+ * @x:   Variable to store result.
+ * @ptr: Source address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple variable from user space to kernel
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and the result of
+ * dereferencing @ptr must be assignable to @x without a cast.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ * On error, the variable @x is set to zero.
+ */
+#define get_user(x, ptr)						\
+	__get_user_check((x), (ptr), sizeof(*(ptr)))
+
+#define __get_user_check(x, ptr, size)					\
 ({									\
-	access_ok(VERIFY_WRITE, (ptr), sizeof(*(ptr)))			\
-		? __put_user((x), (ptr)) : -EFAULT;			\
+	unsigned long __gu_val = 0;					\
+	const typeof(*(ptr)) __user *__gu_addr = (ptr);			\
+	int __gu_err = 0;						\
+									\
+	if (access_ok(VERIFY_READ, __gu_addr, size)) {			\
+		switch (size) {						\
+		case 1:							\
+			__get_user_asm("lbu", __gu_addr, __gu_val,	\
+				       __gu_err);			\
+			break;						\
+		case 2:							\
+			__get_user_asm("lhu", __gu_addr, __gu_val,	\
+				       __gu_err);			\
+			break;						\
+		case 4:							\
+			__get_user_asm("lw", __gu_addr, __gu_val,	\
+				       __gu_err);			\
+			break;						\
+		default:						\
+			__gu_err = __user_bad();			\
+			break;						\
+		}							\
+	} else {							\
+		__gu_err = -EFAULT;					\
+	}								\
+	x = (typeof(*(ptr)))__gu_val;					\
+	__gu_err;							\
 })
 
 #define __get_user(x, ptr)						\
@@ -163,28 +232,102 @@ extern long strnlen_user(const char *src
 		__get_user_asm("lw", (ptr), __gu_val, __gu_err);	\
 		break;							\
 	default:							\
-		__gu_val = 0; __gu_err = -EINVAL;			\
+		/* __gu_val = 0; __gu_err = -EINVAL;*/ __gu_err = __user_bad();\
 	}								\
 	x = (__typeof__(*(ptr))) __gu_val;				\
 	__gu_err;							\
 })
 
-#define __get_user_asm(insn, __gu_ptr, __gu_val, __gu_err)		\
+
+#define __put_user_asm(insn, __gu_ptr, __gu_val, __gu_err)	\
+({								\
+	__asm__ __volatile__ (					\
+			"1:"	insn	" %1, %2, r0;"		\
+			"	addk	%0, r0, r0;"		\
+			"2:			"		\
+			__FIXUP_SECTION				\
+			"3:	brid	2b;"			\
+			"	addik	%0, r0, %3;"		\
+			".previous;"				\
+			__EX_TABLE_SECTION			\
+			".word	1b,3b;"				\
+			".previous;"				\
+		: "=&r"(__gu_err)				\
+		: "r"(__gu_val), "r"(__gu_ptr), "i"(-EFAULT)	\
+	);							\
+})
+
+#define __put_user_asm_8(__gu_ptr, __gu_val, __gu_err)		\
+({								\
+	__asm__ __volatile__ ("	lwi	%0, %1, 0;"		\
+			"1:	swi	%0, %2, 0;"		\
+			"	lwi	%0, %1, 4;"		\
+			"2:	swi	%0, %2, 4;"		\
+			"	addk	%0, r0, r0;"		\
+			"3:			"		\
+			__FIXUP_SECTION				\
+			"4:	brid	3b;"			\
+			"	addik	%0, r0, %3;"		\
+			".previous;"				\
+			__EX_TABLE_SECTION			\
+			".word	1b,4b,2b,4b;"			\
+			".previous;"				\
+		: "=&r"(__gu_err)				\
+		: "r"(&__gu_val), "r"(__gu_ptr), "i"(-EFAULT)	\
+		);						\
+})
+
+/**
+ * put_user: - Write a simple value into user space.
+ * @x:   Value to copy to user space.
+ * @ptr: Destination address, in user space.
+ *
+ * Context: User context only.  This function may sleep.
+ *
+ * This macro copies a single simple value from kernel space to user
+ * space.  It supports simple types like char and int, but not larger
+ * data types like structures or arrays.
+ *
+ * @ptr must have pointer-to-simple-variable type, and @x must be assignable
+ * to the result of dereferencing @ptr.
+ *
+ * Returns zero on success, or -EFAULT on error.
+ */
+#define put_user(x, ptr)						\
+	__put_user_check((x), (ptr), sizeof(*(ptr)))
+
+#define __put_user_check(x, ptr, size)					\
 ({									\
-	__asm__ __volatile__ (						\
-			"1:"	insn	" %1, %2, r0;			\
-				addk	%0, r0, r0;			\
-			2:						\
-			.section .fixup,\"ax\";				\
-			3:	brid	2b;				\
-				addik	%0, r0, %3;			\
-			.previous;					\
-			.section __ex_table,\"a\";			\
-			.word	1b,3b;					\
-			.previous;"					\
-		: "=r"(__gu_err), "=r"(__gu_val)			\
-		: "r"(__gu_ptr), "i"(-EFAULT)				\
-	);								\
+	typeof(*(ptr)) __pu_val;					\
+	typeof(*(ptr)) __user *__pu_addr = (ptr);			\
+	int __pu_err = 0;						\
+									\
+	__pu_val = (x);							\
+	if (access_ok(VERIFY_WRITE, __pu_addr, size)) {			\
+		switch (size) {						\
+		case 1:							\
+			__put_user_asm("sb", __pu_addr, __pu_val,	\
+				       __pu_err);			\
+			break;						\
+		case 2:							\
+			__put_user_asm("sh", __pu_addr, __pu_val,	\
+				       __pu_err);			\
+			break;						\
+		case 4:							\
+			__put_user_asm("sw", __pu_addr, __pu_val,	\
+				       __pu_err);			\
+			break;						\
+		case 8:							\
+			__put_user_asm_8(__pu_addr, __pu_val, __pu_err);\
+			break;						\
+		default:						\
+			__pu_err = __user_bad();			\
+			break;						\
+		}							\
+	} else {							\
+		__pu_err = -EFAULT;					\
+	}								\
+	__pu_err;							\
 })
 
 #define __put_user(x, ptr)						\
@@ -195,7 +338,7 @@ extern long strnlen_user(const char *src
 	case 1:								\
 		__put_user_asm("sb", (ptr), __gu_val, __gu_err);	\
 		break;							\
-	case 2: 							\
+	case 2:								\
 		__put_user_asm("sh", (ptr), __gu_val, __gu_err);	\
 		break;							\
 	case 4:								\
@@ -205,121 +348,70 @@ extern long strnlen_user(const char *src
 		__put_user_asm_8((ptr), __gu_val, __gu_err);		\
 		break;							\
 	default:							\
-		__gu_err = -EINVAL;					\
+		/*__gu_err = -EINVAL;*/	__gu_err = __user_bad();	\
 	}								\
 	__gu_err;							\
 })
 
-#define __put_user_asm_8(__gu_ptr, __gu_val, __gu_err)	\
-({							\
-__asm__ __volatile__ ("	lwi	%0, %1, 0;		\
-		1:	swi	%0, %2, 0;		\
-			lwi	%0, %1, 4;		\
-		2:	swi	%0, %2, 4;		\
-			addk	%0,r0,r0;		\
-		3:					\
-		.section .fixup,\"ax\";			\
-		4:	brid	3b;			\
-			addik	%0, r0, %3;		\
-		.previous;				\
-		.section __ex_table,\"a\";		\
-		.word	1b,4b,2b,4b;			\
-		.previous;"				\
-	: "=&r"(__gu_err)				\
-	: "r"(&__gu_val),				\
-	"r"(__gu_ptr), "i"(-EFAULT)			\
-	);						\
-})
 
-#define __put_user_asm(insn, __gu_ptr, __gu_val, __gu_err)	\
-({								\
-	__asm__ __volatile__ (					\
-			"1:"	insn	" %1, %2, r0;		\
-				addk	%0, r0, r0;		\
-			2:					\
-			.section .fixup,\"ax\";			\
-			3:	brid	2b;			\
-				addik	%0, r0, %3;		\
-			.previous;				\
-			.section __ex_table,\"a\";		\
-			.word	1b,3b;				\
-			.previous;"				\
-		: "=r"(__gu_err)				\
-		: "r"(__gu_val), "r"(__gu_ptr), "i"(-EFAULT)	\
-	);							\
-})
+/* copy_to_from_user */
+#define __copy_from_user(to, from, n)	\
+	__copy_tofrom_user((__force void __user *)(to), \
+				(void __user *)(from), (n))
+#define __copy_from_user_inatomic(to, from, n) \
+		__copy_from_user((to), (from), (n))
 
-/*
- * Return: number of not copied bytes, i.e. 0 if OK or non-zero if fail.
- */
-static inline int clear_user(char *to, int size)
+static inline long copy_from_user(void *to,
+		const void __user *from, unsigned long n)
 {
-	if (size && access_ok(VERIFY_WRITE, to, size)) {
-		__asm__ __volatile__ ("				\
-				1:				\
-					sb	r0, %2, r0;	\
-					addik	%0, %0, -1;	\
-					bneid	%0, 1b;		\
-					addik	%2, %2, 1;	\
-				2:				\
-				.section __ex_table,\"a\";	\
-				.word	1b,2b;			\
-				.section .text;"		\
-			: "=r"(size)				\
-			: "0"(size), "r"(to)
-		);
-	}
-	return size;
+	might_sleep();
+	if (access_ok(VERIFY_READ, from, n))
+		return __copy_from_user(to, from, n);
+	return n;
 }
 
-extern unsigned long __copy_tofrom_user(void __user *to,
-		const void __user *from, unsigned long size);
-
-#define copy_to_user(to, from, n)					\
-	(access_ok(VERIFY_WRITE, (to), (n)) ?				\
-		__copy_tofrom_user((void __user *)(to),			\
-			(__force const void __user *)(from), (n))	\
-		: -EFAULT)
-
-#define __copy_to_user(to, from, n)	copy_to_user((to), (from), (n))
-#define __copy_to_user_inatomic(to, from, n)	copy_to_user((to), (from), (n))
-
-#define copy_from_user(to, from, n)					\
-	(access_ok(VERIFY_READ, (from), (n)) ?				\
-		__copy_tofrom_user((__force void __user *)(to),		\
-			(void __user *)(from), (n))			\
-		: -EFAULT)
+#define __copy_to_user(to, from, n)	\
+		__copy_tofrom_user((void __user *)(to), \
+			(__force const void __user *)(from), (n))
+#define __copy_to_user_inatomic(to, from, n) __copy_to_user((to), (from), (n))
 
-#define __copy_from_user(to, from, n)	copy_from_user((to), (from), (n))
-#define __copy_from_user_inatomic(to, from, n) \
-		copy_from_user((to), (from), (n))
+static inline long copy_to_user(void __user *to,
+		const void *from, unsigned long n)
+{
+	might_sleep();
+	if (access_ok(VERIFY_WRITE, to, n))
+		return __copy_to_user(to, from, n);
+	return n;
+}
 
+/*
+ * Copy a null terminated string from userspace.
+ */
 extern int __strncpy_user(char *to, const char __user *from, int len);
-extern int __strnlen_user(const char __user *sstr, int len);
 
-#define strncpy_from_user(to, from, len)	\
-		(access_ok(VERIFY_READ, from, 1) ?	\
-			__strncpy_user(to, from, len) : -EFAULT)
-#define strnlen_user(str, len)	\
-		(access_ok(VERIFY_READ, str, 1) ? __strnlen_user(str, len) : 0)
+#define __strncpy_from_user	__strncpy_user
 
-#endif /* CONFIG_MMU */
+static inline long
+strncpy_from_user(char *dst, const char __user *src, long count)
+{
+	if (!access_ok(VERIFY_READ, src, 1))
+		return -EFAULT;
+	return __strncpy_from_user(dst, src, count);
+}
 
 /*
- * The exception table consists of pairs of addresses: the first is the
- * address of an instruction that is allowed to fault, and the second is
- * the address at which the program should continue. No registers are
- * modified, so it is entirely up to the continuation code to figure out
- * what to do.
+ * Return the size of a string (including the ending 0)
  *
- * All the routines below use bits of fixup code that are out of line
- * with the main instruction path. This means when everything is well,
- * we don't even have to jump over them. Further, they do not intrude
- * on our cache or tlb entries.
+ * Return 0 on exception, a value greater than N if too long
  */
-struct exception_table_entry {
-	unsigned long insn, fixup;
-};
+extern int __strnlen_user(const char __user *sstr, int len);
+
+static inline long strnlen_user(const char __user *src, long n)
+{
+	if (!access_ok(VERIFY_READ, src, 1))
+		return 0;
+	return __strnlen_user(src, n);
+}
 
 #endif  /* __ASSEMBLY__ */
 #endif /* __KERNEL__ */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/include/asm/unistd.h linux-2.6.31.12-petalinux/arch/microblaze/include/asm/unistd.h
--- linux-2.6.31.12/arch/microblaze/include/asm/unistd.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/include/asm/unistd.h	2010-08-08 17:40:15.853537674 +0200
@@ -377,7 +377,7 @@
 #define __NR_shutdown		359 /* new */
 #define __NR_sendmsg		360 /* new */
 #define __NR_recvmsg		361 /* new */
-#define __NR_accept04		362 /* new */
+#define __NR_accept4		362 /* new */
 #define __NR_preadv		363 /* new */
 #define __NR_pwritev		364 /* new */
 #define __NR_rt_tgsigqueueinfo	365 /* new */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/Kconfig linux-2.6.31.12-petalinux/arch/microblaze/Kconfig
--- linux-2.6.31.12/arch/microblaze/Kconfig	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/Kconfig	2010-08-08 17:40:15.849523897 +0200
@@ -6,7 +6,17 @@ mainmenu "Linux/Microblaze Kernel Config
 config MICROBLAZE
 	def_bool y
 	select HAVE_LMB
+	select HAVE_FUNCTION_TRACER
+	select HAVE_FUNCTION_TRACE_MCOUNT_TEST
+	select HAVE_FUNCTION_GRAPH_TRACER
+	select HAVE_DYNAMIC_FTRACE
+	select HAVE_FTRACE_MCOUNT_RECORD
+	select USB_ARCH_HAS_EHCI
 	select ARCH_WANT_OPTIONAL_GPIOLIB
+	select HAVE_OPROFILE
+	select HAVE_DMA_ATTRS
+	select HAVE_DMA_API_DEBUG
+	select TRACING_SUPPORT
 
 config SWAP
 	def_bool n
@@ -56,10 +66,16 @@ config GENERIC_GPIO
 config GENERIC_CSUM
 	def_bool y
 
-config PCI
-	def_bool n
+config STACKTRACE_SUPPORT
+	def_bool y
+
+config LOCKDEP_SUPPORT
+	def_bool y
 
-config NO_DMA
+config HAVE_LATENCYTOP_SUPPORT
+	def_bool y
+
+config DTC
 	def_bool y
 
 source "init/Kconfig"
@@ -70,7 +86,7 @@ source "arch/microblaze/platform/Kconfig
 
 menu "Processor type and features"
 
-source kernel/time/Kconfig
+source "kernel/time/Kconfig"
 
 source "kernel/Kconfig.preempt"
 
@@ -200,6 +216,10 @@ config TASK_SIZE
 	depends on MMU
 	default "0x80000000"
 
+config KERNEL_PAD
+	hex "Kernel PAD for unpacking" if ADVANCED_OPTIONS
+	default "0x80000" if MMU
+
 config CONSISTENT_START_BOOL
 	bool "Set custom consistent memory pool address"
 	depends on ADVANCED_OPTIONS && NOT_COHERENT_CACHE
@@ -236,6 +256,25 @@ source "fs/Kconfig.binfmt"
 
 endmenu
 
+menu "Bus Options"
+
+config PCI
+	bool "PCI support"
+
+config PCI_DOMAINS
+	def_bool PCI
+
+config PCI_SYSCALL
+	def_bool PCI
+
+config PCI_XILINX
+	bool "Xilinx PCI host bridge support"
+	depends on PCI
+
+source "drivers/pci/Kconfig"
+
+endmenu
+
 source "net/Kconfig"
 
 source "drivers/Kconfig"
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/Kconfig.debug linux-2.6.31.12-petalinux/arch/microblaze/Kconfig.debug
--- linux-2.6.31.12/arch/microblaze/Kconfig.debug	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/Kconfig.debug	2010-08-08 17:22:50.535773472 +0200
@@ -3,6 +3,9 @@
 
 menu "Kernel hacking"
 
+config TRACE_IRQFLAGS_SUPPORT
+	def_bool y
+
 source "lib/Kconfig.debug"
 
 config EARLY_PRINTK
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/asm-offsets.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/asm-offsets.c
--- linux-2.6.31.12/arch/microblaze/kernel/asm-offsets.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/asm-offsets.c	2010-08-08 17:40:15.853537674 +0200
@@ -16,6 +16,7 @@
 #include <linux/hardirq.h>
 #include <linux/thread_info.h>
 #include <linux/kbuild.h>
+#include <asm/cpuinfo.h>
 
 int main(int argc, char *argv[])
 {
@@ -90,6 +91,7 @@ int main(int argc, char *argv[])
 	DEFINE(TI_FLAGS, offsetof(struct thread_info, flags));
 	DEFINE(TI_ADDR_LIMIT, offsetof(struct thread_info, addr_limit));
 	DEFINE(TI_CPU_CONTEXT, offsetof(struct thread_info, cpu_context));
+	DEFINE(TI_PREEMPT_COUNT, offsetof(struct thread_info, preempt_count));
 	BLANK();
 
 	/* struct cpu_context */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/cpu/cache.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/cache.c
--- linux-2.6.31.12/arch/microblaze/kernel/cpu/cache.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/cache.c	2010-08-08 17:40:15.853537674 +0200
@@ -3,7 +3,7 @@
  *
  * Copyright (C) 2007-2009 Michal Simek <monstr@monstr.eu>
  * Copyright (C) 2007-2009 PetaLogix
- * Copyright (C) 2007 John Williams <john.williams@petalogix.com>
+ * Copyright (C) 2007-2009 John Williams <john.williams@petalogix.com>
  *
  * This file is subject to the terms and conditions of the GNU General
  * Public License. See the file COPYING in the main directory of this
@@ -13,243 +13,655 @@
 #include <asm/cacheflush.h>
 #include <linux/cache.h>
 #include <asm/cpuinfo.h>
+#include <asm/pvr.h>
 
-/* Exported functions */
+static inline void __enable_icache_msr(void)
+{
+	__asm__ __volatile__ ("	msrset	r0, %0;		\
+				nop; "			\
+			: : "i" (MSR_ICE) : "memory");
+}
+
+static inline void __disable_icache_msr(void)
+{
+	__asm__ __volatile__ ("	msrclr	r0, %0;		\
+				nop; "			\
+			: : "i" (MSR_ICE) : "memory");
+}
 
-void _enable_icache(void)
+static inline void __enable_dcache_msr(void)
 {
-	if (cpuinfo.use_icache) {
-#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
-		__asm__ __volatile__ ("					\
-				msrset	r0, %0;				\
-				nop; "					\
-				:					\
-				: "i" (MSR_ICE)				\
+	__asm__ __volatile__ ("	msrset	r0, %0;		\
+				nop; "			\
+				:			\
+				: "i" (MSR_DCE)		\
 				: "memory");
-#else
-		__asm__ __volatile__ ("					\
-				mfs	r12, rmsr;			\
-				nop;					\
-				ori	r12, r12, %0;			\
-				mts	rmsr, r12;			\
-				nop; "					\
-				:					\
-				: "i" (MSR_ICE)				\
-				: "memory", "r12");
-#endif
-	}
 }
 
-void _disable_icache(void)
+static inline void __disable_dcache_msr(void)
 {
-	if (cpuinfo.use_icache) {
-#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
-		__asm__ __volatile__ ("					\
-				msrclr r0, %0;				\
-				nop; "					\
-				:					\
-				: "i" (MSR_ICE)				\
+	__asm__ __volatile__ ("	msrclr	r0, %0;		\
+				nop; "			\
+				:			\
+				: "i" (MSR_DCE)		\
 				: "memory");
-#else
-		__asm__ __volatile__ ("					\
-				mfs	r12, rmsr;			\
-				nop;					\
-				andi	r12, r12, ~%0;			\
-				mts	rmsr, r12;			\
-				nop; "					\
-				:					\
-				: "i" (MSR_ICE)				\
+}
+
+static inline void __enable_icache_nomsr(void)
+{
+	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
+				nop;			\
+				ori	r12, r12, %0;	\
+				mts	rmsr, r12;	\
+				nop; "			\
+				:			\
+				: "i" (MSR_ICE)		\
 				: "memory", "r12");
-#endif
-	}
 }
 
-void _invalidate_icache(unsigned int addr)
+static inline void __disable_icache_nomsr(void)
 {
-	if (cpuinfo.use_icache) {
-		__asm__ __volatile__ ("					\
-				wic	%0, r0"				\
-				:					\
-				: "r" (addr));
-	}
+	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
+				nop;			\
+				andi	r12, r12, ~%0;	\
+				mts	rmsr, r12;	\
+				nop; "			\
+				:			\
+				: "i" (MSR_ICE)		\
+				: "memory", "r12");
 }
 
-void _enable_dcache(void)
+static inline void __enable_dcache_nomsr(void)
 {
-	if (cpuinfo.use_dcache) {
-#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
-		__asm__ __volatile__ ("					\
-				msrset	r0, %0;				\
-				nop; "					\
-				:					\
-				: "i" (MSR_DCE)				\
-				: "memory");
-#else
-		__asm__ __volatile__ ("					\
-				mfs	r12, rmsr;			\
-				nop;					\
-				ori	r12, r12, %0;			\
-				mts	rmsr, r12;			\
-				nop; "					\
-				:					\
-				: "i" (MSR_DCE)			\
+	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
+				nop;			\
+				ori	r12, r12, %0;	\
+				mts	rmsr, r12;	\
+				nop; "			\
+				:			\
+				: "i" (MSR_DCE)		\
+				: "memory", "r12");
+}
+
+static inline void __disable_dcache_nomsr(void)
+{
+	__asm__ __volatile__ ("	mfs	r12, rmsr;	\
+				nop;			\
+				andi	r12, r12, ~%0;	\
+				mts	rmsr, r12;	\
+				nop; "			\
+				:			\
+				: "i" (MSR_DCE)		\
 				: "memory", "r12");
+}
+
+
+/* Helper macro for computing the limits of cache range loops
+ *
+ * End address can be unaligned which is OK for C implementation.
+ * ASM implementation align it in ASM macros
+ */
+#define CACHE_LOOP_LIMITS(start, end, cache_line_length, cache_size)	\
+do {									\
+	int align = ~(cache_line_length - 1);				\
+	end = min(start + cache_size, end);				\
+	start &= align;							\
+} while (0);
+
+/*
+ * Helper macro to loop over the specified cache_size/line_length and
+ * execute 'op' on that cacheline
+ */
+#define CACHE_ALL_LOOP(cache_size, line_length, op)			\
+do {									\
+	unsigned int len = cache_size - line_length;			\
+	int step = -line_length;					\
+	WARN_ON(step >= 0);						\
+									\
+	__asm__ __volatile__ (" 1:      " #op " %0, r0;			\
+					bgtid   %0, 1b;			\
+					addk    %0, %0, %1;		\
+					" : : "r" (len), "r" (step)	\
+					: "memory");			\
+} while (0);
+
+/* Used for wdc.flush/clear which can use rB for offset which is not possible
+ * to use for simple wdc or wic.
+ *
+ * start address is cache aligned
+ * end address is not aligned, if end is aligned then I have to substract
+ * cacheline length because I can't flush/invalidate the next cacheline.
+ * If is not, I align it because I will flush/invalidate whole line.
+ */
+#define CACHE_RANGE_LOOP_2(start, end, line_length, op)			\
+do {									\
+	int step = -line_length;					\
+	int align = ~(line_length - 1);					\
+	int count;							\
+	end = ((end & align) == end) ? end - line_length : end & align;	\
+	count = end - start;						\
+	WARN_ON(count < 0);						\
+									\
+	__asm__ __volatile__ (" 1:	" #op "	%0, %1;			\
+					bgtid	%1, 1b;			\
+					addk	%1, %1, %2;		\
+					" : : "r" (start), "r" (count),	\
+					"r" (step) : "memory");		\
+} while (0);
+
+/* It is used only first parameter for OP - for wic, wdc */
+#define CACHE_RANGE_LOOP_1(start, end, line_length, op)			\
+do {									\
+	int volatile temp;						\
+	int align = ~(line_length - 1);					\
+	end = ((end & align) == end) ? end - line_length : end & align;	\
+	WARN_ON(end - start < 0);					\
+									\
+	__asm__ __volatile__ (" 1:	" #op "	%1, r0;			\
+					cmpu	%0, %1, %2;		\
+					bgtid	%0, 1b;			\
+					addk	%1, %1, %3;		\
+				" : : "r" (temp), "r" (start), "r" (end),\
+					"r" (line_length) : "memory");	\
+} while (0);
+
+#define ASM_LOOP
+
+static void __flush_icache_range_msr_irq(unsigned long start, unsigned long end)
+{
+	unsigned long flags;
+#ifndef ASM_LOOP
+	int i;
 #endif
-	}
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.icache_line_length, cpuinfo.icache_size);
+
+	local_irq_save(flags);
+	__disable_icache_msr();
+
+#ifdef ASM_LOOP
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.icache_line_length, wic);
+#else
+	for (i = start; i < end; i += cpuinfo.icache_line_length)
+		__asm__ __volatile__ ("wic	%0, r0;"	\
+				: : "r" (i));
+#endif
+	__enable_icache_msr();
+	local_irq_restore(flags);
 }
 
-void _disable_dcache(void)
+static void __flush_icache_range_nomsr_irq(unsigned long start,
+				unsigned long end)
 {
-#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
-		__asm__ __volatile__ ("					\
-				msrclr	r0, %0;				\
-				nop; "					\
-				:					\
-				: "i" (MSR_DCE)			\
-				: "memory");
+	unsigned long flags;
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.icache_line_length, cpuinfo.icache_size);
+
+	local_irq_save(flags);
+	__disable_icache_nomsr();
+
+#ifdef ASM_LOOP
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.icache_line_length, wic);
 #else
-		__asm__ __volatile__ ("					\
-				mfs	r12, rmsr;			\
-				nop;					\
-				andi	r12, r12, ~%0;			\
-				mts	rmsr, r12;			\
-				nop; "					\
-				:					\
-				: "i" (MSR_DCE)			\
-				: "memory", "r12");
+	for (i = start; i < end; i += cpuinfo.icache_line_length)
+		__asm__ __volatile__ ("wic	%0, r0;"	\
+				: : "r" (i));
 #endif
+
+	__enable_icache_nomsr();
+	local_irq_restore(flags);
 }
 
-void _invalidate_dcache(unsigned int addr)
+static void __flush_icache_range_noirq(unsigned long start,
+				unsigned long end)
 {
-		__asm__ __volatile__ ("					\
-				wdc	%0, r0"				\
-				:					\
-				: "r" (addr));
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.icache_line_length, cpuinfo.icache_size);
+#ifdef ASM_LOOP
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.icache_line_length, wic);
+#else
+	for (i = start; i < end; i += cpuinfo.icache_line_length)
+		__asm__ __volatile__ ("wic	%0, r0;"	\
+				: : "r" (i));
+#endif
 }
 
-void __invalidate_icache_all(void)
+static void __flush_icache_all_msr_irq(void)
 {
-	unsigned int i;
-	unsigned flags;
+	unsigned long flags;
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s\n", __func__);
 
-	if (cpuinfo.use_icache) {
-		local_irq_save(flags);
-		__disable_icache();
+	local_irq_save(flags);
+	__disable_icache_msr();
+#ifdef ASM_LOOP
+	CACHE_ALL_LOOP(cpuinfo.icache_size, cpuinfo.icache_line_length, wic);
+#else
+	for (i = 0; i < cpuinfo.icache_size;
+		 i += cpuinfo.icache_line_length)
+			__asm__ __volatile__ ("wic	%0, r0;" \
+					: : "r" (i));
+#endif
+	__enable_icache_msr();
+	local_irq_restore(flags);
+}
 
-		/* Just loop through cache size and invalidate, no need to add
-			CACHE_BASE address */
-		for (i = 0; i < cpuinfo.icache_size;
-			i += cpuinfo.icache_line)
-				__invalidate_icache(i);
+static void __flush_icache_all_nomsr_irq(void)
+{
+	unsigned long flags;
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s\n", __func__);
 
-		__enable_icache();
-		local_irq_restore(flags);
-	}
+	local_irq_save(flags);
+	__disable_icache_nomsr();
+#ifdef ASM_LOOP
+	CACHE_ALL_LOOP(cpuinfo.icache_size, cpuinfo.icache_line_length, wic);
+#else
+	for (i = 0; i < cpuinfo.icache_size;
+		 i += cpuinfo.icache_line_length)
+			__asm__ __volatile__ ("wic	%0, r0;" \
+					: : "r" (i));
+#endif
+	__enable_icache_nomsr();
+	local_irq_restore(flags);
 }
 
-void __invalidate_icache_range(unsigned long start, unsigned long end)
+static void __flush_icache_all_noirq(void)
 {
-	unsigned int i;
-	unsigned flags;
-	unsigned int align;
-
-	if (cpuinfo.use_icache) {
-		/*
-		 * No need to cover entire cache range,
-		 * just cover cache footprint
-		 */
-		end = min(start + cpuinfo.icache_size, end);
-		align = ~(cpuinfo.icache_line - 1);
-		start &= align; /* Make sure we are aligned */
-		/* Push end up to the next cache line */
-		end = ((end & align) + cpuinfo.icache_line);
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s\n", __func__);
+#ifdef ASM_LOOP
+	CACHE_ALL_LOOP(cpuinfo.icache_size, cpuinfo.icache_line_length, wic);
+#else
+	for (i = 0; i < cpuinfo.icache_size;
+		 i += cpuinfo.icache_line_length)
+			__asm__ __volatile__ ("wic	%0, r0;" \
+					: : "r" (i));
+#endif
+}
 
-		local_irq_save(flags);
-		__disable_icache();
+static void __invalidate_dcache_all_msr_irq(void)
+{
+	unsigned long flags;
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s\n", __func__);
 
-		for (i = start; i < end; i += cpuinfo.icache_line)
-			__invalidate_icache(i);
+	local_irq_save(flags);
+	__disable_dcache_msr();
+#ifdef ASM_LOOP
+	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length, wdc);
+#else
+	for (i = 0; i < cpuinfo.dcache_size;
+		 i += cpuinfo.dcache_line_length)
+			__asm__ __volatile__ ("wdc	%0, r0;" \
+					: : "r" (i));
+#endif
+	__enable_dcache_msr();
+	local_irq_restore(flags);
+}
 
-		__enable_icache();
-		local_irq_restore(flags);
-	}
+static void __invalidate_dcache_all_nomsr_irq(void)
+{
+	unsigned long flags;
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s\n", __func__);
+
+	local_irq_save(flags);
+	__disable_dcache_nomsr();
+#ifdef ASM_LOOP
+	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length, wdc);
+#else
+	for (i = 0; i < cpuinfo.dcache_size;
+		 i += cpuinfo.dcache_line_length)
+			__asm__ __volatile__ ("wdc	%0, r0;" \
+					: : "r" (i));
+#endif
+	__enable_dcache_nomsr();
+	local_irq_restore(flags);
 }
 
-void __invalidate_icache_page(struct vm_area_struct *vma, struct page *page)
+static void __invalidate_dcache_all_noirq_wt(void)
 {
-	__invalidate_icache_all();
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s\n", __func__);
+#ifdef ASM_LOOP
+	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length, wdc)
+#else
+	for (i = 0; i < cpuinfo.dcache_size;
+		 i += cpuinfo.dcache_line_length)
+			__asm__ __volatile__ ("wdc	%0, r0;" \
+					: : "r" (i));
+#endif
 }
 
-void __invalidate_icache_user_range(struct vm_area_struct *vma,
-				struct page *page, unsigned long adr,
-				int len)
+/* FIXME It is blindly invalidation as is expected
+ * but can't be called on noMMU in microblaze_cache_init below
+ *
+ * MS: noMMU kernel won't boot if simple wdc is used
+ * The reason should be that there are discared data which kernel needs
+ */
+static void __invalidate_dcache_all_wb(void)
 {
-	__invalidate_icache_all();
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s\n", __func__);
+#ifdef ASM_LOOP
+	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length,
+					wdc)
+#else
+	for (i = 0; i < cpuinfo.dcache_size;
+		 i += cpuinfo.dcache_line_length)
+			__asm__ __volatile__ ("wdc	%0, r0;" \
+					: : "r" (i));
+#endif
 }
 
-void __invalidate_cache_sigtramp(unsigned long addr)
+static void __invalidate_dcache_range_wb(unsigned long start,
+						unsigned long end)
 {
-	__invalidate_icache_range(addr, addr + 8);
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
+#ifdef ASM_LOOP
+	CACHE_RANGE_LOOP_2(start, end, cpuinfo.dcache_line_length, wdc.clear);
+#else
+	for (i = start; i < end; i += cpuinfo.dcache_line_length)
+		__asm__ __volatile__ ("wdc.clear	%0, r0;"	\
+				: : "r" (i));
+#endif
 }
 
-void __invalidate_dcache_all(void)
+static void __invalidate_dcache_range_nomsr_wt(unsigned long start,
+							unsigned long end)
 {
-	unsigned int i;
-	unsigned flags;
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
 
-	if (cpuinfo.use_dcache) {
-		local_irq_save(flags);
-		__disable_dcache();
+#ifdef ASM_LOOP
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
+#else
+	for (i = start; i < end; i += cpuinfo.dcache_line_length)
+		__asm__ __volatile__ ("wdc	%0, r0;"	\
+				: : "r" (i));
+#endif
+}
 
-		/*
-		 * Just loop through cache size and invalidate,
-		 * no need to add CACHE_BASE address
-		 */
-		for (i = 0; i < cpuinfo.dcache_size;
-			i += cpuinfo.dcache_line)
-				__invalidate_dcache(i);
+static void __invalidate_dcache_range_msr_irq_wt(unsigned long start,
+							unsigned long end)
+{
+	unsigned long flags;
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
 
-		__enable_dcache();
-		local_irq_restore(flags);
-	}
+	local_irq_save(flags);
+	__disable_dcache_msr();
+
+#ifdef ASM_LOOP
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
+#else
+	for (i = start; i < end; i += cpuinfo.dcache_line_length)
+		__asm__ __volatile__ ("wdc	%0, r0;"	\
+				: : "r" (i));
+#endif
+
+	__enable_dcache_msr();
+	local_irq_restore(flags);
 }
 
-void __invalidate_dcache_range(unsigned long start, unsigned long end)
+static void __invalidate_dcache_range_nomsr_irq(unsigned long start,
+							unsigned long end)
 {
-	unsigned int i;
-	unsigned flags;
-	unsigned int align;
-
-	if (cpuinfo.use_dcache) {
-		/*
-		 * No need to cover entire cache range,
-		 * just cover cache footprint
-		 */
-		end = min(start + cpuinfo.dcache_size, end);
-		align = ~(cpuinfo.dcache_line - 1);
-		start &= align; /* Make sure we are aligned */
-		/* Push end up to the next cache line */
-		end = ((end & align) + cpuinfo.dcache_line);
-		local_irq_save(flags);
-		__disable_dcache();
+	unsigned long flags;
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
 
-		for (i = start; i < end; i += cpuinfo.dcache_line)
-			__invalidate_dcache(i);
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
 
-		__enable_dcache();
-		local_irq_restore(flags);
-	}
+	local_irq_save(flags);
+	__disable_dcache_nomsr();
+
+#ifdef ASM_LOOP
+	CACHE_RANGE_LOOP_1(start, end, cpuinfo.dcache_line_length, wdc);
+#else
+	for (i = start; i < end; i += cpuinfo.dcache_line_length)
+		__asm__ __volatile__ ("wdc	%0, r0;"	\
+				: : "r" (i));
+#endif
+
+	__enable_dcache_nomsr();
+	local_irq_restore(flags);
 }
 
-void __invalidate_dcache_page(struct vm_area_struct *vma, struct page *page)
+static void __flush_dcache_all_wb(void)
 {
-	__invalidate_dcache_all();
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s\n", __func__);
+#ifdef ASM_LOOP
+	CACHE_ALL_LOOP(cpuinfo.dcache_size, cpuinfo.dcache_line_length,
+				wdc.flush);
+#else
+	for (i = 0; i < cpuinfo.dcache_size;
+		 i += cpuinfo.dcache_line_length)
+			__asm__ __volatile__ ("wdc.flush	%0, r0;" \
+					: : "r" (i));
+#endif
 }
 
-void __invalidate_dcache_user_range(struct vm_area_struct *vma,
-				struct page *page, unsigned long adr,
-				int len)
+static void __flush_dcache_range_wb(unsigned long start, unsigned long end)
 {
-	__invalidate_dcache_all();
+#ifndef ASM_LOOP
+	int i;
+#endif
+	pr_debug("%s: start 0x%x, end 0x%x\n", __func__,
+				(unsigned int)start, (unsigned int) end);
+
+	CACHE_LOOP_LIMITS(start, end,
+			cpuinfo.dcache_line_length, cpuinfo.dcache_size);
+#ifdef ASM_LOOP
+	CACHE_RANGE_LOOP_2(start, end, cpuinfo.dcache_line_length, wdc.flush);
+#else
+	for (i = start; i < end; i += cpuinfo.dcache_line_length)
+		__asm__ __volatile__ ("wdc.flush	%0, r0;"	\
+				: : "r" (i));
+#endif
+}
+
+/* struct for wb caches and for wt caches */
+struct scache *mbc;
+
+/* new wb cache model */
+const struct scache wb_msr = {
+	.ie = __enable_icache_msr,
+	.id = __disable_icache_msr,
+	.ifl = __flush_icache_all_noirq,
+	.iflr = __flush_icache_range_noirq,
+	.iin = __flush_icache_all_noirq,
+	.iinr = __flush_icache_range_noirq,
+	.de = __enable_dcache_msr,
+	.dd = __disable_dcache_msr,
+	.dfl = __flush_dcache_all_wb,
+	.dflr = __flush_dcache_range_wb,
+	.din = __invalidate_dcache_all_wb,
+	.dinr = __invalidate_dcache_range_wb,
+};
+
+/* There is only difference in ie, id, de, dd functions */
+const struct scache wb_nomsr = {
+	.ie = __enable_icache_nomsr,
+	.id = __disable_icache_nomsr,
+	.ifl = __flush_icache_all_noirq,
+	.iflr = __flush_icache_range_noirq,
+	.iin = __flush_icache_all_noirq,
+	.iinr = __flush_icache_range_noirq,
+	.de = __enable_dcache_nomsr,
+	.dd = __disable_dcache_nomsr,
+	.dfl = __flush_dcache_all_wb,
+	.dflr = __flush_dcache_range_wb,
+	.din = __invalidate_dcache_all_wb,
+	.dinr = __invalidate_dcache_range_wb,
+};
+
+/* Old wt cache model with disabling irq and turn off cache */
+const struct scache wt_msr = {
+	.ie = __enable_icache_msr,
+	.id = __disable_icache_msr,
+	.ifl = __flush_icache_all_msr_irq,
+	.iflr = __flush_icache_range_msr_irq,
+	.iin = __flush_icache_all_msr_irq,
+	.iinr = __flush_icache_range_msr_irq,
+	.de = __enable_dcache_msr,
+	.dd = __disable_dcache_msr,
+	.dfl = __invalidate_dcache_all_msr_irq,
+	.dflr = __invalidate_dcache_range_msr_irq_wt,
+	.din = __invalidate_dcache_all_msr_irq,
+	.dinr = __invalidate_dcache_range_msr_irq_wt,
+};
+
+const struct scache wt_nomsr = {
+	.ie = __enable_icache_nomsr,
+	.id = __disable_icache_nomsr,
+	.ifl = __flush_icache_all_nomsr_irq,
+	.iflr = __flush_icache_range_nomsr_irq,
+	.iin = __flush_icache_all_nomsr_irq,
+	.iinr = __flush_icache_range_nomsr_irq,
+	.de = __enable_dcache_nomsr,
+	.dd = __disable_dcache_nomsr,
+	.dfl = __invalidate_dcache_all_nomsr_irq,
+	.dflr = __invalidate_dcache_range_nomsr_irq,
+	.din = __invalidate_dcache_all_nomsr_irq,
+	.dinr = __invalidate_dcache_range_nomsr_irq,
+};
+
+/* New wt cache model for newer Microblaze versions */
+const struct scache wt_msr_noirq = {
+	.ie = __enable_icache_msr,
+	.id = __disable_icache_msr,
+	.ifl = __flush_icache_all_noirq,
+	.iflr = __flush_icache_range_noirq,
+	.iin = __flush_icache_all_noirq,
+	.iinr = __flush_icache_range_noirq,
+	.de = __enable_dcache_msr,
+	.dd = __disable_dcache_msr,
+	.dfl = __invalidate_dcache_all_noirq_wt,
+	.dflr = __invalidate_dcache_range_nomsr_wt,
+	.din = __invalidate_dcache_all_noirq_wt,
+	.dinr = __invalidate_dcache_range_nomsr_wt,
+};
+
+const struct scache wt_nomsr_noirq = {
+	.ie = __enable_icache_nomsr,
+	.id = __disable_icache_nomsr,
+	.ifl = __flush_icache_all_noirq,
+	.iflr = __flush_icache_range_noirq,
+	.iin = __flush_icache_all_noirq,
+	.iinr = __flush_icache_range_noirq,
+	.de = __enable_dcache_nomsr,
+	.dd = __disable_dcache_nomsr,
+	.dfl = __invalidate_dcache_all_noirq_wt,
+	.dflr = __invalidate_dcache_range_nomsr_wt,
+	.din = __invalidate_dcache_all_noirq_wt,
+	.dinr = __invalidate_dcache_range_nomsr_wt,
+};
+
+/* CPU version code for 7.20.c - see arch/microblaze/kernel/cpu/cpuinfo.c */
+#define CPUVER_7_20_A	0x0c
+#define CPUVER_7_20_D	0x0f
+
+#define INFO(s)	printk(KERN_INFO "cache: " s "\n");
+
+void microblaze_cache_init(void)
+{
+	if (cpuinfo.use_instr & PVR2_USE_MSR_INSTR) {
+		if (cpuinfo.dcache_wb) {
+			INFO("wb_msr");
+			mbc = (struct scache *)&wb_msr;
+			if (cpuinfo.ver_code <= CPUVER_7_20_D) {
+				/* MS: problem with signal handling - hw bug */
+				INFO("WB won't work properly");
+			}
+		} else {
+			if (cpuinfo.ver_code >= CPUVER_7_20_A) {
+				INFO("wt_msr_noirq");
+				mbc = (struct scache *)&wt_msr_noirq;
+			} else {
+				INFO("wt_msr");
+				mbc = (struct scache *)&wt_msr;
+			}
+		}
+	} else {
+		if (cpuinfo.dcache_wb) {
+			INFO("wb_nomsr");
+			mbc = (struct scache *)&wb_nomsr;
+			if (cpuinfo.ver_code <= CPUVER_7_20_D) {
+				/* MS: problem with signal handling - hw bug */
+				INFO("WB won't work properly");
+			}
+		} else {
+			if (cpuinfo.ver_code >= CPUVER_7_20_A) {
+				INFO("wt_nomsr_noirq");
+				mbc = (struct scache *)&wt_nomsr_noirq;
+			} else {
+				INFO("wt_nomsr");
+				mbc = (struct scache *)&wt_nomsr;
+			}
+		}
+	}
+/* FIXME Invalidation is done in U-BOOT
+ * WT cache: Data is already written to main memory
+ * WB cache: Discard data on noMMU which caused that kernel doesn't boot
+ */
+	/* invalidate_dcache(); */
+	enable_dcache();
+
+	invalidate_icache();
+	enable_icache();
 }
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/cpu/cpuinfo.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/cpuinfo.c
--- linux-2.6.31.12/arch/microblaze/kernel/cpu/cpuinfo.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/cpuinfo.c	2010-08-08 17:40:15.853537674 +0200
@@ -28,11 +28,9 @@ const struct cpu_ver_key cpu_ver_lookup[
 	{"7.10.d", 0x0b},
 	{"7.20.a", 0x0c},
 	{"7.20.b", 0x0d},
-	/* FIXME There is no keycode defined in MBV for these versions */
-	{"2.10.a", 0x10},
-	{"3.00.a", 0x20},
-	{"4.00.a", 0x30},
-	{"4.00.b", 0x40},
+	{"7.20.c", 0x0e},
+	{"7.20.d", 0x0f},
+	{"7.30.a", 0x10},
 	{NULL, 0},
 };
 
@@ -49,6 +47,8 @@ const struct family_string_key family_st
 	{"spartan3a", 0xa},
 	{"spartan3an", 0xb},
 	{"spartan3adsp", 0xc},
+	{"spartan6", 0xd},
+	{"virtex6", 0xe},
 	/* FIXME There is no key code defined for spartan2 */
 	{"spartan2", 0xf0},
 	{NULL, 0},
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/cpu/cpuinfo-pvr-full.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/cpuinfo-pvr-full.c
--- linux-2.6.31.12/arch/microblaze/kernel/cpu/cpuinfo-pvr-full.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/cpuinfo-pvr-full.c	2010-08-08 17:22:50.557036231 +0200
@@ -21,8 +21,14 @@
  */
 
 #define CI(c, p) { ci->c = PVR_##p(pvr); }
+
+#if defined(CONFIG_EARLY_PRINTK) && defined(CONFIG_SERIAL_UARTLITE_CONSOLE)
 #define err_printk(x) \
 	early_printk("ERROR: Microblaze " x "-different for PVR and DTS\n");
+#else
+#define err_printk(x) \
+	printk(KERN_INFO "ERROR: Microblaze " x "-different for PVR and DTS\n");
+#endif
 
 void set_cpuinfo_pvr_full(struct cpuinfo *ci, struct device_node *cpu)
 {
@@ -70,7 +76,7 @@ void set_cpuinfo_pvr_full(struct cpuinfo
 	CI(use_icache, USE_ICACHE);
 	CI(icache_tagbits, ICACHE_ADDR_TAG_BITS);
 	CI(icache_write, ICACHE_ALLOW_WR);
-	CI(icache_line, ICACHE_LINE_LEN);
+	ci->icache_line_length = PVR_ICACHE_LINE_LEN(pvr) << 2;
 	CI(icache_size, ICACHE_BYTE_SIZE);
 	CI(icache_base, ICACHE_BASEADDR);
 	CI(icache_high, ICACHE_HIGHADDR);
@@ -78,11 +84,16 @@ void set_cpuinfo_pvr_full(struct cpuinfo
 	CI(use_dcache, USE_DCACHE);
 	CI(dcache_tagbits, DCACHE_ADDR_TAG_BITS);
 	CI(dcache_write, DCACHE_ALLOW_WR);
-	CI(dcache_line, DCACHE_LINE_LEN);
+	ci->dcache_line_length = PVR_DCACHE_LINE_LEN(pvr) << 2;
 	CI(dcache_size, DCACHE_BYTE_SIZE);
 	CI(dcache_base, DCACHE_BASEADDR);
 	CI(dcache_high, DCACHE_HIGHADDR);
 
+	temp = PVR_DCACHE_USE_WRITEBACK(pvr);
+	if (ci->dcache_wb != temp)
+		err_printk("DCACHE WB");
+	ci->dcache_wb = temp;
+
 	CI(use_dopb, D_OPB);
 	CI(use_iopb, I_OPB);
 	CI(use_dlmb, D_LMB);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/cpu/cpuinfo-static.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/cpuinfo-static.c
--- linux-2.6.31.12/arch/microblaze/kernel/cpu/cpuinfo-static.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/cpuinfo-static.c	2010-08-08 17:22:50.557036231 +0200
@@ -72,12 +72,12 @@ void __init set_cpuinfo_static(struct cp
 	ci->use_icache = fcpu(cpu, "xlnx,use-icache");
 	ci->icache_tagbits = fcpu(cpu, "xlnx,addr-tag-bits");
 	ci->icache_write = fcpu(cpu, "xlnx,allow-icache-wr");
-	ci->icache_line = fcpu(cpu, "xlnx,icache-line-len") << 2;
-	if (!ci->icache_line) {
+	ci->icache_line_length = fcpu(cpu, "xlnx,icache-line-len") << 2;
+	if (!ci->icache_line_length) {
 		if (fcpu(cpu, "xlnx,icache-use-fsl"))
-			ci->icache_line = 4 << 2;
+			ci->icache_line_length = 4 << 2;
 		else
-			ci->icache_line = 1 << 2;
+			ci->icache_line_length = 1 << 2;
 	}
 	ci->icache_size = fcpu(cpu, "i-cache-size");
 	ci->icache_base = fcpu(cpu, "i-cache-baseaddr");
@@ -86,16 +86,17 @@ void __init set_cpuinfo_static(struct cp
 	ci->use_dcache = fcpu(cpu, "xlnx,use-dcache");
 	ci->dcache_tagbits = fcpu(cpu, "xlnx,dcache-addr-tag");
 	ci->dcache_write = fcpu(cpu, "xlnx,allow-dcache-wr");
-	ci->dcache_line = fcpu(cpu, "xlnx,dcache-line-len") << 2;
-	if (!ci->dcache_line) {
+	ci->dcache_line_length = fcpu(cpu, "xlnx,dcache-line-len") << 2;
+	if (!ci->dcache_line_length) {
 		if (fcpu(cpu, "xlnx,dcache-use-fsl"))
-			ci->dcache_line = 4 << 2;
+			ci->dcache_line_length = 4 << 2;
 		else
-			ci->dcache_line = 1 << 2;
+			ci->dcache_line_length = 1 << 2;
 	}
 	ci->dcache_size = fcpu(cpu, "d-cache-size");
 	ci->dcache_base = fcpu(cpu, "d-cache-baseaddr");
 	ci->dcache_high = fcpu(cpu, "d-cache-highaddr");
+	ci->dcache_wb = fcpu(cpu, "xlnx,dcache-use-writeback");
 
 	ci->use_dopb = fcpu(cpu, "xlnx,d-opb");
 	ci->use_iopb = fcpu(cpu, "xlnx,i-opb");
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/cpu/Makefile linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/Makefile
--- linux-2.6.31.12/arch/microblaze/kernel/cpu/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/Makefile	2010-08-08 17:40:15.853537674 +0200
@@ -2,6 +2,10 @@
 # Build the appropriate CPU version support
 #
 
+ifdef CONFIG_FUNCTION_TRACER
+CFLAGS_REMOVE_cache.o = -pg
+endif
+
 EXTRA_CFLAGS += -DCPU_MAJOR=$(CPU_MAJOR) -DCPU_MINOR=$(CPU_MINOR) \
 		-DCPU_REV=$(CPU_REV)
 
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/cpu/mb.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/mb.c
--- linux-2.6.31.12/arch/microblaze/kernel/cpu/mb.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/mb.c	2010-08-08 17:40:15.853537674 +0200
@@ -98,16 +98,22 @@ static int show_cpuinfo(struct seq_file 
 
 	if (cpuinfo.use_icache)
 		count += seq_printf(m,
-				"Icache:\t\t%ukB\n",
-				cpuinfo.icache_size >> 10);
+				"Icache:\t\t%ukB\tline length:\t%dB\n",
+				cpuinfo.icache_size >> 10,
+				cpuinfo.icache_line_length);
 	else
 		count += seq_printf(m, "Icache:\t\tno\n");
 
-	if (cpuinfo.use_dcache)
+	if (cpuinfo.use_dcache) {
 		count += seq_printf(m,
-				"Dcache:\t\t%ukB\n",
-				cpuinfo.dcache_size >> 10);
-	else
+				"Dcache:\t\t%ukB\tline length:\t%dB\n",
+				cpuinfo.dcache_size >> 10,
+				cpuinfo.dcache_line_length);
+		if (cpuinfo.dcache_wb)
+			count += seq_printf(m, "\t\twrite-back\n");
+		else
+			count += seq_printf(m, "\t\twrite-through\n");
+	} else
 		count += seq_printf(m, "Dcache:\t\tno\n");
 
 	count += seq_printf(m,
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/cpu/pvr.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/pvr.c
--- linux-2.6.31.12/arch/microblaze/kernel/cpu/pvr.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/cpu/pvr.c	2010-08-08 17:40:15.853537674 +0200
@@ -45,7 +45,7 @@
 
 int cpu_has_pvr(void)
 {
-	unsigned flags;
+	unsigned long flags;
 	unsigned pvr0;
 
 	local_save_flags(flags);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/dma.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/dma.c
--- linux-2.6.31.12/arch/microblaze/kernel/dma.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/dma.c	2010-08-08 17:40:15.853537674 +0200
@@ -0,0 +1,157 @@
+/*
+ * Copyright (C) 2009-2010 PetaLogix
+ * Copyright (C) 2006 Benjamin Herrenschmidt, IBM Corporation
+ *
+ * Provide default implementations of the DMA mapping callbacks for
+ * directly mapped busses.
+ */
+
+#include <linux/device.h>
+#include <linux/dma-mapping.h>
+#include <linux/dma-debug.h>
+#include <asm/bug.h>
+#include <asm/cacheflush.h>
+
+/*
+ * Generic direct DMA implementation
+ *
+ * This implementation supports a per-device offset that can be applied if
+ * the address at which memory is visible to devices is not 0. Platform code
+ * can set archdata.dma_data to an unsigned long holding the offset. By
+ * default the offset is PCI_DRAM_OFFSET.
+ */
+
+static inline void __dma_sync_page(unsigned long paddr, unsigned long offset,
+				size_t size, enum dma_data_direction direction)
+{
+	switch (direction) {
+	case DMA_TO_DEVICE:
+		flush_dcache_range(paddr + offset, paddr + offset + size);
+		break;
+	case DMA_FROM_DEVICE:
+		invalidate_dcache_range(paddr + offset, paddr + offset + size);
+		break;
+	default:
+		BUG();
+	}
+}
+
+static unsigned long get_dma_direct_offset(struct device *dev)
+{
+	if (likely(dev))
+		return (unsigned long)dev->archdata.dma_data;
+
+	return PCI_DRAM_OFFSET; /* FIXME Not sure if is correct */
+}
+
+#define NOT_COHERENT_CACHE
+
+static void *dma_direct_alloc_coherent(struct device *dev, size_t size,
+				dma_addr_t *dma_handle, gfp_t flag)
+{
+#ifdef NOT_COHERENT_CACHE
+	return consistent_alloc(flag, size, dma_handle);
+#else
+	void *ret;
+	struct page *page;
+	int node = dev_to_node(dev);
+
+	/* ignore region specifiers */
+	flag  &= ~(__GFP_HIGHMEM);
+
+	page = alloc_pages_node(node, flag, get_order(size));
+	if (page == NULL)
+		return NULL;
+	ret = page_address(page);
+	memset(ret, 0, size);
+	*dma_handle = virt_to_phys(ret) + get_dma_direct_offset(dev);
+
+	return ret;
+#endif
+}
+
+static void dma_direct_free_coherent(struct device *dev, size_t size,
+			      void *vaddr, dma_addr_t dma_handle)
+{
+#ifdef NOT_COHERENT_CACHE
+	consistent_free(size, vaddr);
+#else
+	free_pages((unsigned long)vaddr, get_order(size));
+#endif
+}
+
+static int dma_direct_map_sg(struct device *dev, struct scatterlist *sgl,
+			     int nents, enum dma_data_direction direction,
+			     struct dma_attrs *attrs)
+{
+	struct scatterlist *sg;
+	int i;
+
+	/* FIXME this part of code is untested */
+	for_each_sg(sgl, sg, nents, i) {
+		sg->dma_address = sg_phys(sg) + get_dma_direct_offset(dev);
+		sg->dma_length = sg->length;
+		__dma_sync_page(page_to_phys(sg_page(sg)), sg->offset,
+							sg->length, direction);
+	}
+
+	return nents;
+}
+
+static void dma_direct_unmap_sg(struct device *dev, struct scatterlist *sg,
+				int nents, enum dma_data_direction direction,
+				struct dma_attrs *attrs)
+{
+}
+
+static int dma_direct_dma_supported(struct device *dev, u64 mask)
+{
+	return 1;
+}
+
+static inline dma_addr_t dma_direct_map_page(struct device *dev,
+					     struct page *page,
+					     unsigned long offset,
+					     size_t size,
+					     enum dma_data_direction direction,
+					     struct dma_attrs *attrs)
+{
+	__dma_sync_page(page_to_phys(page), offset, size, direction);
+	return page_to_phys(page) + offset + get_dma_direct_offset(dev);
+}
+
+static inline void dma_direct_unmap_page(struct device *dev,
+					 dma_addr_t dma_address,
+					 size_t size,
+					 enum dma_data_direction direction,
+					 struct dma_attrs *attrs)
+{
+/* There is not necessary to do cache cleanup
+ *
+ * phys_to_virt is here because in __dma_sync_page is __virt_to_phys and
+ * dma_address is physical address
+ */
+	__dma_sync_page(dma_address, 0 , size, direction);
+}
+
+struct dma_map_ops dma_direct_ops = {
+	.alloc_coherent	= dma_direct_alloc_coherent,
+	.free_coherent	= dma_direct_free_coherent,
+	.map_sg		= dma_direct_map_sg,
+	.unmap_sg	= dma_direct_unmap_sg,
+	.dma_supported	= dma_direct_dma_supported,
+	.map_page	= dma_direct_map_page,
+	.unmap_page	= dma_direct_unmap_page,
+};
+EXPORT_SYMBOL(dma_direct_ops);
+
+/* Number of entries preallocated for DMA-API debugging */
+#define PREALLOC_DMA_DEBUG_ENTRIES (1 << 16)
+
+static int __init dma_init(void)
+{
+       dma_debug_init(PREALLOC_DMA_DEBUG_ENTRIES);
+
+       return 0;
+}
+fs_initcall(dma_init);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/entry-nommu.S linux-2.6.31.12-petalinux/arch/microblaze/kernel/entry-nommu.S
--- linux-2.6.31.12/arch/microblaze/kernel/entry-nommu.S	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/entry-nommu.S	2010-08-08 17:40:15.856883142 +0200
@@ -476,6 +476,8 @@ ENTRY(ret_from_fork)
 	nop
 
 work_pending:
+	enable_irq
+
 	andi	r11, r19, _TIF_NEED_RESCHED
 	beqi	r11, 1f
 	bralid	r15, schedule
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/entry.S linux-2.6.31.12-petalinux/arch/microblaze/kernel/entry.S
--- linux-2.6.31.12/arch/microblaze/kernel/entry.S	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/entry.S	2010-08-08 17:40:15.865516011 +0200
@@ -31,6 +31,8 @@
 #include <linux/errno.h>
 #include <asm/signal.h>
 
+#undef DEBUG
+
 /* The size of a state save frame. */
 #define STATE_SAVE_SIZE		(PT_SIZE + STATE_SAVE_ARG_SPACE)
 
@@ -303,37 +305,68 @@ C_ENTRY(_user_exception):
 	swi	r11, r1, PTO+PT_R1;		/* Store user SP.  */
 	addi	r11, r0, 1;
 	swi	r11, r0, TOPHYS(PER_CPU(KM));	/* Now we're in kernel-mode.  */
-2:	lwi	r31, r0, TOPHYS(PER_CPU(CURRENT_SAVE));	/* get saved current */
+2:	lwi	CURRENT_TASK, r0, TOPHYS(PER_CPU(CURRENT_SAVE));
 	/* Save away the syscall number.  */
 	swi	r12, r1, PTO+PT_R0;
 	tovirt(r1,r1)
 
-	la	r15, r0, ret_from_trap-8
 /* where the trap should return need -8 to adjust for rtsd r15, 8*/
 /* Jump to the appropriate function for the system call number in r12
  * (r12 is not preserved), or return an error if r12 is not valid. The LP
  * register should point to the location where
  * the called function should return.  [note that MAKE_SYS_CALL uses label 1] */
+
+	# Step into virtual mode.
+	set_vms;
+	addik	r11, r0, 3f
+	rtid	r11, 0
+	nop
+3:
+	lwi	r11, CURRENT_TASK, TS_THREAD_INFO /* get thread info */
+	lwi	r11, r11, TI_FLAGS	 /* get flags in thread info */
+	andi	r11, r11, _TIF_WORK_SYSCALL_MASK
+	beqi	r11, 4f
+
+	addik	r3, r0, -ENOSYS
+	swi	r3, r1, PTO + PT_R3
+	brlid	r15, do_syscall_trace_enter
+	addik	r5, r1, PTO + PT_R0
+
+	# do_syscall_trace_enter returns the new syscall nr.
+	addk	r12, r0, r3
+	lwi	r5, r1, PTO+PT_R5;
+	lwi	r6, r1, PTO+PT_R6;
+	lwi	r7, r1, PTO+PT_R7;
+	lwi	r8, r1, PTO+PT_R8;
+	lwi	r9, r1, PTO+PT_R9;
+	lwi	r10, r1, PTO+PT_R10;
+4:
+
+/* Jump to the appropriate function for the system call number in r12 (r12 is not preserved),
+ * or return an error if r12 is not valid. The LP register should point to the location where
+ * the called function should return.  [note that MAKE_SYS_CALL uses label 1]  */
 	/* See if the system call number is valid.  */
 	addi	r11, r12, -__NR_syscalls;
-	bgei	r11,1f;
+	bgei	r11,5f;
 	/* Figure out which function to use for this system call.  */
 	/* Note Microblaze barrel shift is optional, so don't rely on it */
 	add	r12, r12, r12;			/* convert num -> ptr */
 	add	r12, r12, r12;
 
+#ifdef DEBUG
 	/* Trac syscalls and stored them to r0_ram */
-	lwi	r3, r12, 0x400 + TOPHYS(r0_ram)
+	lwi	r3, r12, 0x400 + r0_ram
 	addi	r3, r3, 1
-	swi	r3, r12, 0x400 + TOPHYS(r0_ram)
+	swi	r3, r12, 0x400 + r0_ram
+#endif
+
+	# Find and jump into the syscall handler.
+	lwi	r12, r12, sys_call_table
+	la	r15, r0, ret_from_trap-8  /* where the trap should return need -8 to adjust for rtsd r15, 8*/
+	bra	r12
 
-	lwi	r12, r12, TOPHYS(sys_call_table); /* Function ptr */
-	/* Make the system call.  to r12*/
-	set_vms;
-	rtid	r12, 0;
-	nop;
 	/* The syscall number is invalid, return an error.  */
-1:	VM_ON;	/* RETURN() expects virtual mode*/
+5:
 	addi	r3, r0, -ENOSYS;
 	rtsd	r15,8;		/* looks like a normal subroutine return */
 	or 	r0, r0, r0
@@ -347,43 +380,50 @@ C_ENTRY(ret_from_trap):
 /* See if returning to kernel mode, if so, skip resched &c.  */
 	bnei	r11, 2f;
 
+	swi	r3, r1, PTO + PT_R3
+	swi	r4, r1, PTO + PT_R4
+
 	/* We're returning to user mode, so check for various conditions that
 	 * trigger rescheduling. */
-	/* Get current task ptr into r11 */
-	add	r11, r0, CURRENT_TASK;	/* Get current task ptr into r11 */
-	lwi	r11, r11, TS_THREAD_INFO;	/* get thread info */
+	/* FIXME: Restructure all these flag checks. */
+	lwi	r11, CURRENT_TASK, TS_THREAD_INFO;	/* get thread info */
+	lwi	r11, r11, TI_FLAGS;		/* get flags in thread info */
+	andi	r11, r11, _TIF_WORK_SYSCALL_MASK
+	beqi	r11, 1f
+
+	brlid	r15, do_syscall_trace_leave
+	addik	r5, r1, PTO + PT_R0
+1:
+	/* We're returning to user mode, so check for various conditions that
+	 * trigger rescheduling. */
+	/* get thread info from current task */
+	lwi	r11, CURRENT_TASK, TS_THREAD_INFO;
 	lwi	r11, r11, TI_FLAGS;		/* get flags in thread info */
 	andi	r11, r11, _TIF_NEED_RESCHED;
 	beqi	r11, 5f;
 
-	swi	r3, r1, PTO + PT_R3; /* store syscall result */
-	swi	r4, r1, PTO + PT_R4;
 	bralid	r15, schedule;	/* Call scheduler */
 	nop;				/* delay slot */
-	lwi	r3, r1, PTO + PT_R3; /* restore syscall result */
-	lwi	r4, r1, PTO + PT_R4;
 
 	/* Maybe handle a signal */
-5:	add	r11, r0, CURRENT_TASK; /* Get current task ptr into r11 */
-	lwi	r11, r11, TS_THREAD_INFO;	/* get thread info */
+5:	/* get thread info from current task*/
+	lwi	r11, CURRENT_TASK, TS_THREAD_INFO;
 	lwi	r11, r11, TI_FLAGS;	/* get flags in thread info */
 	andi	r11, r11, _TIF_SIGPENDING;
 	beqi	r11, 1f;		/* Signals to handle, handle them */
 
-	swi	r3, r1, PTO + PT_R3; /* store syscall result */
-	swi	r4, r1, PTO + PT_R4;
 	la	r5, r1, PTO;		/* Arg 1: struct pt_regs *regs */
-	add	r6, r0, r0;		/* Arg 2: sigset_t *oldset */
 	addi	r7, r0, 1;		/* Arg 3: int in_syscall */
 	bralid	r15, do_signal;	/* Handle any signals */
-	nop;
+	add	r6, r0, r0;		/* Arg 2: sigset_t *oldset */
+
+/* Finally, return to user state.  */
+1:
 	lwi	r3, r1, PTO + PT_R3; /* restore syscall result */
 	lwi	r4, r1, PTO + PT_R4;
 
-/* Finally, return to user state.  */
-1:	swi	r0, r0, PER_CPU(KM);	/* Now officially in user state. */
-	add	r11, r0, CURRENT_TASK;	/* Get current task ptr into r11 */
-	swi	r11, r0, PER_CPU(CURRENT_SAVE); /* save current */
+	swi	r0, r0, PER_CPU(KM);	/* Now officially in user state. */
+	swi	CURRENT_TASK, r0, PER_CPU(CURRENT_SAVE); /* save current */
 	VM_OFF;
 	tophys(r1,r1);
 	RESTORE_REGS;
@@ -448,17 +488,6 @@ C_ENTRY(sys_execve):
 	brid	microblaze_execve;	/* Do real work (tail-call).*/
 	nop;
 
-C_ENTRY(sys_rt_sigsuspend_wrapper):
-	swi	r3, r1, PTO+PT_R3; /* restore saved r3, r4 registers */
-	swi	r4, r1, PTO+PT_R4;
-	la	r7, r1, PTO;		/* add user context as 3rd arg */
-	brlid	r15, sys_rt_sigsuspend;	/* Do real work.*/
-	nop;
-	lwi	r3, r1, PTO+PT_R3; /* restore saved r3, r4 registers */
-	lwi	r4, r1, PTO+PT_R4;
-	bri ret_from_trap /* fall through will not work here due to align */
-	nop;
-
 C_ENTRY(sys_rt_sigreturn_wrapper):
 	swi	r3, r1, PTO+PT_R3; /* restore saved r3, r4 registers */
 	swi	r4, r1, PTO+PT_R4;
@@ -524,7 +553,7 @@ C_ENTRY(sys_rt_sigreturn_wrapper):
 	swi	r11, r1, PTO+PT_R1; /* Store user SP.  */		\
 	addi	r11, r0, 1;						\
 	swi	r11, r0, TOPHYS(PER_CPU(KM)); /* Now we're in kernel-mode.*/\
-2:	lwi	r31, r0, TOPHYS(PER_CPU(CURRENT_SAVE)); /* get saved current */\
+2:	lwi	CURRENT_TASK, r0, TOPHYS(PER_CPU(CURRENT_SAVE));	\
 	/* Save away the syscall number.  */				\
 	swi	r0, r1, PTO+PT_R0;					\
 	tovirt(r1,r1)
@@ -544,6 +573,8 @@ C_ENTRY(full_exception_trap):
 	nop
 	mfs	r7, rfsr;		/* save FSR */
 	nop
+	mts	rfsr, r0;	/* Clear sticky fsr */
+	nop
 	la	r12, r0, full_exception
 	set_vms;
 	rtbd	r12, 0;
@@ -630,9 +661,7 @@ C_ENTRY(ret_from_exc):
 
 	/* We're returning to user mode, so check for various conditions that
 	   trigger rescheduling. */
-	/* Get current task ptr into r11 */
-	add	r11, r0, CURRENT_TASK; /* Get current task ptr into r11 */
-	lwi	r11, r11, TS_THREAD_INFO;	/* get thread info */
+	lwi	r11, CURRENT_TASK, TS_THREAD_INFO;	/* get thread info */
 	lwi	r11, r11, TI_FLAGS;	/* get flags in thread info */
 	andi	r11, r11, _TIF_NEED_RESCHED;
 	beqi	r11, 5f;
@@ -642,8 +671,7 @@ C_ENTRY(ret_from_exc):
 	nop;				/* delay slot */
 
 	/* Maybe handle a signal */
-5:	add	r11, r0, CURRENT_TASK; /* Get current task ptr into r11 */
-	lwi	r11, r11, TS_THREAD_INFO;	/* get thread info */
+5:	lwi	r11, CURRENT_TASK, TS_THREAD_INFO;	/* get thread info */
 	lwi	r11, r11, TI_FLAGS;	/* get flags in thread info */
 	andi	r11, r11, _TIF_SIGPENDING;
 	beqi	r11, 1f;		/* Signals to handle, handle them */
@@ -661,20 +689,14 @@ C_ENTRY(ret_from_exc):
 	 * (in a possibly modified form) after do_signal returns.
 	 * store return registers separately because this macros is use
 	 * for others exceptions */
-	swi	r3, r1, PTO + PT_R3;
-	swi	r4, r1, PTO + PT_R4;
 	la	r5, r1, PTO;		/* Arg 1: struct pt_regs *regs */
-	add	r6, r0, r0;		/* Arg 2: sigset_t *oldset */
 	addi	r7, r0, 0;		/* Arg 3: int in_syscall */
 	bralid	r15, do_signal;	/* Handle any signals */
-	nop;
-	lwi	r3, r1, PTO+PT_R3; /* restore saved r3, r4 registers */
-	lwi	r4, r1, PTO+PT_R4;
+	add	r6, r0, r0;		/* Arg 2: sigset_t *oldset */
 
 /* Finally, return to user state.  */
 1:	swi	r0, r0, PER_CPU(KM);	/* Now officially in user state. */
-	add	r11, r0, CURRENT_TASK; /* Get current task ptr into r11 */
-	swi	r11, r0, PER_CPU(CURRENT_SAVE); /* save current */
+	swi	CURRENT_TASK, r0, PER_CPU(CURRENT_SAVE); /* save current */
 	VM_OFF;
 	tophys(r1,r1);
 
@@ -763,7 +785,7 @@ C_ENTRY(_interrupt):
 	swi	r11, r0, TOPHYS(PER_CPU(KM));
 
 2:
-	lwi	r31, r0, TOPHYS(PER_CPU(CURRENT_SAVE));
+	lwi	CURRENT_TASK, r0, TOPHYS(PER_CPU(CURRENT_SAVE));
 	swi	r0, r1, PTO + PT_R0;
 	tovirt(r1,r1)
 	la	r5, r1, PTO;
@@ -778,8 +800,7 @@ ret_from_irq:
 	lwi	r11, r1, PTO + PT_MODE;
 	bnei	r11, 2f;
 
-	add	r11, r0, CURRENT_TASK;
-	lwi	r11, r11, TS_THREAD_INFO;
+	lwi	r11, CURRENT_TASK, TS_THREAD_INFO;
 	lwi	r11, r11, TI_FLAGS; /* MS: get flags from thread info */
 	andi	r11, r11, _TIF_NEED_RESCHED;
 	beqi	r11, 5f
@@ -787,8 +808,7 @@ ret_from_irq:
 	nop; /* delay slot */
 
     /* Maybe handle a signal */
-5:	add	r11, r0, CURRENT_TASK;
-	lwi	r11, r11, TS_THREAD_INFO; /* MS: get thread info */
+5:	lwi	r11, CURRENT_TASK, TS_THREAD_INFO; /* MS: get thread info */
 	lwi	r11, r11, TI_FLAGS; /* get flags in thread info */
 	andi	r11, r11, _TIF_SIGPENDING;
 	beqid	r11, no_intr_resched
@@ -803,8 +823,7 @@ no_intr_resched:
     /* Disable interrupts, we are now committed to the state restore */
 	disable_irq
 	swi	r0, r0, PER_CPU(KM); /* MS: Now officially in user state. */
-	add	r11, r0, CURRENT_TASK;
-	swi	r11, r0, PER_CPU(CURRENT_SAVE);
+	swi	CURRENT_TASK, r0, PER_CPU(CURRENT_SAVE);
 	VM_OFF;
 	tophys(r1,r1);
 	lwi	r3, r1, PTO + PT_R3; /* MS: restore saved r3, r4 registers */
@@ -814,7 +833,28 @@ no_intr_resched:
 	lwi	r1, r1, PT_R1 - PT_SIZE;
 	bri	6f;
 /* MS: Return to kernel state. */
-2:	VM_OFF /* MS: turn off MMU */
+2:
+#ifdef CONFIG_PREEMPT
+	lwi	r11, CURRENT_TASK, TS_THREAD_INFO;
+	/* MS: get preempt_count from thread info */
+	lwi	r5, r11, TI_PREEMPT_COUNT;
+	bgti	r5, restore;
+
+	lwi	r5, r11, TI_FLAGS;		/* get flags in thread info */
+	andi	r5, r5, _TIF_NEED_RESCHED;
+	beqi	r5, restore /* if zero jump over */
+
+preempt:
+	/* interrupts are off that's why I am calling preempt_chedule_irq */
+	bralid	r15, preempt_schedule_irq
+	nop
+	lwi	r11, CURRENT_TASK, TS_THREAD_INFO;	/* get thread info */
+	lwi	r5, r11, TI_FLAGS;		/* get flags in thread info */
+	andi	r5, r5, _TIF_NEED_RESCHED;
+	bnei	r5, preempt /* if non zero jump to resched */
+restore:
+#endif
+	VM_OFF /* MS: turn off MMU */
 	tophys(r1,r1)
 	lwi	r3, r1, PTO + PT_R3; /* MS: restore saved r3, r4 registers */
 	lwi	r4, r1, PTO + PT_R4;
@@ -876,7 +916,7 @@ C_ENTRY(_debug_exception):
 	swi	r11, r1, PTO+PT_R1; /* Store user SP.  */
 	addi	r11, r0, 1;
 	swi	r11, r0, TOPHYS(PER_CPU(KM));	/* Now we're in kernel-mode.  */
-2:	lwi	r31, r0, TOPHYS(PER_CPU(CURRENT_SAVE)); /* get saved current */
+2:	lwi	CURRENT_TASK, r0, TOPHYS(PER_CPU(CURRENT_SAVE));
 	/* Save away the syscall number.  */
 	swi	r0, r1, PTO+PT_R0;
 	tovirt(r1,r1)
@@ -896,8 +936,7 @@ dbtrap_call:	rtbd	r11, 0;
 	bnei	r11, 2f;
 
 	/* Get current task ptr into r11 */
-	add	r11, r0, CURRENT_TASK; /* Get current task ptr into r11 */
-	lwi	r11, r11, TS_THREAD_INFO;	/* get thread info */
+	lwi	r11, CURRENT_TASK, TS_THREAD_INFO;	/* get thread info */
 	lwi	r11, r11, TI_FLAGS;	/* get flags in thread info */
 	andi	r11, r11, _TIF_NEED_RESCHED;
 	beqi	r11, 5f;
@@ -910,8 +949,7 @@ dbtrap_call:	rtbd	r11, 0;
 	/* XXX m68knommu also checks TASK_STATE & TASK_COUNTER here.  */
 
 	/* Maybe handle a signal */
-5:	add	r11, r0, CURRENT_TASK; /* Get current task ptr into r11 */
-	lwi	r11, r11, TS_THREAD_INFO;	/* get thread info */
+5:	lwi	r11, CURRENT_TASK, TS_THREAD_INFO;	/* get thread info */
 	lwi	r11, r11, TI_FLAGS;	/* get flags in thread info */
 	andi	r11, r11, _TIF_SIGPENDING;
 	beqi	r11, 1f;		/* Signals to handle, handle them */
@@ -927,16 +965,14 @@ dbtrap_call:	rtbd	r11, 0;
 	   (in a possibly modified form) after do_signal returns.  */
 
 	la	r5, r1, PTO;		/* Arg 1: struct pt_regs *regs */
-	add	r6, r0, r0;		/* Arg 2: sigset_t *oldset */
 	addi  r7, r0, 0;	/* Arg 3: int in_syscall */
 	bralid	r15, do_signal;	/* Handle any signals */
-	nop;
+	add	r6, r0, r0;		/* Arg 2: sigset_t *oldset */
 
 
 /* Finally, return to user state.  */
 1:	swi	r0, r0, PER_CPU(KM);	/* Now officially in user state. */
-	add	r11, r0, CURRENT_TASK; /* Get current task ptr into r11 */
-	swi	r11, r0, PER_CPU(CURRENT_SAVE); /* save current */
+	swi	CURRENT_TASK, r0, PER_CPU(CURRENT_SAVE); /* save current */
 	VM_OFF;
 	tophys(r1,r1);
 
@@ -968,7 +1004,7 @@ DBTRAP_return:		/* Make global symbol fo
 
 ENTRY(_switch_to)
 	/* prepare return value */
-	addk	r3, r0, r31
+	addk	r3, r0, CURRENT_TASK
 
 	/* save registers in cpu_context */
 	/* use r11 and r12, volatile registers, as temp register */
@@ -1012,10 +1048,10 @@ ENTRY(_switch_to)
 	nop
 	swi	r12, r11, CC_FSR
 
-	/* update r31, the current */
-	lwi	r31, r6, TI_TASK/* give me pointer to task which will be next */
+	/* update r31, the current-give me pointer to task which will be next */
+	lwi	CURRENT_TASK, r6, TI_TASK
 	/* stored it to current_save too */
-	swi	r31, r0, PER_CPU(CURRENT_SAVE)
+	swi	CURRENT_TASK, r0, PER_CPU(CURRENT_SAVE)
 
 	/* get new process' cpu context and restore */
 	/* give me start where start context of next task */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/exceptions.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/exceptions.c
--- linux-2.6.31.12/arch/microblaze/kernel/exceptions.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/exceptions.c	2010-08-08 17:40:15.865516011 +0200
@@ -72,7 +72,8 @@ asmlinkage void full_exception(struct pt
 #endif
 
 #if 0
-	printk(KERN_WARNING "Exception %02x in %s mode, FSR=%08x PC=%08x ESR=%08x\n",
+	printk(KERN_WARNING "Exception %02x in %s mode, FSR=%08x PC=%08x " \
+							"ESR=%08x\n",
 			type, user_mode(regs) ? "user" : "kernel", fsr,
 			(unsigned int) regs->pc, (unsigned int) regs->esr);
 #endif
@@ -80,42 +81,50 @@ asmlinkage void full_exception(struct pt
 	switch (type & 0x1F) {
 	case MICROBLAZE_ILL_OPCODE_EXCEPTION:
 		if (user_mode(regs)) {
-			printk(KERN_WARNING "Illegal opcode exception in user mode.\n");
+			pr_debug(KERN_WARNING "Illegal opcode exception " \
+							"in user mode.\n");
 			_exception(SIGILL, regs, ILL_ILLOPC, addr);
 			return;
 		}
-		printk(KERN_WARNING "Illegal opcode exception in kernel mode.\n");
+		printk(KERN_WARNING "Illegal opcode exception " \
+							"in kernel mode.\n");
 		die("opcode exception", regs, SIGBUS);
 		break;
 	case MICROBLAZE_IBUS_EXCEPTION:
 		if (user_mode(regs)) {
-			printk(KERN_WARNING "Instruction bus error exception in user mode.\n");
+			pr_debug(KERN_WARNING "Instruction bus error " \
+						"exception in user mode.\n");
 			_exception(SIGBUS, regs, BUS_ADRERR, addr);
 			return;
 		}
-		printk(KERN_WARNING "Instruction bus error exception in kernel mode.\n");
+		printk(KERN_WARNING "Instruction bus error exception " \
+							"in kernel mode.\n");
 		die("bus exception", regs, SIGBUS);
 		break;
 	case MICROBLAZE_DBUS_EXCEPTION:
 		if (user_mode(regs)) {
-			printk(KERN_WARNING "Data bus error exception in user mode.\n");
+			pr_debug(KERN_WARNING "Data bus error exception " \
+							"in user mode.\n");
 			_exception(SIGBUS, regs, BUS_ADRERR, addr);
 			return;
 		}
-		printk(KERN_WARNING "Data bus error exception in kernel mode.\n");
+		printk(KERN_WARNING "Data bus error exception " \
+							"in kernel mode.\n");
 		die("bus exception", regs, SIGBUS);
 		break;
 	case MICROBLAZE_DIV_ZERO_EXCEPTION:
 		if (user_mode(regs)) {
-			printk(KERN_WARNING "Divide by zero exception in user mode\n");
-			_exception(SIGILL, regs, ILL_ILLOPC, addr);
+			pr_debug(KERN_WARNING "Divide by zero exception " \
+							"in user mode\n");
+			_exception(SIGILL, regs, FPE_INTDIV, addr);
 			return;
 		}
-		printk(KERN_WARNING "Divide by zero exception in kernel mode.\n");
-		die("Divide by exception", regs, SIGBUS);
+		printk(KERN_WARNING "Divide by zero exception " \
+							"in kernel mode.\n");
+		die("Divide by zero exception", regs, SIGBUS);
 		break;
 	case MICROBLAZE_FPU_EXCEPTION:
-		printk(KERN_WARNING "FPU exception\n");
+		pr_debug(KERN_WARNING "FPU exception\n");
 		/* IEEE FP exception */
 		/* I removed fsr variable and use code var for storing fsr */
 		if (fsr & FSR_IO)
@@ -133,7 +142,7 @@ asmlinkage void full_exception(struct pt
 
 #ifdef CONFIG_MMU
 	case MICROBLAZE_PRIVILEGED_EXCEPTION:
-		printk(KERN_WARNING "Privileged exception\n");
+		pr_debug(KERN_WARNING "Privileged exception\n");
 		/* "brk r0,r0" - used as debug breakpoint */
 		if (get_user(code, (unsigned long *)regs->pc) == 0
 			&& code == 0x980c0000) {
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/ftrace.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/ftrace.c
--- linux-2.6.31.12/arch/microblaze/kernel/ftrace.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/ftrace.c	2010-08-08 17:40:15.865516011 +0200
@@ -0,0 +1,231 @@
+/*
+ * Ftrace support for Microblaze.
+ *
+ * Copyright (C) 2009 Michal Simek <monstr@monstr.eu>
+ * Copyright (C) 2009 PetaLogix
+ *
+ * Based on MIPS and PowerPC ftrace code
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License. See the file "COPYING" in the main directory of this archive
+ * for more details.
+ */
+
+#include <asm/cacheflush.h>
+#include <linux/ftrace.h>
+
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+/*
+ * Hook the return address and push it in the stack of return addrs
+ * in current thread info.
+ */
+void prepare_ftrace_return(unsigned long *parent, unsigned long self_addr)
+{
+	unsigned long old;
+	int faulted, err;
+	struct ftrace_graph_ent trace;
+	unsigned long return_hooker = (unsigned long)
+				&return_to_handler;
+
+	if (unlikely(atomic_read(&current->tracing_graph_pause)))
+		return;
+
+	/*
+	 * Protect against fault, even if it shouldn't
+	 * happen. This tool is too much intrusive to
+	 * ignore such a protection.
+	 */
+	asm volatile("	1:	lwi	%0, %2, 0;		\
+			2:	swi	%3, %2, 0;		\
+				addik	%1, r0, 0;		\
+			3:					\
+				.section .fixup, \"ax\";	\
+			4:	brid	3b;			\
+				addik	%1, r0, 1;		\
+				.previous;			\
+				.section __ex_table,\"a\";	\
+				.word	1b,4b;			\
+				.word	2b,4b;			\
+				.previous;"			\
+			: "=&r" (old), "=r" (faulted)
+			: "r" (parent), "r" (return_hooker)
+	);
+
+	if (unlikely(faulted)) {
+		ftrace_graph_stop();
+		WARN_ON(1);
+		return;
+	}
+
+	err = ftrace_push_return_trace(old, self_addr, &trace.depth, 0);
+	if (err == -EBUSY) {
+		*parent = old;
+		return;
+	}
+
+	trace.func = self_addr;
+	/* Only trace if the calling function expects to */
+	if (!ftrace_graph_entry(&trace)) {
+		current->curr_ret_stack--;
+		*parent = old;
+	}
+}
+#endif /* CONFIG_FUNCTION_GRAPH_TRACER */
+
+#ifdef CONFIG_DYNAMIC_FTRACE
+/* save value to addr - it is save to do it in asm */
+static int ftrace_modify_code(unsigned long addr, unsigned int value)
+{
+	int faulted = 0;
+
+	__asm__ __volatile__("	1:	swi	%2, %1, 0;		\
+					addik	%0, r0, 0;		\
+				2:					\
+					.section .fixup, \"ax\";	\
+				3:	brid	2b;			\
+					addik	%0, r0, 1;		\
+					.previous;			\
+					.section __ex_table,\"a\";	\
+					.word	1b,3b;			\
+					.previous;"			\
+				: "=r" (faulted)
+				: "r" (addr), "r" (value)
+	);
+
+	if (unlikely(faulted))
+		return -EFAULT;
+
+	return 0;
+}
+
+#define MICROBLAZE_NOP 0x80000000
+#define MICROBLAZE_BRI 0xb800000C
+
+static unsigned int recorded; /* if save was or not */
+static unsigned int imm; /* saving whole imm instruction */
+
+/* There are two approaches howto solve ftrace_make nop function - look below */
+#undef USE_FTRACE_NOP
+
+#ifdef USE_FTRACE_NOP
+static unsigned int bralid; /* saving whole bralid instruction */
+#endif
+
+int ftrace_make_nop(struct module *mod,
+			struct dyn_ftrace *rec, unsigned long addr)
+{
+	/* we have this part of code which we are working with
+	 * b000c000        imm     -16384
+	 * b9fc8e30        bralid  r15, -29136     // c0008e30 <_mcount>
+	 * 80000000        or      r0, r0, r0
+	 *
+	 * The first solution (!USE_FTRACE_NOP-could be called branch solution)
+	 * b000c000        bri	12 (0xC - jump to any other instruction)
+	 * b9fc8e30        bralid  r15, -29136     // c0008e30 <_mcount>
+	 * 80000000        or      r0, r0, r0
+	 * any other instruction
+	 *
+	 * The second solution (USE_FTRACE_NOP) - no jump just nops
+	 * 80000000        or      r0, r0, r0
+	 * 80000000        or      r0, r0, r0
+	 * 80000000        or      r0, r0, r0
+	 */
+	int ret = 0;
+
+	if (recorded == 0) {
+		recorded = 1;
+		imm = *(unsigned int *)rec->ip;
+		pr_debug("%s: imm:0x%x\n", __func__, imm);
+#ifdef USE_FTRACE_NOP
+		bralid = *(unsigned int *)(rec->ip + 4);
+		pr_debug("%s: bralid 0x%x\n", __func__, bralid);
+#endif /* USE_FTRACE_NOP */
+	}
+
+#ifdef USE_FTRACE_NOP
+	ret = ftrace_modify_code(rec->ip, MICROBLAZE_NOP);
+	ret += ftrace_modify_code(rec->ip + 4, MICROBLAZE_NOP);
+#else /* USE_FTRACE_NOP */
+	ret = ftrace_modify_code(rec->ip, MICROBLAZE_BRI);
+#endif /* USE_FTRACE_NOP */
+	return ret;
+}
+
+/* I believe that first is called ftrace_make_nop before this function */
+int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
+{
+	int ret;
+	pr_debug("%s: addr:0x%x, rec->ip: 0x%x, imm:0x%x\n",
+		__func__, (unsigned int)addr, (unsigned int)rec->ip, imm);
+	ret = ftrace_modify_code(rec->ip, imm);
+#ifdef USE_FTRACE_NOP
+	pr_debug("%s: bralid:0x%x\n", __func__, bralid);
+	ret += ftrace_modify_code(rec->ip + 4, bralid);
+#endif /* USE_FTRACE_NOP */
+	return ret;
+}
+
+int __init ftrace_dyn_arch_init(void *data)
+{
+	/* The return code is retured via data */
+	*(unsigned long *)data = 0;
+
+	return 0;
+}
+
+int ftrace_update_ftrace_func(ftrace_func_t func)
+{
+	unsigned long ip = (unsigned long)(&ftrace_call);
+	unsigned int upper = (unsigned int)func;
+	unsigned int lower = (unsigned int)func;
+	int ret = 0;
+
+	/* create proper saving to ftrace_call poll */
+	upper = 0xb0000000 + (upper >> 16); /* imm func_upper */
+	lower = 0x32800000 + (lower & 0xFFFF); /* addik r20, r0, func_lower */
+
+	pr_debug("%s: func=0x%x, ip=0x%x, upper=0x%x, lower=0x%x\n",
+		__func__, (unsigned int)func, (unsigned int)ip, upper, lower);
+
+	/* save upper and lower code */
+	ret = ftrace_modify_code(ip, upper);
+	ret += ftrace_modify_code(ip + 4, lower);
+
+	/* We just need to replace the rtsd r15, 8 with NOP */
+	ret += ftrace_modify_code((unsigned long)&ftrace_caller,
+				  MICROBLAZE_NOP);
+
+	/* All changes are done - lets do caches consistent */
+	flush_icache();
+	return ret;
+}
+
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+unsigned int old_jump; /* saving place for jump instruction */
+
+int ftrace_enable_ftrace_graph_caller(void)
+{
+	unsigned int ret;
+	unsigned long ip = (unsigned long)(&ftrace_call_graph);
+
+	old_jump = *(unsigned int *)ip; /* save jump over instruction */
+	ret = ftrace_modify_code(ip, MICROBLAZE_NOP);
+	flush_icache();
+
+	pr_debug("%s: Replace instruction: 0x%x\n", __func__, old_jump);
+	return ret;
+}
+
+int ftrace_disable_ftrace_graph_caller(void)
+{
+	unsigned int ret;
+	unsigned long ip = (unsigned long)(&ftrace_call_graph);
+
+	ret = ftrace_modify_code(ip, old_jump);
+	flush_icache();
+
+	pr_debug("%s\n", __func__);
+	return ret;
+}
+#endif /* CONFIG_FUNCTION_GRAPH_TRACER */
+#endif /* CONFIG_DYNAMIC_FTRACE */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/head.S linux-2.6.31.12-petalinux/arch/microblaze/kernel/head.S
--- linux-2.6.31.12/arch/microblaze/kernel/head.S	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/head.S	2010-08-08 17:40:15.865516011 +0200
@@ -28,6 +28,7 @@
  * for more details.
  */
 
+#include <linux/init.h>
 #include <linux/linkage.h>
 #include <asm/thread_info.h>
 #include <asm/page.h>
@@ -49,11 +50,27 @@ swapper_pg_dir:
 
 #endif /* CONFIG_MMU */
 
-	.text
+	__HEAD
 ENTRY(_start)
+#if CONFIG_KERNEL_BASE_ADDR == 0
+	brai	TOPHYS(real_start)
+	.org	0x100
+real_start:
+#endif
+
 	mfs	r1, rmsr
 	andi	r1, r1, ~2
 	mts	rmsr, r1
+/*
+ * Here is checking mechanism which check if Microblaze has msr instructions
+ * We load msr and compare it with previous r1 value - if is the same,
+ * msr instructions works if not - cpu don't have them.
+ */
+	/* r8=0 - I have msr instr, 1 - I don't have them */
+	rsubi	r0, r0, 1	/* set the carry bit */
+	msrclr	r0, 0x4		/* try to clear it */
+	/* read the carry bit, r8 will be '0' if msrclr exists */
+	addik	r8, r0, 0
 
 /* r7 may point to an FDT, or there may be one linked in.
    if it's in r7, we've got to save it away ASAP.
@@ -89,8 +106,8 @@ no_fdt_arg:
 	tophys(r4,r4)			/* convert to phys address */
 	ori	r3, r0, COMMAND_LINE_SIZE - 1 /* number of loops */
 _copy_command_line:
-	lbu	r7, r5, r6 /* r7=r5+r6 - r5 contain pointer to command line */
-	sb	r7, r4, r6		/* addr[r4+r6]= r7*/
+	lbu	r2, r5, r6 /* r7=r5+r6 - r5 contain pointer to command line */
+	sb	r2, r4, r6		/* addr[r4+r6]= r7*/
 	addik	r6, r6, 1		/* increment counting */
 	bgtid	r3, _copy_command_line	/* loop for all entries       */
 	addik	r3, r3, -1		/* descrement loop */
@@ -118,7 +135,7 @@ _copy_bram:
 	 * virtual to physical.
 	 */
 	nop
-	addik	r3, r0, 63		/* Invalidate all TLB entries */
+	addik	r3, r0, MICROBLAZE_TLB_SIZE -1	/* Invalidate all TLB entries */
 _invalidate:
 	mts	rtlbx, r3
 	mts	rtlbhi, r0			/* flush: ensure V is clear   */
@@ -126,6 +143,11 @@ _invalidate:
 	addik	r3, r3, -1
 	/* sync */
 
+	/* Setup the kernel PID */
+	mts	rpid,r0			/* Load the kernel PID */
+	nop
+	bri	4
+
 	/*
 	 * We should still be executing code at physical address area
 	 * RAM_BASEADDR at this point. However, kernel code is at
@@ -136,9 +158,51 @@ _invalidate:
 	addik	r3,r0, CONFIG_KERNEL_START /* Load the kernel virtual address */
 	tophys(r4,r3)			/* Load the kernel physical address */
 
-	mts	rpid,r0			/* Load the kernel PID */
-	nop
-	bri	4
+	/* start to do TLB calculation */
+	addik	r12, r0, _end
+	rsub	r12, r3, r12
+	addik	r12, r12, CONFIG_KERNEL_PAD /* that's the pad */
+
+	or r9, r0, r0 /* TLB0 = 0 */
+	or r10, r0, r0 /* TLB1 = 0 */
+
+	addik	r11, r12, -0x1000000
+	bgei	r11, GT16 /* size is greater than 16MB */
+	addik	r11, r12, -0x0800000
+	bgei	r11, GT8 /* size is greater than 8MB */
+	addik	r11, r12, -0x0400000
+	bgei	r11, GT4 /* size is greater than 4MB */
+	/* size is less than 4MB */
+	addik	r11, r12, -0x0200000
+	bgei	r11, GT2 /* size is greater than 2MB */
+	addik	r9, r0, 0x0100000 /* TLB0 must be 1MB */
+	addik	r11, r12, -0x0100000
+	bgei	r11, GT1 /* size is greater than 1MB */
+	/* TLB1 is 0 which is setup above */
+	bri tlb_end
+GT4: /* r11 contains the rest - will be either 1 or 4 */
+	ori r9, r0, 0x400000 /* TLB0 is 4MB */
+	bri TLB1
+GT16: /* TLB0 is 16MB */
+	addik	r9, r0, 0x1000000 /* means TLB0 is 16MB */
+TLB1:
+	addik	r2, r11, -0x0400000 /* must be used r2 because of substract if failed */
+	bgei	r2, GT20 /* size is greater than 16MB */
+	/* size is >16MB and <20MB */
+	addik	r11, r11, -0x0100000
+	bgei	r11, GT17 /* size is greater than 17MB */
+	/* kernel is >16MB and < 17MB */
+GT1:
+	addik	r10, r0, 0x0100000 /* means TLB1 is 1MB */
+	bri tlb_end
+GT2: /* TLB0 is 0 and TLB1 will be 4MB */
+GT17: /* TLB1 is 4MB - kernel size <20MB */
+	addik	r10, r0, 0x0400000 /* means TLB1 is 4MB */
+	bri tlb_end
+GT8: /* TLB0 is still zero that's why I can use only TLB1 */
+GT20: /* TLB1 is 16MB - kernel size >20MB */
+	addik	r10, r0, 0x1000000 /* means TLB1 is 16MB */
+tlb_end:
 
 	/*
 	 * Configure and load two entries into TLB slots 0 and 1.
@@ -149,16 +213,55 @@ _invalidate:
 	andi	r4,r4,0xfffffc00	/* Mask off the real page number */
 	ori	r4,r4,(TLB_WR | TLB_EX)	/* Set the write and execute bits */
 
+	beqi	r9, jump_over /* TLB0 can be zeroes that's why we not setup it */
+
+	/* look at the code below */
+	ori	r30, r0, 0x200
+	andi	r29, r9, 0x100000
+	bneid	r29, 1f
+	addik	r30, r30, 0x80
+	andi	r29, r9, 0x400000
+	bneid	r29, 1f
+	addik	r30, r30, 0x80
+	andi	r29, r9, 0x1000000
+	bneid	r29, 1f
+	addik	r30, r30, 0x80
+1:
+	ori r11, r30, 0
+
 	andi	r3,r3,0xfffffc00	/* Mask off the effective page number */
-	ori	r3,r3,(TLB_VALID | TLB_PAGESZ(PAGESZ_16M))
+	ori	r3,r3,(TLB_VALID)
+	or	r3, r3, r11
 
 	mts     rtlbx,r0		/* TLB slow 0 */
 
 	mts	rtlblo,r4		/* Load the data portion of the entry */
 	mts	rtlbhi,r3		/* Load the tag portion of the entry */
 
-	addik	r4, r4, 0x01000000	/* Map next 16 M entries */
-	addik	r3, r3, 0x01000000
+jump_over:
+
+	beqi	r10, jump_over2 /* TLB0 can be zeroes that's why we not setup it */
+
+	/* look at the code below */
+	ori	r30, r0, 0x200
+	andi	r29, r10, 0x100000
+	bneid	r29, 1f
+	addik	r30, r30, 0x80
+	andi	r29, r10, 0x400000
+	bneid	r29, 1f
+	addik	r30, r30, 0x80
+	andi	r29, r10, 0x1000000
+	bneid	r29, 1f
+	addik	r30, r30, 0x80
+1:
+	ori r12, r30, 0
+
+	addk	r4, r4, r9	/* previous addr + TLB0 size */
+	addk	r3, r3, r9
+
+	andi	r3,r3,0xfffffc00	/* Mask off the effective page number */
+	ori	r3,r3,(TLB_VALID)
+	or	r3, r3, r12
 
 	ori	r6,r0,1			/* TLB slot 1 */
 	mts     rtlbx,r6
@@ -166,6 +269,7 @@ _invalidate:
 	mts	rtlblo,r4		/* Load the data portion of the entry */
 	mts	rtlbhi,r3		/* Load the tag portion of the entry */
 
+jump_over2:
 	/*
 	 * Load a TLB entry for LMB, since we need access to
 	 * the exception vectors, using a 4k real==virtual mapping.
@@ -209,8 +313,8 @@ start_here:
 	 * Please see $(ARCH)/mach-$(SUBARCH)/setup.c for
 	 * the function.
 	 */
-	la	r8, r0, machine_early_init
-	brald	r15, r8
+	la	r11, r0, machine_early_init
+	brald	r15, r11
 	nop
 
 #ifndef CONFIG_MMU
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/heartbeat.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/heartbeat.c
--- linux-2.6.31.12/arch/microblaze/kernel/heartbeat.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/heartbeat.c	2010-08-08 17:22:50.561006568 +0200
@@ -45,6 +45,7 @@ void heartbeat(void)
 void setup_heartbeat(void)
 {
 	struct device_node *gpio = NULL;
+	int *prop;
 	int j;
 	char *gpio_list[] = {
 				"xlnx,xps-gpio-1.00.a",
@@ -58,10 +59,14 @@ void setup_heartbeat(void)
 			break;
 	}
 
-	base_addr = *(int *) of_get_property(gpio, "reg", NULL);
-	base_addr = (unsigned long) ioremap(base_addr, PAGE_SIZE);
-	printk(KERN_NOTICE "Heartbeat GPIO at 0x%x\n", base_addr);
+	if (gpio) {
+		base_addr = *(int *) of_get_property(gpio, "reg", NULL);
+		base_addr = (unsigned long) ioremap(base_addr, PAGE_SIZE);
+		printk(KERN_NOTICE "Heartbeat GPIO at 0x%x\n", base_addr);
 
-	if (*(int *) of_get_property(gpio, "xlnx,is-bidir", NULL))
-		out_be32(base_addr + 4, 0); /* GPIO is configured as output */
+		/* GPIO is configured as output */
+		prop = (int *) of_get_property(gpio, "xlnx,is-bidir", NULL);
+		if (prop)
+			out_be32(base_addr + 4, 0);
+	}
 }
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/hw_exception_handler.S linux-2.6.31.12-petalinux/arch/microblaze/kernel/hw_exception_handler.S
--- linux-2.6.31.12/arch/microblaze/kernel/hw_exception_handler.S	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/hw_exception_handler.S	2010-08-08 17:40:15.867945370 +0200
@@ -84,9 +84,10 @@
 #define NUM_TO_REG(num)		r ## num
 
 #ifdef CONFIG_MMU
-/* FIXME you can't change first load of MSR because there is
- * hardcoded jump bri 4 */
 	#define RESTORE_STATE			\
+		lwi	r5, r1, 0;		\
+		mts	rmsr, r5;		\
+		nop;				\
 		lwi	r3, r1, PT_R3;		\
 		lwi	r4, r1, PT_R4;		\
 		lwi	r5, r1, PT_R5;		\
@@ -309,13 +310,16 @@ _hw_exception_handler:
 	lwi	r31, r0, TOPHYS(PER_CPU(CURRENT_SAVE)) /* get saved current */
 #endif
 
-	mfs	r3, resr
+	mfs	r5, rmsr;
+	nop
+	swi	r5, r1, 0;
+	mfs	r4, resr
 	nop
-	mfs	r4, rear;
+	mfs	r3, rear;
 	nop
 
 #ifndef CONFIG_MMU
-	andi	r5, r3, 0x1000;		/* Check ESR[DS] */
+	andi	r5, r4, 0x1000;		/* Check ESR[DS] */
 	beqi	r5, not_in_delay_slot;	/* Branch if ESR[DS] not set */
 	mfs	r17, rbtr;	/* ESR[DS] set - return address in BTR */
 	nop
@@ -323,13 +327,14 @@ not_in_delay_slot:
 	swi	r17, r1, PT_R17
 #endif
 
-	andi	r5, r3, 0x1F;		/* Extract ESR[EXC] */
+	andi	r5, r4, 0x1F;		/* Extract ESR[EXC] */
 
 #ifdef CONFIG_MMU
 	/* Calculate exception vector offset = r5 << 2 */
 	addk	r6, r5, r5; /* << 1 */
 	addk	r6, r6, r6; /* << 2 */
 
+#ifdef DEBUG
 /* counting which exception happen */
 	lwi	r5, r0, 0x200 + TOPHYS(r0_ram)
 	addi	r5, r5, 1
@@ -337,6 +342,7 @@ not_in_delay_slot:
 	lwi	r5, r6, 0x200 + TOPHYS(r0_ram)
 	addi	r5, r5, 1
 	swi	r5, r6, 0x200 + TOPHYS(r0_ram)
+#endif
 /* end */
 	/* Load the HW Exception vector */
 	lwi	r6, r6, TOPHYS(_MB_HW_ExceptionVectorTable)
@@ -372,7 +378,7 @@ handle_other_ex: /* Handle Other excepti
 	swi	r18, r1, PT_R18
 
 	or	r5, r1, r0
-	andi	r6, r3, 0x1F; /* Load ESR[EC] */
+	andi	r6, r4, 0x1F; /* Load ESR[EC] */
 	lwi	r7, r0, PER_CPU(KM) /* MS: saving current kernel mode to regs */
 	swi	r7, r1, PT_MODE
 	mfs	r7, rfsr
@@ -380,6 +386,8 @@ handle_other_ex: /* Handle Other excepti
 	addk	r8, r17, r0; /* Load exception address */
 	bralid	r15, full_exception; /* Branch to the handler */
 	nop;
+	mts	rfsr, r0;	/* Clear sticky fsr */
+	nop
 
 	/*
 	 * Trigger execution of the signal handler by enabling
@@ -420,11 +428,11 @@ handle_other_ex: /* Handle Other excepti
  */
 handle_unaligned_ex:
 	/* Working registers already saved: R3, R4, R5, R6
-	 *  R3 = ESR
-	 *  R4 = EAR
+	 *  R4 = ESR
+	 *  R3 = EAR
 	 */
 #ifdef CONFIG_MMU
-	andi	r6, r3, 0x1000			/* Check ESR[DS] */
+	andi	r6, r4, 0x1000			/* Check ESR[DS] */
 	beqi	r6, _no_delayslot		/* Branch if ESR[DS] not set */
 	mfs	r17, rbtr;	/* ESR[DS] set - return address in BTR */
 	nop
@@ -433,7 +441,7 @@ _no_delayslot:
 	RESTORE_STATE;
 	bri	unaligned_data_trap
 #endif
-	andi	r6, r3, 0x3E0; /* Mask and extract the register operand */
+	andi	r6, r4, 0x3E0; /* Mask and extract the register operand */
 	srl	r6, r6; /* r6 >> 5 */
 	srl	r6, r6;
 	srl	r6, r6;
@@ -442,33 +450,33 @@ _no_delayslot:
 	/* Store the register operand in a temporary location */
 	sbi	r6, r0, TOPHYS(ex_reg_op);
 
-	andi	r6, r3, 0x400; /* Extract ESR[S] */
+	andi	r6, r4, 0x400; /* Extract ESR[S] */
 	bnei	r6, ex_sw;
 ex_lw:
-	andi	r6, r3, 0x800; /* Extract ESR[W] */
+	andi	r6, r4, 0x800; /* Extract ESR[W] */
 	beqi	r6, ex_lhw;
-	lbui	r5, r4, 0; /* Exception address in r4 */
+	lbui	r5, r3, 0; /* Exception address in r3 */
 	/* Load a word, byte-by-byte from destination address
 		and save it in tmp space */
 	sbi	r5, r0, TOPHYS(ex_tmp_data_loc_0);
-	lbui	r5, r4, 1;
+	lbui	r5, r3, 1;
 	sbi	r5, r0, TOPHYS(ex_tmp_data_loc_1);
-	lbui	r5, r4, 2;
+	lbui	r5, r3, 2;
 	sbi	r5, r0, TOPHYS(ex_tmp_data_loc_2);
-	lbui	r5, r4, 3;
+	lbui	r5, r3, 3;
 	sbi	r5, r0, TOPHYS(ex_tmp_data_loc_3);
-	/* Get the destination register value into r3 */
-	lwi	r3, r0, TOPHYS(ex_tmp_data_loc_0);
+	/* Get the destination register value into r4 */
+	lwi	r4, r0, TOPHYS(ex_tmp_data_loc_0);
 	bri	ex_lw_tail;
 ex_lhw:
-	lbui	r5, r4, 0; /* Exception address in r4 */
+	lbui	r5, r3, 0; /* Exception address in r3 */
 	/* Load a half-word, byte-by-byte from destination
 		address and save it in tmp space */
 	sbi	r5, r0, TOPHYS(ex_tmp_data_loc_0);
-	lbui	r5, r4, 1;
+	lbui	r5, r3, 1;
 	sbi	r5, r0, TOPHYS(ex_tmp_data_loc_1);
-	/* Get the destination register value into r3 */
-	lhui	r3, r0, TOPHYS(ex_tmp_data_loc_0);
+	/* Get the destination register value into r4 */
+	lhui	r4, r0, TOPHYS(ex_tmp_data_loc_0);
 ex_lw_tail:
 	/* Get the destination register number into r5 */
 	lbui	r5, r0, TOPHYS(ex_reg_op);
@@ -496,25 +504,25 @@ ex_sw_tail:
 	andi	r6, r6, 0x800; /* Extract ESR[W] */
 	beqi	r6, ex_shw;
 	/* Get the word - delay slot */
-	swi	r3, r0, TOPHYS(ex_tmp_data_loc_0);
+	swi	r4, r0, TOPHYS(ex_tmp_data_loc_0);
 	/* Store the word, byte-by-byte into destination address */
-	lbui	r3, r0, TOPHYS(ex_tmp_data_loc_0);
-	sbi	r3, r4, 0;
-	lbui	r3, r0, TOPHYS(ex_tmp_data_loc_1);
-	sbi	r3, r4, 1;
-	lbui	r3, r0, TOPHYS(ex_tmp_data_loc_2);
-	sbi	r3, r4, 2;
-	lbui	r3, r0, TOPHYS(ex_tmp_data_loc_3);
-	sbi	r3, r4, 3;
+	lbui	r4, r0, TOPHYS(ex_tmp_data_loc_0);
+	sbi	r4, r3, 0;
+	lbui	r4, r0, TOPHYS(ex_tmp_data_loc_1);
+	sbi	r4, r3, 1;
+	lbui	r4, r0, TOPHYS(ex_tmp_data_loc_2);
+	sbi	r4, r3, 2;
+	lbui	r4, r0, TOPHYS(ex_tmp_data_loc_3);
+	sbi	r4, r3, 3;
 	bri	ex_handler_done;
 
 ex_shw:
 	/* Store the lower half-word, byte-by-byte into destination address */
-	swi	r3, r0, TOPHYS(ex_tmp_data_loc_0);
-	lbui	r3, r0, TOPHYS(ex_tmp_data_loc_2);
-	sbi	r3, r4, 0;
-	lbui	r3, r0, TOPHYS(ex_tmp_data_loc_3);
-	sbi	r3, r4, 1;
+	swi	r4, r0, TOPHYS(ex_tmp_data_loc_0);
+	lbui	r4, r0, TOPHYS(ex_tmp_data_loc_2);
+	sbi	r4, r3, 0;
+	lbui	r4, r0, TOPHYS(ex_tmp_data_loc_3);
+	sbi	r4, r3, 1;
 ex_sw_end: /* Exception handling of store word, ends. */
 
 ex_handler_done:
@@ -554,21 +562,16 @@ ex_handler_done:
 		 */
 		mfs	r11, rpid
 		nop
-		bri	4
-		mfs	r3, rear		/* Get faulting address */
-		nop
 		/* If we are faulting a kernel address, we have to use the
 		 * kernel page tables.
 		 */
-		ori	r4, r0, CONFIG_KERNEL_START
-		cmpu	r4, r3, r4
-		bgti	r4, ex3
+		ori	r5, r0, CONFIG_KERNEL_START
+		cmpu	r5, r3, r5
+		bgti	r5, ex3
 		/* First, check if it was a zone fault (which means a user
 		 * tried to access a kernel or read-protected page - always
 		 * a SEGV). All other faults here must be stores, so no
 		 * need to check ESR_S as well. */
-		mfs	r4, resr
-		nop
 		andi	r4, r4, 0x800		/* ESR_Z - zone protection */
 		bnei	r4, ex2
 
@@ -583,8 +586,6 @@ ex_handler_done:
 		 * tried to access a kernel or read-protected page - always
 		 * a SEGV). All other faults here must be stores, so no
 		 * need to check ESR_S as well. */
-		mfs	r4, resr
-		nop
 		andi	r4, r4, 0x800		/* ESR_Z */
 		bnei	r4, ex2
 		/* get current task address */
@@ -659,8 +660,6 @@ ex_handler_done:
 		 * R3 = ESR
 		 */
 
-		mfs	r3, rear		/* Get faulting address */
-		nop
 		RESTORE_STATE;
 		bri	page_fault_instr_trap
 
@@ -671,18 +670,15 @@ ex_handler_done:
 	 */
 	handle_data_tlb_miss_exception:
 		/* Working registers already saved: R3, R4, R5, R6
-		 * R3 = ESR
+		 * R3 = EAR, R4 = ESR
 		 */
 		mfs	r11, rpid
 		nop
-		bri	4
-		mfs	r3, rear		/* Get faulting address */
-		nop
 
 		/* If we are faulting a kernel address, we have to use the
 		 * kernel page tables. */
-		ori	r4, r0, CONFIG_KERNEL_START
-		cmpu	r4, r3, r4
+		ori	r6, r0, CONFIG_KERNEL_START
+		cmpu	r4, r3, r6
 		bgti	r4, ex5
 		ori	r4, r0, swapper_pg_dir
 		mts	rpid, r0		/* TLB will have 0 TID */
@@ -725,9 +721,8 @@ ex_handler_done:
 		 * Many of these bits are software only. Bits we don't set
 		 * here we (properly should) assume have the appropriate value.
 		 */
+		brid	finish_tlb_load
 		andni	r4, r4, 0x0ce2		/* Make sure 20, 21 are zero */
-
-		bri	finish_tlb_load
 	ex7:
 		/* The bailout. Restore registers to pre-exception conditions
 		 * and call the heavyweights to help us out.
@@ -748,9 +743,6 @@ ex_handler_done:
 		 */
 		mfs	r11, rpid
 		nop
-		bri	4
-		mfs	r3, rear		/* Get faulting address */
-		nop
 
 		/* If we are faulting a kernel address, we have to use the
 		 * kernel page tables.
@@ -786,7 +778,7 @@ ex_handler_done:
 		lwi	r4, r5, 0		/* Get Linux PTE */
 
 		andi	r6, r4, _PAGE_PRESENT
-		beqi	r6, ex7
+		beqi	r6, ex10
 
 		ori	r4, r4, _PAGE_ACCESSED
 		swi	r4, r5, 0
@@ -799,9 +791,8 @@ ex_handler_done:
 		 * Many of these bits are software only. Bits we don't set
 		 * here we (properly should) assume have the appropriate value.
 		 */
+		brid	finish_tlb_load
 		andni	r4, r4, 0x0ce2		/* Make sure 20, 21 are zero */
-
-		bri	finish_tlb_load
 	ex10:
 		/* The bailout. Restore registers to pre-exception conditions
 		 * and call the heavyweights to help us out.
@@ -831,9 +822,9 @@ ex_handler_done:
 		andi	r5, r5, (MICROBLAZE_TLB_SIZE-1)
 		ori	r6, r0, 1
 		cmp	r31, r5, r6
-		blti	r31, sem
+		blti	r31, ex12
 		addik	r5, r6, 1
-	sem:
+	ex12:
 		/* MS: save back current TLB index */
 		swi	r5, r0, TOPHYS(tlb_index)
 
@@ -853,7 +844,6 @@ ex_handler_done:
 		nop
 
 		/* Done...restore registers and get out of here. */
-	ex12:
 		mts	rpid, r11
 		nop
 		bri 4
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/intc.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/intc.c
--- linux-2.6.31.12/arch/microblaze/kernel/intc.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/intc.c	2010-08-08 17:40:15.867945370 +0200
@@ -42,8 +42,16 @@ unsigned int nr_irq;
 
 static void intc_enable_or_unmask(unsigned int irq)
 {
+	unsigned long mask = 1 << irq;
 	pr_debug("enable_or_unmask: %d\n", irq);
-	out_be32(INTC_BASE + SIE, 1 << irq);
+	out_be32(INTC_BASE + SIE, mask);
+
+	/* ack level irqs because they can't be acked during
+	 * ack function since the handle_level_irq function
+	 * acks the irq before calling the interrupt handler
+	 */
+	if (irq_desc[irq].status & IRQ_LEVEL)
+		out_be32(INTC_BASE + IAR, mask);
 }
 
 static void intc_disable_or_mask(unsigned int irq)
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/irq.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/irq.c
--- linux-2.6.31.12/arch/microblaze/kernel/irq.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/irq.c	2010-08-08 17:40:15.867945370 +0200
@@ -9,6 +9,7 @@
  */
 
 #include <linux/init.h>
+#include <linux/ftrace.h>
 #include <linux/kernel.h>
 #include <linux/hardirq.h>
 #include <linux/interrupt.h>
@@ -32,7 +33,7 @@ EXPORT_SYMBOL_GPL(irq_of_parse_and_map);
 
 static u32 concurrent_irq;
 
-void do_IRQ(struct pt_regs *regs)
+void __irq_entry do_IRQ(struct pt_regs *regs)
 {
 	unsigned int irq;
 	struct pt_regs *old_regs = set_irq_regs(regs);
@@ -93,3 +94,18 @@ skip:
 	}
 	return 0;
 }
+
+/* MS: There is no any advance mapping mechanism. We are using simple 32bit
+  intc without any cascades or any connection that's why mapping is 1:1 */
+unsigned int irq_create_mapping(struct irq_host *host, irq_hw_number_t hwirq)
+{
+	return hwirq;
+}
+EXPORT_SYMBOL_GPL(irq_create_mapping);
+
+unsigned int irq_create_of_mapping(struct device_node *controller,
+					u32 *intspec, unsigned int intsize)
+{
+	return intspec[0];
+}
+EXPORT_SYMBOL_GPL(irq_create_of_mapping);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/Makefile linux-2.6.31.12-petalinux/arch/microblaze/kernel/Makefile
--- linux-2.6.31.12/arch/microblaze/kernel/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/Makefile	2010-08-08 17:40:15.853537674 +0200
@@ -2,12 +2,22 @@
 # Makefile
 #
 
+ifdef CONFIG_FUNCTION_TRACER
+# Do not trace early boot code and low level code
+CFLAGS_REMOVE_timer.o = -pg
+CFLAGS_REMOVE_intc.o = -pg
+CFLAGS_REMOVE_early_printk.o = -pg
+CFLAGS_REMOVE_selfmod.o = -pg
+CFLAGS_REMOVE_heartbeat.o = -pg
+CFLAGS_REMOVE_ftrace.o = -pg
+endif
+
 extra-y := head.o vmlinux.lds
 
-obj-y += exceptions.o \
+obj-y += dma.o exceptions.o \
 	hw_exception_handler.o init_task.o intc.o irq.o of_device.o \
 	of_platform.o process.o prom.o prom_parse.o ptrace.o \
-	setup.o signal.o sys_microblaze.o timer.o traps.o
+	setup.o signal.o sys_microblaze.o timer.o traps.o reset.o
 
 obj-y += cpu/
 
@@ -16,5 +26,7 @@ obj-$(CONFIG_SELFMOD)		+= selfmod.o
 obj-$(CONFIG_HEART_BEAT)	+= heartbeat.o
 obj-$(CONFIG_MODULES)		+= microblaze_ksyms.o module.o
 obj-$(CONFIG_MMU)		+= misc.o
+obj-$(CONFIG_STACKTRACE)	+= stacktrace.o
+obj-$(CONFIG_FUNCTION_TRACER)	+= ftrace.o mcount.o
 
 obj-y	+= entry$(MMU).o
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/mcount.S linux-2.6.31.12-petalinux/arch/microblaze/kernel/mcount.S
--- linux-2.6.31.12/arch/microblaze/kernel/mcount.S	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/mcount.S	2010-08-08 17:40:15.867945370 +0200
@@ -0,0 +1,170 @@
+/*
+ * Low-level ftrace handling
+ *
+ * Copyright (C) 2009 Michal Simek <monstr@monstr.eu>
+ * Copyright (C) 2009 PetaLogix
+ *
+ * This file is subject to the terms and conditions of the GNU General
+ * Public License. See the file COPYING in the main directory of this
+ * archive for more details.
+ */
+
+#include <linux/linkage.h>
+
+#define NOALIGN_ENTRY(name)	.globl name; name:
+
+/* FIXME MS: I think that I don't need to save all regs */
+#define SAVE_REGS		\
+	addik	r1, r1, -120;	\
+	swi	r2, r1, 4;	\
+	swi	r3, r1, 8;	\
+	swi	r4, r1, 12;	\
+	swi	r5, r1, 116;	\
+	swi	r6, r1, 16;	\
+	swi	r7, r1, 20;	\
+	swi	r8, r1, 24;	\
+	swi	r9, r1, 28;	\
+	swi	r10, r1, 32;	\
+	swi	r11, r1, 36;	\
+	swi	r12, r1, 40;	\
+	swi	r13, r1, 44;	\
+	swi	r14, r1, 48;	\
+	swi	r16, r1, 52;	\
+	swi	r17, r1, 56;	\
+	swi	r18, r1, 60;	\
+	swi	r19, r1, 64;	\
+	swi	r20, r1, 68;	\
+	swi	r21, r1, 72;	\
+	swi	r22, r1, 76;	\
+	swi	r23, r1, 80;	\
+	swi	r24, r1, 84;	\
+	swi	r25, r1, 88;	\
+	swi	r26, r1, 92;	\
+	swi	r27, r1, 96;	\
+	swi	r28, r1, 100;	\
+	swi	r29, r1, 104;	\
+	swi	r30, r1, 108;	\
+	swi	r31, r1, 112;
+
+#define RESTORE_REGS		\
+	lwi	r2, r1, 4;	\
+	lwi	r3, r1, 8;	\
+	lwi	r4, r1, 12;	\
+	lwi	r5, r1, 116;	\
+	lwi	r6, r1, 16;	\
+	lwi	r7, r1, 20;	\
+	lwi	r8, r1, 24;	\
+	lwi	r9, r1, 28;	\
+	lwi	r10, r1, 32;	\
+	lwi	r11, r1, 36;	\
+	lwi	r12, r1, 40;	\
+	lwi	r13, r1, 44;	\
+	lwi	r14, r1, 48;	\
+	lwi	r16, r1, 52;	\
+	lwi	r17, r1, 56;	\
+	lwi	r18, r1, 60;	\
+	lwi	r19, r1, 64;	\
+	lwi	r20, r1, 68;	\
+	lwi	r21, r1, 72;	\
+	lwi	r22, r1, 76;	\
+	lwi	r23, r1, 80;	\
+	lwi	r24, r1, 84;	\
+	lwi	r25, r1, 88;	\
+	lwi	r26, r1, 92;	\
+	lwi	r27, r1, 96;	\
+	lwi	r28, r1, 100;	\
+	lwi	r29, r1, 104;	\
+	lwi	r30, r1, 108;	\
+	lwi	r31, r1, 112;	\
+	addik	r1, r1, 120;
+
+ENTRY(ftrace_stub)
+	rtsd	r15, 8;
+	nop;
+
+ENTRY(_mcount)
+#ifdef CONFIG_DYNAMIC_FTRACE
+ENTRY(ftrace_caller)
+	/* MS: It is just barrier which is removed from C code */
+	rtsd	r15, 8
+	nop
+#endif /* CONFIG_DYNAMIC_FTRACE */
+	SAVE_REGS
+	swi	r15, r1, 0;
+	/* MS: HAVE_FUNCTION_TRACE_MCOUNT_TEST begin of checking */
+	lwi	r5, r0, function_trace_stop;
+	bneid	r5, end;
+	nop;
+	/* MS: HAVE_FUNCTION_TRACE_MCOUNT_TEST end of checking */
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+#ifndef CONFIG_DYNAMIC_FTRACE
+	lwi	r5, r0, ftrace_graph_return;
+	addik	r6, r0, ftrace_stub; /* asm implementation */
+	cmpu	r5, r5, r6; /* ftrace_graph_return != ftrace_stub */
+	beqid	r5, end_graph_tracer;
+	nop;
+
+	lwi	r6, r0, ftrace_graph_entry;
+	addik	r5, r0, ftrace_graph_entry_stub; /* implemented in C */
+	cmpu	r5, r5, r6; /* ftrace_graph_entry != ftrace_graph_entry_stub */
+	beqid	r5, end_graph_tracer;
+	nop;
+#else /* CONFIG_DYNAMIC_FTRACE */
+NOALIGN_ENTRY(ftrace_call_graph)
+	/* MS: jump over graph function - replaced from C code */
+	bri	end_graph_tracer
+#endif /* CONFIG_DYNAMIC_FTRACE */
+	addik	r5, r1, 120; /* MS: load parent addr */
+	addik	r6, r15, 0; /* MS: load current function addr */
+	bralid	r15, prepare_ftrace_return;
+	nop;
+	/* MS: graph was taken that's why - can jump over function trace */
+	brid	end;
+	nop;
+end_graph_tracer:
+#endif /* CONFIG_FUNCTION_GRAPH_TRACER */
+#ifndef CONFIG_DYNAMIC_FTRACE
+	/* MS: test function trace if is taken or not */
+	lwi	r20, r0, ftrace_trace_function;
+	addik	r6, r0, ftrace_stub;
+	cmpu	r5, r20, r6; /* ftrace_trace_function != ftrace_stub */
+	beqid	r5, end; /* MS: not taken -> jump over */
+	nop;
+#else /* CONFIG_DYNAMIC_FTRACE */
+NOALIGN_ENTRY(ftrace_call)
+/* instruction for setup imm FUNC_part1, addik r20, r0, FUNC_part2 */
+	nop
+	nop
+#endif /* CONFIG_DYNAMIC_FTRACE */
+/* static normal trace */
+	lwi	r6, r1, 120; /* MS: load parent addr */
+	addik	r5, r15, 0; /* MS: load current function addr */
+	/* MS: here is dependency on previous code */
+	brald	r15, r20; /* MS: jump to ftrace handler */
+	nop;
+end:
+	lwi	r15, r1, 0;
+	RESTORE_REGS
+
+	rtsd	r15, 8; /* MS: jump back */
+	nop;
+
+#ifdef CONFIG_FUNCTION_GRAPH_TRACER
+ENTRY(return_to_handler)
+	nop; /* MS: just barrier for rtsd r15, 8 */
+	nop;
+	SAVE_REGS
+	swi	r15, r1, 0;
+
+	/* MS: find out returning address */
+	bralid	r15, ftrace_return_to_handler;
+	nop;
+
+	/* MS: return value from ftrace_return_to_handler is my returning addr
+	 * must be before restore regs because I have to restore r3 content */
+	addik	r15, r3, 0;
+	RESTORE_REGS
+
+	rtsd	r15, 8; /* MS: jump back */
+	nop;
+#endif	/* CONFIG_FUNCTION_TRACER */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/microblaze_ksyms.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/microblaze_ksyms.c
--- linux-2.6.31.12/arch/microblaze/kernel/microblaze_ksyms.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/microblaze_ksyms.c	2010-08-08 17:40:15.867945370 +0200
@@ -18,6 +18,7 @@
 #include <linux/io.h>
 #include <asm/page.h>
 #include <asm/system.h>
+#include <linux/ftrace.h>
 #include <linux/uaccess.h>
 
 /*
@@ -47,3 +48,19 @@ extern void __umodsi3(void);
 EXPORT_SYMBOL(__umodsi3);
 extern char *_ebss;
 EXPORT_SYMBOL_GPL(_ebss);
+
+/*
+ * Assembly functions that may be used (directly or indirectly) by modules
+ */
+#ifdef CONFIG_OPT_LIB_ASM
+EXPORT_SYMBOL(memcpy);
+EXPORT_SYMBOL(memmove);
+#endif
+
+EXPORT_SYMBOL(__copy_tofrom_user);
+EXPORT_SYMBOL(__strncpy_user);
+
+#ifdef CONFIG_FUNCTION_TRACER
+extern void _mcount(void);
+EXPORT_SYMBOL(_mcount);
+#endif
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/misc.S linux-2.6.31.12-petalinux/arch/microblaze/kernel/misc.S
--- linux-2.6.31.12/arch/microblaze/kernel/misc.S	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/misc.S	2010-08-08 17:40:15.867945370 +0200
@@ -26,9 +26,10 @@
  * We avoid flushing the pinned 0, 1 and possibly 2 entries.
  */
 .globl _tlbia;
+.type  _tlbia, @function
 .align 4;
 _tlbia:
-	addik	r12, r0, 63 /* flush all entries (63 - 3) */
+	addik	r12, r0, MICROBLAZE_TLB_SIZE - 1 /* flush all entries (63 - 3) */
 	/* isync */
 _tlbia_1:
 	mts	rtlbx, r12
@@ -41,11 +42,13 @@ _tlbia_1:
 	/* sync */
 	rtsd	r15, 8
 	nop
+	.size  _tlbia, . - _tlbia
 
 /*
  * Flush MMU TLB for a particular address (in r5)
  */
 .globl _tlbie;
+.type  _tlbie, @function
 .align 4;
 _tlbie:
 	mts	rtlbsx, r5 /* look up the address in TLB */
@@ -59,17 +62,20 @@ _tlbie_1:
 	rtsd	r15, 8
 	nop
 
+	.size  _tlbie, . - _tlbie
+
 /*
  * Allocate TLB entry for early console
  */
 .globl early_console_reg_tlb_alloc;
+.type  early_console_reg_tlb_alloc, @function
 .align 4;
 early_console_reg_tlb_alloc:
 	/*
 	 * Load a TLB entry for the UART, so that microblaze_progress() can use
 	 * the UARTs nice and early.  We use a 4k real==virtual mapping.
 	 */
-	ori	r4, r0, 63
+	ori	r4, r0, MICROBLAZE_TLB_SIZE - 1
 	mts	rtlbx, r4 /* TLB slot 2 */
 
 	or	r4,r5,r0
@@ -86,35 +92,4 @@ early_console_reg_tlb_alloc:
 	rtsd	r15, 8
 	nop
 
-/*
- * Copy a whole page (4096 bytes).
- */
-#define COPY_16_BYTES		\
-	lwi	r7, r6, 0;	\
-	lwi	r8, r6, 4;	\
-	lwi	r9, r6, 8;	\
-	lwi	r10, r6, 12;	\
-	swi	r7, r5, 0;	\
-	swi	r8, r5, 4;	\
-	swi	r9, r5, 8;	\
-	swi	r10, r5, 12
-
-
-/* FIXME DCACHE_LINE_BYTES (CONFIG_XILINX_MICROBLAZE0_DCACHE_LINE_LEN * 4)*/
-#define DCACHE_LINE_BYTES (4 * 4)
-
-.globl copy_page;
-.align 4;
-copy_page:
-	ori	r11, r0, (PAGE_SIZE/DCACHE_LINE_BYTES) - 1
-_copy_page_loop:
-	COPY_16_BYTES
-#if DCACHE_LINE_BYTES >= 32
-	COPY_16_BYTES
-#endif
-	addik	r6, r6, DCACHE_LINE_BYTES
-	addik	r5, r5, DCACHE_LINE_BYTES
-	bneid	r11, _copy_page_loop
-	addik	r11, r11, -1
-	rtsd	r15, 8
-	nop
+	.size  early_console_reg_tlb_alloc, . - early_console_reg_tlb_alloc
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/module.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/module.c
--- linux-2.6.31.12/arch/microblaze/kernel/module.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/module.c	2010-08-08 17:40:15.867945370 +0200
@@ -17,6 +17,7 @@
 #include <linux/string.h>
 
 #include <asm/pgtable.h>
+#include <asm/cacheflush.h>
 
 void *module_alloc(unsigned long size)
 {
@@ -152,6 +153,7 @@ int apply_relocate_add(Elf32_Shdr *sechd
 int module_finalize(const Elf32_Ehdr *hdr, const Elf_Shdr *sechdrs,
 		struct module *module)
 {
+	flush_dcache();
 	return 0;
 }
 
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/process.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/process.c
--- linux-2.6.31.12/arch/microblaze/kernel/process.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/process.c	2010-08-08 17:40:15.867945370 +0200
@@ -15,6 +15,8 @@
 #include <linux/bitops.h>
 #include <asm/system.h>
 #include <asm/pgalloc.h>
+#include <asm/uaccess.h> /* for USER_DS macros */
+#include <asm/cacheflush.h>
 
 void show_regs(struct pt_regs *regs)
 {
@@ -73,7 +75,10 @@ __setup("hlt", hlt_setup);
 
 void default_idle(void)
 {
-	if (!hlt_counter) {
+	if (likely(hlt_counter)) {
+		while (!need_resched())
+			cpu_relax();
+	} else {
 		clear_thread_flag(TIF_POLLING_NRFLAG);
 		smp_mb__after_clear_bit();
 		local_irq_disable();
@@ -81,9 +86,7 @@ void default_idle(void)
 			cpu_sleep();
 		local_irq_enable();
 		set_thread_flag(TIF_POLLING_NRFLAG);
-	} else
-		while (!need_resched())
-			cpu_relax();
+	}
 }
 
 void cpu_idle(void)
@@ -235,6 +238,9 @@ void start_thread(struct pt_regs *regs, 
 	regs->pc = pc;
 	regs->r1 = usp;
 	regs->pt_mode = 0;
+#ifdef CONFIG_MMU
+	regs->msr |= MSR_UMS;
+#endif
 }
 
 #ifdef CONFIG_MMU
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/prom_parse.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/prom_parse.c
--- linux-2.6.31.12/arch/microblaze/kernel/prom_parse.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/prom_parse.c	2010-08-08 17:40:15.867945370 +0200
@@ -256,7 +256,7 @@ int of_irq_map_pci(struct pci_dev *pdev,
 		if (ppdev == NULL) {
 			struct pci_controller *host;
 			host = pci_bus_to_host(pdev->bus);
-			ppnode = host ? host->arch_data : NULL;
+			ppnode = host ? host->dn : NULL;
 			/* No node for host bridge ? give up */
 			if (ppnode == NULL)
 				return -EINVAL;
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/ptrace.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/ptrace.c
--- linux-2.6.31.12/arch/microblaze/kernel/ptrace.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/ptrace.c	2010-08-08 17:40:15.867945370 +0200
@@ -29,11 +29,17 @@
 #include <linux/sched.h>
 #include <linux/ptrace.h>
 #include <linux/signal.h>
+#include <linux/elf.h>
+#include <linux/audit.h>
+#include <linux/seccomp.h>
+#include <linux/tracehook.h>
 
 #include <linux/errno.h>
 #include <asm/processor.h>
 #include <linux/uaccess.h>
 #include <asm/asm-offsets.h>
+#include <asm/cacheflush.h>
+#include <asm/io.h>
 
 /* Returns the address where the register at REG_OFFS in P is stashed away. */
 static microblaze_reg_t *reg_save_addr(unsigned reg_offs,
@@ -71,29 +77,8 @@ long arch_ptrace(struct task_struct *chi
 {
 	int rval;
 	unsigned long val = 0;
-	unsigned long copied;
 
 	switch (request) {
-	case PTRACE_PEEKTEXT: /* read word at location addr. */
-	case PTRACE_PEEKDATA:
-		pr_debug("PEEKTEXT/PEEKDATA at %08lX\n", addr);
-		copied = access_process_vm(child, addr, &val, sizeof(val), 0);
-		rval = -EIO;
-		if (copied != sizeof(val))
-			break;
-		rval = put_user(val, (unsigned long *)data);
-		break;
-
-	case PTRACE_POKETEXT: /* write the word at location addr. */
-	case PTRACE_POKEDATA:
-		pr_debug("POKETEXT/POKEDATA to %08lX\n", addr);
-		rval = 0;
-		if (access_process_vm(child, addr, &data, sizeof(data), 1)
-		    == sizeof(data))
-			break;
-		rval = -EIO;
-		break;
-
 	/* Read/write the word at location ADDR in the registers. */
 	case PTRACE_PEEKUSR:
 	case PTRACE_POKEUSR:
@@ -126,53 +111,69 @@ long arch_ptrace(struct task_struct *chi
 		if (rval == 0 && request == PTRACE_PEEKUSR)
 			rval = put_user(val, (unsigned long *)data);
 		break;
-	/* Continue and stop at next (return from) syscall */
-	case PTRACE_SYSCALL:
-		pr_debug("PTRACE_SYSCALL\n");
-	case PTRACE_SINGLESTEP:
-		pr_debug("PTRACE_SINGLESTEP\n");
-	/* Restart after a signal.  */
-	case PTRACE_CONT:
-		pr_debug("PTRACE_CONT\n");
-		rval = -EIO;
-		if (!valid_signal(data))
-			break;
-
-		if (request == PTRACE_SYSCALL)
-			set_tsk_thread_flag(child, TIF_SYSCALL_TRACE);
-		else
-			clear_tsk_thread_flag(child, TIF_SYSCALL_TRACE);
-
-		child->exit_code = data;
-		pr_debug("wakeup_process\n");
-		wake_up_process(child);
-		rval = 0;
-		break;
+	default:
+		rval = ptrace_request(child, request, addr, data);
+	}
+	return rval;
+}
+
+asmlinkage long do_syscall_trace_enter(struct pt_regs *regs)
+{
+	long ret = 0;
+
+	secure_computing(regs->r12);
+
+	if (test_thread_flag(TIF_SYSCALL_TRACE) &&
+	    tracehook_report_syscall_entry(regs))
+		/*
+		 * Tracing decided this syscall should not happen.
+		 * We'll return a bogus call number to get an ENOSYS
+		 * error, but leave the original number in regs->regs[0].
+		 */
+		ret = -1L;
+
+	if (unlikely(current->audit_context))
+		audit_syscall_entry(EM_XILINX_MICROBLAZE, regs->r12,
+				    regs->r5, regs->r6,
+				    regs->r7, regs->r8);
 
+	return ret ?: regs->r12;
+}
+
+asmlinkage void do_syscall_trace_leave(struct pt_regs *regs)
+{
+	int step;
+
+	if (unlikely(current->audit_context))
+		audit_syscall_exit(AUDITSC_RESULT(regs->r3), regs->r3);
+
+	step = test_thread_flag(TIF_SINGLESTEP);
+	if (step || test_thread_flag(TIF_SYSCALL_TRACE))
+		tracehook_report_syscall_exit(regs, step);
+}
+
+#if 0
+static asmlinkage void syscall_trace(void)
+{
+	if (!test_thread_flag(TIF_SYSCALL_TRACE))
+		return;
+	if (!(current->ptrace & PT_PTRACED))
+		return;
+	/* The 0x80 provides a way for the tracing parent to distinguish
+	 between a syscall stop and SIGTRAP delivery */
+	ptrace_notify(SIGTRAP | ((current->ptrace & PT_TRACESYSGOOD)
+				? 0x80 : 0));
 	/*
-	 * make the child exit.  Best I can do is send it a sigkill.
-	 * perhaps it should be put in the status that it wants to
-	 * exit.
+	 * this isn't the same as continuing with a signal, but it will do
+	 * for normal use. strace only continues with a signal if the
+	 * stopping signal is not SIGTRAP. -brl
 	 */
-	case PTRACE_KILL:
-		pr_debug("PTRACE_KILL\n");
-		rval = 0;
-		if (child->exit_state == EXIT_ZOMBIE)	/* already dead */
-			break;
-		child->exit_code = SIGKILL;
-		wake_up_process(child);
-		break;
-
-	case PTRACE_DETACH: /* detach a process that was attached. */
-		pr_debug("PTRACE_DETACH\n");
-		rval = ptrace_detach(child, data);
-		break;
-	default:
-		/* rval = ptrace_request(child, request, addr, data); noMMU */
-		rval = -EIO;
+	if (current->exit_code) {
+		send_sig(current->exit_code, current, 1);
+		current->exit_code = 0;
 	}
-	return rval;
 }
+#endif
 
 void ptrace_disable(struct task_struct *child)
 {
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/reset.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/reset.c
--- linux-2.6.31.12/arch/microblaze/kernel/reset.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/reset.c	2010-08-08 17:22:50.587778546 +0200
@@ -0,0 +1,140 @@
+/*
+ * Copyright (C) 2009 Michal Simek <monstr@monstr.eu>
+ * Copyright (C) 2009 PetaLogix
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License. See the file "COPYING" in the main directory of this archive
+ * for more details.
+ */
+
+#include <linux/init.h>
+#include <linux/of_platform.h>
+#include <asm/prom.h>
+
+/* Trigger specific functions */
+#ifdef CONFIG_GPIOLIB
+
+#include <linux/of_gpio.h>
+
+static int handle; /* reset pin handle */
+static unsigned int reset_val;
+
+static int of_reset_gpio_handle(void)
+{
+	int ret; /* variable which stored handle reset gpio pin */
+	struct device_node *root; /* root node */
+	struct device_node *gpio; /* gpio node */
+	struct of_gpio_chip *of_gc = NULL;
+	enum of_gpio_flags flags ;
+	const void *gpio_spec;
+
+	/* find out root node */
+	root = of_find_node_by_path("/");
+
+	/* give me handle for gpio node to be possible allocate pin */
+	ret = of_parse_phandles_with_args(root, "hard-reset-gpios",
+				"#gpio-cells", 0, &gpio, &gpio_spec);
+	if (ret) {
+		pr_debug("%s: can't parse gpios property\n", __func__);
+		goto err0;
+	}
+
+	of_gc = gpio->data;
+	if (!of_gc) {
+		pr_debug("%s: gpio controller %s isn't registered\n",
+			 root->full_name, gpio->full_name);
+		ret = -ENODEV;
+		goto err1;
+	}
+
+	ret = of_gc->xlate(of_gc, root, gpio_spec, &flags);
+	if (ret < 0)
+		goto err1;
+
+	ret += of_gc->gc.base;
+err1:
+	of_node_put(gpio);
+err0:
+	pr_debug("%s exited with status %d\n", __func__, ret);
+	return ret;
+}
+
+void of_platform_reset_gpio_probe(void)
+{
+	int ret;
+	handle = of_reset_gpio_handle();
+
+	if (!gpio_is_valid(handle)) {
+		printk(KERN_INFO "Skipping unavailable RESET gpio %d (%s)\n",
+				handle, "reset");
+	}
+
+	ret = gpio_request(handle, "reset");
+	if (ret < 0) {
+		printk(KERN_INFO "GPIO pin is already allocated\n");
+		return;
+	}
+
+	/* get current setup value */
+	reset_val = gpio_get_value(handle);
+	/* FIXME maybe worth to perform any action */
+	pr_debug("Reset: Gpio output state: 0x%x\n", reset_val);
+
+	/* Setup GPIO as output */
+	ret = gpio_direction_output(handle, 0);
+	if (ret < 0)
+		goto err;
+
+	/* Setup output direction */
+	gpio_set_value(handle, 0);
+
+	printk(KERN_INFO "RESET: Registered gpio device: %d, current val: %d\n",
+							handle, reset_val);
+	return;
+err:
+	gpio_free(handle);
+	return;
+}
+
+
+static void gpio_system_reset(void)
+{
+	gpio_set_value(handle, 1 - reset_val);
+}
+#else
+#define gpio_system_reset() do {} while (0)
+void of_platform_reset_gpio_probe(void)
+{
+	return;
+}
+#endif
+
+void machine_restart(char *cmd)
+{
+	printk(KERN_NOTICE "Machine restart...\n");
+	gpio_system_reset();
+	dump_stack();
+	while (1)
+		;
+}
+
+void machine_shutdown(void)
+{
+	printk(KERN_NOTICE "Machine shutdown...\n");
+	while (1)
+		;
+}
+
+void machine_halt(void)
+{
+	printk(KERN_NOTICE "Machine halt...\n");
+	while (1)
+		;
+}
+
+void machine_power_off(void)
+{
+	printk(KERN_NOTICE "Machine power off...\n");
+	while (1)
+		;
+}
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/setup.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/setup.c
--- linux-2.6.31.12/arch/microblaze/kernel/setup.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/setup.c	2010-08-08 17:40:15.867945370 +0200
@@ -22,7 +22,10 @@
 #include <linux/io.h>
 #include <linux/bug.h>
 #include <linux/param.h>
+#include <linux/pci.h>
 #include <linux/cache.h>
+#include <linux/of_platform.h>
+#include <linux/dma-mapping.h>
 #include <asm/cacheflush.h>
 #include <asm/entry.h>
 #include <asm/cpuinfo.h>
@@ -52,16 +55,14 @@ void __init setup_arch(char **cmdline_p)
 	/* irq_early_init(); */
 	setup_cpuinfo();
 
-	__invalidate_icache_all();
-	__enable_icache();
-
-	__invalidate_dcache_all();
-	__enable_dcache();
+	microblaze_cache_init();
 
 	panic_timeout = 120;
 
 	setup_memory();
 
+	xilinx_pci_init();
+
 #if defined(CONFIG_SELFMOD_INTC) || defined(CONFIG_SELFMOD_TIMER)
 	printk(KERN_NOTICE "Self modified code enable\n");
 #endif
@@ -93,8 +94,17 @@ inline unsigned get_romfs_len(unsigned *
 }
 #endif	/* CONFIG_MTD_UCLINUX_EBSS */
 
+unsigned long kernel_tlb;
+
+#if defined(CONFIG_EARLY_PRINTK) && defined(CONFIG_SERIAL_UARTLITE_CONSOLE)
+#define eprintk early_printk
+#else
+#define eprintk printk
+#endif
+
 void __init machine_early_init(const char *cmdline, unsigned int ram,
-		unsigned int fdt)
+		unsigned int fdt, unsigned int msr, unsigned int tlb0,
+		unsigned int tlb1)
 {
 	unsigned long *src, *dst = (unsigned long *)0x0;
 
@@ -131,6 +141,8 @@ void __init machine_early_init(const cha
 		strlcpy(cmd_line, cmdline, COMMAND_LINE_SIZE);
 #endif
 
+	lockdep_init();
+
 /* initialize device tree for usage in early_printk */
 	early_init_devtree((void *)_fdt_start);
 
@@ -138,23 +150,39 @@ void __init machine_early_init(const cha
 	setup_early_printk(NULL);
 #endif
 
-	early_printk("Ramdisk addr 0x%08x, ", ram);
+	/* setup kernel_tlb after BSS cleaning
+	 * Maybe worth to move to asm code */
+	kernel_tlb = tlb0 + tlb1;
+	/* eprintk("TLB1 0x%08x, TLB0 0x%08x, tlb 0x%x\n", tlb0,
+							tlb1, kernel_tlb); */
+
+	eprintk("Ramdisk addr 0x%08x, ", ram);
 	if (fdt)
-		early_printk("FDT at 0x%08x\n", fdt);
+		eprintk("FDT at 0x%08x\n", fdt);
 	else
-		early_printk("Compiled-in FDT at 0x%08x\n",
+		eprintk("Compiled-in FDT at 0x%08x\n",
 					(unsigned int)_fdt_start);
 
 #ifdef CONFIG_MTD_UCLINUX
-	early_printk("Found romfs @ 0x%08x (0x%08x)\n",
+	eprintk("Found romfs @ 0x%08x (0x%08x)\n",
 			romfs_base, romfs_size);
-	early_printk("#### klimit %p ####\n", old_klimit);
+	eprintk("#### klimit %p ####\n", old_klimit);
 	BUG_ON(romfs_size < 0); /* What else can we do? */
 
-	early_printk("Moved 0x%08x bytes from 0x%08x to 0x%08x\n",
+	eprintk("Moved 0x%08x bytes from 0x%08x to 0x%08x\n",
 			romfs_size, romfs_base, (unsigned)&_ebss);
 
-	early_printk("New klimit: 0x%08x\n", (unsigned)klimit);
+	eprintk("New klimit: 0x%08x\n", (unsigned)klimit);
+#endif
+
+#if CONFIG_XILINX_MICROBLAZE0_USE_MSR_INSTR
+	if (msr)
+		eprintk("!!!Your kernel has setup MSR instruction but "
+				"CPU don't have it %d\n", msr);
+#else
+	if (!msr)
+		eprintk("!!!Your kernel not setup MSR instruction but "
+				"CPU have it %d\n", msr);
 #endif
 
 	for (src = __ivt_start; src < __ivt_end; src++, dst++)
@@ -177,31 +205,36 @@ static int microblaze_debugfs_init(void)
 arch_initcall(microblaze_debugfs_init);
 #endif
 
-void machine_restart(char *cmd)
+static int dflt_bus_notify(struct notifier_block *nb,
+				unsigned long action, void *data)
 {
-	printk(KERN_NOTICE "Machine restart...\n");
-	dump_stack();
-	while (1)
-		;
-}
+	struct device *dev = data;
 
-void machine_shutdown(void)
-{
-	printk(KERN_NOTICE "Machine shutdown...\n");
-	while (1)
-		;
-}
+	/* We are only intereted in device addition */
+	if (action != BUS_NOTIFY_ADD_DEVICE)
+		return 0;
 
-void machine_halt(void)
-{
-	printk(KERN_NOTICE "Machine halt...\n");
-	while (1)
-		;
+	set_dma_ops(dev, &dma_direct_ops);
+
+	return NOTIFY_DONE;
 }
 
-void machine_power_off(void)
+static struct notifier_block dflt_plat_bus_notifier = {
+	.notifier_call = dflt_bus_notify,
+	.priority = INT_MAX,
+};
+
+static struct notifier_block dflt_of_bus_notifier = {
+	.notifier_call = dflt_bus_notify,
+	.priority = INT_MAX,
+};
+
+static int __init setup_bus_notifier(void)
 {
-	printk(KERN_NOTICE "Machine power off...\n");
-	while (1)
-		;
+	bus_register_notifier(&platform_bus_type, &dflt_plat_bus_notifier);
+	bus_register_notifier(&of_platform_bus_type, &dflt_of_bus_notifier);
+
+	return 0;
 }
+
+arch_initcall(setup_bus_notifier);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/signal.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/signal.c
--- linux-2.6.31.12/arch/microblaze/kernel/signal.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/signal.c	2010-08-08 17:40:15.867945370 +0200
@@ -44,7 +44,6 @@
 
 asmlinkage int do_signal(struct pt_regs *regs, sigset_t *oldset, int in_sycall);
 
-
 asmlinkage long
 sys_sigaltstack(const stack_t __user *uss, stack_t __user *uoss,
 		struct pt_regs *regs)
@@ -176,6 +175,11 @@ static void setup_rt_frame(int sig, stru
 	struct rt_sigframe __user *frame;
 	int err = 0;
 	int signal;
+	unsigned long address = 0;
+#ifdef CONFIG_MMU
+	pmd_t *pmdp;
+	pte_t *ptep;
+#endif
 
 	frame = get_sigframe(ka, regs, sizeof(*frame));
 
@@ -216,8 +220,29 @@ static void setup_rt_frame(int sig, stru
 	 Negative 8 offset because return is rtsd r15, 8 */
 	regs->r15 = ((unsigned long)frame->tramp)-8;
 
-	__invalidate_cache_sigtramp((unsigned long)frame->tramp);
-
+	address = ((unsigned long)frame->tramp);
+#ifdef CONFIG_MMU
+	pmdp = pmd_offset(pud_offset(
+			pgd_offset(current->mm, address),
+					address), address);
+
+	preempt_disable();
+	ptep = pte_offset_map(pmdp, address);
+	if (pte_present(*ptep)) {
+		address = (unsigned long) page_address(pte_page(*ptep));
+		/* MS: I need add offset in page */
+		address += ((unsigned long)frame->tramp) & ~PAGE_MASK;
+		/* MS address is virtual */
+		address = virt_to_phys(address);
+		invalidate_icache_range(address, address + 8);
+		flush_dcache_range(address, address + 8);
+	}
+	pte_unmap(ptep);
+	preempt_enable();
+#else
+	flush_icache_range(address, address + 8);
+	flush_dcache_range(address, address + 8);
+#endif
 	if (err)
 		goto give_sigsegv;
 
@@ -233,6 +258,10 @@ static void setup_rt_frame(int sig, stru
 
 	set_fs(USER_DS);
 
+	/* the tracer may want to single-step inside the handler */
+	if (test_thread_flag(TIF_SINGLESTEP))
+		ptrace_notify(SIGTRAP);
+
 #ifdef DEBUG_SIG
 	printk(KERN_INFO "SIG deliver (%s:%d): sp=%p pc=%08lx\n",
 		current->comm, current->pid, frame, regs->pc);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/stacktrace.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/stacktrace.c
--- linux-2.6.31.12/arch/microblaze/kernel/stacktrace.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/stacktrace.c	2010-08-08 17:40:15.867945370 +0200
@@ -0,0 +1,65 @@
+/*
+ * Stack trace support for Microblaze.
+ *
+ * Copyright (C) 2009 Michal Simek <monstr@monstr.eu>
+ * Copyright (C) 2009 PetaLogix
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License. See the file "COPYING" in the main directory of this archive
+ * for more details.
+ */
+
+#include <linux/sched.h>
+#include <linux/stacktrace.h>
+#include <linux/thread_info.h>
+#include <linux/ptrace.h>
+#include <linux/module.h>
+
+/* FIXME initial support */
+void save_stack_trace(struct stack_trace *trace)
+{
+	unsigned long *sp;
+	unsigned long addr;
+	asm("addik %0, r1, 0" : "=r" (sp));
+
+	while (!kstack_end(sp)) {
+		addr = *sp++;
+		if (__kernel_text_address(addr)) {
+			if (trace->skip > 0)
+				trace->skip--;
+			else
+				trace->entries[trace->nr_entries++] = addr;
+
+			if (trace->nr_entries >= trace->max_entries)
+				break;
+		}
+	}
+}
+EXPORT_SYMBOL_GPL(save_stack_trace);
+
+void save_stack_trace_tsk(struct task_struct *tsk, struct stack_trace *trace)
+{
+	unsigned int *sp;
+	unsigned long addr;
+
+	struct thread_info *ti = task_thread_info(tsk);
+
+	if (tsk == current)
+		asm("addik %0, r1, 0" : "=r" (sp));
+	else
+		sp = (unsigned int *)ti->cpu_context.r1;
+
+	while (!kstack_end(sp)) {
+		addr = *sp++;
+		if (__kernel_text_address(addr)) {
+			if (trace->skip > 0)
+				trace->skip--;
+			else
+				trace->entries[trace->nr_entries++] = addr;
+
+			if (trace->nr_entries >= trace->max_entries)
+				break;
+		}
+	}
+}
+EXPORT_SYMBOL_GPL(save_stack_trace_tsk);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/syscall_table.S linux-2.6.31.12-petalinux/arch/microblaze/kernel/syscall_table.S
--- linux-2.6.31.12/arch/microblaze/kernel/syscall_table.S	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/syscall_table.S	2010-08-08 17:40:15.867945370 +0200
@@ -183,7 +183,7 @@ ENTRY(sys_call_table)
 	.long sys_rt_sigpending
 	.long sys_rt_sigtimedwait
 	.long sys_rt_sigqueueinfo
-	.long sys_rt_sigsuspend_wrapper
+	.long sys_rt_sigsuspend
 	.long sys_pread64		/* 180 */
 	.long sys_pwrite64
 	.long sys_chown
@@ -303,7 +303,7 @@ ENTRY(sys_call_table)
 	.long sys_mkdirat
 	.long sys_mknodat
 	.long sys_fchownat
-	.long sys_ni_syscall
+	.long sys_futimesat
 	.long sys_fstatat64		/* 300 */
 	.long sys_unlinkat
 	.long sys_renameat
@@ -366,7 +366,7 @@ ENTRY(sys_call_table)
 	.long sys_shutdown
 	.long sys_sendmsg		/* 360 */
 	.long sys_recvmsg
-	.long sys_ni_syscall
+	.long sys_accept4
 	.long sys_ni_syscall
 	.long sys_ni_syscall
 	.long sys_rt_tgsigqueueinfo	/* 365 */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/timer.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/timer.c
--- linux-2.6.31.12/arch/microblaze/kernel/timer.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/timer.c	2010-08-08 17:40:15.867945370 +0200
@@ -183,6 +183,31 @@ static cycle_t microblaze_read(struct cl
 	return (cycle_t) (in_be32(TIMER_BASE + TCR1));
 }
 
+static struct timecounter microblaze_tc = {
+	.cc = NULL,
+};
+
+static cycle_t microblaze_cc_read(const struct cyclecounter *cc)
+{
+	return microblaze_read(NULL);
+}
+
+static struct cyclecounter microblaze_cc = {
+	.read = microblaze_cc_read,
+	.mask = CLOCKSOURCE_MASK(32),
+	.shift = 24,
+};
+
+int __init init_microblaze_timecounter(void)
+{
+	microblaze_cc.mult = div_sc(cpuinfo.cpu_clock_freq, NSEC_PER_SEC,
+				microblaze_cc.shift);
+
+	timecounter_init(&microblaze_tc, &microblaze_cc, sched_clock());
+
+	return 0;
+}
+
 static struct clocksource clocksource_microblaze = {
 	.name		= "microblaze_clocksource",
 	.rating		= 300,
@@ -204,6 +229,9 @@ static int __init microblaze_clocksource
 	out_be32(TIMER_BASE + TCSR1, in_be32(TIMER_BASE + TCSR1) & ~TCSR_ENT);
 	/* start timer1 - up counting without interrupt */
 	out_be32(TIMER_BASE + TCSR1, TCSR_TINT|TCSR_ENT|TCSR_ARHT);
+
+	/* register timecounter - for ftrace support */
+	init_microblaze_timecounter();
 	return 0;
 }
 
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/traps.c linux-2.6.31.12-petalinux/arch/microblaze/kernel/traps.c
--- linux-2.6.31.12/arch/microblaze/kernel/traps.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/traps.c	2010-08-08 17:40:15.872768119 +0200
@@ -73,8 +73,10 @@ void show_stack(struct task_struct *task
 		if (task)
 			sp = (unsigned long *) ((struct thread_info *)
 						(task->stack))->cpu_context.r1;
-		else
+		else {
 			sp = (unsigned long *)&sp;
+			sp -= 2;	/* Pick up caller of dump_stack() */
+		}
 	}
 
 	stack = sp;
@@ -97,37 +99,3 @@ void dump_stack(void)
 	show_stack(NULL, NULL);
 }
 EXPORT_SYMBOL(dump_stack);
-
-#ifdef CONFIG_MMU
-void __bug(const char *file, int line, void *data)
-{
-	if (data)
-		printk(KERN_CRIT "kernel BUG at %s:%d (data = %p)!\n",
-			file, line, data);
-	else
-		printk(KERN_CRIT "kernel BUG at %s:%d!\n", file, line);
-
-	machine_halt();
-}
-
-int bad_trap(int trap_num, struct pt_regs *regs)
-{
-	printk(KERN_CRIT
-		"unimplemented trap %d called at 0x%08lx, pid %d!\n",
-		trap_num, regs->pc, current->pid);
-	return -ENOSYS;
-}
-
-int debug_trap(struct pt_regs *regs)
-{
-	int i;
-	printk(KERN_CRIT "debug trap\n");
-	for (i = 0; i < 32; i++) {
-		/* printk("r%i:%08X\t",i,regs->gpr[i]); */
-		if ((i % 4) == 3)
-			printk(KERN_CRIT "\n");
-	}
-	printk(KERN_CRIT "pc:%08lX\tmsr:%08lX\n", regs->pc, regs->msr);
-	return -ENOSYS;
-}
-#endif
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/kernel/vmlinux.lds.S linux-2.6.31.12-petalinux/arch/microblaze/kernel/vmlinux.lds.S
--- linux-2.6.31.12/arch/microblaze/kernel/vmlinux.lds.S	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/kernel/vmlinux.lds.S	2010-08-08 17:40:15.872768119 +0200
@@ -12,45 +12,48 @@ OUTPUT_FORMAT("elf32-microblaze", "elf32
 OUTPUT_ARCH(microblaze)
 ENTRY(_start)
 
+#include <asm/page.h>
 #include <asm-generic/vmlinux.lds.h>
+#include <asm/thread_info.h>
 
 jiffies = jiffies_64 + 4;
 
 SECTIONS {
 	. = CONFIG_KERNEL_START;
-	.text : {
+	_start = CONFIG_KERNEL_BASE_ADDR;
+	.text : AT(ADDR(.text) - LOAD_OFFSET) {
 		_text = . ;
 		_stext = . ;
-		*(.text .text.*)
+		HEAD_TEXT
+		TEXT_TEXT
 		*(.fixup)
-
-		*(.exitcall.exit)
+		EXIT_TEXT
+		EXIT_CALL
 		SCHED_TEXT
 		LOCK_TEXT
 		KPROBES_TEXT
+		IRQENTRY_TEXT
 		. = ALIGN (4) ;
 		_etext = . ;
 	}
 
 	. = ALIGN (4) ;
-	_fdt_start = . ; /* place for fdt blob */
-	. = . + 0x4000;
-	_fdt_end = . ;
+	__fdt_blob : AT(ADDR(__fdt_blob) - LOAD_OFFSET) {
+		_fdt_start = . ;		/* place for fdt blob */
+		*(__fdt_blob) ;			/* Any link-placed DTB */
+	        . = _fdt_start + 0x4000;	/* Pad up to 16kbyte */
+		_fdt_end = . ;
+	}
 
 	. = ALIGN(16);
 	RODATA
-	. = ALIGN(16);
-	__ex_table : {
-		__start___ex_table = .;
-		*(__ex_table)
-		__stop___ex_table = .;
-	}
+	EXCEPTION_TABLE(16)
 
 	/*
 	 * sdata2 section can go anywhere, but must be word aligned
 	 * and SDA2_BASE must point to the middle of it
 	 */
-	.sdata2 : {
+	.sdata2 : AT(ADDR(.sdata2) - LOAD_OFFSET) {
 		_ssrw = .;
 		. = ALIGN(4096); /* page aligned when MMU used - origin 0x8 */
 		*(.sdata2)
@@ -61,12 +64,7 @@ SECTIONS {
 	}
 
 	_sdata = . ;
-	.data ALIGN (4096) : { /* page aligned when MMU used - origin 0x4 */
-		DATA_DATA
-		CONSTRUCTORS
-	}
-	. = ALIGN(32);
-	.data.cacheline_aligned : { *(.data.cacheline_aligned) }
+	RW_DATA_SECTION(32, PAGE_SIZE, THREAD_SIZE)
 	_edata = . ;
 
 	/* Reserve some low RAM for r0 based memory references */
@@ -74,18 +72,14 @@ SECTIONS {
 	r0_ram = . ;
 	. = . +  4096;	/* a page should be enough */
 
-	/* The initial task */
-	. = ALIGN(8192);
-	.data.init_task : { *(.data.init_task) }
-
 	/* Under the microblaze ABI, .sdata and .sbss must be contiguous */
 	. = ALIGN(8);
-	.sdata : {
+	.sdata : AT(ADDR(.sdata) - LOAD_OFFSET) {
 		_ssro = .;
 		*(.sdata)
 	}
 
-	.sbss :	{
+	.sbss :	AT(ADDR(.sbss) - LOAD_OFFSET) {
 		_ssbss = .;
 		*(.sbss)
 		_esbss = .;
@@ -94,49 +88,39 @@ SECTIONS {
 		_KERNEL_SDA_BASE_ = _ssro + (_ssro_size / 2) ;
 	}
 
+	. = ALIGN(PAGE_SIZE);
 	__init_begin = .;
 
-	. = ALIGN(4096);
-	.init.text : {
-		_sinittext = . ;
-		INIT_TEXT
-		_einittext = .;
-	}
+	INIT_TEXT_SECTION(PAGE_SIZE)
 
-	.init.data : {
+	.init.data : AT(ADDR(.init.data) - LOAD_OFFSET) {
 		INIT_DATA
 	}
 
 	. = ALIGN(4);
-	.init.ivt : {
+	.init.ivt : AT(ADDR(.init.ivt) - LOAD_OFFSET) {
 		__ivt_start = .;
 		*(.init.ivt)
 		__ivt_end = .;
 	}
 
-	.init.setup : {
-		__setup_start = .;
-		*(.init.setup)
-		__setup_end = .;
-	}
-
-	.initcall.init : {
-		__initcall_start = .;
-		INITCALLS
-		__initcall_end = .;
-	}
-
-	.con_initcall.init : {
-		__con_initcall_start = .;
-		*(.con_initcall.init)
-		__con_initcall_end = .;
+	.init.setup : AT(ADDR(.init.setup) - LOAD_OFFSET) {
+		INIT_SETUP(0)
+	}
+
+	.initcall.init : AT(ADDR(.initcall.init) - LOAD_OFFSET ) {
+		INIT_CALLS
+	}
+
+	.con_initcall.init : AT(ADDR(.con_initcall.init) - LOAD_OFFSET) {
+		CON_INITCALL
 	}
 
 	SECURITY_INIT
 
 	__init_end_before_initramfs = .;
 
-	.init.ramfs ALIGN(4096) : {
+	.init.ramfs ALIGN(4096) : AT(ADDR(.init.ramfs) - LOAD_OFFSET) {
 		__initramfs_start = .;
 		*(.init.ramfs)
 		__initramfs_end = .;
@@ -152,7 +136,8 @@ SECTIONS {
 	}
 	__init_end = .;
 
-	.bss ALIGN (4096) : { /* page aligned when MMU used */
+	.bss ALIGN (4096) : AT(ADDR(.bss) - LOAD_OFFSET) {
+		/* page aligned when MMU used */
 		__bss_start = . ;
 			*(.bss*)
 			*(COMMON)
@@ -162,4 +147,5 @@ SECTIONS {
 	}
 	. = ALIGN(4096);
 	_end = .;
+
 }
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/lib/fastcopy.S linux-2.6.31.12-petalinux/arch/microblaze/lib/fastcopy.S
--- linux-2.6.31.12/arch/microblaze/lib/fastcopy.S	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/lib/fastcopy.S	2010-08-08 17:40:15.872768119 +0200
@@ -30,8 +30,9 @@
  */
 
 #include <linux/linkage.h>
-
+	.text
 	.globl	memcpy
+	.type  memcpy, @function
 	.ent	memcpy
 
 memcpy:
@@ -345,9 +346,11 @@ a_done:
 	rtsd	r15, 8
 	nop
 
+.size  memcpy, . - memcpy
 .end memcpy
 /*----------------------------------------------------------------------------*/
 	.globl	memmove
+	.type  memmove, @function
 	.ent	memmove
 
 memmove:
@@ -659,4 +662,5 @@ d_done:
 	rtsd	r15, 8
 	nop
 
+.size  memmove, . - memmove
 .end memmove
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/lib/Makefile linux-2.6.31.12-petalinux/arch/microblaze/lib/Makefile
--- linux-2.6.31.12/arch/microblaze/lib/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/lib/Makefile	2010-08-08 17:40:15.872768119 +0200
@@ -10,5 +10,4 @@ else
 lib-y += memcpy.o memmove.o
 endif
 
-lib-$(CONFIG_NO_MMU) += uaccess.o
-lib-$(CONFIG_MMU) += uaccess_old.o
+lib-y += uaccess_old.o
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/lib/memcpy.c linux-2.6.31.12-petalinux/arch/microblaze/lib/memcpy.c
--- linux-2.6.31.12/arch/microblaze/lib/memcpy.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/lib/memcpy.c	2010-08-08 17:40:15.872768119 +0200
@@ -9,7 +9,7 @@
  * It is based on demo code originally Copyright 2001 by Intel Corp, taken from
  * http://www.embedded.com/showArticle.jhtml?articleID=19205567
  *
- * Attempts were made, unsuccesfully, to contact the original
+ * Attempts were made, unsuccessfully, to contact the original
  * author of this code (Michael Morrow, Intel).  Below is the original
  * copyright notice.
  *
@@ -53,7 +53,7 @@ void *memcpy(void *v_dst, const void *v_
 	const uint32_t *i_src;
 	uint32_t *i_dst;
 
-	if (c >= 4) {
+	if (likely(c >= 4)) {
 		unsigned  value, buf_hold;
 
 		/* Align the dstination to a word boundry. */
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/lib/memmove.c linux-2.6.31.12-petalinux/arch/microblaze/lib/memmove.c
--- linux-2.6.31.12/arch/microblaze/lib/memmove.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/lib/memmove.c	2010-08-08 17:40:15.872768119 +0200
@@ -9,7 +9,7 @@
  * It is based on demo code originally Copyright 2001 by Intel Corp, taken from
  * http://www.embedded.com/showArticle.jhtml?articleID=19205567
  *
- * Attempts were made, unsuccesfully, to contact the original
+ * Attempts were made, unsuccessfully, to contact the original
  * author of this code (Michael Morrow, Intel).  Below is the original
  * copyright notice.
  *
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/lib/memset.c linux-2.6.31.12-petalinux/arch/microblaze/lib/memset.c
--- linux-2.6.31.12/arch/microblaze/lib/memset.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/lib/memset.c	2010-08-08 17:40:15.872768119 +0200
@@ -9,7 +9,7 @@
  * It is based on demo code originally Copyright 2001 by Intel Corp, taken from
  * http://www.embedded.com/showArticle.jhtml?articleID=19205567
  *
- * Attempts were made, unsuccesfully, to contact the original
+ * Attempts were made, unsuccessfully, to contact the original
  * author of this code (Michael Morrow, Intel).  Below is the original
  * copyright notice.
  *
@@ -33,22 +33,23 @@
 #ifdef __HAVE_ARCH_MEMSET
 void *memset(void *v_src, int c, __kernel_size_t n)
 {
-
 	char *src = v_src;
 #ifdef CONFIG_OPT_LIB_FUNCTION
 	uint32_t *i_src;
-	uint32_t w32;
+	uint32_t w32 = 0;
 #endif
 	/* Truncate c to 8 bits */
 	c = (c & 0xFF);
 
 #ifdef CONFIG_OPT_LIB_FUNCTION
-	/* Make a repeating word out of it */
-	w32 = c;
-	w32 |= w32 << 8;
-	w32 |= w32 << 16;
+	if (unlikely(c)) {
+		/* Make a repeating word out of it */
+		w32 = c;
+		w32 |= w32 << 8;
+		w32 |= w32 << 16;
+	}
 
-	if (n >= 4) {
+	if (likely(n >= 4)) {
 		/* Align the destination to a word boundary */
 		/* This is done in an endian independant manner */
 		switch ((unsigned) src & 3) {
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/lib/uaccess.c linux-2.6.31.12-petalinux/arch/microblaze/lib/uaccess.c
--- linux-2.6.31.12/arch/microblaze/lib/uaccess.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/lib/uaccess.c	1970-01-01 01:00:00.000000000 +0100
@@ -1,41 +0,0 @@
-/*
- * Copyright (C) 2006 Atmark Techno, Inc.
- *
- * This file is subject to the terms and conditions of the GNU General Public
- * License.  See the file "COPYING" in the main directory of this archive
- * for more details.
- */
-
-#include <linux/string.h>
-#include <asm/uaccess.h>
-
-#include <asm/bug.h>
-
-long strnlen_user(const char __user *src, long count)
-{
-	return strlen(src) + 1;
-}
-
-#define __do_strncpy_from_user(dst, src, count, res)			\
-	do {								\
-		char *tmp;						\
-		strncpy(dst, src, count);				\
-		for (tmp = dst; *tmp && count > 0; tmp++, count--)	\
-			;						\
-		res = (tmp - dst);					\
-	} while (0)
-
-long __strncpy_from_user(char *dst, const char __user *src, long count)
-{
-	long res;
-	__do_strncpy_from_user(dst, src, count, res);
-	return res;
-}
-
-long strncpy_from_user(char *dst, const char __user *src, long count)
-{
-	long res = -EFAULT;
-	if (access_ok(VERIFY_READ, src, 1))
-		__do_strncpy_from_user(dst, src, count, res);
-	return res;
-}
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/lib/uaccess_old.S linux-2.6.31.12-petalinux/arch/microblaze/lib/uaccess_old.S
--- linux-2.6.31.12/arch/microblaze/lib/uaccess_old.S	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/lib/uaccess_old.S	2010-08-08 17:40:15.872768119 +0200
@@ -22,6 +22,7 @@
 
 	.text
 .globl __strncpy_user;
+.type  __strncpy_user, @function
 .align 4;
 __strncpy_user:
 
@@ -50,7 +51,7 @@ __strncpy_user:
 3:
 	rtsd	r15,8
 	nop
-
+	.size   __strncpy_user, . - __strncpy_user
 
 	.section	.fixup, "ax"
 	.align	2
@@ -72,6 +73,7 @@ __strncpy_user:
 
 	.text
 .globl __strnlen_user;
+.type  __strnlen_user, @function
 .align 4;
 __strnlen_user:
 	addik	r3,r6,0
@@ -90,7 +92,7 @@ __strnlen_user:
 3:
 	rtsd	r15,8
 	nop
-
+	.size   __strnlen_user, . - __strnlen_user
 
 	.section	.fixup,"ax"
 4:
@@ -108,6 +110,7 @@ __strnlen_user:
  */
 	.text
 .globl __copy_tofrom_user;
+.type  __copy_tofrom_user, @function
 .align 4;
 __copy_tofrom_user:
 	/*
@@ -116,20 +119,34 @@ __copy_tofrom_user:
 	 * r7, r3 - count
 	 * r4 - tempval
 	 */
-	addik	r3,r7,0
-	beqi	r3,3f
-1:
-	lbu	r4,r6,r0
-	addik	r6,r6,1
-2:
-	sb	r4,r5,r0
-	addik	r3,r3,-1
-	bneid	r3,1b
-	addik	r5,r5,1		/* delay slot */
+	beqid	r7, 3f /* zero size is not likely */
+	andi	r3, r7, 0x3 /* filter add count */
+	bneid	r3, 4f /* if is odd value then byte copying */
+	or	r3, r5, r6 /* find if is any to/from unaligned */
+	andi	r3, r3, 0x3 /* mask unaligned */
+	bneid	r3, 1f /* it is unaligned -> then jump */
+	or	r3, r0, r0
+
+/* at least one 4 byte copy */
+5:	lw	r4, r6, r3
+6:	sw	r4, r5, r3
+	addik	r7, r7, -4
+	bneid	r7, 5b
+	addik	r3, r3, 4
+	addik	r3, r7, 0
+	rtsd	r15, 8
+	nop
+4:	or	r3, r0, r0
+1:	lbu	r4,r6,r3
+2:	sb	r4,r5,r3
+	addik	r7,r7,-1
+	bneid	r7,1b
+	addik	r3,r3,1		/* delay slot */
 3:
+	addik	r3,r7,0
 	rtsd	r15,8
 	nop
-
+	.size   __copy_tofrom_user, . - __copy_tofrom_user
 
 	.section	__ex_table,"a"
-	.word	1b,3b,2b,3b
+	.word	1b,3b,2b,3b,5b,3b,6b,3b
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/Makefile linux-2.6.31.12-petalinux/arch/microblaze/Makefile
--- linux-2.6.31.12/arch/microblaze/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/Makefile	2010-08-08 17:40:15.849523897 +0200
@@ -37,12 +37,12 @@ CPUFLAGS-$(CONFIG_XILINX_MICROBLAZE0_USE
 CPUFLAGS-1 += $(call cc-option,-mcpu=v$(CPU_VER))
 
 # r31 holds current when in kernel mode
-KBUILD_KERNEL += -ffixed-r31 $(CPUFLAGS-1) $(CPUFLAGS-2)
+KBUILD_CFLAGS += -ffixed-r31 $(CPUFLAGS-1) $(CPUFLAGS-2)
 
 LDFLAGS		:=
 LDFLAGS_vmlinux	:=
 
-LIBGCC := $(shell $(CC) $(KBUILD_KERNEL) -print-libgcc-file-name)
+LIBGCC := $(shell $(CC) $(KBUILD_CFLAGS) -print-libgcc-file-name)
 
 head-y := arch/microblaze/kernel/head.o
 libs-y += arch/microblaze/lib/
@@ -50,25 +50,49 @@ libs-y += $(LIBGCC)
 core-y += arch/microblaze/kernel/
 core-y += arch/microblaze/mm/
 core-y += arch/microblaze/platform/
+core-$(CONFIG_PCI) += arch/microblaze/pci/
+
+drivers-$(CONFIG_OPROFILE) += arch/microblaze/oprofile/
 
 boot := arch/microblaze/boot
 
+# Are we making a simpleImage.<boardname> target? If so, crack out the boardname
+DTB:=$(subst simpleImage.,,$(filter simpleImage.%, $(MAKECMDGOALS)))
+
+ifneq ($(DTB),)
+	core-y	+= $(boot)/
+endif
+
 # defines filename extension depending memory management type
 ifeq ($(CONFIG_MMU),)
 MMU := -nommu
 endif
 
-export MMU
+export MMU DTB
 
 all: linux.bin
 
+BOOT_TARGETS = linux.bin linux.bin.gz simpleImage.%
+
 archclean:
 	$(Q)$(MAKE) $(clean)=$(boot)
 
-linux.bin linux.bin.gz: vmlinux
+$(BOOT_TARGETS): vmlinux
 	$(Q)$(MAKE) $(build)=$(boot) $(boot)/$@
 
 define archhelp
-  echo  '* linux.bin    - Create raw binary'
-  echo  '  linux.bin.gz - Create compressed raw binary'
+  echo '* linux.bin    - Create raw binary'
+  echo '  linux.bin.gz - Create compressed raw binary'
+  echo '  simpleImage.<dt> - ELF image with $(arch)/boot/dts/<dt>.dts linked in'
+  echo '                   - stripped elf with fdt blob'
+  echo '  simpleImage.<dt>.unstrip - full ELF image with fdt blob'
+  echo '  *_defconfig      - Select default config from arch/microblaze/configs'
+  echo ''
+  echo '  Targets with <dt> embed a device tree blob inside the image'
+  echo '  These targets support board with firmware that does not'
+  echo '  support passing a device tree directly. Replace <dt> with the'
+  echo '  name of a dts file from the arch/microblaze/boot/dts/ directory'
+  echo '  (minus the .dts extension).'
 endef
+
+MRPROPER_FILES += $(boot)/simpleImage.*
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/mm/consistent.c linux-2.6.31.12-petalinux/arch/microblaze/mm/consistent.c
--- linux-2.6.31.12/arch/microblaze/mm/consistent.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/mm/consistent.c	2010-08-08 17:40:15.872768119 +0200
@@ -0,0 +1,254 @@
+/*
+ * Microblaze support for cache consistent memory.
+ * Copyright (C) 2010 Michal Simek <monstr@monstr.eu>
+ * Copyright (C) 2010 PetaLogix
+ * Copyright (C) 2005 John Williams <jwilliams@itee.uq.edu.au>
+ *
+ * Based on PowerPC version derived from arch/arm/mm/consistent.c
+ * Copyright (C) 2001 Dan Malek (dmalek@jlc.net)
+ * Copyright (C) 2000 Russell King
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <linux/module.h>
+#include <linux/signal.h>
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/string.h>
+#include <linux/types.h>
+#include <linux/ptrace.h>
+#include <linux/mman.h>
+#include <linux/mm.h>
+#include <linux/swap.h>
+#include <linux/stddef.h>
+#include <linux/vmalloc.h>
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/bootmem.h>
+#include <linux/highmem.h>
+#include <linux/pci.h>
+#include <linux/interrupt.h>
+
+#include <asm/pgalloc.h>
+#include <linux/io.h>
+#include <linux/hardirq.h>
+#include <asm/mmu_context.h>
+#include <asm/mmu.h>
+#include <linux/uaccess.h>
+#include <asm/pgtable.h>
+#include <asm/cpuinfo.h>
+#include <asm/tlbflush.h>
+
+#ifndef CONFIG_MMU
+/* I have to use dcache values because I can't relate on ram size */
+# define UNCACHED_SHADOW_MASK (cpuinfo.dcache_high - cpuinfo.dcache_base + 1)
+#endif
+
+/*
+ * Consistent memory allocators. Used for DMA devices that want to
+ * share uncached memory with the processor core.
+ * My crufty no-MMU approach is simple. In the HW platform we can optionally
+ * mirror the DDR up above the processor cacheable region.  So, memory accessed
+ * in this mirror region will not be cached.  It's alloced from the same
+ * pool as normal memory, but the handle we return is shifted up into the
+ * uncached region.  This will no doubt cause big problems if memory allocated
+ * here is not also freed properly. -- JW
+ */
+void *consistent_alloc(int gfp, size_t size, dma_addr_t *dma_handle)
+{
+	unsigned long order, vaddr;
+	void *ret;
+	unsigned int i, err = 0;
+	struct page *page, *end;
+
+#ifdef CONFIG_MMU
+	phys_addr_t pa;
+	struct vm_struct *area;
+	unsigned long va;
+#endif
+
+	if (in_interrupt())
+		BUG();
+
+	/* Only allocate page size areas. */
+	size = PAGE_ALIGN(size);
+	order = get_order(size);
+
+	vaddr = __get_free_pages(gfp, order);
+	if (!vaddr)
+		return NULL;
+
+	/*
+	 * we need to ensure that there are no cachelines in use,
+	 * or worse dirty in this area.
+	 */
+	flush_dcache_range(virt_to_phys((void *)vaddr),
+					virt_to_phys((void *)vaddr) + size);
+
+#ifndef CONFIG_MMU
+	ret = (void *)vaddr;
+	/*
+	 * Here's the magic!  Note if the uncached shadow is not implemented,
+	 * it's up to the calling code to also test that condition and make
+	 * other arranegments, such as manually flushing the cache and so on.
+	 */
+# ifdef CONFIG_XILINX_UNCACHED_SHADOW
+	ret = (void *)((unsigned) ret | UNCACHED_SHADOW_MASK);
+# endif
+	if ((unsigned int)ret > cpuinfo.dcache_base &&
+				(unsigned int)ret < cpuinfo.dcache_high)
+		printk(KERN_WARNING
+			"ERROR: Your cache coherent area is CACHED!!!\n");
+
+	/* dma_handle is same as physical (shadowed) address */
+	*dma_handle = (dma_addr_t)ret;
+#else
+	/* Allocate some common virtual space to map the new pages. */
+	area = get_vm_area(size, VM_ALLOC);
+	if (!area) {
+		free_pages(vaddr, order);
+		return NULL;
+	}
+	va = (unsigned long) area->addr;
+	ret = (void *)va;
+
+	/* This gives us the real physical address of the first page. */
+	*dma_handle = pa = virt_to_bus((void *)vaddr);
+#endif
+
+	/*
+	 * free wasted pages.  We skip the first page since we know
+	 * that it will have count = 1 and won't require freeing.
+	 * We also mark the pages in use as reserved so that
+	 * remap_page_range works.
+	 */
+	page = virt_to_page(vaddr);
+	end = page + (1 << order);
+
+	split_page(page, order);
+
+	for (i = 0; i < size && err == 0; i += PAGE_SIZE) {
+#ifdef CONFIG_MMU
+		/* MS: This is the whole magic - use cache inhibit pages */
+		err = map_page(va + i, pa + i, _PAGE_KERNEL | _PAGE_NO_CACHE);
+#endif
+
+		SetPageReserved(page);
+		page++;
+	}
+
+	/* Free the otherwise unused pages. */
+	while (page < end) {
+		__free_page(page);
+		page++;
+	}
+
+	if (err) {
+		free_pages(vaddr, order);
+		return NULL;
+	}
+
+	return ret;
+}
+EXPORT_SYMBOL(consistent_alloc);
+
+/*
+ * free page(s) as defined by the above mapping.
+ */
+void consistent_free(size_t size, void *vaddr)
+{
+	struct page *page;
+
+	if (in_interrupt())
+		BUG();
+
+	size = PAGE_ALIGN(size);
+
+#ifndef CONFIG_MMU
+	/* Clear SHADOW_MASK bit in address, and free as per usual */
+# ifdef CONFIG_XILINX_UNCACHED_SHADOW
+	vaddr = (void *)((unsigned)vaddr & ~UNCACHED_SHADOW_MASK);
+# endif
+	page = virt_to_page(vaddr);
+
+	do {
+		ClearPageReserved(page);
+		__free_page(page);
+		page++;
+	} while (size -= PAGE_SIZE);
+#else
+	do {
+		pte_t *ptep;
+		unsigned long pfn;
+
+		ptep = pte_offset_kernel(pmd_offset(pgd_offset_k(
+						(unsigned int)vaddr),
+					(unsigned int)vaddr),
+				(unsigned int)vaddr);
+		if (!pte_none(*ptep) && pte_present(*ptep)) {
+			pfn = pte_pfn(*ptep);
+			pte_clear(&init_mm, (unsigned int)vaddr, ptep);
+			if (pfn_valid(pfn)) {
+				page = pfn_to_page(pfn);
+
+				ClearPageReserved(page);
+				__free_page(page);
+			}
+		}
+		vaddr += PAGE_SIZE;
+	} while (size -= PAGE_SIZE);
+
+	/* flush tlb */
+	flush_tlb_all();
+#endif
+}
+EXPORT_SYMBOL(consistent_free);
+
+/*
+ * make an area consistent.
+ */
+void consistent_sync(void *vaddr, size_t size, int direction)
+{
+	unsigned long start;
+	unsigned long end;
+
+	start = (unsigned long)vaddr;
+
+	/* Convert start address back down to unshadowed memory region */
+#ifdef CONFIG_XILINX_UNCACHED_SHADOW
+	start &= ~UNCACHED_SHADOW_MASK;
+#endif
+	end = start + size;
+
+	switch (direction) {
+	case PCI_DMA_NONE:
+		BUG();
+	case PCI_DMA_FROMDEVICE:	/* invalidate only */
+		invalidate_dcache_range(start, end);
+		break;
+	case PCI_DMA_TODEVICE:		/* writeback only */
+		flush_dcache_range(start, end);
+		break;
+	case PCI_DMA_BIDIRECTIONAL:	/* writeback and invalidate */
+		flush_dcache_range(start, end);
+		break;
+	}
+}
+EXPORT_SYMBOL(consistent_sync);
+
+/*
+ * consistent_sync_page makes memory consistent. identical
+ * to consistent_sync, but takes a struct page instead of a
+ * virtual address
+ */
+void consistent_sync_page(struct page *page, unsigned long offset,
+	size_t size, int direction)
+{
+	unsigned long start = (unsigned long)page_address(page) + offset;
+	consistent_sync((void *)start, size, direction);
+}
+EXPORT_SYMBOL(consistent_sync_page);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/mm/fault.c linux-2.6.31.12-petalinux/arch/microblaze/mm/fault.c
--- linux-2.6.31.12/arch/microblaze/mm/fault.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/mm/fault.c	2010-08-08 17:40:15.872768119 +0200
@@ -106,7 +106,7 @@ void do_page_fault(struct pt_regs *regs,
 	regs->esr = error_code;
 
 	/* On a kernel SLB miss we can only check for a valid exception entry */
-	if (kernel_mode(regs) && (address >= TASK_SIZE)) {
+	if (unlikely(kernel_mode(regs) && (address >= TASK_SIZE))) {
 		printk(KERN_WARNING "kernel task_size exceed");
 		_exception(SIGSEGV, regs, code, address);
 	}
@@ -122,7 +122,7 @@ void do_page_fault(struct pt_regs *regs,
 	}
 #endif /* CONFIG_KGDB */
 
-	if (in_atomic() || !mm) {
+	if (unlikely(in_atomic() || !mm)) {
 		if (kernel_mode(regs))
 			goto bad_area_nosemaphore;
 
@@ -150,7 +150,7 @@ void do_page_fault(struct pt_regs *regs,
 	 * source.  If this is invalid we can skip the address space check,
 	 * thus avoiding the deadlock.
 	 */
-	if (!down_read_trylock(&mm->mmap_sem)) {
+	if (unlikely(!down_read_trylock(&mm->mmap_sem))) {
 		if (kernel_mode(regs) && !search_exception_tables(regs->pc))
 			goto bad_area_nosemaphore;
 
@@ -158,16 +158,16 @@ void do_page_fault(struct pt_regs *regs,
 	}
 
 	vma = find_vma(mm, address);
-	if (!vma)
+	if (unlikely(!vma))
 		goto bad_area;
 
 	if (vma->vm_start <= address)
 		goto good_area;
 
-	if (!(vma->vm_flags & VM_GROWSDOWN))
+	if (unlikely(!(vma->vm_flags & VM_GROWSDOWN)))
 		goto bad_area;
 
-	if (!is_write)
+	if (unlikely(!is_write))
 		goto bad_area;
 
 	/*
@@ -179,7 +179,7 @@ void do_page_fault(struct pt_regs *regs,
 	 * before setting the user r1.  Thus we allow the stack to
 	 * expand to 1MB without further checks.
 	 */
-	if (address + 0x100000 < vma->vm_end) {
+	if (unlikely(address + 0x100000 < vma->vm_end)) {
 
 		/* get user regs even if this fault is in kernel mode */
 		struct pt_regs *uregs = current->thread.regs;
@@ -209,15 +209,15 @@ good_area:
 	code = SEGV_ACCERR;
 
 	/* a write */
-	if (is_write) {
-		if (!(vma->vm_flags & VM_WRITE))
+	if (unlikely(is_write)) {
+		if (unlikely(!(vma->vm_flags & VM_WRITE)))
 			goto bad_area;
 	/* a read */
 	} else {
 		/* protection fault */
-		if (error_code & 0x08000000)
+		if (unlikely(error_code & 0x08000000))
 			goto bad_area;
-		if (!(vma->vm_flags & (VM_READ | VM_EXEC)))
+		if (unlikely(!(vma->vm_flags & (VM_READ | VM_EXEC))))
 			goto bad_area;
 	}
 
@@ -235,7 +235,7 @@ survive:
 			goto do_sigbus;
 		BUG();
 	}
-	if (fault & VM_FAULT_MAJOR)
+	if (unlikely(fault & VM_FAULT_MAJOR))
 		current->maj_flt++;
 	else
 		current->min_flt++;
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/mm/init.c linux-2.6.31.12-petalinux/arch/microblaze/mm/init.c
--- linux-2.6.31.12/arch/microblaze/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/mm/init.c	2010-08-08 17:40:15.872768119 +0200
@@ -23,6 +23,9 @@
 #include <asm/sections.h>
 #include <asm/tlb.h>
 
+/* Use for MMU and noMMU because of PCI generic code */
+int mem_init_done;
+
 #ifndef CONFIG_MMU
 unsigned int __page_offset;
 EXPORT_SYMBOL(__page_offset);
@@ -30,7 +33,6 @@ EXPORT_SYMBOL(__page_offset);
 #else
 DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);
 
-int mem_init_done;
 static int init_bootmem_done;
 #endif /* CONFIG_MMU */
 
@@ -41,8 +43,10 @@ char *klimit = _end;
  * have available.
  */
 unsigned long memory_start;
+EXPORT_SYMBOL(memory_start);
 unsigned long memory_end; /* due to mm/nommu.c */
 unsigned long memory_size;
+EXPORT_SYMBOL(memory_size);
 
 /*
  * paging_init() sets up the page tables - in fact we've already done this.
@@ -162,7 +166,6 @@ void free_init_pages(char *what, unsigne
 	for (addr = begin; addr < end; addr += PAGE_SIZE) {
 		ClearPageReserved(virt_to_page(addr));
 		init_page_count(virt_to_page(addr));
-		memset((void *)addr, 0xcc, PAGE_SIZE);
 		free_page(addr);
 		totalram_pages++;
 	}
@@ -180,7 +183,8 @@ void free_initrd_mem(unsigned long start
 		totalram_pages++;
 		pages++;
 	}
-	printk(KERN_NOTICE "Freeing initrd memory: %dk freed\n", pages);
+	printk(KERN_NOTICE "Freeing initrd memory: %dk freed\n",
+					(int)(pages * (PAGE_SIZE / 1024)));
 }
 #endif
 
@@ -191,12 +195,6 @@ void free_initmem(void)
 			(unsigned long)(&__init_end));
 }
 
-/* FIXME from arch/powerpc/mm/mem.c*/
-void show_mem(void)
-{
-	printk(KERN_NOTICE "%s\n", __func__);
-}
-
 void __init mem_init(void)
 {
 	high_memory = (void *)__va(memory_end);
@@ -204,22 +202,16 @@ void __init mem_init(void)
 	totalram_pages += free_all_bootmem();
 
 	printk(KERN_INFO "Memory: %luk/%luk available\n",
-	       (unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+	       nr_free_pages() << (PAGE_SHIFT-10),
 	       num_physpages << (PAGE_SHIFT-10));
-#ifdef CONFIG_MMU
 	mem_init_done = 1;
-#endif
 }
 
 #ifndef CONFIG_MMU
-/* Check against bounds of physical memory */
-int ___range_ok(unsigned long addr, unsigned long size)
+int page_is_ram(unsigned long pfn)
 {
-	return ((addr < memory_start) ||
-		((addr + size) > memory_end));
+	return __range_ok(pfn, 0);
 }
-EXPORT_SYMBOL(___range_ok);
-
 #else
 int page_is_ram(unsigned long pfn)
 {
@@ -285,10 +277,16 @@ asmlinkage void __init mmu_init(void)
 		machine_restart(NULL);
 	}
 
-	if ((u32) lmb.memory.region[0].size < 0x1000000) {
-		printk(KERN_EMERG "Memory must be greater than 16MB\n");
+	if ((u32) lmb.memory.region[0].size < 0x400000) {
+		printk(KERN_EMERG "Memory must be greater than 4MB\n");
+		machine_restart(NULL);
+	}
+
+	if ((u32) lmb.memory.region[0].size < kernel_tlb) {
+		printk(KERN_EMERG "Kernel size is greater than memory node\n");
 		machine_restart(NULL);
 	}
+
 	/* Find main memory where the kernel is */
 	memory_start = (u32) lmb.memory.region[0].base;
 	memory_end = (u32) lmb.memory.region[0].base +
@@ -339,12 +337,35 @@ void __init *early_get_page(void)
 		p = alloc_bootmem_pages(PAGE_SIZE);
 	} else {
 		/*
-		 * Mem start + 32MB -> here is limit
+		 * Mem start + kernel_tlb -> here is limit
 		 * because of mem mapping from head.S
 		 */
 		p = __va(lmb_alloc_base(PAGE_SIZE, PAGE_SIZE,
-					memory_start + 0x2000000));
+					memory_start + kernel_tlb));
 	}
 	return p;
 }
+
 #endif /* CONFIG_MMU */
+
+void * __init_refok alloc_maybe_bootmem(size_t size, gfp_t mask)
+{
+	if (mem_init_done)
+		return kmalloc(size, mask);
+	else
+		return alloc_bootmem(size);
+}
+
+void * __init_refok zalloc_maybe_bootmem(size_t size, gfp_t mask)
+{
+	void *p;
+
+	if (mem_init_done)
+		p = kzalloc(size, mask);
+	else {
+		p = alloc_bootmem(size);
+		if (p)
+			memset(p, 0, size);
+	}
+	return p;
+}
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/mm/Makefile linux-2.6.31.12-petalinux/arch/microblaze/mm/Makefile
--- linux-2.6.31.12/arch/microblaze/mm/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/mm/Makefile	2010-08-08 17:40:15.872768119 +0200
@@ -2,6 +2,6 @@
 # Makefile
 #
 
-obj-y := init.o
+obj-y := consistent.o init.o
 
 obj-$(CONFIG_MMU) += pgtable.o mmu_context.o fault.o
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/mm/pgtable.c linux-2.6.31.12-petalinux/arch/microblaze/mm/pgtable.c
--- linux-2.6.31.12/arch/microblaze/mm/pgtable.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/mm/pgtable.c	2010-08-08 17:40:15.872768119 +0200
@@ -42,6 +42,7 @@
 
 unsigned long ioremap_base;
 unsigned long ioremap_bot;
+EXPORT_SYMBOL(ioremap_bot);
 
 /* The maximum lowmem defaults to 768Mb, but this can be configured to
  * another value.
@@ -103,7 +104,7 @@ static void __iomem *__ioremap(phys_addr
 		area = get_vm_area(size, VM_IOREMAP);
 		if (area == NULL)
 			return NULL;
-		v = VMALLOC_VMADDR(area->addr);
+		v = (unsigned long) area->addr;
 	} else {
 		v = (ioremap_bot -= size);
 	}
@@ -144,7 +145,6 @@ int map_page(unsigned long va, phys_addr
 	pmd_t *pd;
 	pte_t *pg;
 	int err = -ENOMEM;
-	/* spin_lock(&init_mm.page_table_lock); */
 	/* Use upper 10 bits of VA to index the first level map */
 	pd = pmd_offset(pgd_offset_k(va), va);
 	/* Use middle 10 bits of VA to index the second-level map */
@@ -155,39 +155,13 @@ int map_page(unsigned long va, phys_addr
 		err = 0;
 		set_pte_at(&init_mm, va, pg, pfn_pte(pa >> PAGE_SHIFT,
 				__pgprot(flags)));
-		if (mem_init_done)
+		if (unlikely(mem_init_done))
 			flush_HPTE(0, va, pmd_val(*pd));
 			/* flush_HPTE(0, va, pg); */
-
 	}
-	/* spin_unlock(&init_mm.page_table_lock); */
 	return err;
 }
 
-void __init adjust_total_lowmem(void)
-{
-/* TBD */
-#if 0
-	unsigned long max_low_mem = MAX_LOW_MEM;
-
-	if (total_lowmem > max_low_mem) {
-		total_lowmem = max_low_mem;
-#ifndef CONFIG_HIGHMEM
-		printk(KERN_INFO "Warning, memory limited to %ld Mb, use "
-				"CONFIG_HIGHMEM to reach %ld Mb\n",
-				max_low_mem >> 20, total_memory >> 20);
-		total_memory = total_lowmem;
-#endif /* CONFIG_HIGHMEM */
-	}
-#endif
-}
-
-static void show_tmem(unsigned long tmem)
-{
-	volatile unsigned long a;
-	a = a + tmem;
-}
-
 /*
  * Map in all of physical memory starting at CONFIG_KERNEL_START.
  */
@@ -197,7 +171,6 @@ void __init mapin_ram(void)
 
 	v = CONFIG_KERNEL_START;
 	p = memory_start;
-	show_tmem(memory_size);
 	for (s = 0; s < memory_size; s += PAGE_SIZE) {
 		f = _PAGE_PRESENT | _PAGE_ACCESSED |
 				_PAGE_SHARED | _PAGE_HWEXEC;
@@ -216,24 +189,6 @@ void __init mapin_ram(void)
 /* is x a power of 2? */
 #define is_power_of_2(x)	((x) != 0 && (((x) & ((x) - 1)) == 0))
 
-/*
- * Set up a mapping for a block of I/O.
- * virt, phys, size must all be page-aligned.
- * This should only be called before ioremap is called.
- */
-void __init io_block_mapping(unsigned long virt, phys_addr_t phys,
-			     unsigned int size, int flags)
-{
-	int i;
-
-	if (virt > CONFIG_KERNEL_START && virt < ioremap_bot)
-		ioremap_bot = ioremap_base = virt;
-
-	/* Put it in the page tables. */
-	for (i = 0; i < size; i += PAGE_SIZE)
-		map_page(virt + i, phys + i, flags);
-}
-
 /* Scan the real Linux page tables and return a PTE pointer for
  * a virtual address in a context.
  * Returns true (1) if PTE was found, zero otherwise.  The pointer to
@@ -284,3 +239,18 @@ unsigned long iopa(unsigned long addr)
 
 	return pa;
 }
+
+__init_refok pte_t *pte_alloc_one_kernel(struct mm_struct *mm,
+		unsigned long address)
+{
+	pte_t *pte;
+	if (mem_init_done) {
+		pte = (pte_t *)__get_free_page(GFP_KERNEL |
+					__GFP_REPEAT | __GFP_ZERO);
+	} else {
+		pte = (pte_t *)early_get_page();
+		if (pte)
+			clear_page(pte);
+	}
+	return pte;
+}
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/oprofile/Makefile linux-2.6.31.12-petalinux/arch/microblaze/oprofile/Makefile
--- linux-2.6.31.12/arch/microblaze/oprofile/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/oprofile/Makefile	2010-08-08 17:22:50.593041855 +0200
@@ -0,0 +1,13 @@
+#
+# arch/microblaze/oprofile/Makefile
+#
+
+obj-$(CONFIG_OPROFILE) += oprofile.o
+
+DRIVER_OBJS := $(addprefix ../../../drivers/oprofile/, \
+		oprof.o cpu_buffer.o buffer_sync.o \
+		event_buffer.o oprofile_files.o \
+		oprofilefs.o oprofile_stats.o \
+		timer_int.o )
+
+oprofile-y := $(DRIVER_OBJS) microblaze_oprofile.o
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/oprofile/microblaze_oprofile.c linux-2.6.31.12-petalinux/arch/microblaze/oprofile/microblaze_oprofile.c
--- linux-2.6.31.12/arch/microblaze/oprofile/microblaze_oprofile.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/oprofile/microblaze_oprofile.c	2010-08-08 17:22:50.593041855 +0200
@@ -0,0 +1,22 @@
+/*
+ * Microblaze oprofile code
+ *
+ * Copyright (C) 2009 Michal Simek <monstr@monstr.eu>
+ * Copyright (C) 2009 PetaLogix
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License. See the file "COPYING" in the main directory of this archive
+ * for more details.
+ */
+
+#include <linux/oprofile.h>
+#include <linux/init.h>
+
+int __init oprofile_arch_init(struct oprofile_operations *ops)
+{
+	return -1;
+}
+
+void oprofile_arch_exit(void)
+{
+}
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/pci/indirect_pci.c linux-2.6.31.12-petalinux/arch/microblaze/pci/indirect_pci.c
--- linux-2.6.31.12/arch/microblaze/pci/indirect_pci.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/pci/indirect_pci.c	2010-08-08 17:40:15.872768119 +0200
@@ -0,0 +1,163 @@
+/*
+ * Support for indirect PCI bridges.
+ *
+ * Copyright (C) 1998 Gabriel Paubert.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/delay.h>
+#include <linux/string.h>
+#include <linux/init.h>
+
+#include <asm/io.h>
+#include <asm/prom.h>
+#include <asm/pci-bridge.h>
+
+static int
+indirect_read_config(struct pci_bus *bus, unsigned int devfn, int offset,
+		     int len, u32 *val)
+{
+	struct pci_controller *hose = pci_bus_to_host(bus);
+	volatile void __iomem *cfg_data;
+	u8 cfg_type = 0;
+	u32 bus_no, reg;
+
+	if (hose->indirect_type & INDIRECT_TYPE_NO_PCIE_LINK) {
+		if (bus->number != hose->first_busno)
+			return PCIBIOS_DEVICE_NOT_FOUND;
+		if (devfn != 0)
+			return PCIBIOS_DEVICE_NOT_FOUND;
+	}
+
+	if (hose->indirect_type & INDIRECT_TYPE_SET_CFG_TYPE)
+		if (bus->number != hose->first_busno)
+			cfg_type = 1;
+
+	bus_no = (bus->number == hose->first_busno) ?
+			hose->self_busno : bus->number;
+
+	if (hose->indirect_type & INDIRECT_TYPE_EXT_REG)
+		reg = ((offset & 0xf00) << 16) | (offset & 0xfc);
+	else
+		reg = offset & 0xfc; /* Only 3 bits for function */
+
+	if (hose->indirect_type & INDIRECT_TYPE_BIG_ENDIAN)
+		out_be32(hose->cfg_addr, (0x80000000 | (bus_no << 16) |
+			 (devfn << 8) | reg | cfg_type));
+	else
+		out_le32(hose->cfg_addr, (0x80000000 | (bus_no << 16) |
+			 (devfn << 8) | reg | cfg_type));
+
+	/*
+	 * Note: the caller has already checked that offset is
+	 * suitably aligned and that len is 1, 2 or 4.
+	 */
+	cfg_data = hose->cfg_data + (offset & 3); /* Only 3 bits for function */
+	switch (len) {
+	case 1:
+		*val = in_8(cfg_data);
+		break;
+	case 2:
+		*val = in_le16(cfg_data);
+		break;
+	default:
+		*val = in_le32(cfg_data);
+		break;
+	}
+	return PCIBIOS_SUCCESSFUL;
+}
+
+static int
+indirect_write_config(struct pci_bus *bus, unsigned int devfn, int offset,
+		      int len, u32 val)
+{
+	struct pci_controller *hose = pci_bus_to_host(bus);
+	volatile void __iomem *cfg_data;
+	u8 cfg_type = 0;
+	u32 bus_no, reg;
+
+	if (hose->indirect_type & INDIRECT_TYPE_NO_PCIE_LINK) {
+		if (bus->number != hose->first_busno)
+			return PCIBIOS_DEVICE_NOT_FOUND;
+		if (devfn != 0)
+			return PCIBIOS_DEVICE_NOT_FOUND;
+	}
+
+	if (hose->indirect_type & INDIRECT_TYPE_SET_CFG_TYPE)
+		if (bus->number != hose->first_busno)
+			cfg_type = 1;
+
+	bus_no = (bus->number == hose->first_busno) ?
+			hose->self_busno : bus->number;
+
+	if (hose->indirect_type & INDIRECT_TYPE_EXT_REG)
+		reg = ((offset & 0xf00) << 16) | (offset & 0xfc);
+	else
+		reg = offset & 0xfc;
+
+	if (hose->indirect_type & INDIRECT_TYPE_BIG_ENDIAN)
+		out_be32(hose->cfg_addr, (0x80000000 | (bus_no << 16) |
+			 (devfn << 8) | reg | cfg_type));
+	else
+		out_le32(hose->cfg_addr, (0x80000000 | (bus_no << 16) |
+			 (devfn << 8) | reg | cfg_type));
+
+	/* surpress setting of PCI_PRIMARY_BUS */
+	if (hose->indirect_type & INDIRECT_TYPE_SURPRESS_PRIMARY_BUS)
+		if ((offset == PCI_PRIMARY_BUS) &&
+			(bus->number == hose->first_busno))
+			val &= 0xffffff00;
+
+	/* Workaround for PCI_28 Errata in 440EPx/GRx */
+	if ((hose->indirect_type & INDIRECT_TYPE_BROKEN_MRM) &&
+			offset == PCI_CACHE_LINE_SIZE) {
+		val = 0;
+	}
+
+	/*
+	 * Note: the caller has already checked that offset is
+	 * suitably aligned and that len is 1, 2 or 4.
+	 */
+	cfg_data = hose->cfg_data + (offset & 3);
+	switch (len) {
+	case 1:
+		out_8(cfg_data, val);
+		break;
+	case 2:
+		out_le16(cfg_data, val);
+		break;
+	default:
+		out_le32(cfg_data, val);
+		break;
+	}
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+static struct pci_ops indirect_pci_ops = {
+	.read = indirect_read_config,
+	.write = indirect_write_config,
+};
+
+void __init
+setup_indirect_pci(struct pci_controller *hose,
+		   resource_size_t cfg_addr,
+		   resource_size_t cfg_data, u32 flags)
+{
+	resource_size_t base = cfg_addr & PAGE_MASK;
+	void __iomem *mbase;
+
+	mbase = ioremap(base, PAGE_SIZE);
+	hose->cfg_addr = mbase + (cfg_addr & ~PAGE_MASK);
+	if ((cfg_data & PAGE_MASK) != base)
+		mbase = ioremap(cfg_data & PAGE_MASK, PAGE_SIZE);
+	hose->cfg_data = mbase + (cfg_data & ~PAGE_MASK);
+	hose->ops = &indirect_pci_ops;
+	hose->indirect_type = flags;
+}
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/pci/iomap.c linux-2.6.31.12-petalinux/arch/microblaze/pci/iomap.c
--- linux-2.6.31.12/arch/microblaze/pci/iomap.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/pci/iomap.c	2010-08-08 17:40:15.872768119 +0200
@@ -0,0 +1,39 @@
+/*
+ * ppc64 "iomap" interface implementation.
+ *
+ * (C) Copyright 2004 Linus Torvalds
+ */
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/mm.h>
+#include <asm/io.h>
+#include <asm/pci-bridge.h>
+
+void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long max)
+{
+	resource_size_t start = pci_resource_start(dev, bar);
+	resource_size_t len = pci_resource_len(dev, bar);
+	unsigned long flags = pci_resource_flags(dev, bar);
+
+	if (!len)
+		return NULL;
+	if (max && len > max)
+		len = max;
+	if (flags & IORESOURCE_IO)
+		return ioport_map(start, len);
+	if (flags & IORESOURCE_MEM)
+		return ioremap(start, len);
+	/* What? */
+	return NULL;
+}
+EXPORT_SYMBOL(pci_iomap);
+
+void pci_iounmap(struct pci_dev *dev, void __iomem *addr)
+{
+	if (isa_vaddr_is_ioport(addr))
+		return;
+	if (pcibios_vaddr_is_ioport(addr))
+		return;
+	iounmap(addr);
+}
+EXPORT_SYMBOL(pci_iounmap);
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/pci/Makefile linux-2.6.31.12-petalinux/arch/microblaze/pci/Makefile
--- linux-2.6.31.12/arch/microblaze/pci/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/pci/Makefile	2010-08-08 17:40:15.872768119 +0200
@@ -0,0 +1,6 @@
+#
+# Makefile
+#
+
+obj-$(CONFIG_PCI)		+= pci_32.o pci-common.o indirect_pci.o iomap.o
+obj-$(CONFIG_PCI_XILINX)	+= xilinx_pci.o
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/pci/pci_32.c linux-2.6.31.12-petalinux/arch/microblaze/pci/pci_32.c
--- linux-2.6.31.12/arch/microblaze/pci/pci_32.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/pci/pci_32.c	2010-08-08 17:40:15.872768119 +0200
@@ -0,0 +1,430 @@
+/*
+ * Common pmac/prep/chrp pci routines. -- Cort
+ */
+
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/delay.h>
+#include <linux/string.h>
+#include <linux/init.h>
+#include <linux/capability.h>
+#include <linux/sched.h>
+#include <linux/errno.h>
+#include <linux/bootmem.h>
+#include <linux/irq.h>
+#include <linux/list.h>
+#include <linux/of.h>
+
+#include <asm/processor.h>
+#include <asm/io.h>
+#include <asm/prom.h>
+#include <asm/sections.h>
+#include <asm/pci-bridge.h>
+#include <asm/byteorder.h>
+#include <asm/uaccess.h>
+
+#undef DEBUG
+
+unsigned long isa_io_base;
+unsigned long pci_dram_offset;
+int pcibios_assign_bus_offset = 1;
+
+static u8 *pci_to_OF_bus_map;
+
+/* By default, we don't re-assign bus numbers. We do this only on
+ * some pmacs
+ */
+static int pci_assign_all_buses;
+
+static int pci_bus_count;
+
+/*
+ * Functions below are used on OpenFirmware machines.
+ */
+static void
+make_one_node_map(struct device_node *node, u8 pci_bus)
+{
+	const int *bus_range;
+	int len;
+
+	if (pci_bus >= pci_bus_count)
+		return;
+	bus_range = of_get_property(node, "bus-range", &len);
+	if (bus_range == NULL || len < 2 * sizeof(int)) {
+		printk(KERN_WARNING "Can't get bus-range for %s, "
+		       "assuming it starts at 0\n", node->full_name);
+		pci_to_OF_bus_map[pci_bus] = 0;
+	} else
+		pci_to_OF_bus_map[pci_bus] = bus_range[0];
+
+	for_each_child_of_node(node, node) {
+		struct pci_dev *dev;
+		const unsigned int *class_code, *reg;
+
+		class_code = of_get_property(node, "class-code", NULL);
+		if (!class_code ||
+			((*class_code >> 8) != PCI_CLASS_BRIDGE_PCI &&
+			(*class_code >> 8) != PCI_CLASS_BRIDGE_CARDBUS))
+			continue;
+		reg = of_get_property(node, "reg", NULL);
+		if (!reg)
+			continue;
+		dev = pci_get_bus_and_slot(pci_bus, ((reg[0] >> 8) & 0xff));
+		if (!dev || !dev->subordinate) {
+			pci_dev_put(dev);
+			continue;
+		}
+		make_one_node_map(node, dev->subordinate->number);
+		pci_dev_put(dev);
+	}
+}
+
+void
+pcibios_make_OF_bus_map(void)
+{
+	int i;
+	struct pci_controller *hose, *tmp;
+	struct property *map_prop;
+	struct device_node *dn;
+
+	pci_to_OF_bus_map = kmalloc(pci_bus_count, GFP_KERNEL);
+	if (!pci_to_OF_bus_map) {
+		printk(KERN_ERR "Can't allocate OF bus map !\n");
+		return;
+	}
+
+	/* We fill the bus map with invalid values, that helps
+	 * debugging.
+	 */
+	for (i = 0; i < pci_bus_count; i++)
+		pci_to_OF_bus_map[i] = 0xff;
+
+	/* For each hose, we begin searching bridges */
+	list_for_each_entry_safe(hose, tmp, &hose_list, list_node) {
+		struct device_node *node = hose->dn;
+
+		if (!node)
+			continue;
+		make_one_node_map(node, hose->first_busno);
+	}
+	dn = of_find_node_by_path("/");
+	map_prop = of_find_property(dn, "pci-OF-bus-map", NULL);
+	if (map_prop) {
+		BUG_ON(pci_bus_count > map_prop->length);
+		memcpy(map_prop->value, pci_to_OF_bus_map, pci_bus_count);
+	}
+	of_node_put(dn);
+#ifdef DEBUG
+	printk(KERN_INFO "PCI->OF bus map:\n");
+	for (i = 0; i < pci_bus_count; i++) {
+		if (pci_to_OF_bus_map[i] == 0xff)
+			continue;
+		printk(KERN_INFO "%d -> %d\n", i, pci_to_OF_bus_map[i]);
+	}
+#endif
+}
+
+typedef int (*pci_OF_scan_iterator)(struct device_node *node, void *data);
+
+static struct device_node *scan_OF_pci_childs(struct device_node *parent,
+					pci_OF_scan_iterator filter, void *data)
+{
+	struct device_node *node;
+	struct device_node *sub_node;
+
+	for_each_child_of_node(parent, node) {
+		const unsigned int *class_code;
+
+		if (filter(node, data)) {
+			of_node_put(node);
+			return node;
+		}
+
+		/* For PCI<->PCI bridges or CardBus bridges, we go down
+		 * Note: some OFs create a parent node "multifunc-device" as
+		 * a fake root for all functions of a multi-function device,
+		 * we go down them as well.
+		 */
+		class_code = of_get_property(node, "class-code", NULL);
+		if ((!class_code ||
+			((*class_code >> 8) != PCI_CLASS_BRIDGE_PCI &&
+			(*class_code >> 8) != PCI_CLASS_BRIDGE_CARDBUS)) &&
+			strcmp(node->name, "multifunc-device"))
+			continue;
+		sub_node = scan_OF_pci_childs(node, filter, data);
+		if (sub_node) {
+			of_node_put(node);
+			return sub_node;
+		}
+	}
+	return NULL;
+}
+
+static struct device_node *scan_OF_for_pci_dev(struct device_node *parent,
+					       unsigned int devfn)
+{
+	struct device_node *np, *cnp;
+	const u32 *reg;
+	unsigned int psize;
+
+	for_each_child_of_node(parent, np) {
+		reg = of_get_property(np, "reg", &psize);
+		if (reg && psize >= 4 && ((reg[0] >> 8) & 0xff) == devfn)
+			return np;
+
+		/* Note: some OFs create a parent node "multifunc-device" as
+		 * a fake root for all functions of a multi-function device,
+		 * we go down them as well. */
+		if (!strcmp(np->name, "multifunc-device")) {
+			cnp = scan_OF_for_pci_dev(np, devfn);
+			if (cnp)
+				return cnp;
+		}
+	}
+	return NULL;
+}
+
+
+static struct device_node *scan_OF_for_pci_bus(struct pci_bus *bus)
+{
+	struct device_node *parent, *np;
+
+	/* Are we a root bus ? */
+	if (bus->self == NULL || bus->parent == NULL) {
+		struct pci_controller *hose = pci_bus_to_host(bus);
+		if (hose == NULL)
+			return NULL;
+		return of_node_get(hose->dn);
+	}
+
+	/* not a root bus, we need to get our parent */
+	parent = scan_OF_for_pci_bus(bus->parent);
+	if (parent == NULL)
+		return NULL;
+
+	/* now iterate for children for a match */
+	np = scan_OF_for_pci_dev(parent, bus->self->devfn);
+	of_node_put(parent);
+
+	return np;
+}
+
+/*
+ * Scans the OF tree for a device node matching a PCI device
+ */
+struct device_node *
+pci_busdev_to_OF_node(struct pci_bus *bus, int devfn)
+{
+	struct device_node *parent, *np;
+
+	pr_debug("pci_busdev_to_OF_node(%d,0x%x)\n", bus->number, devfn);
+	parent = scan_OF_for_pci_bus(bus);
+	if (parent == NULL)
+		return NULL;
+	pr_debug(" parent is %s\n", parent ? parent->full_name : "<NULL>");
+	np = scan_OF_for_pci_dev(parent, devfn);
+	of_node_put(parent);
+	pr_debug(" result is %s\n", np ? np->full_name : "<NULL>");
+
+	/* XXX most callers don't release the returned node
+	 * mostly because ppc64 doesn't increase the refcount,
+	 * we need to fix that.
+	 */
+	return np;
+}
+EXPORT_SYMBOL(pci_busdev_to_OF_node);
+
+struct device_node*
+pci_device_to_OF_node(struct pci_dev *dev)
+{
+	return pci_busdev_to_OF_node(dev->bus, dev->devfn);
+}
+EXPORT_SYMBOL(pci_device_to_OF_node);
+
+static int
+find_OF_pci_device_filter(struct device_node *node, void *data)
+{
+	return ((void *)node == data);
+}
+
+/*
+ * Returns the PCI device matching a given OF node
+ */
+int
+pci_device_from_OF_node(struct device_node *node, u8 *bus, u8 *devfn)
+{
+	const unsigned int *reg;
+	struct pci_controller *hose;
+	struct pci_dev *dev = NULL;
+
+	/* Make sure it's really a PCI device */
+	hose = pci_find_hose_for_OF_device(node);
+	if (!hose || !hose->dn)
+		return -ENODEV;
+	if (!scan_OF_pci_childs(hose->dn,
+			find_OF_pci_device_filter, (void *)node))
+		return -ENODEV;
+	reg = of_get_property(node, "reg", NULL);
+	if (!reg)
+		return -ENODEV;
+	*bus = (reg[0] >> 16) & 0xff;
+	*devfn = ((reg[0] >> 8) & 0xff);
+
+	/* Ok, here we need some tweak. If we have already renumbered
+	 * all busses, we can't rely on the OF bus number any more.
+	 * the pci_to_OF_bus_map is not enough as several PCI busses
+	 * may match the same OF bus number.
+	 */
+	if (!pci_to_OF_bus_map)
+		return 0;
+
+	for_each_pci_dev(dev)
+		if (pci_to_OF_bus_map[dev->bus->number] == *bus &&
+				dev->devfn == *devfn) {
+			*bus = dev->bus->number;
+			pci_dev_put(dev);
+			return 0;
+		}
+
+	return -ENODEV;
+}
+EXPORT_SYMBOL(pci_device_from_OF_node);
+
+/* We create the "pci-OF-bus-map" property now so it appears in the
+ * /proc device tree
+ */
+void __init
+pci_create_OF_bus_map(void)
+{
+	struct property *of_prop;
+	struct device_node *dn;
+
+	of_prop = (struct property *) alloc_bootmem(sizeof(struct property) + \
+									 256);
+	if (!of_prop)
+		return;
+	dn = of_find_node_by_path("/");
+	if (dn) {
+		memset(of_prop, -1, sizeof(struct property) + 256);
+		of_prop->name = "pci-OF-bus-map";
+		of_prop->length = 256;
+		of_prop->value = &of_prop[1];
+		prom_add_property(dn, of_prop);
+		of_node_put(dn);
+	}
+}
+
+static void __devinit pcibios_scan_phb(struct pci_controller *hose)
+{
+	struct pci_bus *bus;
+	struct device_node *node = hose->dn;
+	unsigned long io_offset;
+	struct resource *res = &hose->io_resource;
+
+	pr_debug("PCI: Scanning PHB %s\n",
+		 node ? node->full_name : "<NO NAME>");
+
+	/* Create an empty bus for the toplevel */
+	bus = pci_create_bus(hose->parent, hose->first_busno, hose->ops, hose);
+	if (bus == NULL) {
+		printk(KERN_ERR "Failed to create bus for PCI domain %04x\n",
+		       hose->global_number);
+		return;
+	}
+	bus->secondary = hose->first_busno;
+	hose->bus = bus;
+
+	/* Fixup IO space offset */
+	io_offset = (unsigned long)hose->io_base_virt - isa_io_base;
+	res->start = (res->start + io_offset) & 0xffffffffu;
+	res->end = (res->end + io_offset) & 0xffffffffu;
+
+	/* Wire up PHB bus resources */
+	pcibios_setup_phb_resources(hose);
+
+	/* Scan children */
+	hose->last_busno = bus->subordinate = pci_scan_child_bus(bus);
+}
+
+static int __init pcibios_init(void)
+{
+	struct pci_controller *hose, *tmp;
+	int next_busno = 0;
+
+	printk(KERN_INFO "PCI: Probing PCI hardware\n");
+
+	if (pci_flags & PCI_REASSIGN_ALL_BUS) {
+		printk(KERN_INFO "setting pci_asign_all_busses\n");
+		pci_assign_all_buses = 1;
+	}
+
+	/* Scan all of the recorded PCI controllers.  */
+	list_for_each_entry_safe(hose, tmp, &hose_list, list_node) {
+		if (pci_assign_all_buses)
+			hose->first_busno = next_busno;
+		hose->last_busno = 0xff;
+		pcibios_scan_phb(hose);
+		printk(KERN_INFO "calling pci_bus_add_devices()\n");
+		pci_bus_add_devices(hose->bus);
+		if (pci_assign_all_buses || next_busno <= hose->last_busno)
+			next_busno = hose->last_busno + \
+					pcibios_assign_bus_offset;
+	}
+	pci_bus_count = next_busno;
+
+	/* OpenFirmware based machines need a map of OF bus
+	 * numbers vs. kernel bus numbers since we may have to
+	 * remap them.
+	 */
+	if (pci_assign_all_buses)
+		pcibios_make_OF_bus_map();
+
+	/* Call common code to handle resource allocation */
+	pcibios_resource_survey();
+
+	return 0;
+}
+
+subsys_initcall(pcibios_init);
+
+static struct pci_controller*
+pci_bus_to_hose(int bus)
+{
+	struct pci_controller *hose, *tmp;
+
+	list_for_each_entry_safe(hose, tmp, &hose_list, list_node)
+		if (bus >= hose->first_busno && bus <= hose->last_busno)
+			return hose;
+	return NULL;
+}
+
+/* Provide information on locations of various I/O regions in physical
+ * memory.  Do this on a per-card basis so that we choose the right
+ * root bridge.
+ * Note that the returned IO or memory base is a physical address
+ */
+
+long sys_pciconfig_iobase(long which, unsigned long bus, unsigned long devfn)
+{
+	struct pci_controller *hose;
+	long result = -EOPNOTSUPP;
+
+	hose = pci_bus_to_hose(bus);
+	if (!hose)
+		return -ENODEV;
+
+	switch (which) {
+	case IOBASE_BRIDGE_NUMBER:
+		return (long)hose->first_busno;
+	case IOBASE_MEMORY:
+		return (long)hose->pci_mem_offset;
+	case IOBASE_IO:
+		return (long)hose->io_base_phys;
+	case IOBASE_ISA_IO:
+		return (long)isa_io_base;
+	case IOBASE_ISA_MEM:
+		return (long)isa_mem_base;
+	}
+
+	return result;
+}
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/pci/pci-common.c linux-2.6.31.12-petalinux/arch/microblaze/pci/pci-common.c
--- linux-2.6.31.12/arch/microblaze/pci/pci-common.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/pci/pci-common.c	2010-08-08 17:40:15.872768119 +0200
@@ -0,0 +1,1642 @@
+/*
+ * Contains common pci routines for ALL ppc platform
+ * (based on pci_32.c and pci_64.c)
+ *
+ * Port for PPC64 David Engebretsen, IBM Corp.
+ * Contains common pci routines for ppc64 platform, pSeries and iSeries brands.
+ *
+ * Copyright (C) 2003 Anton Blanchard <anton@au.ibm.com>, IBM
+ *   Rework, based on alpha PCI code.
+ *
+ * Common pmac/prep/chrp pci routines. -- Cort
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/string.h>
+#include <linux/init.h>
+#include <linux/bootmem.h>
+#include <linux/mm.h>
+#include <linux/list.h>
+#include <linux/syscalls.h>
+#include <linux/irq.h>
+#include <linux/vmalloc.h>
+
+#include <asm/processor.h>
+#include <asm/io.h>
+#include <asm/prom.h>
+#include <asm/pci-bridge.h>
+#include <asm/byteorder.h>
+
+static DEFINE_SPINLOCK(hose_spinlock);
+LIST_HEAD(hose_list);
+
+/* XXX kill that some day ... */
+static int global_phb_number;		/* Global phb counter */
+
+/* ISA Memory physical address */
+resource_size_t isa_mem_base;
+
+/* Default PCI flags is 0 on ppc32, modified at boot on ppc64 */
+unsigned int pci_flags;
+
+static struct dma_map_ops *pci_dma_ops = &dma_direct_ops;
+
+void set_pci_dma_ops(struct dma_map_ops *dma_ops)
+{
+	pci_dma_ops = dma_ops;
+}
+
+struct dma_map_ops *get_pci_dma_ops(void)
+{
+	return pci_dma_ops;
+}
+EXPORT_SYMBOL(get_pci_dma_ops);
+
+int pci_set_dma_mask(struct pci_dev *dev, u64 mask)
+{
+	return dma_set_mask(&dev->dev, mask);
+}
+
+int pci_set_consistent_dma_mask(struct pci_dev *dev, u64 mask)
+{
+	int rc;
+
+	rc = dma_set_mask(&dev->dev, mask);
+	dev->dev.coherent_dma_mask = dev->dma_mask;
+
+	return rc;
+}
+
+struct pci_controller *pcibios_alloc_controller(struct device_node *dev)
+{
+	struct pci_controller *phb;
+
+	phb = zalloc_maybe_bootmem(sizeof(struct pci_controller), GFP_KERNEL);
+	if (!phb)
+		return NULL;
+	spin_lock(&hose_spinlock);
+	phb->global_number = global_phb_number++;
+	list_add_tail(&phb->list_node, &hose_list);
+	spin_unlock(&hose_spinlock);
+	phb->dn = dev;
+	phb->is_dynamic = mem_init_done;
+	return phb;
+}
+
+void pcibios_free_controller(struct pci_controller *phb)
+{
+	spin_lock(&hose_spinlock);
+	list_del(&phb->list_node);
+	spin_unlock(&hose_spinlock);
+
+	if (phb->is_dynamic)
+		kfree(phb);
+}
+
+static resource_size_t pcibios_io_size(const struct pci_controller *hose)
+{
+	return hose->io_resource.end - hose->io_resource.start + 1;
+}
+
+int pcibios_vaddr_is_ioport(void __iomem *address)
+{
+	int ret = 0;
+	struct pci_controller *hose;
+	resource_size_t size;
+
+	spin_lock(&hose_spinlock);
+	list_for_each_entry(hose, &hose_list, list_node) {
+		size = pcibios_io_size(hose);
+		if (address >= hose->io_base_virt &&
+		    address < (hose->io_base_virt + size)) {
+			ret = 1;
+			break;
+		}
+	}
+	spin_unlock(&hose_spinlock);
+	return ret;
+}
+
+unsigned long pci_address_to_pio(phys_addr_t address)
+{
+	struct pci_controller *hose;
+	resource_size_t size;
+	unsigned long ret = ~0;
+
+	spin_lock(&hose_spinlock);
+	list_for_each_entry(hose, &hose_list, list_node) {
+		size = pcibios_io_size(hose);
+		if (address >= hose->io_base_phys &&
+		    address < (hose->io_base_phys + size)) {
+			unsigned long base =
+				(unsigned long)hose->io_base_virt - _IO_BASE;
+			ret = base + (address - hose->io_base_phys);
+			break;
+		}
+	}
+	spin_unlock(&hose_spinlock);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(pci_address_to_pio);
+
+/*
+ * Return the domain number for this bus.
+ */
+int pci_domain_nr(struct pci_bus *bus)
+{
+	struct pci_controller *hose = pci_bus_to_host(bus);
+
+	return hose->global_number;
+}
+EXPORT_SYMBOL(pci_domain_nr);
+
+/* This routine is meant to be used early during boot, when the
+ * PCI bus numbers have not yet been assigned, and you need to
+ * issue PCI config cycles to an OF device.
+ * It could also be used to "fix" RTAS config cycles if you want
+ * to set pci_assign_all_buses to 1 and still use RTAS for PCI
+ * config cycles.
+ */
+struct pci_controller *pci_find_hose_for_OF_device(struct device_node *node)
+{
+	while (node) {
+		struct pci_controller *hose, *tmp;
+		list_for_each_entry_safe(hose, tmp, &hose_list, list_node)
+			if (hose->dn == node)
+				return hose;
+		node = node->parent;
+	}
+	return NULL;
+}
+
+static ssize_t pci_show_devspec(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct pci_dev *pdev;
+	struct device_node *np;
+
+	pdev = to_pci_dev(dev);
+	np = pci_device_to_OF_node(pdev);
+	if (np == NULL || np->full_name == NULL)
+		return 0;
+	return sprintf(buf, "%s", np->full_name);
+}
+static DEVICE_ATTR(devspec, S_IRUGO, pci_show_devspec, NULL);
+
+/* Add sysfs properties */
+int pcibios_add_platform_entries(struct pci_dev *pdev)
+{
+	return device_create_file(&pdev->dev, &dev_attr_devspec);
+}
+
+char __devinit *pcibios_setup(char *str)
+{
+	return str;
+}
+
+/*
+ * Reads the interrupt pin to determine if interrupt is use by card.
+ * If the interrupt is used, then gets the interrupt line from the
+ * openfirmware and sets it in the pci_dev and pci_config line.
+ */
+int pci_read_irq_line(struct pci_dev *pci_dev)
+{
+	struct of_irq oirq;
+	unsigned int virq;
+
+	/* The current device-tree that iSeries generates from the HV
+	 * PCI informations doesn't contain proper interrupt routing,
+	 * and all the fallback would do is print out crap, so we
+	 * don't attempt to resolve the interrupts here at all, some
+	 * iSeries specific fixup does it.
+	 *
+	 * In the long run, we will hopefully fix the generated device-tree
+	 * instead.
+	 */
+	pr_debug("PCI: Try to map irq for %s...\n", pci_name(pci_dev));
+
+#ifdef DEBUG
+	memset(&oirq, 0xff, sizeof(oirq));
+#endif
+	/* Try to get a mapping from the device-tree */
+	if (of_irq_map_pci(pci_dev, &oirq)) {
+		u8 line, pin;
+
+		/* If that fails, lets fallback to what is in the config
+		 * space and map that through the default controller. We
+		 * also set the type to level low since that's what PCI
+		 * interrupts are. If your platform does differently, then
+		 * either provide a proper interrupt tree or don't use this
+		 * function.
+		 */
+		if (pci_read_config_byte(pci_dev, PCI_INTERRUPT_PIN, &pin))
+			return -1;
+		if (pin == 0)
+			return -1;
+		if (pci_read_config_byte(pci_dev, PCI_INTERRUPT_LINE, &line) ||
+		    line == 0xff || line == 0) {
+			return -1;
+		}
+		pr_debug(" No map ! Using line %d (pin %d) from PCI config\n",
+			 line, pin);
+
+		virq = irq_create_mapping(NULL, line);
+		if (virq != NO_IRQ)
+			set_irq_type(virq, IRQ_TYPE_LEVEL_LOW);
+	} else {
+		pr_debug(" Got one, spec %d cells (0x%08x 0x%08x...) on %s\n",
+			 oirq.size, oirq.specifier[0], oirq.specifier[1],
+			 oirq.controller ? oirq.controller->full_name :
+			 "<default>");
+
+		virq = irq_create_of_mapping(oirq.controller, oirq.specifier,
+					     oirq.size);
+	}
+	if (virq == NO_IRQ) {
+		pr_debug(" Failed to map !\n");
+		return -1;
+	}
+
+	pr_debug(" Mapped to linux irq %d\n", virq);
+
+	pci_dev->irq = virq;
+
+	return 0;
+}
+EXPORT_SYMBOL(pci_read_irq_line);
+
+/*
+ * Platform support for /proc/bus/pci/X/Y mmap()s,
+ * modelled on the sparc64 implementation by Dave Miller.
+ *  -- paulus.
+ */
+
+/*
+ * Adjust vm_pgoff of VMA such that it is the physical page offset
+ * corresponding to the 32-bit pci bus offset for DEV requested by the user.
+ *
+ * Basically, the user finds the base address for his device which he wishes
+ * to mmap.  They read the 32-bit value from the config space base register,
+ * add whatever PAGE_SIZE multiple offset they wish, and feed this into the
+ * offset parameter of mmap on /proc/bus/pci/XXX for that device.
+ *
+ * Returns negative error code on failure, zero on success.
+ */
+static struct resource *__pci_mmap_make_offset(struct pci_dev *dev,
+					       resource_size_t *offset,
+					       enum pci_mmap_state mmap_state)
+{
+	struct pci_controller *hose = pci_bus_to_host(dev->bus);
+	unsigned long io_offset = 0;
+	int i, res_bit;
+
+	if (hose == 0)
+		return NULL;		/* should never happen */
+
+	/* If memory, add on the PCI bridge address offset */
+	if (mmap_state == pci_mmap_mem) {
+#if 0 /* See comment in pci_resource_to_user() for why this is disabled */
+		*offset += hose->pci_mem_offset;
+#endif
+		res_bit = IORESOURCE_MEM;
+	} else {
+		io_offset = (unsigned long)hose->io_base_virt - _IO_BASE;
+		*offset += io_offset;
+		res_bit = IORESOURCE_IO;
+	}
+
+	/*
+	 * Check that the offset requested corresponds to one of the
+	 * resources of the device.
+	 */
+	for (i = 0; i <= PCI_ROM_RESOURCE; i++) {
+		struct resource *rp = &dev->resource[i];
+		int flags = rp->flags;
+
+		/* treat ROM as memory (should be already) */
+		if (i == PCI_ROM_RESOURCE)
+			flags |= IORESOURCE_MEM;
+
+		/* Active and same type? */
+		if ((flags & res_bit) == 0)
+			continue;
+
+		/* In the range of this resource? */
+		if (*offset < (rp->start & PAGE_MASK) || *offset > rp->end)
+			continue;
+
+		/* found it! construct the final physical address */
+		if (mmap_state == pci_mmap_io)
+			*offset += hose->io_base_phys - io_offset;
+		return rp;
+	}
+
+	return NULL;
+}
+
+/*
+ * Set vm_page_prot of VMA, as appropriate for this architecture, for a pci
+ * device mapping.
+ */
+static pgprot_t __pci_mmap_set_pgprot(struct pci_dev *dev, struct resource *rp,
+				      pgprot_t protection,
+				      enum pci_mmap_state mmap_state,
+				      int write_combine)
+{
+	pgprot_t prot = protection;
+
+	/* Write combine is always 0 on non-memory space mappings. On
+	 * memory space, if the user didn't pass 1, we check for a
+	 * "prefetchable" resource. This is a bit hackish, but we use
+	 * this to workaround the inability of /sysfs to provide a write
+	 * combine bit
+	 */
+	if (mmap_state != pci_mmap_mem)
+		write_combine = 0;
+	else if (write_combine == 0) {
+		if (rp->flags & IORESOURCE_PREFETCH)
+			write_combine = 1;
+	}
+
+	return pgprot_noncached(prot);
+}
+
+/*
+ * This one is used by /dev/mem and fbdev who have no clue about the
+ * PCI device, it tries to find the PCI device first and calls the
+ * above routine
+ */
+pgprot_t pci_phys_mem_access_prot(struct file *file,
+				  unsigned long pfn,
+				  unsigned long size,
+				  pgprot_t prot)
+{
+	struct pci_dev *pdev = NULL;
+	struct resource *found = NULL;
+	resource_size_t offset = ((resource_size_t)pfn) << PAGE_SHIFT;
+	int i;
+
+	if (page_is_ram(pfn))
+		return prot;
+
+	prot = pgprot_noncached(prot);
+	for_each_pci_dev(pdev) {
+		for (i = 0; i <= PCI_ROM_RESOURCE; i++) {
+			struct resource *rp = &pdev->resource[i];
+			int flags = rp->flags;
+
+			/* Active and same type? */
+			if ((flags & IORESOURCE_MEM) == 0)
+				continue;
+			/* In the range of this resource? */
+			if (offset < (rp->start & PAGE_MASK) ||
+			    offset > rp->end)
+				continue;
+			found = rp;
+			break;
+		}
+		if (found)
+			break;
+	}
+	if (found) {
+		if (found->flags & IORESOURCE_PREFETCH)
+			prot = pgprot_noncached_wc(prot);
+		pci_dev_put(pdev);
+	}
+
+	pr_debug("PCI: Non-PCI map for %llx, prot: %lx\n",
+		 (unsigned long long)offset, pgprot_val(prot));
+
+	return prot;
+}
+
+/*
+ * Perform the actual remap of the pages for a PCI device mapping, as
+ * appropriate for this architecture.  The region in the process to map
+ * is described by vm_start and vm_end members of VMA, the base physical
+ * address is found in vm_pgoff.
+ * The pci device structure is provided so that architectures may make mapping
+ * decisions on a per-device or per-bus basis.
+ *
+ * Returns a negative error code on failure, zero on success.
+ */
+int pci_mmap_page_range(struct pci_dev *dev, struct vm_area_struct *vma,
+			enum pci_mmap_state mmap_state, int write_combine)
+{
+	resource_size_t offset =
+		((resource_size_t)vma->vm_pgoff) << PAGE_SHIFT;
+	struct resource *rp;
+	int ret;
+
+	rp = __pci_mmap_make_offset(dev, &offset, mmap_state);
+	if (rp == NULL)
+		return -EINVAL;
+
+	vma->vm_pgoff = offset >> PAGE_SHIFT;
+	vma->vm_page_prot = __pci_mmap_set_pgprot(dev, rp,
+						  vma->vm_page_prot,
+						  mmap_state, write_combine);
+
+	ret = remap_pfn_range(vma, vma->vm_start, vma->vm_pgoff,
+			       vma->vm_end - vma->vm_start, vma->vm_page_prot);
+
+	return ret;
+}
+
+/* This provides legacy IO read access on a bus */
+int pci_legacy_read(struct pci_bus *bus, loff_t port, u32 *val, size_t size)
+{
+	unsigned long offset;
+	struct pci_controller *hose = pci_bus_to_host(bus);
+	struct resource *rp = &hose->io_resource;
+	void __iomem *addr;
+
+	/* Check if port can be supported by that bus. We only check
+	 * the ranges of the PHB though, not the bus itself as the rules
+	 * for forwarding legacy cycles down bridges are not our problem
+	 * here. So if the host bridge supports it, we do it.
+	 */
+	offset = (unsigned long)hose->io_base_virt - _IO_BASE;
+	offset += port;
+
+	if (!(rp->flags & IORESOURCE_IO))
+		return -ENXIO;
+	if (offset < rp->start || (offset + size) > rp->end)
+		return -ENXIO;
+	addr = hose->io_base_virt + port;
+
+	switch (size) {
+	case 1:
+		*((u8 *)val) = in_8(addr);
+		return 1;
+	case 2:
+		if (port & 1)
+			return -EINVAL;
+		*((u16 *)val) = in_le16(addr);
+		return 2;
+	case 4:
+		if (port & 3)
+			return -EINVAL;
+		*((u32 *)val) = in_le32(addr);
+		return 4;
+	}
+	return -EINVAL;
+}
+
+/* This provides legacy IO write access on a bus */
+int pci_legacy_write(struct pci_bus *bus, loff_t port, u32 val, size_t size)
+{
+	unsigned long offset;
+	struct pci_controller *hose = pci_bus_to_host(bus);
+	struct resource *rp = &hose->io_resource;
+	void __iomem *addr;
+
+	/* Check if port can be supported by that bus. We only check
+	 * the ranges of the PHB though, not the bus itself as the rules
+	 * for forwarding legacy cycles down bridges are not our problem
+	 * here. So if the host bridge supports it, we do it.
+	 */
+	offset = (unsigned long)hose->io_base_virt - _IO_BASE;
+	offset += port;
+
+	if (!(rp->flags & IORESOURCE_IO))
+		return -ENXIO;
+	if (offset < rp->start || (offset + size) > rp->end)
+		return -ENXIO;
+	addr = hose->io_base_virt + port;
+
+	/* WARNING: The generic code is idiotic. It gets passed a pointer
+	 * to what can be a 1, 2 or 4 byte quantity and always reads that
+	 * as a u32, which means that we have to correct the location of
+	 * the data read within those 32 bits for size 1 and 2
+	 */
+	switch (size) {
+	case 1:
+		out_8(addr, val >> 24);
+		return 1;
+	case 2:
+		if (port & 1)
+			return -EINVAL;
+		out_le16(addr, val >> 16);
+		return 2;
+	case 4:
+		if (port & 3)
+			return -EINVAL;
+		out_le32(addr, val);
+		return 4;
+	}
+	return -EINVAL;
+}
+
+/* This provides legacy IO or memory mmap access on a bus */
+int pci_mmap_legacy_page_range(struct pci_bus *bus,
+			       struct vm_area_struct *vma,
+			       enum pci_mmap_state mmap_state)
+{
+	struct pci_controller *hose = pci_bus_to_host(bus);
+	resource_size_t offset =
+		((resource_size_t)vma->vm_pgoff) << PAGE_SHIFT;
+	resource_size_t size = vma->vm_end - vma->vm_start;
+	struct resource *rp;
+
+	pr_debug("pci_mmap_legacy_page_range(%04x:%02x, %s @%llx..%llx)\n",
+		 pci_domain_nr(bus), bus->number,
+		 mmap_state == pci_mmap_mem ? "MEM" : "IO",
+		 (unsigned long long)offset,
+		 (unsigned long long)(offset + size - 1));
+
+	if (mmap_state == pci_mmap_mem) {
+		/* Hack alert !
+		 *
+		 * Because X is lame and can fail starting if it gets an error
+		 * trying to mmap legacy_mem (instead of just moving on without
+		 * legacy memory access) we fake it here by giving it anonymous
+		 * memory, effectively behaving just like /dev/zero
+		 */
+		if ((offset + size) > hose->isa_mem_size) {
+#ifdef CONFIG_MMU
+			printk(KERN_DEBUG
+				"Process %s (pid:%d) mapped non-existing PCI"
+				"legacy memory for 0%04x:%02x\n",
+				current->comm, current->pid, pci_domain_nr(bus),
+								bus->number);
+#endif
+			if (vma->vm_flags & VM_SHARED)
+				return shmem_zero_setup(vma);
+			return 0;
+		}
+		offset += hose->isa_mem_phys;
+	} else {
+		unsigned long io_offset = (unsigned long)hose->io_base_virt - \
+								_IO_BASE;
+		unsigned long roffset = offset + io_offset;
+		rp = &hose->io_resource;
+		if (!(rp->flags & IORESOURCE_IO))
+			return -ENXIO;
+		if (roffset < rp->start || (roffset + size) > rp->end)
+			return -ENXIO;
+		offset += hose->io_base_phys;
+	}
+	pr_debug(" -> mapping phys %llx\n", (unsigned long long)offset);
+
+	vma->vm_pgoff = offset >> PAGE_SHIFT;
+	vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
+	return remap_pfn_range(vma, vma->vm_start, vma->vm_pgoff,
+			       vma->vm_end - vma->vm_start,
+			       vma->vm_page_prot);
+}
+
+void pci_resource_to_user(const struct pci_dev *dev, int bar,
+			  const struct resource *rsrc,
+			  resource_size_t *start, resource_size_t *end)
+{
+	struct pci_controller *hose = pci_bus_to_host(dev->bus);
+	resource_size_t offset = 0;
+
+	if (hose == NULL)
+		return;
+
+	if (rsrc->flags & IORESOURCE_IO)
+		offset = (unsigned long)hose->io_base_virt - _IO_BASE;
+
+	/* We pass a fully fixed up address to userland for MMIO instead of
+	 * a BAR value because X is lame and expects to be able to use that
+	 * to pass to /dev/mem !
+	 *
+	 * That means that we'll have potentially 64 bits values where some
+	 * userland apps only expect 32 (like X itself since it thinks only
+	 * Sparc has 64 bits MMIO) but if we don't do that, we break it on
+	 * 32 bits CHRPs :-(
+	 *
+	 * Hopefully, the sysfs insterface is immune to that gunk. Once X
+	 * has been fixed (and the fix spread enough), we can re-enable the
+	 * 2 lines below and pass down a BAR value to userland. In that case
+	 * we'll also have to re-enable the matching code in
+	 * __pci_mmap_make_offset().
+	 *
+	 * BenH.
+	 */
+#if 0
+	else if (rsrc->flags & IORESOURCE_MEM)
+		offset = hose->pci_mem_offset;
+#endif
+
+	*start = rsrc->start - offset;
+	*end = rsrc->end - offset;
+}
+
+/**
+ * pci_process_bridge_OF_ranges - Parse PCI bridge resources from device tree
+ * @hose: newly allocated pci_controller to be setup
+ * @dev: device node of the host bridge
+ * @primary: set if primary bus (32 bits only, soon to be deprecated)
+ *
+ * This function will parse the "ranges" property of a PCI host bridge device
+ * node and setup the resource mapping of a pci controller based on its
+ * content.
+ *
+ * Life would be boring if it wasn't for a few issues that we have to deal
+ * with here:
+ *
+ *   - We can only cope with one IO space range and up to 3 Memory space
+ *     ranges. However, some machines (thanks Apple !) tend to split their
+ *     space into lots of small contiguous ranges. So we have to coalesce.
+ *
+ *   - We can only cope with all memory ranges having the same offset
+ *     between CPU addresses and PCI addresses. Unfortunately, some bridges
+ *     are setup for a large 1:1 mapping along with a small "window" which
+ *     maps PCI address 0 to some arbitrary high address of the CPU space in
+ *     order to give access to the ISA memory hole.
+ *     The way out of here that I've chosen for now is to always set the
+ *     offset based on the first resource found, then override it if we
+ *     have a different offset and the previous was set by an ISA hole.
+ *
+ *   - Some busses have IO space not starting at 0, which causes trouble with
+ *     the way we do our IO resource renumbering. The code somewhat deals with
+ *     it for 64 bits but I would expect problems on 32 bits.
+ *
+ *   - Some 32 bits platforms such as 4xx can have physical space larger than
+ *     32 bits so we need to use 64 bits values for the parsing
+ */
+void __devinit pci_process_bridge_OF_ranges(struct pci_controller *hose,
+					    struct device_node *dev,
+					    int primary)
+{
+	const u32 *ranges;
+	int rlen;
+	int pna = of_n_addr_cells(dev);
+	int np = pna + 5;
+	int memno = 0, isa_hole = -1;
+	u32 pci_space;
+	unsigned long long pci_addr, cpu_addr, pci_next, cpu_next, size;
+	unsigned long long isa_mb = 0;
+	struct resource *res;
+
+	printk(KERN_INFO "PCI host bridge %s %s ranges:\n",
+	       dev->full_name, primary ? "(primary)" : "");
+
+	/* Get ranges property */
+	ranges = of_get_property(dev, "ranges", &rlen);
+	if (ranges == NULL)
+		return;
+
+	/* Parse it */
+	pr_debug("Parsing ranges property...\n");
+	while ((rlen -= np * 4) >= 0) {
+		/* Read next ranges element */
+		pci_space = ranges[0];
+		pci_addr = of_read_number(ranges + 1, 2);
+		cpu_addr = of_translate_address(dev, ranges + 3);
+		size = of_read_number(ranges + pna + 3, 2);
+
+		pr_debug("pci_space: 0x%08x pci_addr:0x%016llx "
+				"cpu_addr:0x%016llx size:0x%016llx\n",
+					pci_space, pci_addr, cpu_addr, size);
+
+		ranges += np;
+
+		/* If we failed translation or got a zero-sized region
+		 * (some FW try to feed us with non sensical zero sized regions
+		 * such as power3 which look like some kind of attempt
+		 * at exposing the VGA memory hole)
+		 */
+		if (cpu_addr == OF_BAD_ADDR || size == 0)
+			continue;
+
+		/* Now consume following elements while they are contiguous */
+		for (; rlen >= np * sizeof(u32);
+		     ranges += np, rlen -= np * 4) {
+			if (ranges[0] != pci_space)
+				break;
+			pci_next = of_read_number(ranges + 1, 2);
+			cpu_next = of_translate_address(dev, ranges + 3);
+			if (pci_next != pci_addr + size ||
+			    cpu_next != cpu_addr + size)
+				break;
+			size += of_read_number(ranges + pna + 3, 2);
+		}
+
+		/* Act based on address space type */
+		res = NULL;
+		switch ((pci_space >> 24) & 0x3) {
+		case 1:		/* PCI IO space */
+			printk(KERN_INFO
+			       "  IO 0x%016llx..0x%016llx -> 0x%016llx\n",
+			       cpu_addr, cpu_addr + size - 1, pci_addr);
+
+			/* We support only one IO range */
+			if (hose->pci_io_size) {
+				printk(KERN_INFO
+				       " \\--> Skipped (too many) !\n");
+				continue;
+			}
+			/* On 32 bits, limit I/O space to 16MB */
+			if (size > 0x01000000)
+				size = 0x01000000;
+
+			/* 32 bits needs to map IOs here */
+			hose->io_base_virt = ioremap(cpu_addr, size);
+
+			/* Expect trouble if pci_addr is not 0 */
+			if (primary)
+				isa_io_base =
+					(unsigned long)hose->io_base_virt;
+			/* pci_io_size and io_base_phys always represent IO
+			 * space starting at 0 so we factor in pci_addr
+			 */
+			hose->pci_io_size = pci_addr + size;
+			hose->io_base_phys = cpu_addr - pci_addr;
+
+			/* Build resource */
+			res = &hose->io_resource;
+			res->flags = IORESOURCE_IO;
+			res->start = pci_addr;
+			break;
+		case 2:		/* PCI Memory space */
+		case 3:		/* PCI 64 bits Memory space */
+			printk(KERN_INFO
+			       " MEM 0x%016llx..0x%016llx -> 0x%016llx %s\n",
+			       cpu_addr, cpu_addr + size - 1, pci_addr,
+			       (pci_space & 0x40000000) ? "Prefetch" : "");
+
+			/* We support only 3 memory ranges */
+			if (memno >= 3) {
+				printk(KERN_INFO
+				       " \\--> Skipped (too many) !\n");
+				continue;
+			}
+			/* Handles ISA memory hole space here */
+			if (pci_addr == 0) {
+				isa_mb = cpu_addr;
+				isa_hole = memno;
+				if (primary || isa_mem_base == 0)
+					isa_mem_base = cpu_addr;
+				hose->isa_mem_phys = cpu_addr;
+				hose->isa_mem_size = size;
+			}
+
+			/* We get the PCI/Mem offset from the first range or
+			 * the, current one if the offset came from an ISA
+			 * hole. If they don't match, bugger.
+			 */
+			if (memno == 0 ||
+			    (isa_hole >= 0 && pci_addr != 0 &&
+			     hose->pci_mem_offset == isa_mb))
+				hose->pci_mem_offset = cpu_addr - pci_addr;
+			else if (pci_addr != 0 &&
+				 hose->pci_mem_offset != cpu_addr - pci_addr) {
+				printk(KERN_INFO
+				       " \\--> Skipped (offset mismatch) !\n");
+				continue;
+			}
+
+			/* Build resource */
+			res = &hose->mem_resources[memno++];
+			res->flags = IORESOURCE_MEM;
+			if (pci_space & 0x40000000)
+				res->flags |= IORESOURCE_PREFETCH;
+			res->start = cpu_addr;
+			break;
+		}
+		if (res != NULL) {
+			res->name = dev->full_name;
+			res->end = res->start + size - 1;
+			res->parent = NULL;
+			res->sibling = NULL;
+			res->child = NULL;
+		}
+	}
+
+	/* If there's an ISA hole and the pci_mem_offset is -not- matching
+	 * the ISA hole offset, then we need to remove the ISA hole from
+	 * the resource list for that brige
+	 */
+	if (isa_hole >= 0 && hose->pci_mem_offset != isa_mb) {
+		unsigned int next = isa_hole + 1;
+		printk(KERN_INFO " Removing ISA hole at 0x%016llx\n", isa_mb);
+		if (next < memno)
+			memmove(&hose->mem_resources[isa_hole],
+				&hose->mem_resources[next],
+				sizeof(struct resource) * (memno - next));
+		hose->mem_resources[--memno].flags = 0;
+	}
+}
+
+/* Decide whether to display the domain number in /proc */
+int pci_proc_domain(struct pci_bus *bus)
+{
+	struct pci_controller *hose = pci_bus_to_host(bus);
+
+	if (!(pci_flags & PCI_ENABLE_PROC_DOMAINS))
+		return 0;
+	if (pci_flags & PCI_COMPAT_DOMAIN_0)
+		return hose->global_number != 0;
+	return 1;
+}
+
+void pcibios_resource_to_bus(struct pci_dev *dev, struct pci_bus_region *region,
+			     struct resource *res)
+{
+	resource_size_t offset = 0, mask = (resource_size_t)-1;
+	struct pci_controller *hose = pci_bus_to_host(dev->bus);
+
+	if (!hose)
+		return;
+	if (res->flags & IORESOURCE_IO) {
+		offset = (unsigned long)hose->io_base_virt - _IO_BASE;
+		mask = 0xffffffffu;
+	} else if (res->flags & IORESOURCE_MEM)
+		offset = hose->pci_mem_offset;
+
+	region->start = (res->start - offset) & mask;
+	region->end = (res->end - offset) & mask;
+}
+EXPORT_SYMBOL(pcibios_resource_to_bus);
+
+void pcibios_bus_to_resource(struct pci_dev *dev, struct resource *res,
+			     struct pci_bus_region *region)
+{
+	resource_size_t offset = 0, mask = (resource_size_t)-1;
+	struct pci_controller *hose = pci_bus_to_host(dev->bus);
+
+	if (!hose)
+		return;
+	if (res->flags & IORESOURCE_IO) {
+		offset = (unsigned long)hose->io_base_virt - _IO_BASE;
+		mask = 0xffffffffu;
+	} else if (res->flags & IORESOURCE_MEM)
+		offset = hose->pci_mem_offset;
+	res->start = (region->start + offset) & mask;
+	res->end = (region->end + offset) & mask;
+}
+EXPORT_SYMBOL(pcibios_bus_to_resource);
+
+/* Fixup a bus resource into a linux resource */
+static void __devinit fixup_resource(struct resource *res, struct pci_dev *dev)
+{
+	struct pci_controller *hose = pci_bus_to_host(dev->bus);
+	resource_size_t offset = 0, mask = (resource_size_t)-1;
+
+	if (res->flags & IORESOURCE_IO) {
+		offset = (unsigned long)hose->io_base_virt - _IO_BASE;
+		mask = 0xffffffffu;
+	} else if (res->flags & IORESOURCE_MEM)
+		offset = hose->pci_mem_offset;
+
+	res->start = (res->start + offset) & mask;
+	res->end = (res->end + offset) & mask;
+}
+
+/* This header fixup will do the resource fixup for all devices as they are
+ * probed, but not for bridge ranges
+ */
+static void __devinit pcibios_fixup_resources(struct pci_dev *dev)
+{
+	struct pci_controller *hose = pci_bus_to_host(dev->bus);
+	int i;
+
+	if (!hose) {
+		printk(KERN_ERR "No host bridge for PCI dev %s !\n",
+		       pci_name(dev));
+		return;
+	}
+	for (i = 0; i < DEVICE_COUNT_RESOURCE; i++) {
+		struct resource *res = dev->resource + i;
+		if (!res->flags)
+			continue;
+		/* On platforms that have PCI_PROBE_ONLY set, we don't
+		 * consider 0 as an unassigned BAR value. It's technically
+		 * a valid value, but linux doesn't like it... so when we can
+		 * re-assign things, we do so, but if we can't, we keep it
+		 * around and hope for the best...
+		 */
+		if (res->start == 0 && !(pci_flags & PCI_PROBE_ONLY)) {
+			pr_debug("PCI:%s Resource %d %016llx-%016llx [%x]" \
+							"is unassigned\n",
+				 pci_name(dev), i,
+				 (unsigned long long)res->start,
+				 (unsigned long long)res->end,
+				 (unsigned int)res->flags);
+			res->end -= res->start;
+			res->start = 0;
+			res->flags |= IORESOURCE_UNSET;
+			continue;
+		}
+
+		pr_debug("PCI:%s Resource %d %016llx-%016llx [%x] fixup...\n",
+			 pci_name(dev), i,
+			 (unsigned long long)res->start,\
+			 (unsigned long long)res->end,
+			 (unsigned int)res->flags);
+
+		fixup_resource(res, dev);
+
+		pr_debug("PCI:%s            %016llx-%016llx\n",
+			 pci_name(dev),
+			 (unsigned long long)res->start,
+			 (unsigned long long)res->end);
+	}
+}
+DECLARE_PCI_FIXUP_HEADER(PCI_ANY_ID, PCI_ANY_ID, pcibios_fixup_resources);
+
+/* This function tries to figure out if a bridge resource has been initialized
+ * by the firmware or not. It doesn't have to be absolutely bullet proof, but
+ * things go more smoothly when it gets it right. It should covers cases such
+ * as Apple "closed" bridge resources and bare-metal pSeries unassigned bridges
+ */
+static int __devinit pcibios_uninitialized_bridge_resource(struct pci_bus *bus,
+							   struct resource *res)
+{
+	struct pci_controller *hose = pci_bus_to_host(bus);
+	struct pci_dev *dev = bus->self;
+	resource_size_t offset;
+	u16 command;
+	int i;
+
+	/* We don't do anything if PCI_PROBE_ONLY is set */
+	if (pci_flags & PCI_PROBE_ONLY)
+		return 0;
+
+	/* Job is a bit different between memory and IO */
+	if (res->flags & IORESOURCE_MEM) {
+		/* If the BAR is non-0 (res != pci_mem_offset) then it's
+		 * probably been initialized by somebody
+		 */
+		if (res->start != hose->pci_mem_offset)
+			return 0;
+
+		/* The BAR is 0, let's check if memory decoding is enabled on
+		 * the bridge. If not, we consider it unassigned
+		 */
+		pci_read_config_word(dev, PCI_COMMAND, &command);
+		if ((command & PCI_COMMAND_MEMORY) == 0)
+			return 1;
+
+		/* Memory decoding is enabled and the BAR is 0. If any of
+		 * the bridge resources covers that starting address (0 then
+		 * it's good enough for us for memory
+		 */
+		for (i = 0; i < 3; i++) {
+			if ((hose->mem_resources[i].flags & IORESOURCE_MEM) &&
+			   hose->mem_resources[i].start == hose->pci_mem_offset)
+				return 0;
+		}
+
+		/* Well, it starts at 0 and we know it will collide so we may as
+		 * well consider it as unassigned. That covers the Apple case.
+		 */
+		return 1;
+	} else {
+		/* If the BAR is non-0, then we consider it assigned */
+		offset = (unsigned long)hose->io_base_virt - _IO_BASE;
+		if (((res->start - offset) & 0xfffffffful) != 0)
+			return 0;
+
+		/* Here, we are a bit different than memory as typically IO
+		 * space starting at low addresses -is- valid. What we do
+		 * instead if that we consider as unassigned anything that
+		 * doesn't have IO enabled in the PCI command register,
+		 * and that's it.
+		 */
+		pci_read_config_word(dev, PCI_COMMAND, &command);
+		if (command & PCI_COMMAND_IO)
+			return 0;
+
+		/* It's starting at 0 and IO is disabled in the bridge, consider
+		 * it unassigned
+		 */
+		return 1;
+	}
+}
+
+/* Fixup resources of a PCI<->PCI bridge */
+static void __devinit pcibios_fixup_bridge(struct pci_bus *bus)
+{
+	struct resource *res;
+	int i;
+
+	struct pci_dev *dev = bus->self;
+
+	for (i = 0; i < PCI_BUS_NUM_RESOURCES; ++i) {
+		res = bus->resource[i];
+		if (!res)
+			continue;
+		if (!res->flags)
+			continue;
+		if (i >= 3 && bus->self->transparent)
+			continue;
+
+		pr_debug("PCI:%s Bus rsrc %d %016llx-%016llx [%x] fixup...\n",
+			 pci_name(dev), i,
+			 (unsigned long long)res->start,\
+			 (unsigned long long)res->end,
+			 (unsigned int)res->flags);
+
+		/* Perform fixup */
+		fixup_resource(res, dev);
+
+		/* Try to detect uninitialized P2P bridge resources,
+		 * and clear them out so they get re-assigned later
+		 */
+		if (pcibios_uninitialized_bridge_resource(bus, res)) {
+			res->flags = 0;
+			pr_debug("PCI:%s            (unassigned)\n",
+								pci_name(dev));
+		} else {
+			pr_debug("PCI:%s            %016llx-%016llx\n",
+				 pci_name(dev),
+				 (unsigned long long)res->start,
+				 (unsigned long long)res->end);
+		}
+	}
+}
+
+void __devinit pcibios_setup_bus_self(struct pci_bus *bus)
+{
+	/* Fix up the bus resources for P2P bridges */
+	if (bus->self != NULL)
+		pcibios_fixup_bridge(bus);
+}
+
+void __devinit pcibios_setup_bus_devices(struct pci_bus *bus)
+{
+	struct pci_dev *dev;
+
+	pr_debug("PCI: Fixup bus devices %d (%s)\n",
+		 bus->number, bus->self ? pci_name(bus->self) : "PHB");
+
+	list_for_each_entry(dev, &bus->devices, bus_list) {
+		struct dev_archdata *sd = &dev->dev.archdata;
+
+		/* Setup OF node pointer in archdata */
+		sd->of_node = pci_device_to_OF_node(dev);
+
+		/* Fixup NUMA node as it may not be setup yet by the generic
+		 * code and is needed by the DMA init
+		 */
+		set_dev_node(&dev->dev, pcibus_to_node(dev->bus));
+
+		/* Hook up default DMA ops */
+		sd->dma_ops = pci_dma_ops;
+		sd->dma_data = (void *)PCI_DRAM_OFFSET;
+
+		/* Read default IRQs and fixup if necessary */
+		pci_read_irq_line(dev);
+	}
+}
+
+void __devinit pcibios_fixup_bus(struct pci_bus *bus)
+{
+	/* When called from the generic PCI probe, read PCI<->PCI bridge
+	 * bases. This is -not- called when generating the PCI tree from
+	 * the OF device-tree.
+	 */
+	if (bus->self != NULL)
+		pci_read_bridge_bases(bus);
+
+	/* Now fixup the bus bus */
+	pcibios_setup_bus_self(bus);
+
+	/* Now fixup devices on that bus */
+	pcibios_setup_bus_devices(bus);
+}
+EXPORT_SYMBOL(pcibios_fixup_bus);
+
+static int skip_isa_ioresource_align(struct pci_dev *dev)
+{
+	if ((pci_flags & PCI_CAN_SKIP_ISA_ALIGN) &&
+	    !(dev->bus->bridge_ctl & PCI_BRIDGE_CTL_ISA))
+		return 1;
+	return 0;
+}
+
+/*
+ * We need to avoid collisions with `mirrored' VGA ports
+ * and other strange ISA hardware, so we always want the
+ * addresses to be allocated in the 0x000-0x0ff region
+ * modulo 0x400.
+ *
+ * Why? Because some silly external IO cards only decode
+ * the low 10 bits of the IO address. The 0x00-0xff region
+ * is reserved for motherboard devices that decode all 16
+ * bits, so it's ok to allocate at, say, 0x2800-0x28ff,
+ * but we want to try to avoid allocating at 0x2900-0x2bff
+ * which might have be mirrored at 0x0100-0x03ff..
+ */
+void pcibios_align_resource(void *data, struct resource *res,
+				resource_size_t size, resource_size_t align)
+{
+	struct pci_dev *dev = data;
+
+	if (res->flags & IORESOURCE_IO) {
+		resource_size_t start = res->start;
+
+		if (skip_isa_ioresource_align(dev))
+			return;
+		if (start & 0x300) {
+			start = (start + 0x3ff) & ~0x3ff;
+			res->start = start;
+		}
+	}
+}
+EXPORT_SYMBOL(pcibios_align_resource);
+
+/*
+ * Reparent resource children of pr that conflict with res
+ * under res, and make res replace those children.
+ */
+static int __init reparent_resources(struct resource *parent,
+				     struct resource *res)
+{
+	struct resource *p, **pp;
+	struct resource **firstpp = NULL;
+
+	for (pp = &parent->child; (p = *pp) != NULL; pp = &p->sibling) {
+		if (p->end < res->start)
+			continue;
+		if (res->end < p->start)
+			break;
+		if (p->start < res->start || p->end > res->end)
+			return -1;	/* not completely contained */
+		if (firstpp == NULL)
+			firstpp = pp;
+	}
+	if (firstpp == NULL)
+		return -1;	/* didn't find any conflicting entries? */
+	res->parent = parent;
+	res->child = *firstpp;
+	res->sibling = *pp;
+	*firstpp = res;
+	*pp = NULL;
+	for (p = res->child; p != NULL; p = p->sibling) {
+		p->parent = res;
+		pr_debug("PCI: Reparented %s [%llx..%llx] under %s\n",
+			 p->name,
+			 (unsigned long long)p->start,
+			 (unsigned long long)p->end, res->name);
+	}
+	return 0;
+}
+
+/*
+ *  Handle resources of PCI devices.  If the world were perfect, we could
+ *  just allocate all the resource regions and do nothing more.  It isn't.
+ *  On the other hand, we cannot just re-allocate all devices, as it would
+ *  require us to know lots of host bridge internals.  So we attempt to
+ *  keep as much of the original configuration as possible, but tweak it
+ *  when it's found to be wrong.
+ *
+ *  Known BIOS problems we have to work around:
+ *	- I/O or memory regions not configured
+ *	- regions configured, but not enabled in the command register
+ *	- bogus I/O addresses above 64K used
+ *	- expansion ROMs left enabled (this may sound harmless, but given
+ *	  the fact the PCI specs explicitly allow address decoders to be
+ *	  shared between expansion ROMs and other resource regions, it's
+ *	  at least dangerous)
+ *
+ *  Our solution:
+ *	(1) Allocate resources for all buses behind PCI-to-PCI bridges.
+ *	    This gives us fixed barriers on where we can allocate.
+ *	(2) Allocate resources for all enabled devices.  If there is
+ *	    a collision, just mark the resource as unallocated. Also
+ *	    disable expansion ROMs during this step.
+ *	(3) Try to allocate resources for disabled devices.  If the
+ *	    resources were assigned correctly, everything goes well,
+ *	    if they weren't, they won't disturb allocation of other
+ *	    resources.
+ *	(4) Assign new addresses to resources which were either
+ *	    not configured at all or misconfigured.  If explicitly
+ *	    requested by the user, configure expansion ROM address
+ *	    as well.
+ */
+
+void pcibios_allocate_bus_resources(struct pci_bus *bus)
+{
+	struct pci_bus *b;
+	int i;
+	struct resource *res, *pr;
+
+	pr_debug("PCI: Allocating bus resources for %04x:%02x...\n",
+		 pci_domain_nr(bus), bus->number);
+
+	for (i = 0; i < PCI_BUS_NUM_RESOURCES; ++i) {
+		res = bus->resource[i];
+		if (!res || !res->flags
+		    || res->start > res->end || res->parent)
+			continue;
+		if (bus->parent == NULL)
+			pr = (res->flags & IORESOURCE_IO) ?
+				&ioport_resource : &iomem_resource;
+		else {
+			/* Don't bother with non-root busses when
+			 * re-assigning all resources. We clear the
+			 * resource flags as if they were colliding
+			 * and as such ensure proper re-allocation
+			 * later.
+			 */
+			if (pci_flags & PCI_REASSIGN_ALL_RSRC)
+				goto clear_resource;
+			pr = pci_find_parent_resource(bus->self, res);
+			if (pr == res) {
+				/* this happens when the generic PCI
+				 * code (wrongly) decides that this
+				 * bridge is transparent  -- paulus
+				 */
+				continue;
+			}
+		}
+
+		pr_debug("PCI: %s (bus %d) bridge rsrc %d: %016llx-%016llx "
+			 "[0x%x], parent %p (%s)\n",
+			 bus->self ? pci_name(bus->self) : "PHB",
+			 bus->number, i,
+			 (unsigned long long)res->start,
+			 (unsigned long long)res->end,
+			 (unsigned int)res->flags,
+			 pr, (pr && pr->name) ? pr->name : "nil");
+
+		if (pr && !(pr->flags & IORESOURCE_UNSET)) {
+			if (request_resource(pr, res) == 0)
+				continue;
+			/*
+			 * Must be a conflict with an existing entry.
+			 * Move that entry (or entries) under the
+			 * bridge resource and try again.
+			 */
+			if (reparent_resources(pr, res) == 0)
+				continue;
+		}
+		printk(KERN_WARNING "PCI: Cannot allocate resource region "
+		       "%d of PCI bridge %d, will remap\n", i, bus->number);
+clear_resource:
+		res->flags = 0;
+	}
+
+	list_for_each_entry(b, &bus->children, node)
+		pcibios_allocate_bus_resources(b);
+}
+
+static inline void __devinit alloc_resource(struct pci_dev *dev, int idx)
+{
+	struct resource *pr, *r = &dev->resource[idx];
+
+	pr_debug("PCI: Allocating %s: Resource %d: %016llx..%016llx [%x]\n",
+		 pci_name(dev), idx,
+		 (unsigned long long)r->start,
+		 (unsigned long long)r->end,
+		 (unsigned int)r->flags);
+
+	pr = pci_find_parent_resource(dev, r);
+	if (!pr || (pr->flags & IORESOURCE_UNSET) ||
+	    request_resource(pr, r) < 0) {
+		printk(KERN_WARNING "PCI: Cannot allocate resource region %d"
+		       " of device %s, will remap\n", idx, pci_name(dev));
+		if (pr)
+			pr_debug("PCI:  parent is %p: %016llx-%016llx [%x]\n",
+				 pr,
+				 (unsigned long long)pr->start,
+				 (unsigned long long)pr->end,
+				 (unsigned int)pr->flags);
+		/* We'll assign a new address later */
+		r->flags |= IORESOURCE_UNSET;
+		r->end -= r->start;
+		r->start = 0;
+	}
+}
+
+static void __init pcibios_allocate_resources(int pass)
+{
+	struct pci_dev *dev = NULL;
+	int idx, disabled;
+	u16 command;
+	struct resource *r;
+
+	for_each_pci_dev(dev) {
+		pci_read_config_word(dev, PCI_COMMAND, &command);
+		for (idx = 0; idx <= PCI_ROM_RESOURCE; idx++) {
+			r = &dev->resource[idx];
+			if (r->parent)		/* Already allocated */
+				continue;
+			if (!r->flags || (r->flags & IORESOURCE_UNSET))
+				continue;	/* Not assigned at all */
+			/* We only allocate ROMs on pass 1 just in case they
+			 * have been screwed up by firmware
+			 */
+			if (idx == PCI_ROM_RESOURCE)
+				disabled = 1;
+			if (r->flags & IORESOURCE_IO)
+				disabled = !(command & PCI_COMMAND_IO);
+			else
+				disabled = !(command & PCI_COMMAND_MEMORY);
+			if (pass == disabled)
+				alloc_resource(dev, idx);
+		}
+		if (pass)
+			continue;
+		r = &dev->resource[PCI_ROM_RESOURCE];
+		if (r->flags) {
+			/* Turn the ROM off, leave the resource region,
+			 * but keep it unregistered.
+			 */
+			u32 reg;
+			pci_read_config_dword(dev, dev->rom_base_reg, &reg);
+			if (reg & PCI_ROM_ADDRESS_ENABLE) {
+				pr_debug("PCI: Switching off ROM of %s\n",
+					 pci_name(dev));
+				r->flags &= ~IORESOURCE_ROM_ENABLE;
+				pci_write_config_dword(dev, dev->rom_base_reg,
+						reg & ~PCI_ROM_ADDRESS_ENABLE);
+			}
+		}
+	}
+}
+
+static void __init pcibios_reserve_legacy_regions(struct pci_bus *bus)
+{
+	struct pci_controller *hose = pci_bus_to_host(bus);
+	resource_size_t	offset;
+	struct resource *res, *pres;
+	int i;
+
+	pr_debug("Reserving legacy ranges for domain %04x\n",
+							pci_domain_nr(bus));
+
+	/* Check for IO */
+	if (!(hose->io_resource.flags & IORESOURCE_IO))
+		goto no_io;
+	offset = (unsigned long)hose->io_base_virt - _IO_BASE;
+	res = kzalloc(sizeof(struct resource), GFP_KERNEL);
+	BUG_ON(res == NULL);
+	res->name = "Legacy IO";
+	res->flags = IORESOURCE_IO;
+	res->start = offset;
+	res->end = (offset + 0xfff) & 0xfffffffful;
+	pr_debug("Candidate legacy IO: %pR\n", res);
+	if (request_resource(&hose->io_resource, res)) {
+		printk(KERN_DEBUG
+		       "PCI %04x:%02x Cannot reserve Legacy IO %pR\n",
+		       pci_domain_nr(bus), bus->number, res);
+		kfree(res);
+	}
+
+ no_io:
+	/* Check for memory */
+	offset = hose->pci_mem_offset;
+	pr_debug("hose mem offset: %016llx\n", (unsigned long long)offset);
+	for (i = 0; i < 3; i++) {
+		pres = &hose->mem_resources[i];
+		if (!(pres->flags & IORESOURCE_MEM))
+			continue;
+		pr_debug("hose mem res: %pR\n", pres);
+		if ((pres->start - offset) <= 0xa0000 &&
+		    (pres->end - offset) >= 0xbffff)
+			break;
+	}
+	if (i >= 3)
+		return;
+	res = kzalloc(sizeof(struct resource), GFP_KERNEL);
+	BUG_ON(res == NULL);
+	res->name = "Legacy VGA memory";
+	res->flags = IORESOURCE_MEM;
+	res->start = 0xa0000 + offset;
+	res->end = 0xbffff + offset;
+	pr_debug("Candidate VGA memory: %pR\n", res);
+	if (request_resource(pres, res)) {
+		printk(KERN_DEBUG
+		       "PCI %04x:%02x Cannot reserve VGA memory %pR\n",
+		       pci_domain_nr(bus), bus->number, res);
+		kfree(res);
+	}
+}
+
+void __init pcibios_resource_survey(void)
+{
+	struct pci_bus *b;
+
+	/* Allocate and assign resources. If we re-assign everything, then
+	 * we skip the allocate phase
+	 */
+	list_for_each_entry(b, &pci_root_buses, node)
+		pcibios_allocate_bus_resources(b);
+
+	if (!(pci_flags & PCI_REASSIGN_ALL_RSRC)) {
+		pcibios_allocate_resources(0);
+		pcibios_allocate_resources(1);
+	}
+
+	/* Before we start assigning unassigned resource, we try to reserve
+	 * the low IO area and the VGA memory area if they intersect the
+	 * bus available resources to avoid allocating things on top of them
+	 */
+	if (!(pci_flags & PCI_PROBE_ONLY)) {
+		list_for_each_entry(b, &pci_root_buses, node)
+			pcibios_reserve_legacy_regions(b);
+	}
+
+	/* Now, if the platform didn't decide to blindly trust the firmware,
+	 * we proceed to assigning things that were left unassigned
+	 */
+	if (!(pci_flags & PCI_PROBE_ONLY)) {
+		pr_debug("PCI: Assigning unassigned resources...\n");
+		pci_assign_unassigned_resources();
+	}
+}
+
+#ifdef CONFIG_HOTPLUG
+
+/* This is used by the PCI hotplug driver to allocate resource
+ * of newly plugged busses. We can try to consolidate with the
+ * rest of the code later, for now, keep it as-is as our main
+ * resource allocation function doesn't deal with sub-trees yet.
+ */
+void __devinit pcibios_claim_one_bus(struct pci_bus *bus)
+{
+	struct pci_dev *dev;
+	struct pci_bus *child_bus;
+
+	list_for_each_entry(dev, &bus->devices, bus_list) {
+		int i;
+
+		for (i = 0; i < PCI_NUM_RESOURCES; i++) {
+			struct resource *r = &dev->resource[i];
+
+			if (r->parent || !r->start || !r->flags)
+				continue;
+
+			pr_debug("PCI: Claiming %s: "
+				 "Resource %d: %016llx..%016llx [%x]\n",
+				 pci_name(dev), i,
+				 (unsigned long long)r->start,
+				 (unsigned long long)r->end,
+				 (unsigned int)r->flags);
+
+			pci_claim_resource(dev, i);
+		}
+	}
+
+	list_for_each_entry(child_bus, &bus->children, node)
+		pcibios_claim_one_bus(child_bus);
+}
+EXPORT_SYMBOL_GPL(pcibios_claim_one_bus);
+
+
+/* pcibios_finish_adding_to_bus
+ *
+ * This is to be called by the hotplug code after devices have been
+ * added to a bus, this include calling it for a PHB that is just
+ * being added
+ */
+void pcibios_finish_adding_to_bus(struct pci_bus *bus)
+{
+	pr_debug("PCI: Finishing adding to hotplug bus %04x:%02x\n",
+		 pci_domain_nr(bus), bus->number);
+
+	/* Allocate bus and devices resources */
+	pcibios_allocate_bus_resources(bus);
+	pcibios_claim_one_bus(bus);
+
+	/* Add new devices to global lists.  Register in proc, sysfs. */
+	pci_bus_add_devices(bus);
+
+	/* Fixup EEH */
+	/* eeh_add_device_tree_late(bus); */
+}
+EXPORT_SYMBOL_GPL(pcibios_finish_adding_to_bus);
+
+#endif /* CONFIG_HOTPLUG */
+
+int pcibios_enable_device(struct pci_dev *dev, int mask)
+{
+	return pci_enable_resources(dev, mask);
+}
+
+void __devinit pcibios_setup_phb_resources(struct pci_controller *hose)
+{
+	struct pci_bus *bus = hose->bus;
+	struct resource *res;
+	int i;
+
+	/* Hookup PHB IO resource */
+	bus->resource[0] = res = &hose->io_resource;
+
+	if (!res->flags) {
+		printk(KERN_WARNING "PCI: I/O resource not set for host"
+		       " bridge %s (domain %d)\n",
+		       hose->dn->full_name, hose->global_number);
+		/* Workaround for lack of IO resource only on 32-bit */
+		res->start = (unsigned long)hose->io_base_virt - isa_io_base;
+		res->end = res->start + IO_SPACE_LIMIT;
+		res->flags = IORESOURCE_IO;
+	}
+
+	pr_debug("PCI: PHB IO resource    = %016llx-%016llx [%lx]\n",
+		 (unsigned long long)res->start,
+		 (unsigned long long)res->end,
+		 (unsigned long)res->flags);
+
+	/* Hookup PHB Memory resources */
+	for (i = 0; i < 3; ++i) {
+		res = &hose->mem_resources[i];
+		if (!res->flags) {
+			if (i > 0)
+				continue;
+			printk(KERN_ERR "PCI: Memory resource 0 not set for "
+			       "host bridge %s (domain %d)\n",
+			       hose->dn->full_name, hose->global_number);
+
+			/* Workaround for lack of MEM resource only on 32-bit */
+			res->start = hose->pci_mem_offset;
+			res->end = (resource_size_t)-1LL;
+			res->flags = IORESOURCE_MEM;
+
+		}
+		bus->resource[i+1] = res;
+
+		pr_debug("PCI: PHB MEM resource %d = %016llx-%016llx [%lx]\n",
+			i, (unsigned long long)res->start,
+			(unsigned long long)res->end,
+			(unsigned long)res->flags);
+	}
+
+	pr_debug("PCI: PHB MEM offset     = %016llx\n",
+		 (unsigned long long)hose->pci_mem_offset);
+	pr_debug("PCI: PHB IO  offset     = %08lx\n",
+		 (unsigned long)hose->io_base_virt - _IO_BASE);
+}
+
+/*
+ * Null PCI config access functions, for the case when we can't
+ * find a hose.
+ */
+#define NULL_PCI_OP(rw, size, type)					\
+static int								\
+null_##rw##_config_##size(struct pci_dev *dev, int offset, type val)	\
+{									\
+	return PCIBIOS_DEVICE_NOT_FOUND;    				\
+}
+
+static int
+null_read_config(struct pci_bus *bus, unsigned int devfn, int offset,
+		 int len, u32 *val)
+{
+	return PCIBIOS_DEVICE_NOT_FOUND;
+}
+
+static int
+null_write_config(struct pci_bus *bus, unsigned int devfn, int offset,
+		  int len, u32 val)
+{
+	return PCIBIOS_DEVICE_NOT_FOUND;
+}
+
+static struct pci_ops null_pci_ops = {
+	.read = null_read_config,
+	.write = null_write_config,
+};
+
+/*
+ * These functions are used early on before PCI scanning is done
+ * and all of the pci_dev and pci_bus structures have been created.
+ */
+static struct pci_bus *
+fake_pci_bus(struct pci_controller *hose, int busnr)
+{
+	static struct pci_bus bus;
+
+	if (!hose) {
+		printk(KERN_ERR "Can't find hose for PCI bus %d!\n", busnr);
+	}
+	bus.number = busnr;
+	bus.sysdata = hose;
+	bus.ops = hose ? hose->ops : &null_pci_ops;
+	return &bus;
+}
+
+#define EARLY_PCI_OP(rw, size, type)					\
+int early_##rw##_config_##size(struct pci_controller *hose, int bus,	\
+			       int devfn, int offset, type value)	\
+{									\
+	return pci_bus_##rw##_config_##size(fake_pci_bus(hose, bus),	\
+					    devfn, offset, value);	\
+}
+
+EARLY_PCI_OP(read, byte, u8 *)
+EARLY_PCI_OP(read, word, u16 *)
+EARLY_PCI_OP(read, dword, u32 *)
+EARLY_PCI_OP(write, byte, u8)
+EARLY_PCI_OP(write, word, u16)
+EARLY_PCI_OP(write, dword, u32)
+
+int early_find_capability(struct pci_controller *hose, int bus, int devfn,
+			  int cap)
+{
+	return pci_bus_find_capability(fake_pci_bus(hose, bus), devfn, cap);
+}
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/pci/xilinx_pci.c linux-2.6.31.12-petalinux/arch/microblaze/pci/xilinx_pci.c
--- linux-2.6.31.12/arch/microblaze/pci/xilinx_pci.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/pci/xilinx_pci.c	2010-08-08 17:40:15.872768119 +0200
@@ -0,0 +1,168 @@
+/*
+ * PCI support for Xilinx plbv46_pci soft-core which can be used on
+ * Xilinx Virtex ML410 / ML510 boards.
+ *
+ * Copyright 2009 Roderick Colenbrander
+ * Copyright 2009 Secret Lab Technologies Ltd.
+ *
+ * The pci bridge fixup code was copied from ppc4xx_pci.c and was written
+ * by Benjamin Herrenschmidt.
+ * Copyright 2007 Ben. Herrenschmidt <benh@kernel.crashing.org>, IBM Corp.
+ *
+ * This file is licensed under the terms of the GNU General Public License
+ * version 2. This program is licensed "as is" without any warranty of any
+ * kind, whether express or implied.
+ */
+
+#include <linux/ioport.h>
+#include <linux/of.h>
+#include <linux/pci.h>
+#include <asm/io.h>
+
+#define XPLB_PCI_ADDR 0x10c
+#define XPLB_PCI_DATA 0x110
+#define XPLB_PCI_BUS  0x114
+
+#define PCI_HOST_ENABLE_CMD (PCI_COMMAND_SERR | PCI_COMMAND_PARITY | \
+				PCI_COMMAND_MASTER | PCI_COMMAND_MEMORY)
+
+static struct of_device_id xilinx_pci_match[] = {
+	{ .compatible = "xlnx,plbv46-pci-1.03.a", },
+	{}
+};
+
+/**
+ * xilinx_pci_fixup_bridge - Block Xilinx PHB configuration.
+ */
+static void xilinx_pci_fixup_bridge(struct pci_dev *dev)
+{
+	struct pci_controller *hose;
+	int i;
+
+	if (dev->devfn || dev->bus->self)
+		return;
+
+	hose = pci_bus_to_host(dev->bus);
+	if (!hose)
+		return;
+
+	if (!of_match_node(xilinx_pci_match, hose->dn))
+		return;
+
+	/* Hide the PCI host BARs from the kernel as their content doesn't
+	 * fit well in the resource management
+	 */
+	for (i = 0; i < DEVICE_COUNT_RESOURCE; i++) {
+		dev->resource[i].start = 0;
+		dev->resource[i].end = 0;
+		dev->resource[i].flags = 0;
+	}
+
+	dev_info(&dev->dev, "Hiding Xilinx plb-pci host bridge resources %s\n",
+		 pci_name(dev));
+}
+DECLARE_PCI_FIXUP_HEADER(PCI_ANY_ID, PCI_ANY_ID, xilinx_pci_fixup_bridge);
+
+#ifdef DEBUG
+/**
+ * xilinx_pci_exclude_device - Don't do config access for non-root bus
+ *
+ * This is a hack.  Config access to any bus other than bus 0 does not
+ * currently work on the ML510 so we prevent it here.
+ */
+static int
+xilinx_pci_exclude_device(struct pci_controller *hose, u_char bus, u8 devfn)
+{
+	return (bus != 0);
+}
+
+/**
+ * xilinx_early_pci_scan - List pci config space for available devices
+ *
+ * List pci devices in very early phase.
+ */
+void __init xilinx_early_pci_scan(struct pci_controller *hose)
+{
+	u32 bus = 0;
+	u32 val, dev, func, offset;
+
+	/* Currently we have only 2 device connected - up-to 32 devices */
+	for (dev = 0; dev < 2; dev++) {
+		/* List only first function number - up-to 8 functions */
+		for (func = 0; func < 1; func++) {
+			printk(KERN_INFO "%02x:%02x:%02x", bus, dev, func);
+			/* read the first 64 standardized bytes */
+			/* Up-to 192 bytes can be list of capabilities */
+			for (offset = 0; offset < 64; offset += 4) {
+				early_read_config_dword(hose, bus,
+					PCI_DEVFN(dev, func), offset, &val);
+				if (offset == 0 && val == 0xFFFFFFFF) {
+					printk(KERN_CONT "\nABSENT");
+					break;
+				}
+				if(!(offset % 0x10)) {
+					printk(KERN_CONT "\n%04x:    ", offset);
+				}
+				printk(KERN_CONT "%08x  ", val);
+			}
+			printk(KERN_INFO "\n");
+		}
+	}
+}
+#else
+void __init xilinx_early_pci_scan(struct pci_controller *hose)
+{
+}
+#endif
+
+/**
+ * xilinx_pci_init - Find and register a Xilinx PCI host bridge
+ */
+void __init xilinx_pci_init(void)
+{
+	struct pci_controller *hose;
+	struct resource r;
+	void __iomem *pci_reg;
+	struct device_node *pci_node;
+
+	pci_node = of_find_matching_node(NULL, xilinx_pci_match);
+	if (!pci_node)
+		return;
+
+	if (of_address_to_resource(pci_node, 0, &r)) {
+		pr_err("xilinx-pci: cannot resolve base address\n");
+		return;
+	}
+
+	hose = pcibios_alloc_controller(pci_node);
+	if (!hose) {
+		pr_err("xilinx-pci: pcibios_alloc_controller() failed\n");
+		return;
+	}
+
+	/* Setup config space */
+	setup_indirect_pci(hose, r.start + XPLB_PCI_ADDR,
+			   r.start + XPLB_PCI_DATA,
+			   INDIRECT_TYPE_SET_CFG_TYPE);
+
+	/* According to the xilinx plbv46_pci documentation the soft-core starts
+	 * a self-init when the bus master enable bit is set. Without this bit
+	 * set the pci bus can't be scanned.
+	 */
+	early_write_config_word(hose, 0, 0, PCI_COMMAND, PCI_HOST_ENABLE_CMD);
+
+	/* Set the max latency timer to 255 */
+	early_write_config_byte(hose, 0, 0, PCI_LATENCY_TIMER, 0xff);
+
+	/* Set the max bus number to 255, and bus/subbus no's to 0 */
+	pci_reg = of_iomap(pci_node, 0);
+	out_be32(pci_reg + XPLB_PCI_BUS, 0x000000ff);
+	iounmap(pci_reg);
+
+	/* Register the host bridge with the linux kernel! */
+	pci_process_bridge_OF_ranges(hose, pci_node,
+					INDIRECT_TYPE_SET_CFG_TYPE);
+
+	pr_info("xilinx-pci: Registered PCI host bridge\n");
+	xilinx_early_pci_scan(hose);
+}
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/platform/generic/Kconfig.auto linux-2.6.31.12-petalinux/arch/microblaze/platform/generic/Kconfig.auto
--- linux-2.6.31.12/arch/microblaze/platform/generic/Kconfig.auto	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/platform/generic/Kconfig.auto	2010-08-08 17:22:50.597038242 +0200
@@ -21,7 +21,6 @@
 
 # Definitions for MICROBLAZE0
 comment "Definitions for MICROBLAZE0"
-	depends on ALLOW_EDIT_AUTO
 
 config KERNEL_BASE_ADDR
 	hex "Physical address where Linux Kernel is"
@@ -30,33 +29,33 @@ config KERNEL_BASE_ADDR
 	  BASE Address for kernel
 
 config XILINX_MICROBLAZE0_FAMILY
-	string "Targetted FPGA family" if ALLOW_EDIT_AUTO
+	string "Targetted FPGA family"
 	default "virtex5"
 
 config XILINX_MICROBLAZE0_USE_MSR_INSTR
-	int "USE_MSR_INSTR range (0:1)" if ALLOW_EDIT_AUTO
-	default 1
+	int "USE_MSR_INSTR range (0:1)"
+	default 0
 
 config XILINX_MICROBLAZE0_USE_PCMP_INSTR
-	int "USE_PCMP_INSTR range (0:1)" if ALLOW_EDIT_AUTO
-	default 1
+	int "USE_PCMP_INSTR range (0:1)"
+	default 0
 
 config XILINX_MICROBLAZE0_USE_BARREL
-	int "USE_BARREL range (0:1)" if ALLOW_EDIT_AUTO
-	default 1
+	int "USE_BARREL range (0:1)"
+	default 0
 
 config XILINX_MICROBLAZE0_USE_DIV
-	int "USE_DIV range (0:1)" if ALLOW_EDIT_AUTO
-	default 1
+	int "USE_DIV range (0:1)"
+	default 0
 
 config XILINX_MICROBLAZE0_USE_HW_MUL
-	int "USE_HW_MUL values (0=NONE, 1=MUL32, 2=MUL64)" if ALLOW_EDIT_AUTO
-	default 2
+	int "USE_HW_MUL values (0=NONE, 1=MUL32, 2=MUL64)"
+	default 0
 
 config XILINX_MICROBLAZE0_USE_FPU
-	int "USE_FPU values (0=NONE, 1=BASIC, 2=EXTENDED)" if ALLOW_EDIT_AUTO
-	default 2
+	int "USE_FPU values (0=NONE, 1=BASIC, 2=EXTENDED)"
+	default 0
 
 config XILINX_MICROBLAZE0_HW_VER
-	string "Core version number" if ALLOW_EDIT_AUTO
+	string "Core version number"
 	default 7.10.d
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/platform/generic/system.dts linux-2.6.31.12-petalinux/arch/microblaze/platform/generic/system.dts
--- linux-2.6.31.12/arch/microblaze/platform/generic/system.dts	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/platform/generic/system.dts	2010-08-08 17:22:50.597038242 +0200
@@ -32,11 +32,16 @@
 	#address-cells = <1>;
 	#size-cells = <1>;
 	compatible = "xlnx,microblaze";
+	hard-reset-gpios = <&LEDs_8Bit 2 1>;
 	model = "testing";
 	DDR2_SDRAM: memory@90000000 {
 		device_type = "memory";
 		reg = < 0x90000000 0x10000000 >;
 	} ;
+	aliases {
+		ethernet0 = &Hard_Ethernet_MAC;
+		serial0 = &RS232_Uart_1;
+	} ;
 	chosen {
 		bootargs = "console=ttyUL0,115200 highres=on";
 		linux,stdout-path = "/plb@0/serial@84000000";
@@ -127,7 +132,7 @@
 	mb_plb: plb@0 {
 		#address-cells = <1>;
 		#size-cells = <1>;
-		compatible = "xlnx,plb-v46-1.03.a", "simple-bus";
+		compatible = "xlnx,plb-v46-1.03.a", "xlnx,plb-v46-1.00.a", "simple-bus";
 		ranges ;
 		FLASH: flash@a0000000 {
 			bank-width = <2>;
@@ -214,12 +219,12 @@
 			#size-cells = <1>;
 			compatible = "xlnx,compound";
 			ethernet@81c00000 {
-				compatible = "xlnx,xps-ll-temac-1.01.b";
+				compatible = "xlnx,xps-ll-temac-1.01.b", "xlnx,xps-ll-temac-1.00.a";
 				device_type = "network";
 				interrupt-parent = <&xps_intc_0>;
 				interrupts = < 5 2 >;
 				llink-connected = <&PIM3>;
-				local-mac-address = [ 02 00 00 00 00 00 ];
+				local-mac-address = [ 00 0a 35 00 00 00 ];
 				reg = < 0x81c00000 0x40 >;
 				xlnx,bus2core-clk-ratio = <0x1>;
 				xlnx,phy-type = <0x1>;
@@ -261,6 +266,33 @@
 			xlnx,is-dual = <0x0>;
 			xlnx,tri-default = <0xffffffff>;
 			xlnx,tri-default-2 = <0xffffffff>;
+			#gpio-cells = <2>;
+			gpio-controller;
+		} ;
+
+		gpio-leds {
+			compatible = "gpio-leds";
+
+			heartbeat {
+				label = "Heartbeat";
+				gpios = <&LEDs_8Bit 4 1>;
+				linux,default-trigger = "heartbeat";
+			};
+
+			yellow {
+				label = "Yellow";
+				gpios = <&LEDs_8Bit 5 1>;
+			};
+
+			red {
+				label = "Red";
+				gpios = <&LEDs_8Bit 6 1>;
+			};
+
+			green {
+				label = "Green";
+				gpios = <&LEDs_8Bit 7 1>;
+			};
 		} ;
 		RS232_Uart_1: serial@84000000 {
 			clock-frequency = <125000000>;
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/platform/Kconfig.platform linux-2.6.31.12-petalinux/arch/microblaze/platform/Kconfig.platform
--- linux-2.6.31.12/arch/microblaze/platform/Kconfig.platform	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/platform/Kconfig.platform	2010-08-08 17:22:50.597038242 +0200
@@ -53,31 +53,12 @@ config OPT_LIB_FUNCTION
 
 config OPT_LIB_ASM
 	bool "Optimalized lib function ASM"
-	depends on OPT_LIB_FUNCTION
+	depends on OPT_LIB_FUNCTION && (XILINX_MICROBLAZE0_USE_BARREL = 1)
 	default n
 	help
 	  Allows turn on optimalized library function (memcpy and memmove).
 	  Function are written in asm code.
 
-# This is still a bit broken - disabling for now JW 20070504
-config ALLOW_EDIT_AUTO
-	bool "Permit Display/edit of Kconfig.auto platform settings"
-	default n
-	help
-	  Allows the editing of auto-generated platform settings from
-	  the Kconfig.auto file. Obviously this does not change the
-	  underlying hardware, so be very careful if you go editing
-	  these settings.
-
-	  Also, if you enable this, and edit various Kconfig.auto
-	  settings, YOUR CHANGES WILL BE LOST if you then disable it
-	  again. You have been warned!
-
-	  If unsure, say no.
-
-comment "Automatic platform settings from Kconfig.auto"
-	depends on ALLOW_EDIT_AUTO
-
 if PLATFORM_GENERIC=y
 	source "arch/microblaze/platform/generic/Kconfig.auto"
 endif
diff -purN --exclude=.git linux-2.6.31.12/arch/microblaze/platform/platform.c linux-2.6.31.12-petalinux/arch/microblaze/platform/platform.c
--- linux-2.6.31.12/arch/microblaze/platform/platform.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/microblaze/platform/platform.c	2010-08-08 17:22:50.597038242 +0200
@@ -13,6 +13,7 @@
 #include <linux/init.h>
 #include <linux/of_platform.h>
 #include <asm/prom.h>
+#include <asm/setup.h>
 
 static struct of_device_id xilinx_of_bus_ids[] __initdata = {
 	{ .compatible = "simple-bus", },
@@ -26,6 +27,7 @@ static struct of_device_id xilinx_of_bus
 static int __init microblaze_device_probe(void)
 {
 	of_platform_bus_probe(NULL, xilinx_of_bus_ids, NULL);
+	of_platform_reset_gpio_probe();
 	return 0;
 }
 device_initcall(microblaze_device_probe);
diff -purN --exclude=.git linux-2.6.31.12/arch/mips/mm/init.c linux-2.6.31.12-petalinux/arch/mips/mm/init.c
--- linux-2.6.31.12/arch/mips/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/mips/mm/init.c	2010-08-08 17:40:15.872768119 +0200
@@ -417,7 +417,7 @@ void __init mem_init(void)
 
 	printk(KERN_INFO "Memory: %luk/%luk available (%ldk kernel code, "
 	       "%ldk reserved, %ldk data, %ldk init, %ldk highmem)\n",
-	       (unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+	       nr_free_pages() << (PAGE_SHIFT-10),
 	       ram << (PAGE_SHIFT-10),
 	       codesize >> 10,
 	       reservedpages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/arch/mn10300/mm/init.c linux-2.6.31.12-petalinux/arch/mn10300/mm/init.c
--- linux-2.6.31.12/arch/mn10300/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/mn10300/mm/init.c	2010-08-08 17:40:15.872768119 +0200
@@ -112,7 +112,7 @@ void __init mem_init(void)
 	       "Memory: %luk/%luk available"
 	       " (%dk kernel code, %dk reserved, %dk data, %dk init,"
 	       " %ldk highmem)\n",
-	       (unsigned long) nr_free_pages() << (PAGE_SHIFT - 10),
+	       nr_free_pages() << (PAGE_SHIFT - 10),
 	       max_mapnr << (PAGE_SHIFT - 10),
 	       codesize >> 10,
 	       reservedpages << (PAGE_SHIFT - 10),
diff -purN --exclude=.git linux-2.6.31.12/arch/parisc/mm/init.c linux-2.6.31.12-petalinux/arch/parisc/mm/init.c
--- linux-2.6.31.12/arch/parisc/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/parisc/mm/init.c	2010-08-08 17:40:15.872768119 +0200
@@ -506,7 +506,7 @@ void __init mem_init(void)
 #endif
 
 	printk(KERN_INFO "Memory: %luk/%luk available (%dk kernel code, %dk reserved, %dk data, %dk init)\n",
-		(unsigned long)nr_free_pages() << (PAGE_SHIFT-10),
+		nr_free_pages() << (PAGE_SHIFT-10),
 		num_physpages << (PAGE_SHIFT-10),
 		codesize >> 10,
 		reservedpages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/arch/powerpc/boot/kernel_fdt.its linux-2.6.31.12-petalinux/arch/powerpc/boot/kernel_fdt.its
--- linux-2.6.31.12/arch/powerpc/boot/kernel_fdt.its	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/powerpc/boot/kernel_fdt.its	2010-08-08 17:40:15.875847631 +0200
@@ -0,0 +1,50 @@
+/*
+ * Simple U-boot uImage source file containing a single kernel and FDT blob
+ */
+/ {
+	description = "PetaLinux PPC uImage with single Linux kernel and FDT blob";
+	#address-cells = <1>;
+
+	images {
+		kernel@1 {
+			description = "PetaLinux kernel";
+			data = /incbin/("./vmlinux.bin.gz");
+			type = "kernel";
+			arch = "ppc";
+			os = "linux";
+			compression = "gzip";
+			load = <00000000>;
+			entry = <00000000>;
+			hash@1 {
+				algo = "crc32";
+			};
+			hash@2 {
+				algo = "sha1";
+			};
+		};
+		fdt@1 {
+			description = "Flattened Device Tree blob";
+			data = /incbin/("./target.dtb");
+			type = "flat_dt";
+			arch = "ppc";
+			compression = "none";
+/*
+			hash@1 {
+				algo = "crc32";
+			};
+			hash@2 {
+				algo = "sha1";
+			};
+*/
+		};
+	};
+
+	configurations {
+		default = "conf@1";
+		conf@1 {
+			description = "Boot Linux kernel with FDT blob";
+			kernel = "kernel@1";
+			fdt = "fdt@1";
+		};
+	};
+};
diff -purN --exclude=.git linux-2.6.31.12/arch/powerpc/boot/Makefile linux-2.6.31.12-petalinux/arch/powerpc/boot/Makefile
--- linux-2.6.31.12/arch/powerpc/boot/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/powerpc/boot/Makefile	2010-08-08 17:40:15.875847631 +0200
@@ -305,6 +305,9 @@ $(obj)/zImage.iseries: vmlinux
 $(obj)/uImage: vmlinux $(wrapperbits)
 	$(call if_changed,wrap,uboot)
 
+$(obj)/uImage.%: vmlinux $(obj)/%.dtb $(wrapperbits)
+	$(call if_changed,wrap,uboot-fit,,$(obj)/$*.dtb)
+
 $(obj)/cuImage.initrd.%: vmlinux $(obj)/%.dtb $(wrapperbits)
 	$(call if_changed,wrap,cuboot-$*,,$(obj)/$*.dtb,$(obj)/ramdisk.image.gz)
 
diff -purN --exclude=.git linux-2.6.31.12/arch/powerpc/boot/wrapper linux-2.6.31.12-petalinux/arch/powerpc/boot/wrapper
--- linux-2.6.31.12/arch/powerpc/boot/wrapper	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/powerpc/boot/wrapper	2010-08-08 17:40:15.875847631 +0200
@@ -138,7 +138,10 @@ objflags=-S
 tmp=$tmpdir/zImage.$$.o
 ksection=.kernel:vmlinux.strip
 isection=.kernel:initrd
-link_address='0x400000'
+
+# default auto-calculate link_address to make room for the kernel
+# round up kernel image size to nearest megabyte
+link_address=`${CROSS}size -x ${kernel} | grep ${kernel} | awk '{printf("0x%08x", and($4 + 0x0fffff, 0xfffe0000))}'`
 
 case "$platform" in
 pseries)
@@ -153,7 +156,7 @@ coff)
     lds=$object/zImage.coff.lds
     link_address='0x500000'
     ;;
-miboot|uboot)
+miboot|uboot|uboot-fit)
     # miboot and U-boot want just the bare bits, not an ELF binary
     ext=bin
     objflags="-O binary"
@@ -269,6 +272,16 @@ uboot)
     fi
     exit 0
     ;;
+uboot-fit)
+    pwd
+    rm -f "$ofile"
+    #[ "$vmz" != vmlinux.bin.gz ] && mv "$vmz" "vmlinux.bin.gz"
+    mv "$dtb" "target.dtb"
+    cp arch/powerpc/boot/kernel_fdt.its .
+    mkimage -f kernel_fdt.its "$ofile"
+    #rm kernet_fdt.its
+    exit 0
+    ;;
 esac
 
 addsec() {
diff -purN --exclude=.git linux-2.6.31.12/arch/powerpc/Makefile linux-2.6.31.12-petalinux/arch/powerpc/Makefile
--- linux-2.6.31.12/arch/powerpc/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/powerpc/Makefile	2010-08-08 17:40:15.875847631 +0200
@@ -158,7 +158,7 @@ drivers-$(CONFIG_OPROFILE)	+= arch/power
 # Default to zImage, override when needed
 all: zImage
 
-BOOT_TARGETS = zImage zImage.initrd uImage zImage% dtbImage% treeImage.% cuImage.% simpleImage.%
+BOOT_TARGETS = zImage zImage.initrd uImage uImage.% zImage% dtbImage% treeImage.% cuImage.% simpleImage.%
 
 PHONY += $(BOOT_TARGETS)
 
diff -purN --exclude=.git linux-2.6.31.12/arch/powerpc/mm/mem.c linux-2.6.31.12-petalinux/arch/powerpc/mm/mem.c
--- linux-2.6.31.12/arch/powerpc/mm/mem.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/powerpc/mm/mem.c	2010-08-08 17:40:15.875847631 +0200
@@ -372,7 +372,7 @@ void __init mem_init(void)
 
 	printk(KERN_INFO "Memory: %luk/%luk available (%luk kernel code, "
 	       "%luk reserved, %luk data, %luk bss, %luk init)\n",
-		(unsigned long)nr_free_pages() << (PAGE_SHIFT-10),
+		nr_free_pages() << (PAGE_SHIFT-10),
 		num_physpages << (PAGE_SHIFT-10),
 		codesize >> 10,
 		reservedpages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/arch/s390/mm/init.c linux-2.6.31.12-petalinux/arch/s390/mm/init.c
--- linux-2.6.31.12/arch/s390/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/s390/mm/init.c	2010-08-08 17:40:15.875847631 +0200
@@ -105,7 +105,7 @@ void __init mem_init(void)
 	datasize =  (unsigned long) &_edata - (unsigned long) &_etext;
 	initsize =  (unsigned long) &__init_end - (unsigned long) &__init_begin;
         printk("Memory: %luk/%luk available (%ldk kernel code, %ldk reserved, %ldk data, %ldk init)\n",
-                (unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+		nr_free_pages() << (PAGE_SHIFT-10),
                 max_mapnr << (PAGE_SHIFT-10),
                 codesize >> 10,
                 reservedpages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/arch/sh/mm/init.c linux-2.6.31.12-petalinux/arch/sh/mm/init.c
--- linux-2.6.31.12/arch/sh/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/sh/mm/init.c	2010-08-08 17:40:15.875847631 +0200
@@ -224,7 +224,7 @@ void __init mem_init(void)
 
 	printk(KERN_INFO "Memory: %luk/%luk available (%dk kernel code, "
 	       "%dk data, %dk init)\n",
-		(unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+		nr_free_pages() << (PAGE_SHIFT-10),
 		num_physpages << (PAGE_SHIFT-10),
 		codesize >> 10,
 		datasize >> 10,
diff -purN --exclude=.git linux-2.6.31.12/arch/sparc/mm/init_32.c linux-2.6.31.12-petalinux/arch/sparc/mm/init_32.c
--- linux-2.6.31.12/arch/sparc/mm/init_32.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/sparc/mm/init_32.c	2010-08-08 17:40:16.391983688 +0200
@@ -468,7 +468,7 @@ void __init mem_init(void)
 			reservedpages++;
 
 	printk(KERN_INFO "Memory: %luk/%luk available (%dk kernel code, %dk reserved, %dk data, %dk init, %ldk highmem)\n",
-	       (unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+	       nr_free_pages() << (PAGE_SHIFT-10),
 	       num_physpages << (PAGE_SHIFT - 10),
 	       codepages << (PAGE_SHIFT-10),
 	       reservedpages << (PAGE_SHIFT - 10),
diff -purN --exclude=.git linux-2.6.31.12/arch/um/kernel/mem.c linux-2.6.31.12-petalinux/arch/um/kernel/mem.c
--- linux-2.6.31.12/arch/um/kernel/mem.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/um/kernel/mem.c	2010-08-08 17:40:16.391983688 +0200
@@ -77,7 +77,7 @@ void __init mem_init(void)
 	num_physpages = totalram_pages;
 	max_pfn = totalram_pages;
 	printk(KERN_INFO "Memory: %luk available\n",
-	       (unsigned long) nr_free_pages() << (PAGE_SHIFT-10));
+	       nr_free_pages() << (PAGE_SHIFT-10));
 	kmalloc_ok = 1;
 
 #ifdef CONFIG_HIGHMEM
diff -purN --exclude=.git linux-2.6.31.12/arch/x86/mm/init_32.c linux-2.6.31.12-petalinux/arch/x86/mm/init_32.c
--- linux-2.6.31.12/arch/x86/mm/init_32.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/x86/mm/init_32.c	2010-08-08 17:40:16.425534179 +0200
@@ -892,7 +892,7 @@ void __init mem_init(void)
 
 	printk(KERN_INFO "Memory: %luk/%luk available (%dk kernel code, "
 			"%dk reserved, %dk data, %dk init, %ldk highmem)\n",
-		(unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+		nr_free_pages() << (PAGE_SHIFT-10),
 		num_physpages << (PAGE_SHIFT-10),
 		codesize >> 10,
 		reservedpages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/arch/x86/mm/init_64.c linux-2.6.31.12-petalinux/arch/x86/mm/init_64.c
--- linux-2.6.31.12/arch/x86/mm/init_64.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/x86/mm/init_64.c	2010-08-08 17:40:16.428593925 +0200
@@ -687,7 +687,7 @@ void __init mem_init(void)
 
 	printk(KERN_INFO "Memory: %luk/%luk available (%ldk kernel code, "
 			 "%ldk absent, %ldk reserved, %ldk data, %ldk init)\n",
-		(unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+		nr_free_pages() << (PAGE_SHIFT-10),
 		max_pfn << (PAGE_SHIFT-10),
 		codesize >> 10,
 		absent_pages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/arch/xtensa/mm/init.c linux-2.6.31.12-petalinux/arch/xtensa/mm/init.c
--- linux-2.6.31.12/arch/xtensa/mm/init.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/arch/xtensa/mm/init.c	2010-08-08 17:40:16.428593925 +0200
@@ -203,7 +203,7 @@ void __init mem_init(void)
 
 	printk("Memory: %luk/%luk available (%ldk kernel code, %ldk reserved, "
 	       "%ldk data, %ldk init %ldk highmem)\n",
-	       (unsigned long) nr_free_pages() << (PAGE_SHIFT-10),
+	       nr_free_pages() << (PAGE_SHIFT-10),
 	       ram << (PAGE_SHIFT-10),
 	       codesize >> 10,
 	       reservedpages << (PAGE_SHIFT-10),
diff -purN --exclude=.git linux-2.6.31.12/drivers/block/xsysace.c linux-2.6.31.12-petalinux/drivers/block/xsysace.c
--- linux-2.6.31.12/drivers/block/xsysace.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/block/xsysace.c	2010-08-08 17:26:20.785029811 +0200
@@ -1192,7 +1192,7 @@ ace_of_probe(struct of_device *op, const
 {
 	struct resource res;
 	resource_size_t physaddr;
-	const u32 *id;
+	const u32 *id, *mem_width;
 	int irq, bus_width, rc;
 
 	dev_dbg(&op->dev, "ace_of_probe(%p, %p)\n", op, match);
@@ -1215,6 +1215,20 @@ ace_of_probe(struct of_device *op, const
 	bus_width = ACE_BUS_WIDTH_16;
 	if (of_find_property(op->node, "8-bit", NULL))
 		bus_width = ACE_BUS_WIDTH_8;
+	else {
+		mem_width = of_get_property(op->node, "xlnx,mem-width", NULL);
+		if (mem_width) {
+			switch (*mem_width) {
+			case 8:
+				bus_width = ACE_BUS_WIDTH_8; break;
+			case 16:
+				bus_width = ACE_BUS_WIDTH_16; break;
+			default:
+				dev_err(&op->dev, "invalid width (%i)\n",
+								*mem_width);
+			}
+		}
+	}
 
 	/* Call the bus-independant setup code */
 	return ace_alloc(&op->dev, id ? *id : 0, physaddr, irq, bus_width);
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/Kconfig linux-2.6.31.12-petalinux/drivers/i2c/algos/Kconfig
--- linux-2.6.31.12/drivers/i2c/algos/Kconfig	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/Kconfig	2010-08-08 17:40:16.452802309 +0200
@@ -14,4 +14,10 @@ config I2C_ALGOPCF
 config I2C_ALGOPCA
 	tristate "I2C PCA 9564 interfaces"
 
+config XILINX_IIC
+	tristate "Xilinx IIC interface"
+	depends on I2C && XILINX_DRIVERS
+	help
+	  Supports the Xilinx IIC interface.
+
 endmenu
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/Makefile linux-2.6.31.12-petalinux/drivers/i2c/algos/Makefile
--- linux-2.6.31.12/drivers/i2c/algos/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/Makefile	2010-08-08 17:40:16.452802309 +0200
@@ -5,6 +5,7 @@
 obj-$(CONFIG_I2C_ALGOBIT)	+= i2c-algo-bit.o
 obj-$(CONFIG_I2C_ALGOPCF)	+= i2c-algo-pcf.o
 obj-$(CONFIG_I2C_ALGOPCA)	+= i2c-algo-pca.o
+obj-$(CONFIG_XILINX_IIC)        += xilinx_iic/
 
 ifeq ($(CONFIG_I2C_DEBUG_ALGO),y)
 EXTRA_CFLAGS += -DDEBUG
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/i2c-algo-xilinx.c linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/i2c-algo-xilinx.c
--- linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/i2c-algo-xilinx.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/i2c-algo-xilinx.c	2010-08-08 17:40:16.483745768 +0200
@@ -0,0 +1,646 @@
+/*
+ * i2c-algo-xilinx.c
+ *
+ * Xilinx IIC Adapter component to interface IIC component to Linux
+ *
+ * Author: MontaVista Software, Inc.
+ *         source@mvista.com
+ *
+ * 2002 (c) MontaVista, Software, Inc.  This file is licensed under the terms
+ * of the GNU General Public License version 2.  This program is licensed
+ * "as is" without any warranty of any kind, whether express or implied.
+ */
+
+/*
+ * I2C drivers are split into two pieces: the adapter and the algorithm.
+ * The adapter is responsible for actually manipulating the hardware and
+ * the algorithm is the layer above that that handles the higher level
+ * tasks such as transmitting or receiving a buffer.  The best example
+ * (in my opinion) of this is the bit banging algorithm has a number of
+ * different adapters that can plug in under it to actually wiggle the
+ * SDA and SCL.
+ *
+ * The interesting part is that the drivers Xilinx provides with their
+ * IP are also split into two pieces where one part is the OS
+ * independent code and the other part is the OS dependent code.  All of
+ * the other sources in this directory are the OS independent files as
+ * provided by Xilinx with no changes made to them.
+ *
+ * As it turns out, this maps quite well into the I2C driver philosophy.
+ * This file is the I2C algorithm that communicates with the Xilinx OS
+ * independent function that will serve as our I2C adapter.  The
+ * unfortunate part is that the term "adapter" is overloaded in our
+ * context.  Xilinx refers to the OS dependent part of a driver as an
+ * adapter.  So from an I2C driver perspective, this file is not an
+ * adapter; that role is filled by the Xilinx OS independent files.
+ * From a Xilinx perspective, this file is an adapter; it adapts their
+ * OS independent code to Linux.
+ *
+ * Another thing to consider is that the Xilinx OS dependent code knows
+ * nothing about Linux I2C adapters, so even though this file is billed
+ * as the I2C algorithm, it takes care of the i2c_adapter structure.
+ *
+ * Fortunately, naming conventions will give you a clue as to what comes
+ * from where.  Functions beginning with XIic_ are provided by the
+ * Xilinx OS independent files.  Functions beginning with i2c_ are
+ * provided by the I2C Linux core.  All functions in this file that are
+ * called by Linux have names that begin with xiic_.  The functions in
+ * this file that have Handler in their name are registered as callbacks
+ * with the underlying Xilinx OS independent layer.  Any other functions
+ * are static helper functions.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/interrupt.h>
+#include <linux/device.h>
+#include <linux/i2c.h>
+#include <linux/xilinx_devices.h>
+
+#include <asm/delay.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+
+#include "xbasic_types.h"
+#include "xiic.h"
+#include "xiic_i.h"
+
+#include <linux/of_device.h>
+#include <linux/of_platform.h>
+#include <linux/of_i2c.h>
+
+MODULE_AUTHOR("MontaVista Software, Inc. <source@mvista.com>");
+MODULE_DESCRIPTION("Xilinx IIC driver");
+MODULE_LICENSE("GPL");
+MODULE_PARM_DESC(scan, "Scan for active chips on the bus");
+static int scan = 0;		/* have a look at what's hanging 'round */
+
+/* SAATODO: actually use these? */
+#define XIIC_TIMEOUT           100
+#define XIIC_RETRY             3
+
+#define XILINX_IIC             "xilinx_iic"
+
+/* Our private per device data. */
+struct xiic_data {
+	struct i2c_adapter adap;	/* The Linux I2C core data  */
+	int index;		/* index taken from platform_device */
+	struct completion complete;	/* for waiting for interrupts */
+	u32 base;		/* base memory address */
+	unsigned int irq;	/* device IRQ number    */
+    volatile u32 transmit_intr_flag;   /* semaphore across task and interrupt - ECM */
+    volatile u32 receive_intr_flag;   /* semaphore across task and interrupt - ECM */
+    volatile u32 status_intr_flag;   /* semaphore across task and interrupt - ECM */
+	/*
+	 * The underlying OS independent code needs space as well.  A
+	 * pointer to the following XIic structure will be passed to
+	 * any XIic_ function that requires it.  However, we treat the
+	 * data as an opaque object in this file (meaning that we never
+	 * reference any of the fields inside of the structure).
+	 */
+	XIic Iic;
+
+	/*
+	 * The following bit fields are used to keep track of what
+	 * all has been done to initialize the xiic_dev to make
+	 * error handling out of probe() easier.
+	 */
+	unsigned int reqirq:1;	/* Has request_irq() been called? */
+	unsigned int remapped:1;	/* Has ioremap() been called? */
+	unsigned int started:1;	/* Has XIic_Start() been called? */
+	unsigned int added:1;	/* Has i2c_add_adapter() been called? */
+};
+
+/*******************************************************************************
+ * This configuration stuff should become unnecessary after EDK version 8.x is
+ * released.
+ ******************************************************************************/
+
+static DECLARE_MUTEX(cfg_sem);
+static int
+xiic_xfer(struct i2c_adapter *i2c_adap, struct i2c_msg msgs[], int num)
+{
+    struct xiic_data *dev = (struct xiic_data *) i2c_adap;
+    struct i2c_msg *pmsg;
+    u32 options;
+    int i, retries;
+    u32 Status;
+    u32 writeop;
+	
+    for (i = 0; i < num; i++)
+    {
+        pmsg = &msgs[i];
+
+        if (!pmsg->len) /* If length is zero */
+             continue;  /* on to the next request. */
+
+        /*
+         * This code checks up to 16 times for the
+         * bus busy condition.
+         */
+        retries = 4;
+        while((XIic_IsIicBusy(&dev->Iic) == TRUE) &&
+              (retries-- != 0))
+        {
+            set_current_state(TASK_INTERRUPTIBLE);
+            schedule_timeout(HZ/250);
+        }
+
+
+        /* If bus is still busy, bail */
+        if (XIic_IsIicBusy(&dev->Iic) == TRUE)
+        {
+            printk(KERN_WARNING
+                   "%s #%d: Could not talk to device 0x%2x (%d), bus always busy, trying to reset\n",
+                   dev->adap.name, dev->index, pmsg->addr,
+                   dev->status_intr_flag);
+
+			/* Try stopping, reseting and starting device to clear condition
+			*/
+			if (XIic_Stop(&dev->Iic) != XST_SUCCESS)
+			{
+				/* The bus was in use.. */
+				printk(KERN_WARNING
+					   "%s #%d: Could not stop device. Restart from higher layer.\n",
+					   dev->adap.name, dev->index);
+				return -ENXIO;
+			}
+			else
+			{
+				XIic_Reset(&dev->Iic);
+				if (XIic_Start(&dev->Iic) != XST_SUCCESS)
+				{
+					printk(KERN_ERR "%s #%d: Could not start device.\n",
+						   dev->adap.name, dev->index);
+					return -ENODEV;
+				}
+
+				return -ENXIO;
+			}
+        }
+
+        options = 0;
+        if (pmsg->flags & I2C_M_TEN)
+            options |= XII_SEND_10_BIT_OPTION;
+        XIic_SetOptions(&dev->Iic, options);
+
+        if (XIic_SetAddress(&dev->Iic, XII_ADDR_TO_SEND_TYPE,
+                    pmsg->addr) != XST_SUCCESS)
+        {
+            printk(KERN_WARNING
+                   "%s #%d: Could not set address to 0x%2x.\n",
+                   dev->adap.name, dev->index, pmsg->addr);
+            return -EIO;
+        }
+
+
+        dev->transmit_intr_flag = 0xFFFFFFFF;
+        dev->receive_intr_flag = 0xFFFFFFFF;
+        dev->status_intr_flag = 0xFFFFFFFF;
+
+        /* set the writeop flag to 0 so the adapter does not wait
+         * at bottom of loop
+         */
+        writeop = 0;
+
+		dev->Iic.Stats.TxErrors = 0;
+
+        if (pmsg->flags & I2C_M_RD)
+        {
+            Status = XIic_MasterRecv(&dev->Iic, pmsg->buf, pmsg->len);
+        }
+        else
+        {
+            Status = XIic_MasterSend(&dev->Iic, pmsg->buf, pmsg->len);
+        }
+
+        if (Status != XST_SUCCESS)
+        {
+            printk(KERN_WARNING
+                   "%s #%d: Unexpected error %d.\n",
+                   dev->adap.name, dev->index, (int)Status);
+            return -EIO;
+        }
+
+        /*
+	 * Wait till the data is transmitted or received. If there is an error
+	 * retry for 10 times.
+	 */
+	retries = 10;
+
+	if(pmsg->flags & I2C_M_RD)
+	{
+		while((((volatile int)(dev->receive_intr_flag)) != 0) && (retries != 0))
+		{
+			if ( dev->Iic.Stats.TxErrors != 0)
+			{
+				udelay(25);
+				Status = XIic_MasterRecv(&dev->Iic, pmsg->buf, pmsg->len);
+				dev->Iic.Stats.TxErrors = 0;
+				retries--;
+			}
+
+			/* the udelay was not working for Microblaze and this seems
+			   like a better solution */	
+			schedule_timeout_interruptible(1);
+                }
+	}
+	else
+	{
+		while((((volatile int)(dev->transmit_intr_flag)) != 0) && (retries != 0))
+		{
+			if ( dev->Iic.Stats.TxErrors != 0)
+			{
+				udelay(25);
+				Status = XIic_MasterSend(&dev->Iic, pmsg->buf, pmsg->len);
+				dev->Iic.Stats.TxErrors = 0;
+				retries--;
+			}
+
+			/* the udelay was not working for Microblaze and this seems
+			   like a better solution */	
+			schedule_timeout_interruptible(1);
+		}
+	}
+
+	if(retries == 0)
+	{
+		printk("Unable to talk to Device\n");
+		printk("Wrong Slave address or Slave device Busy\n");
+	}
+    }
+    return num;
+}
+
+static u32 xiic_bit_func(struct i2c_adapter *adap)
+{
+	return I2C_FUNC_SMBUS_EMUL | I2C_FUNC_10BIT_ADDR |
+	    I2C_FUNC_PROTOCOL_MANGLING;
+}
+
+static struct i2c_algorithm xiic_algo = {
+	.master_xfer = xiic_xfer,	/* master_xfer          */
+	.smbus_xfer = NULL,	/* smbus_xfer           */
+	.functionality = xiic_bit_func,	/* functionality        */
+};
+
+/*
+ * This routine is registered with the OS as the function to call when
+ * the IIC interrupts.  It in turn, calls the Xilinx OS independent
+ * interrupt function.  The Xilinx OS independent interrupt function
+ * will in turn call any callbacks that we have registered for various
+ * conditions.
+ */
+static irqreturn_t xiic_interrupt(int irq, void *dev_id)
+{
+	struct xiic_data *dev = dev_id;
+
+	XIic_InterruptHandler(&dev->Iic);
+	return IRQ_HANDLED;
+}
+
+static void RecvHandler(void *CallbackRef, int ByteCount)
+{
+	struct xiic_data *dev = (struct xiic_data *)CallbackRef;
+
+	if (ByteCount == 0) {
+		(dev->receive_intr_flag) = XST_SUCCESS;
+		complete(&dev->complete);
+	}
+}
+
+static void SendHandler(void *CallbackRef, int ByteCount)
+{
+	struct xiic_data *dev = (struct xiic_data *)CallbackRef;
+
+	if (ByteCount == 0) {
+		(dev->transmit_intr_flag) = XST_SUCCESS;
+		complete(&dev->complete);
+	}
+}
+
+static void StatusHandler(void *CallbackRef, int Status)
+{
+	struct xiic_data *dev = (struct xiic_data *)CallbackRef;
+
+	(dev->status_intr_flag) = Status;
+	complete(&dev->complete);
+}
+
+static char *xilinx_iic_do_scan(struct xiic_data *dev)
+{
+	int i;
+	char *page = kmalloc(PAGE_SIZE, GFP_KERNEL);
+	char *cptr = page;
+	u8 data;
+	u32 status;
+
+	for (i = 0x08; i < 0x78 && cptr; i++) {
+
+		snprintf(cptr, PAGE_SIZE - (cptr - page), "%02X: ", i);
+		cptr += strlen(cptr);
+
+		init_completion(&dev->complete);
+		if (XIic_SetAddress(&dev->Iic, XII_ADDR_TO_SEND_TYPE,
+				    i) != XST_SUCCESS) {
+
+			snprintf(cptr, PAGE_SIZE - (cptr - page),
+				 "can't set address\n");
+			cptr += strlen(cptr);
+			continue;
+		}
+
+		dev->receive_intr_flag = ~0;
+		status = XIic_MasterRecv(&dev->Iic, &data, sizeof(data));
+		if (status != XST_SUCCESS) {
+			snprintf(cptr, PAGE_SIZE - (cptr - page),
+				 "unexpected error\n");
+			cptr += strlen(cptr);
+			continue;
+		}
+
+		wait_for_completion(&dev->complete);
+
+		snprintf(cptr, PAGE_SIZE - (cptr - page),
+			 dev->receive_intr_flag == XST_SUCCESS ?
+			 "OK\n" : "not respoding\n");
+		cptr += strlen(cptr);
+	}
+
+	return page;
+}
+
+static ssize_t scan_show(struct device *d, struct device_attribute *attr,
+			 char *text)
+{
+	int len = 0;
+	char *scan_text = xilinx_iic_do_scan(dev_get_drvdata(d));
+
+	if (scan_text) {
+		len = strlen(scan_text);
+		memcpy(text, scan_text, len);
+		kfree(scan_text);
+	}
+	return len;
+}
+
+static  DEVICE_ATTR(scan, S_IRUGO, scan_show, NULL);
+
+static int __devexit xilinx_iic_remove(struct device *device)
+{
+	struct xiic_data *dev;
+
+	dev = dev_get_drvdata(device);
+
+	/*
+	 * If we've told the core I2C code about this dev, tell
+	 * the core I2C code to forget the dev.
+	 */
+	if (dev->added) {
+		/*
+		 * If an error is returned, there's not a whole lot we can
+		 * do.  An error has already been printed out so we'll
+		 * just keep trundling along.
+		 */
+		(void)i2c_del_adapter(&dev->adap);
+	}
+
+	/* Tell the Xilinx code to take this IIC interface down. */
+	if (dev->started) {
+		while (XIic_Stop(&dev->Iic) != XST_SUCCESS) {
+			/* The bus was busy.  Retry. */
+			printk(KERN_WARNING
+			       "%s #%d: Could not stop device.  Will retry.\n",
+			       dev->adap.name, dev->index);
+			set_current_state(TASK_INTERRUPTIBLE);
+			schedule_timeout(HZ / 2);
+		}
+	}
+
+	/*
+	 * Now that the Xilinx code isn't using the IRQ or registers,
+	 * unmap the registers and free the IRQ.
+	 */
+	if (dev->remapped) {
+		iounmap((void *)dev->Iic.BaseAddress);
+	}
+
+	if (dev->reqirq) {
+		disable_irq(dev->irq);
+		free_irq(dev->irq, dev);
+	}
+
+	device_remove_file(device, &dev_attr_scan);
+	kfree(dev);
+
+	return 0;
+}
+
+/** Shared device initialization code */
+static int __devinit xilinx_iic_setup(
+				struct device *device,
+				struct device_node *node,
+				struct resource *r_mem,
+				struct resource *r_irq,
+				u32 ten_bit_addr, 
+				u32 gpo_width) {
+
+	XIic_Config xiic_cfg;
+	struct xiic_data *dev;
+	char *scan_results;
+	int error;
+
+	/* Allocate the dev and zero it out. */
+	dev = kmalloc(sizeof(struct xiic_data), GFP_KERNEL);
+	if (!dev) {
+		dev_err(device, "Cannot allocate struct xiic_data\n");
+		error = -ENOMEM;
+		goto out2;
+	}
+	memset(dev, 0, sizeof(struct xiic_data));
+
+	dev_set_drvdata(device, dev);
+
+	dev->irq = r_irq->start;
+
+	/* initialize fields to satisfy i2c  */
+	dev->index = 0;
+
+	init_completion(&dev->complete);
+
+	memset(&xiic_cfg, 0, sizeof(XIic_Config));
+	xiic_cfg.DeviceId = 0;
+
+	/* Change the addresses to be virtual; save the old ones to restore. */
+	dev->base = r_mem->start;
+	xiic_cfg.BaseAddress =
+	    (u32) ioremap(r_mem->start, r_mem->end - r_mem->start + 1);
+
+	dev->remapped = 1;
+	down(&cfg_sem);
+
+	xiic_cfg.Has10BitAddr = (int)ten_bit_addr;
+	xiic_cfg.GpOutWidth = (u8)gpo_width;
+
+	/* Tell the Xilinx code to bring this IIC interface up. */
+	if (XIic_CfgInitialize(&dev->Iic, &xiic_cfg, xiic_cfg.BaseAddress) !=
+	    XST_SUCCESS) {
+		up(&cfg_sem);
+		dev_err(device, "could not initialize device.\n");
+		error = -ENODEV;
+		goto out;
+	}
+	up(&cfg_sem);
+	XIic_SetRecvHandler(&dev->Iic, (void *)dev, RecvHandler);
+	XIic_SetSendHandler(&dev->Iic, (void *)dev, SendHandler);
+	XIic_SetStatusHandler(&dev->Iic, (void *)dev, StatusHandler);
+
+	/* Grab the IRQ */
+	error = request_irq(dev->irq, xiic_interrupt, 0, dev->adap.name, dev);
+	if (error) {
+		dev_err(device, "could not allocate interrupt %d.\n", dev->irq);
+		goto out;
+	}
+	dev->reqirq = 1;
+
+	if (XIic_Start(&dev->Iic) != XST_SUCCESS) {
+		dev_err(device, "could not start device\n");
+		error = -ENODEV;
+		goto out;
+	}
+	dev->started = 1;
+
+	/* Now tell the core I2C code about our new device. */
+	/*
+	 * SAATODO: Get a real ID (perhaps I2C_HW_XILINX) after
+	 * initial release.  Will need to email lm78@stimpy.netroedge.com
+	 * per http://www2.lm-sensors.nu/~lm78/support.html
+	 */
+	dev->adap.id = 0;
+	dev->adap.algo = &xiic_algo;
+	dev->adap.algo_data = NULL;
+	dev->adap.timeout = XIIC_TIMEOUT;
+	dev->adap.retries = XIIC_RETRY;
+	error = i2c_add_adapter(&dev->adap);
+
+	if (error) {
+		dev_err(device, "could not add i2c adapter\n");
+		goto out;
+	}
+	dev->added = 1;
+
+	printk("%s #%d at 0x%08X mapped to 0x%08X, irq=%d\n",
+	       dev->adap.name, dev->index,
+	       dev->base, (unsigned int)dev->Iic.BaseAddress, dev->irq);
+
+	if (scan) {
+		scan_results = xilinx_iic_do_scan(dev);
+		if (scan_results) {
+			printk(scan_results);
+			kfree(scan_results);
+		}
+	}
+	
+	if (node) {
+		of_register_i2c_devices(&dev->adap, node);
+	}
+
+	error = device_create_file(device, &dev_attr_scan);
+      out:
+	if (error)
+		xilinx_iic_remove(device);
+      out2:
+	return error;
+}
+
+/* Match table for of_platform binding */
+static struct of_device_id __devinitdata xilinx_iic_of_match[] = {
+	{ .compatible = "xlnx,xps-iic-2.00.a", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, xilinx_iic_of_match);
+
+static u32 get_u32(struct of_device *ofdev, const char *s) {
+	u32 *p = (u32 *)of_get_property(ofdev->node, s, NULL);
+	if(p) {
+		return *p;
+	} else {
+		dev_warn(&ofdev->dev, "Parameter %s not found, defaulting to 0.\n", s);
+		return 0;
+	}
+}
+
+static int __devinit xilinx_iic_of_probe(struct of_device *ofdev, const struct of_device_id *match)
+{
+	u32 ten_bit_addr, gpo_width;
+	struct resource r_irq_struct;
+	struct resource r_mem_struct;
+
+	struct resource *r_irq = &r_irq_struct;	/* Interrupt resources */
+	struct resource *r_mem = &r_mem_struct;	/* IO mem resources */
+	int rc = 0;
+
+	printk(KERN_INFO "Device Tree Probing \'%s\'\n",
+                        ofdev->node->name);
+
+	/* Get iospace for the device */
+	rc = of_address_to_resource(ofdev->node, 0, r_mem);
+	if(rc) {
+		dev_warn(&ofdev->dev, "invalid address\n");
+		return rc;
+	}
+
+	/* Get IRQ for the device */
+	rc = of_irq_to_resource(ofdev->node, 0, r_irq);
+	if(rc == NO_IRQ) {
+		dev_warn(&ofdev->dev, "no IRQ found.\n");
+		return rc;
+	}
+
+	ten_bit_addr = get_u32(ofdev, "xlnx,ten-bit-adr");
+	gpo_width = get_u32(ofdev, "xlnx,gpo-width");
+
+        return xilinx_iic_setup(&ofdev->dev, ofdev->node, r_mem, r_irq, ten_bit_addr, gpo_width);
+}
+
+static int __devexit xilinx_iic_of_remove(struct of_device *ofdev)
+{
+	return xilinx_iic_remove(&ofdev->dev);
+}
+
+static struct of_platform_driver xilinx_iic_of_driver = {
+	.name		= "iic",
+	.match_table	= xilinx_iic_of_match,
+	.probe		= xilinx_iic_of_probe,
+	.remove		= __devexit_p(xilinx_iic_of_remove), };
+
+/* Registration helpers to keep the number of #ifdefs to a minimum */
+static inline int __init xilinx_iic_of_register(void)
+{
+	return of_register_platform_driver(&xilinx_iic_of_driver);
+}
+
+static inline void __exit xilinx_iic_of_unregister(void)
+{
+	of_unregister_platform_driver(&xilinx_iic_of_driver);
+}
+
+static int __init xiic_init(void)
+{
+	int ret;
+
+	ret = xilinx_iic_of_register();
+	if (ret) 
+		printk(KERN_ERR "registering iic driver failed: err=%i", ret);
+
+	return ret;
+}
+
+static void __exit xiic_cleanup(void)
+{
+	xilinx_iic_of_unregister();
+}
+
+module_init(xiic_init);
+module_exit(xiic_cleanup);
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/Makefile linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/Makefile
--- linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/Makefile	2010-08-08 17:40:16.483745768 +0200
@@ -0,0 +1,14 @@
+#
+# Makefile for the Xilinx IIC driver
+#
+
+EXTRA_CFLAGS	+= -Idrivers/xilinx_common
+
+obj-$(CONFIG_XILINX_IIC) := xilinx_iic.o
+
+# The Linux adapter for the Xilinx driver code.
+xilinx_iic-objs	:= i2c-algo-xilinx.o
+
+# The Xilinx OS independent code.
+xilinx_iic-objs	+= xiic.o xiic_options.o xiic_master.o \
+		   xiic_intr.o xiic_l.o
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic.c linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic.c
--- linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic.c	2010-08-08 17:40:16.483745768 +0200
@@ -0,0 +1,778 @@
+/* $Id: xiic.c,v 1.1 2007/12/03 15:44:58 meinelte Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002-2006 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xiic.c
+*
+* Contains required functions for the XIic component. See xiic.h for more
+* information on the driver.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- --- ------- -----------------------------------------------
+* 1.01a rfp  10/19/01 release
+* 1.01c ecm  12/05/02 new rev
+* 1.01c rmm  05/14/03 Fixed diab compiler warnings relating to asserts.
+* 1.01d jhl  10/08/03 Added general purpose output feature
+* 1.02a jvb  12/13/05 I changed Initialize() into CfgInitialize(), and made
+*                     CfgInitialize() take a pointer to a config structure
+*                     instead of a device id. I moved Initialize() into
+*                     xgpio_sinit.c, and had Initialize() call CfgInitialize()
+*                     after it retrieved the config structure using the device
+*                     id. I removed include of xparameters.h along with any
+*                     dependencies on xparameters.h and the _g.c config table.
+* 1.02a mta	 03/09/06 Added a new function XIic_IsIicBusy() which returns
+*					  whether IIC Bus is Busy or Free.
+* 1.13a wgr  03/22/07 Converted to new coding style.
+* </pre>
+*
+****************************************************************************/
+
+/***************************** Include Files *******************************/
+
+#include "xiic.h"
+#include "xiic_i.h"
+#include "xio.h"
+
+/************************** Constant Definitions ***************************/
+
+
+/**************************** Type Definitions *****************************/
+
+
+/***************** Macros (Inline Functions) Definitions *******************/
+
+
+/************************** Function Prototypes ****************************/
+
+static void XIic_StubStatusHandler(void *CallBackRef, int ErrorCode);
+
+static void XIic_StubHandler(void *CallBackRef, int ByteCount);
+
+/************************** Variable Definitions **************************/
+
+
+/*****************************************************************************/
+/**
+*
+* Initializes a specific XIic instance.  The initialization entails:
+*
+* - Check the device has an entry in the configuration table.
+* - Initialize the driver to allow access to the device registers and
+*   initialize other subcomponents necessary for the operation of the device.
+* - Default options to:
+*     - 7-bit slave addressing
+*     - Send messages as a slave device
+*     - Repeated start off
+*     - General call recognition disabled
+* - Clear messageing and error statistics
+*
+* The XIic_Start() function must be called after this function before the device
+* is ready to send and receive data on the IIC bus.
+*
+* Before XIic_Start() is called, the interrupt control must connect the ISR
+* routine to the interrupt handler. This is done by the user, and not
+* XIic_Start() to allow the user to use an interrupt controller of their choice.
+*
+* @param InstancePtr is a pointer to the XIic instance to be worked on.
+* @param Config is a reference to a structure containing information about
+*        a specific IIC device. This function initializes an InstancePtr object
+*        for a specific device specified by the contents of Config. This
+*        function can initialize multiple instance objects with the use of
+*        multiple calls giving different Config information on each call.
+* @param EffectiveAddr is the device base address in the virtual memory address
+*        space. The caller is responsible for keeping the address mapping
+*        from EffectiveAddr to the device physical base address unchanged
+*        once this function is invoked. Unexpected errors may occur if the
+*        address mapping changes after this function is called. If address
+*        translation is not used, use Config->BaseAddress for this parameters,
+*        passing the physical address instead.
+*
+* @return
+*
+* - XST_SUCCESS when successful
+* - XST_DEVICE_IS_STARTED indicates the device is started (i.e. interrupts
+*   enabled and messaging is possible). Must stop before re-initialization
+*   is allowed.
+*
+* @note
+*
+* None.
+*
+****************************************************************************/
+int XIic_CfgInitialize(XIic * InstancePtr, XIic_Config * Config,
+		       u32 EffectiveAddr)
+{
+	/*
+	 * Asserts test the validity of selected input arguments.
+	 */
+	XASSERT_NONVOID(InstancePtr != NULL);
+
+	InstancePtr->IsReady = 0;
+
+	/*
+	 * If the device is started, disallow the initialize and return a Status
+	 * indicating it is started.  This allows the user to stop the device
+	 * and reinitialize, but prevents a user from inadvertently initializing
+	 */
+	if (InstancePtr->IsStarted == XCOMPONENT_IS_STARTED) {
+		return XST_DEVICE_IS_STARTED;
+	}
+
+	/*
+	 * Set default values and configuration data, including setting the
+	 * callback handlers to stubs  so the system will not crash should the
+	 * application not assign its own callbacks.
+	 */
+	InstancePtr->IsStarted = 0;
+	InstancePtr->BaseAddress = EffectiveAddr;
+	InstancePtr->RecvHandler = XIic_StubHandler;
+	InstancePtr->RecvBufferPtr = NULL;
+	InstancePtr->SendHandler = XIic_StubHandler;
+	InstancePtr->SendBufferPtr = NULL;
+	InstancePtr->StatusHandler = XIic_StubStatusHandler;
+	InstancePtr->Has10BitAddr = Config->Has10BitAddr;
+	InstancePtr->IsReady = XCOMPONENT_IS_READY;
+	InstancePtr->Options = 0;
+	InstancePtr->BNBOnly = FALSE;
+	InstancePtr->GpOutWidth = Config->GpOutWidth;
+	InstancePtr->IsDynamic = FALSE;
+
+	/*
+	 * Reset the device so it's in the reset state, this must be after the
+	 * IPIF is initialized since it resets thru the IPIF and clear the stats
+	 */
+	XIic_Reset(InstancePtr);
+
+	XIIC_CLEAR_STATS(InstancePtr);
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************/
+/**
+*
+* This function starts the IIC device and driver by enabling the proper
+* interrupts such that data may be sent and received on the IIC bus.
+* This function must be called before the functions to send and receive data.
+*
+* Before XIic_Start() is called, the interrupt control must connect the ISR
+* routine to the interrupt handler. This is done by the user, and not
+* XIic_Start() to allow the user to use an interrupt controller of their choice.
+*
+* Start enables:
+*  - IIC device
+*  - Interrupts:
+*     - Addressed as slave to allow messages from another master
+*     - Arbitration Lost to detect Tx arbitration errors
+*     - Global IIC interrupt within the IPIF interface
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @return
+*
+* XST_SUCCESS always
+*
+* @note
+*
+* The device interrupt is connected to the interrupt controller, but no
+* "messaging" interrupts are enabled. Addressed as Slave is enabled to
+* reception of messages when this devices address is written to the bus.
+* The correct messaging interrupts are enabled when sending or receiving
+* via the IicSend() and IicRecv() functions. No action is required
+* by the user to control any IIC interrupts as the driver completely
+* manages all 8 interrupts. Start and Stop control the ability
+* to use the device. Stopping the device completely stops all device
+* interrupts from the processor.
+*
+****************************************************************************/
+int XIic_Start(XIic * InstancePtr)
+{
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/*
+	 * Mask off all interrupts, each is enabled when needed.
+	 */
+	XIIC_WRITE_IIER(InstancePtr->BaseAddress, 0);
+
+	/*
+	 * Clear all interrupts by reading and rewriting exact value back.
+	 * Only those bits set will get written as 1 (writing 1 clears intr)
+	 */
+	XIic_mClearIntr(InstancePtr->BaseAddress, 0xFFFFFFFF);
+
+	/*
+	 * Enable the device
+	 */
+	XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET,
+		 XIIC_CR_ENABLE_DEVICE_MASK);
+	/*
+	 * Set Rx FIFO Occupancy depth to throttle at first byte(after reset = 0)
+	 */
+	XIo_Out8(InstancePtr->BaseAddress + XIIC_RFD_REG_OFFSET, 0);
+
+	/*
+	 * Clear and enable the interrupts needed
+	 */
+	XIic_mClearEnableIntr(InstancePtr->BaseAddress,
+			      XIIC_INTR_AAS_MASK | XIIC_INTR_ARB_LOST_MASK);
+
+	InstancePtr->IsStarted = XCOMPONENT_IS_STARTED;
+	InstancePtr->IsDynamic = FALSE;
+
+	/* Enable all interrupts by the global enable in the IPIF */
+
+	XIIC_GINTR_ENABLE(InstancePtr->BaseAddress);
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************/
+/**
+*
+* This function stops the IIC device and driver such that data is no longer
+* sent or received on the IIC bus. This function stops the device by
+* disabling interrupts. This function only disables interrupts within the
+* device such that the caller is responsible for disconnecting the interrupt
+* handler of the device from the interrupt source and disabling interrupts
+* at other levels.
+*
+* Due to bus throttling that could hold the bus between messages when using
+* repeated start option, stop will not occur when the device is actively
+* sending or receiving data from the IIC bus or the bus is being throttled
+* by this device, but instead return XST_IIC_BUS_BUSY.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @return
+*
+* - XST_SUCCESS indicates all IIC interrupts are disabled. No messages can
+*   be received or transmitted until XIic_Start() is called.
+* - XST_IIC_BUS_BUSY indicates this device is currently engaged in message
+*   traffic and cannot be stopped.
+*
+* @note
+*
+* None.
+*
+****************************************************************************/
+int XIic_Stop(XIic * InstancePtr)
+{
+	u8 Status;
+	u8 CntlReg;
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+
+	/*
+	 * Disable all interrupts globally using the IPIF
+	 */
+	XIIC_GINTR_DISABLE(InstancePtr->BaseAddress);
+
+	CntlReg = XIo_In8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET);
+	Status = XIo_In8(InstancePtr->BaseAddress + XIIC_SR_REG_OFFSET);
+
+	if ((CntlReg & XIIC_CR_MSMS_MASK) ||
+	    (Status & XIIC_SR_ADDR_AS_SLAVE_MASK)) {
+		/* when this device is using the bus
+		 * - re-enable interrupts to finish current messaging
+		 * - return bus busy
+		 */
+		XIIC_GINTR_ENABLE(InstancePtr->BaseAddress);
+
+		return XST_IIC_BUS_BUSY;
+	}
+
+	InstancePtr->IsStarted = 0;
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************/
+/**
+*
+* Resets the IIC device. Reset must only be called after the driver has been
+* initialized. The configuration after this reset is as follows:
+*   - Repeated start is disabled
+*   - General call is disabled
+*
+* The upper layer software is responsible for initializing and re-configuring
+* (if necessary) and restarting the IIC device after the reset.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+* @internal
+*
+* The reset is accomplished by setting the IPIF reset register.  This takes
+* care of resetting all IPIF hardware blocks, including the IIC device.
+*
+****************************************************************************/
+void XIic_Reset(XIic * InstancePtr)
+{
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	XIIC_RESET(InstancePtr->BaseAddress);
+}
+
+/*****************************************************************************/
+/**
+*
+* This function sets the bus addresses. The addresses include the device
+* address that the device responds to as a slave, or the slave address
+* to communicate with on the bus.  The IIC device hardware is built to
+* allow either 7 or 10 bit slave addressing only at build time rather
+* than at run time. When this device is a master, slave addressing can
+* be selected at run time to match addressing modes for other bus devices.
+*
+* Addresses are represented as hex values with no adjustment for the data
+* direction bit as the software manages address bit placement.
+* Example: For a 7 address written to the device of 1010 011X where X is
+* the transfer direction (send/recv), the address parameter for this function
+* needs to be 01010011 or 0x53 where the correct bit alllignment will be
+* handled for 7 as well as 10 bit devices. This is especially important as
+* the bit placement is not handled the same depending on which options are
+* used such as repeated start.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+* @param    AddressType indicates which address is being modified; the address
+*           which this device responds to on the IIC bus as a slave, or the
+*           slave address to communicate with when this device is a master. One
+*           of the following values must be contained in this argument.
+* <pre>
+*   XII_ADDRESS_TO_SEND         Slave being addressed by a this master
+*   XII_ADDRESS_TO_RESPOND      Address to respond to as a slave device
+* </pre>
+* @param    Address contains the address to be set; 7 bit or 10 bit address.
+*           A ten bit address must be within the range: 0 - 1023 and a 7 bit
+*           address must be within the range 0 - 127.
+*
+* @return
+*
+* XST_SUCCESS is returned if the address was successfully set, otherwise one
+* of the following errors is returned.
+* - XST_IIC_NO_10_BIT_ADDRESSING indicates only 7 bit addressing supported.
+* - XST_INVALID_PARAM indicates an invalid parameter was specified.
+*
+* @note
+*
+* Upper bits of 10-bit address is written only when current device is built
+* as a ten bit device.
+*
+****************************************************************************/
+int XIic_SetAddress(XIic * InstancePtr, int AddressType, int Address)
+{
+	u8 SendAddr;
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(Address < 1023);
+
+	/* Set address to respond to for this device into address registers */
+
+	if (AddressType == XII_ADDR_TO_RESPOND_TYPE) {
+		SendAddr = (u8) ((Address & 0x007F) << 1);	/* Addr in upper 7 bits */
+		XIo_Out8(InstancePtr->BaseAddress + XIIC_ADR_REG_OFFSET,
+			 SendAddr);
+
+		if (InstancePtr->Has10BitAddr == TRUE) {
+			/* Write upper 3 bits of addr to DTR only when 10 bit option
+			 * included in design i.e. register exists
+			 */
+			SendAddr = (u8) ((Address & 0x0380) >> 7);
+			XIo_Out8(InstancePtr->BaseAddress + XIIC_TBA_REG_OFFSET,
+				 SendAddr);
+		}
+
+		return XST_SUCCESS;
+	}
+
+	/* Store address of slave device being read from */
+
+	if (AddressType == XII_ADDR_TO_SEND_TYPE) {
+		InstancePtr->AddrOfSlave = Address;
+		return XST_SUCCESS;
+	}
+
+	return XST_INVALID_PARAM;
+}
+
+/*****************************************************************************/
+/**
+*
+* This function gets the addresses for the IIC device driver. The addresses
+* include the device address that the device responds to as a slave, or the
+* slave address to communicate with on the bus. The address returned has the
+* same format whether 7 or 10 bits.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+* @param    AddressType indicates which address, the address which this
+*           responds to on the IIC bus as a slave, or the slave address to
+*           communicate with when this device is a master. One of the following
+*           values must be contained in this argument.
+* <pre>
+*   XII_ADDRESS_TO_SEND_TYPE         slave being addressed as a master
+*   XII_ADDRESS_TO_RESPOND_TYPE      slave address to respond to as a slave
+* </pre>
+*  If neither of the two valid arguments are used, the function returns
+*  the address of the slave device
+*
+* @return
+*
+* The address retrieved.
+*
+* @note
+*
+* None.
+*
+****************************************************************************/
+u16 XIic_GetAddress(XIic * InstancePtr, int AddressType)
+{
+	u8 LowAddr;
+	u16 HighAddr = 0;
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+
+	/* return this devices address */
+
+	if (AddressType == XII_ADDR_TO_RESPOND_TYPE) {
+
+		LowAddr =
+			XIo_In8(InstancePtr->BaseAddress + XIIC_ADR_REG_OFFSET);
+
+		if (InstancePtr->Has10BitAddr == TRUE) {
+			HighAddr = (u16) XIo_In8(InstancePtr->BaseAddress +
+						 XIIC_TBA_REG_OFFSET);
+		}
+		return ((HighAddr << 8) & (u16) LowAddr);
+	}
+
+	/* Otherwise return address of slave device on the IIC bus */
+
+	return InstancePtr->AddrOfSlave;
+}
+
+/*****************************************************************************/
+/**
+*
+* This function sets the contents of the General Purpose Output register
+* for the IIC device driver. Note that the number of bits in this register is
+* parameterizable in the hardware such that it may not exist.  This function
+* checks to ensure that it does exist to prevent bus errors, but does not
+* ensure that the number of bits in the register are sufficient for the
+* value being written (won't cause a bus error).
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @param    OutputValue contains the value to be written to the register.
+*
+* @return
+*
+* A value indicating success, XST_SUCCESS, or XST_NO_FEATURE if the hardware
+* is configured such that this register does not contain any bits to read
+* or write.
+*
+* @note
+*
+* None.
+*
+****************************************************************************/
+int XIic_SetGpOutput(XIic * InstancePtr, u8 OutputValue)
+{
+	XASSERT_NONVOID(InstancePtr != NULL);
+
+	/* If the general purpose output register is implemented by the hardware
+	 * then write the specified value to it, otherwise indicate an error
+	 */
+	if (InstancePtr->GpOutWidth > 0) {
+		XIic_mWriteReg(InstancePtr->BaseAddress, XIIC_GPO_REG_OFFSET,
+			       OutputValue);
+		return XST_SUCCESS;
+	}
+	else {
+		return XST_NO_FEATURE;
+	}
+}
+
+
+/*****************************************************************************/
+/**
+*
+* This function gets the contents of the General Purpose Output register
+* for the IIC device driver. Note that the number of bits in this register is
+* parameterizable in the hardware such that it may not exist.  This function
+* checks to ensure that it does exist to prevent bus errors.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @param    OutputValuePtr contains the value which was read from the
+*           register.
+*
+* @return
+*
+* A value indicating success, XST_SUCCESS, or XST_NO_FEATURE if the hardware
+* is configured such that this register does not contain any bits to read
+* or write.
+*
+* The OutputValuePtr is also an output as it contains the value read.
+*
+* @note
+*
+* None.
+*
+****************************************************************************/
+int XIic_GetGpOutput(XIic * InstancePtr, u8 *OutputValuePtr)
+{
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(OutputValuePtr != NULL);
+
+	/* If the general purpose output register is implemented by the hardware
+	 * then read the value from it, otherwise indicate an error
+	 */
+	if (InstancePtr->GpOutWidth > 0) {
+		*OutputValuePtr = XIic_mReadReg(InstancePtr->BaseAddress,
+						XIIC_GPO_REG_OFFSET);
+		return XST_SUCCESS;
+	}
+	else {
+		return XST_NO_FEATURE;
+	}
+}
+
+/*****************************************************************************/
+/**
+*
+* A function to determine if the device is currently addressed as a slave
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @return
+*
+* TRUE if the device is addressed as slave, and FALSE otherwise.
+*
+* @note
+*
+* None.
+*
+****************************************************************************/
+u32 XIic_IsSlave(XIic * InstancePtr)
+{
+	XASSERT_NONVOID(InstancePtr != NULL);
+
+	if ((XIo_In8(InstancePtr->BaseAddress + XIIC_SR_REG_OFFSET) &
+	     XIIC_SR_ADDR_AS_SLAVE_MASK) == 0) {
+		return FALSE;
+	}
+	return TRUE;
+}
+
+/*****************************************************************************/
+/**
+*
+* Sets the receive callback function, the receive handler, which the driver
+* calls when it finishes receiving data. The number of bytes used to signal
+* when the receive is complete is the number of bytes set in the XIic_Recv
+* function.
+*
+* The handler executes in an interrupt context such that it must minimize
+* the amount of processing performed such as transferring data to a thread
+* context.
+*
+* The number of bytes received is passed to the handler as an argument.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+* @param    CallBackRef is the upper layer callback reference passed back when
+*           the callback function is invoked.
+* @param    FuncPtr is the pointer to the callback function.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* The handler is called within interrupt context ...
+*
+****************************************************************************/
+void XIic_SetRecvHandler(XIic * InstancePtr, void *CallBackRef,
+			 XIic_Handler FuncPtr)
+{
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(FuncPtr != NULL);
+
+	InstancePtr->RecvHandler = FuncPtr;
+	InstancePtr->RecvCallBackRef = CallBackRef;
+}
+
+/*****************************************************************************/
+/**
+*
+* Sets the send callback function, the send handler, which the driver calls when
+* it receives confirmation of sent data. The handler executes in an interrupt
+* context such that it must minimize the amount of processing performed such
+* as transferring data to a thread context.
+*
+* @param    InstancePtr the pointer to the XIic instance to be worked on.
+* @param    CallBackRef the upper layer callback reference passed back when
+*           the callback function is invoked.
+* @param    FuncPtr the pointer to the callback function.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* The handler is called within interrupt context ...
+*
+****************************************************************************/
+void XIic_SetSendHandler(XIic * InstancePtr, void *CallBackRef,
+			 XIic_Handler FuncPtr)
+{
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	XASSERT_VOID(FuncPtr != NULL);
+
+	InstancePtr->SendHandler = FuncPtr;
+	InstancePtr->SendCallBackRef = CallBackRef;
+}
+
+/*****************************************************************************/
+/**
+*
+* Sets the status callback function, the status handler, which the driver calls
+* when it encounters conditions which are not data related. The handler
+* executes in an interrupt context such that it must minimize the amount of
+* processing performed such as transferring data to a thread context. The
+* status events that can be returned are described in xiic.h.
+*
+* @param    InstancePtr points to the XIic instance to be worked on.
+* @param    CallBackRef is the upper layer callback reference passed back when
+*           the callback function is invoked.
+* @param    FuncPtr is the pointer to the callback function.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* The handler is called within interrupt context ...
+*
+****************************************************************************/
+void XIic_SetStatusHandler(XIic * InstancePtr, void *CallBackRef,
+			   XIic_StatusHandler FuncPtr)
+{
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	XASSERT_VOID(FuncPtr != NULL);
+
+	InstancePtr->StatusHandler = FuncPtr;
+	InstancePtr->StatusCallBackRef = CallBackRef;
+}
+
+/*****************************************************************************
+*
+* This is a stub for the send and recv callbacks. The stub is here in case the
+* upper layers forget to set the handlers.
+*
+* @param    CallBackRef is a pointer to the upper layer callback reference
+* @param    ByteCount is the number of bytes sent or received
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+static void XIic_StubHandler(void *CallBackRef, int ByteCount)
+{
+	XASSERT_VOID_ALWAYS();
+}
+
+/*****************************************************************************
+*
+* This is a stub for the asynchronous error callback. The stub is here in case
+* the upper layers forget to set the handler.
+*
+* @param    CallBackRef is a pointer to the upper layer callback reference
+* @param    ErrorCode is the Xilinx error code, indicating the cause of the error
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+static void XIic_StubStatusHandler(void *CallBackRef, int ErrorCode)
+{
+	XASSERT_VOID_ALWAYS();
+}
+
+/*****************************************************************************
+*
+* This is a function which tells whether Bus is Busy or free.
+*
+* @param    InstancePtr points to the XIic instance to be worked on.
+*
+* @return  TRUE if Bus is Busy else FALSE
+*
+* @note    None.
+*
+******************************************************************************/
+u32 XIic_IsIicBusy(XIic * InstancePtr)
+{
+	u8 StatusReg;
+
+	StatusReg = XIic_mReadReg(InstancePtr->BaseAddress, XIIC_SR_REG_OFFSET);
+	if (StatusReg & XIIC_SR_BUS_BUSY_MASK) {
+		return TRUE;
+	}
+	else {
+		return FALSE;
+	}
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic.h linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic.h
--- linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic.h	2010-08-08 17:40:16.483745768 +0200
@@ -0,0 +1,527 @@
+/* $Id: xiic.h,v 1.3 2007/12/17 19:15:38 meinelte Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*      (c) Copyright 2002-2007 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xiic.h
+*
+* XIic is the driver for an IIC master or slave device.
+*
+* In order to reduce the memory requirements of the driver the driver is
+* partitioned such that there are optional parts of the driver.
+* Slave, master, and multimaster features are optional such that all these files
+* are not required at the same time.
+* In order to use the slave and multimaster features of the driver, the user
+* must call functions (XIic_SlaveInclude and XIic_MultiMasterInclude)
+* to dynamically include the code. These functions may be called at any time.
+*
+* Two sets of higher level API's are available in the XIic driver that can
+* be used for Transmission/Reception in Master mode :
+* - XIic_MasterSend()/ XIic_MasterRecv() which is used in normal mode.
+* - XIic_DynMasterSend()/XIic_DynMasterRecv() which is used in Dynamic mode.
+*
+* Similarly two sets of lower level API's are available in XIic driver that
+* can be used for Transmission/Reception in Master mode:
+* - XIic_Send()/XIic_Recv() which is used in normal mode
+* - XIic_DynSend()/XIic_DynRecv() which is used in Dynamic mode.
+*
+* The user should use a single set of APIs as per his requirement and
+* should not intermix them.
+*
+* All the driver APIs can be used for read, write and  combined mode of
+* operations on the IIC bus.
+*
+* In the normal mode IIC support both 7-bit and 10-bit addressing, and in
+* the dynamic mode support only 7-bit addressing.
+*
+* <b>Initialization & Configuration</b>
+*
+* The XIic_Config structure is used by the driver to configure itself. This
+* configuration structure is typically created by the tool-chain based on HW
+* build properties.
+*
+* To support multiple runtime loading and initialization strategies employed
+* by various operating systems, the driver instance can be initialized in one
+* of the following ways:
+*
+*   - XIic_Initialize(InstancePtr, DeviceId) - The driver looks up its own
+*     configuration structure created by the tool-chain based on an ID provided
+*     by the tool-chain.
+*
+*   - XIic_CfgInitialize(InstancePtr, CfgPtr, EffectiveAddr) - Uses a
+*     configuration structure provided by the caller. If running in a system
+*     with address translation, the provided virtual memory base address
+*     replaces the physical address present in the configuration structure.
+*
+* <b>General Purpose Output</b>
+* The IIC hardware provides a General Purpose Output Register that allows the
+* user to connect general purpose outputs to devices, such as a write protect,
+* for an EEPROM. This register is parameterizable in the hardware such that
+* there could be zero bits in this register and in this case it will cause
+* a bus error if read or written.
+*
+* <b>Bus Throttling</b>
+*
+* The IIC hardware provides bus throttling which allows either the device, as
+* either a master or a slave, to stop the clock on the IIC bus. This feature
+* allows the software to perform the appropriate processing for each interrupt
+* without an unreasonable response restriction.  With this design, it is
+* important for the user to understand the implications of bus throttling.
+*
+* <b>Repeated Start</b>
+*
+* An application can send multiple messages, as a master, to a slave device
+* and re-acquire the IIC bus each time a message is sent. The repeated start
+* option allows the application to send multiple messages without re-acquiring
+* the IIC bus for each message. The transactions involving repeated start
+* are also called combined transfers if there is Read and Write in the
+* same transaction.
+*
+* The repeated start feature works with all the API's in XIic driver.
+*
+* The Repeated Start feature also could cause the application to lock up, or
+* monopolize the IIC bus, should repeated start option be enabled and sequences
+* of messages never end(periodic data collection).
+* Also when repeated start is not disable before the last master message is
+* sent or received, will leave the bus captive to the master, but unused.
+*
+* <b>Addressing</b>
+*
+* The IIC hardware is parameterized such that it can be built for 7 or 10
+* bit addresses. The driver provides the ability to control which address
+* size is sent in messages as a master to a slave device.  The address size
+* which the hardware responds to as a slave is parameterized as 7 or 10 bits
+* but fixed by the hardware build.
+*
+* Addresses are represented as hex values with no adjustment for the data
+* direction bit as the software manages address bit placement. This is
+* especially important as the bit placement is not handled the same depending
+* on which options are used such as repeated start and 7 vs 10 bit addessing.
+*
+* <b>Data Rates</b>
+*
+* The IIC hardware is parameterized such that it can be built to support
+* data rates from DC to 400KBit. The frequency of the interrupts which
+* occur is proportional to the data rate.
+*
+* <b>Polled Mode Operation</b>
+*
+* This driver does not provide a polled mode of operation primarily because
+* polled mode which is non-blocking is difficult with the amount of
+* interaction with the hardware that is necessary.
+*
+* <b>Interrupts</b>
+*
+* The device has many interrupts which allow IIC data transactions as well
+* as bus status processing to occur.
+*
+* The interrupts are divided into two types, data and status. Data interrupts
+* indicate data has been received or transmitted while the status interrupts
+* indicate the status of the IIC bus. Some of the interrupts, such as Not
+* Addressed As Slave and Bus Not Busy, are only used when these specific
+* events must be recognized as opposed to being enabled at all times.
+*
+* Many of the interrupts are not a single event in that they are continuously
+* present such that they must be disabled after recognition or when undesired.
+* Some of these interrupts, which are data related, may be acknowledged by the
+* software by reading or writing data to the appropriate register, or must
+* be disabled. The following interrupts can be continuous rather than single
+* events.
+*   - Data Transmit Register Empty/Transmit FIFO Empty
+*   - Data Receive Register Full/Receive FIFO
+*   - Transmit FIFO Half Empty
+*   - Bus Not Busy
+*   - Addressed As Slave
+*   - Not Addressed As Slave
+*
+* The following interrupts are not passed directly to the application thru the
+* status callback.  These are only used internally for the driver processing
+* and may result in the receive and send handlers being called to indicate
+* completion of an operation.  The following interrupts are data related
+* rather than status.
+*   - Data Transmit Register Empty/Transmit FIFO Empty
+*   - Data Receive Register Full/Receive FIFO
+*   - Transmit FIFO Half Empty
+*   - Slave Transmit Complete
+*
+* <b>Interrupt To Event Mapping</b>
+*
+* The following table provides a mapping of the interrupts to the events which
+* are passed to the status handler and the intended role (master or slave) for
+* the event.  Some interrupts can cause multiple events which are combined
+* together into a single status event such as XII_MASTER_WRITE_EVENT and
+* XII_GENERAL_CALL_EVENT
+* <pre>
+* Interrupt                         Event(s)                     Role
+*
+* Arbitration Lost Interrupt        XII_ARB_LOST_EVENT            Master
+* Transmit Error                    XII_SLAVE_NO_ACK_EVENT        Master
+* IIC Bus Not Busy                  XII_BUS_NOT_BUSY_EVENT        Master
+* Addressed As Slave                XII_MASTER_READ_EVENT,        Slave
+*                                   XII_MASTER_WRITE_EVENT,       Slave
+*                                   XII_GENERAL_CALL_EVENT        Slave
+* </pre>
+* <b>Not Addressed As Slave Interrupt</b>
+*
+* The Not Addressed As Slave interrupt is not passed directly to the
+* application thru the status callback.  It is used to determine the end of
+* a message being received by a slave when there was no stop condition
+* (repeated start).  It will cause the receive handler to be called to
+* indicate completion of the operation.
+*
+* <b>RTOS Independence</b>
+*
+* This driver is intended to be RTOS and processor independent.  It works
+* with physical addresses only.  Any needs for dynamic memory management,
+* threads or thread mutual exclusion, virtual memory, or cache control must
+* be satisfied by the layer above this driver.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 1.01a rfp  10/19/01 release
+* 1.01c ecm  12/05/02 new rev
+* 1.01d jhl  10/08/03 Added general purpose output feature
+* 1.01d sv   05/09/05 Changed the data being written to the Address/Control
+*                     Register and removed the code for testing the
+*                     Receive Data Register in XIic_SelfTest function of
+*                     xiic_selftest.c source file
+* 1.02a jvb  12/14/05 I separated dependency on the static config table and
+*                     xparameters.h from the driver initialization by moving
+*                     _Initialize and _LookupConfig to _sinit.c. I also added
+*                     the new _CfgInitialize routine.
+* 1.02a mta  03/09/06 Added a new function XIic_IsIicBusy() which returns
+*					  whether IIC Bus is Busy or Free.
+* 1.02a mta  03/09/06 Implemented Repeated Start in the Low Level Driver.
+* 1.03a mta  07/17/06 Added files to support Dynamic IIC controller in High
+*		      level driver. Added xiic_dyn_master.c. Added support
+* 		      for IIC Dynamic controller in Low level driver in xiic_l.c
+* 1.13a wgr  03/22/07 Converted to new coding style.
+* 1.13b ecm  11/29/07 added BB polling loops to the DynSend and DynRecv
+*					  routines to handle the race condition with BNB in IISR.
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XIIC_H			/* prevent circular inclusions */
+#define XIIC_H			/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xstatus.h"
+#include "xiic_l.h"
+
+/************************** Constant Definitions *****************************/
+
+/** @name Configuration options
+ *
+ * The following options may be specified or retrieved for the device and
+ * enable/disable additional features of the IIC bus.  Each of the options
+ * are bit fields such that more than one may be specified.
+ * @{
+ */
+/**
+ * <pre>
+ * XII_GENERAL_CALL_OPTION      The general call option allows an IIC slave to
+ *                              recognized the general call address. The status
+ *                              handler is called as usual indicating the device
+ *                              has been addressed as a slave with a general
+ *                              call. It is the application's responsibility to
+ *                              perform any special processing for the general
+ *                              call.
+ *
+ * XII_REPEATED_START_OPTION    The repeated start option allows multiple
+ *                              messages to be sent/received on the IIC bus
+ *                              without rearbitrating for the bus.  The messages
+ *                              are sent as a series of messages such that the
+ *                              option must be enabled before the 1st message of
+ *                              the series, to prevent an stop condition from
+ *                              being generated on the bus, and disabled before
+ *                              the last message of the series, to allow the
+ *                              stop condition to be generated.
+ *
+ * XII_SEND_10_BIT_OPTION       The send 10 bit option allows 10 bit addresses
+ *                              to be sent on the bus when the device is a
+ *                              master. The device can be configured to respond
+ *                              as to 7 bit addresses even though it may be
+ *                              communicating with other devices that support 10
+ *                              bit addresses.  When this option is not enabled,
+ *                              only 7 bit addresses are sent on the bus.
+ *
+ * </pre>
+ */
+#define XII_GENERAL_CALL_OPTION    0x00000001
+#define XII_REPEATED_START_OPTION  0x00000002
+#define XII_SEND_10_BIT_OPTION     0x00000004
+
+/*@}*/
+
+/** @name Status events
+ *
+ * The following status events occur during IIC bus processing and are passed
+ * to the status callback. Each event is only valid during the appropriate
+ * processing of the IIC bus. Each of these events are bit fields such that
+ * more than one may be specified.
+ * @{
+ */
+/**
+ * <pre>
+ *   XII_BUS_NOT_BUSY_EVENT      bus transitioned to not busy
+ *   XII_ARB_LOST_EVENT          arbitration was lost
+ *   XII_SLAVE_NO_ACK_EVENT      slave did not acknowledge data (had error)
+ *   XII_MASTER_READ_EVENT       master reading from slave
+ *   XII_MASTER_WRITE_EVENT      master writing to slave
+ *   XII_GENERAL_CALL_EVENT      general call to all slaves
+ * </pre>
+ */
+#define XII_BUS_NOT_BUSY_EVENT   0x00000001
+#define XII_ARB_LOST_EVENT       0x00000002
+#define XII_SLAVE_NO_ACK_EVENT   0x00000004
+#define XII_MASTER_READ_EVENT    0x00000008
+#define XII_MASTER_WRITE_EVENT   0x00000010
+#define XII_GENERAL_CALL_EVENT   0x00000020
+/*@}*/
+
+
+/* The following address types are used when setting and getting the addresses
+ * of the driver. These are mutually exclusive such that only one or the other
+ * may be specified.
+ */
+/** bus address of slave device */
+#define XII_ADDR_TO_SEND_TYPE       1
+/** this device's bus address when slave */
+#define XII_ADDR_TO_RESPOND_TYPE    2
+
+/**************************** Type Definitions *******************************/
+
+/**
+ * This typedef contains configuration information for the device.
+ */
+typedef struct {
+	u16 DeviceId;	/**< Unique ID  of device */
+	u32 BaseAddress;/**< Device base address */
+	int Has10BitAddr;
+		       /**< does device have 10 bit address decoding */
+	u8 GpOutWidth;	/**< number of bits in general purpose output */
+} XIic_Config;
+
+/**
+ * This callback function data type is defined to handle the asynchronous
+ * processing of sent and received data of the IIC driver.  The application
+ * using this driver is expected to define a handler of this type to support
+ * interrupt driven mode. The handlers are called in an interrupt context such
+ * that minimal processing should be performed. The handler data type is
+ * utilized for both send and receive handlers.
+ *
+ * @param CallBackRef is a callback reference passed in by the upper layer when
+ *        setting the callback functions, and passed back to the upper layer
+ *        when the callback is invoked. Its type is unimportant to the driver
+ *        component, so it is a void pointer.
+ *
+ * @param ByteCount indicates the number of bytes remaining to be sent or
+ *        received.  A value of zero indicates that the requested number of
+ *        bytes were sent or received.
+ */
+typedef void (*XIic_Handler) (void *CallBackRef, int ByteCount);
+
+/**
+ * This callback function data type is defined to handle the asynchronous
+ * processing of status events of the IIC driver.  The application using
+ * this driver is expected to define a handler of this type to support
+ * interrupt driven mode. The handler is called in an interrupt context such
+ * that minimal processing should be performed.
+ *
+ * @param CallBackRef is a callback reference passed in by the upper layer when
+ *        setting the callback functions, and passed back to the upper layer
+ *        when the callback is invoked. Its type is unimportant to the driver
+ *        component, so it is a void pointer.
+ *
+ * @param StatusEvent indicates one or more status events that occurred.  See
+ *        the definition of the status events above.
+ */
+typedef void (*XIic_StatusHandler) (void *CallBackRef, int StatusEvent);
+
+/**
+ * XIic statistics
+ */
+typedef struct {
+	u8 ArbitrationLost;/**< Number of times arbitration was lost */
+	u8 RepeatedStarts; /**< Number of repeated starts */
+	u8 BusBusy;	   /**< Number of times bus busy status returned */
+	u8 RecvBytes;	   /**< Number of bytes received */
+	u8 RecvInterrupts; /**< Number of receive interrupts */
+	u8 SendBytes;	   /**< Number of transmit bytes received */
+	u8 SendInterrupts; /**< Number of transmit interrupts */
+	u8 TxErrors;	   /**< Number of transmit errors (no ack) */
+	u8 IicInterrupts;  /**< Number of IIC (device) interrupts */
+} XIicStats;
+
+
+/**
+ * The XIic driver instance data. The user is required to allocate a
+ * variable of this type for every IIC device in the system. A pointer
+ * to a variable of this type is then passed to the driver API functions.
+ */
+typedef struct {
+	XIicStats Stats;	/* Statistics                              */
+	u32 BaseAddress;	/* Device base address                     */
+	int Has10BitAddr;	/* TRUE when 10 bit addressing in design  */
+	int IsReady;		/* Device is initialized and ready         */
+	int IsStarted;		/* Device has been started                 */
+	int AddrOfSlave;	/* Slave addr writing to                   */
+
+	u32 Options;		/* current operating options               */
+	u8 *SendBufferPtr;	/* Buffer to send (state)                  */
+	u8 *RecvBufferPtr;	/* Buffer to receive (state)               */
+	u8 TxAddrMode;		/* State of Tx Address transmission        */
+	int SendByteCount;	/* Number of data bytes in buffer (state)  */
+	int RecvByteCount;	/* Number of empty bytes in buffer (state) */
+
+	u32 BNBOnly;		/* TRUE when BNB interrupt needs to   */
+	/* call callback  */
+	u8 GpOutWidth;		/* General purpose output width            */
+
+	XIic_StatusHandler StatusHandler;
+	void *StatusCallBackRef;	/* Callback reference for status handler */
+	XIic_Handler RecvHandler;
+	void *RecvCallBackRef;	/* Callback reference for recv handler */
+	XIic_Handler SendHandler;
+	void *SendCallBackRef;	/* Callback reference for send handler */
+	int IsDynamic;
+
+} XIic;
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+/*
+ * Initialization functions in xiic_sinit.c
+ */
+int XIic_Initialize(XIic * InstancePtr, u16 DeviceId);
+XIic_Config *XIic_LookupConfig(u16 DeviceId);
+
+/*
+ * Required functions in xiic.c
+ */
+int XIic_CfgInitialize(XIic * InstancePtr, XIic_Config * Config,
+		       u32 EffectiveAddr);
+
+int XIic_Start(XIic * InstancePtr);
+int XIic_Stop(XIic * InstancePtr);
+
+void XIic_Reset(XIic * InstancePtr);
+
+int XIic_SetAddress(XIic * InstancePtr, int AddressType, int Address);
+u16 XIic_GetAddress(XIic * InstancePtr, int AddressType);
+
+int XIic_SetGpOutput(XIic * InstancePtr, u8 OutputValue);
+int XIic_GetGpOutput(XIic * InstancePtr, u8 *OutputValuePtr);
+
+u32 XIic_IsSlave(XIic * InstancePtr);
+
+void XIic_SetRecvHandler(XIic * InstancePtr, void *CallBackRef,
+			 XIic_Handler FuncPtr);
+void XIic_SetSendHandler(XIic * InstancePtr, void *CallBackRef,
+			 XIic_Handler FuncPtr);
+void XIic_SetStatusHandler(XIic * InstancePtr, void *CallBackRef,
+			   XIic_StatusHandler FuncPtr);
+
+
+/*
+ * Interrupt functions in xiic_intr.c
+ */
+void XIic_InterruptHandler(void *InstancePtr);
+
+/*
+ * Master send and receive functions in normal mode in xiic_master.c
+ */
+int XIic_MasterRecv(XIic * InstancePtr, u8 *RxMsgPtr, int ByteCount);
+int XIic_MasterSend(XIic * InstancePtr, u8 *TxMsgPtr, int ByteCount);
+
+/*
+ * Master send and receive functions in dynamic mode in xiic_master.c
+ */
+int XIic_DynMasterRecv(XIic * InstancePtr, u8 *RxMsgPtr, u8 ByteCount);
+int XIic_DynMasterSend(XIic * InstancePtr, u8 *TxMsgPtr, u8 ByteCount);
+
+/*
+ * Dynamic IIC Core Initialization.
+ */
+int XIic_DynamicInitialize(XIic * InstancePtr);
+
+/*
+ * Slave send and receive functions in xiic_slave.c
+ */
+void XIic_SlaveInclude(void);
+int XIic_SlaveRecv(XIic * InstancePtr, u8 *RxMsgPtr, int ByteCount);
+int XIic_SlaveSend(XIic * InstancePtr, u8 *TxMsgPtr, int ByteCount);
+
+/*
+ * Statistics functions in xiic_stats.c
+ */
+void XIic_GetStats(XIic * InstancePtr, XIicStats * StatsPtr);
+void XIic_ClearStats(XIic * InstancePtr);
+
+/*
+ * Self test functions in xiic_selftest.c
+ */
+int XIic_SelfTest(XIic * InstancePtr);
+
+/*
+ * Bus busy Function in xiic.c
+ */
+u32 XIic_IsIicBusy(XIic * InstancePtr);
+
+/*
+ * Options functions in xiic_options.c
+ */
+void XIic_SetOptions(XIic * InstancePtr, u32 Options);
+u32 XIic_GetOptions(XIic * InstancePtr);
+
+/*
+ * Multi-master functions in xiic_multi_master.c
+ */
+void XIic_MultiMasterInclude(void);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_i.h linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_i.h
--- linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_i.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_i.h	2010-08-08 17:40:16.483745768 +0200
@@ -0,0 +1,425 @@
+/* $Id: xiic_i.h,v 1.1 2007/12/03 15:44:58 meinelte Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002-07 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xiic_i.h
+*
+* This header file contains internal identifiers, which are those shared
+* between XIic components.  The identifiers in this file are not intended for
+* use external to the driver.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 1.01a rfp  10/19/01 release
+* 1.01c ecm  12/05/02 new rev
+* 1.13a wgr  03/22/07 Converted to new coding style.
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XIIC_I_H		/* prevent circular inclusions */
+#define XIIC_I_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xstatus.h"
+#include "xiic.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/******************************************************************************
+*
+* This macro sends the first byte of the address for a 10 bit address during
+* both read and write operations. It takes care of the details to format the
+* address correctly.
+*
+* address = 1111_0xxD   xx = address MSBits
+*                        D = Tx direction = 0 = write
+*
+* @param	SlaveAddress contains the address of the slave to send to.
+* @param	Operation indicates XIIC_READ_OPERATION or XIIC_WRITE_OPERATION
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mSend10BitAddrByte1(u16 SlaveAddress, u8 Operation);
+*
+******************************************************************************/
+#define XIic_mSend10BitAddrByte1(SlaveAddress, Operation)                  \
+{                                                                            \
+    u8 LocalAddr = (u8)((SlaveAddress) >> 7);                        \
+    LocalAddr = (LocalAddr & 0xF6) | 0xF0 | (Operation);                     \
+    XIo_Out8(InstancePtr->BaseAddress + XIIC_DTR_REG_OFFSET, LocalAddr);  \
+}
+
+/******************************************************************************
+*
+* This macro sends the second byte of the address for a 10 bit address during
+* both read and write operations. It takes care of the details to format the
+* address correctly.
+*
+* @param	SlaveAddress contains the address of the slave to send to.
+*
+* @return	None.
+*
+* @note		Signature: void XIic_mSend10BitAddrByte2(u16 SlaveAddress,
+*                                            u8 Operation);
+*
+******************************************************************************/
+#define XIic_mSend10BitAddrByte2(SlaveAddress)                        \
+    XIo_Out8(InstancePtr->BaseAddress + XIIC_DTR_REG_OFFSET,         \
+             (u8)(SlaveAddress));
+
+/******************************************************************************
+*
+* This macro sends the address for a 7 bit address during both read and write
+* operations. It takes care of the details to format the address correctly.
+*
+* @param	SlaveAddress contains the address of the slave to send to.
+* @param	Operation indicates XIIC_READ_OPERATION or XIIC_WRITE_OPERATION
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mSend7BitAddr(u16 SlaveAddress, u8 Operation);
+*
+******************************************************************************/
+#define XIic_mSend7BitAddr(SlaveAddress, Operation)                          \
+{                                                                            \
+    u8 LocalAddr = (u8)(SlaveAddress << 1);                          \
+    LocalAddr = (LocalAddr & 0xFE) | (Operation);                            \
+    XIo_Out8(InstancePtr->BaseAddress + XIIC_DTR_REG_OFFSET, LocalAddr);  \
+}
+
+/******************************************************************************
+*
+* This macro disables the specified interrupts in the Interrupt enable
+* register.  It is non-destructive in that the register is read and only the
+* interrupts specified is changed.
+*
+* @param	BaseAddress is the base address of the IIC device.
+* @param	InterruptMask contains the interrupts to be disabled
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mDisableIntr(u32 BaseAddress, u32 InterruptMask);
+*
+******************************************************************************/
+#define XIic_mDisableIntr(BaseAddress, InterruptMask)           \
+    XIIC_WRITE_IIER((BaseAddress),                        \
+        XIIC_READ_IIER(BaseAddress) & ~(InterruptMask))
+
+/******************************************************************************
+*
+* This macro enables the specified interrupts in the Interrupt enable
+* register.  It is non-destructive in that the register is read and only the
+* interrupts specified is changed.
+*
+* @param	BaseAddress is the base address of the IIC device.
+* @param	InterruptMask contains the interrupts to be disabled
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mEnableIntr(u32 BaseAddress, u32 InterruptMask);
+*
+******************************************************************************/
+#define XIic_mEnableIntr(BaseAddress, InterruptMask)           \
+    XIIC_WRITE_IIER((BaseAddress),                       \
+        XIIC_READ_IIER(BaseAddress) | (InterruptMask))
+
+/******************************************************************************
+*
+* This macro clears the specified interrupt in the Interrupt status
+* register.  It is non-destructive in that the register is read and only the
+* interrupt specified is cleared.  Clearing an interrupt acknowledges it.
+*
+* @param	BaseAddress is the base address of the IIC device.
+* @param	InterruptMask contains the interrupts to be disabled
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mClearIntr(u32 BaseAddress, u32 InterruptMask);
+*
+******************************************************************************/
+#define XIic_mClearIntr(BaseAddress, InterruptMask)                 \
+    XIIC_WRITE_IISR((BaseAddress),                            \
+        XIIC_READ_IISR(BaseAddress) & (InterruptMask))
+
+/******************************************************************************
+*
+* This macro clears and enables the specified interrupt in the Interrupt
+* status and enable registers.  It is non-destructive in that the registers are
+* read and only the interrupt specified is modified.
+* Clearing an interrupt acknowledges it.
+*
+* @param	BaseAddress is the base address of the IIC device.
+* @param	InterruptMask contains the interrupts to be cleared and enabled
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mClearEnableIntr(u32 BaseAddress, u32 InterruptMask);
+*
+******************************************************************************/
+#define XIic_mClearEnableIntr(BaseAddress, InterruptMask)          \
+{                                                                       \
+    XIIC_WRITE_IISR(BaseAddress,                              \
+        (XIIC_READ_IISR(BaseAddress) & (InterruptMask)));     \
+                                                                        \
+    XIIC_WRITE_IIER(BaseAddress,                              \
+        (XIIC_READ_IIER(BaseAddress) | (InterruptMask)));     \
+}
+
+/******************************************************************************
+*
+* This macro flushes the receive FIFO such that all bytes contained within it
+* are discarded.
+*
+* @param	InstancePtr is a pointer to the IIC instance containing the FIFO
+*		to be flushed.
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mFlushRxFifo(XIic *InstancePtr);
+*
+******************************************************************************/
+#define XIic_mFlushRxFifo(InstancePtr)                                     \
+{                                                                           \
+    int LoopCnt;                                                            \
+    u8 Temp;                                                            \
+    u8 BytesToRead = XIo_In8(InstancePtr->BaseAddress +              \
+                                 XIIC_RFO_REG_OFFSET) + 1;                  \
+    for(LoopCnt = 0; LoopCnt < BytesToRead; LoopCnt++)                      \
+    {                                                                       \
+        Temp = XIo_In8(InstancePtr->BaseAddress + XIIC_DRR_REG_OFFSET);  \
+    }                                                                       \
+}
+
+/******************************************************************************
+*
+* This macro flushes the transmit FIFO such that all bytes contained within it
+* are discarded.
+*
+* @param	InstancePtr is a pointer to the IIC instance containing the FIFO
+*		to be flushed.
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mFlushTxFifo(XIic *InstancePtr);
+*
+******************************************************************************/
+#define XIic_mFlushTxFifo(InstancePtr);                                    \
+{                                                                           \
+    u8 CntlReg = XIo_In8(InstancePtr->BaseAddress +                  \
+                             XIIC_CR_REG_OFFSET);                           \
+    XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET,              \
+             CntlReg | XIIC_CR_TX_FIFO_RESET_MASK);                         \
+    XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET, CntlReg);    \
+}
+
+/******************************************************************************
+*
+* This macro reads the next available received byte from the receive FIFO
+* and updates all the data structures to reflect it.
+*
+* @param	InstancePtr is a pointer to the IIC instance to be operated on.
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mReadRecvByte(XIic *InstancePtr);
+*
+******************************************************************************/
+#define XIic_mReadRecvByte(InstancePtr)                                    \
+{                                                                           \
+    *InstancePtr->RecvBufferPtr++ =                                         \
+        XIo_In8(InstancePtr->BaseAddress + XIIC_DRR_REG_OFFSET);         \
+    InstancePtr->RecvByteCount--;                                           \
+    InstancePtr->Stats.RecvBytes++;                                         \
+}
+
+/******************************************************************************
+*
+* This macro writes the next byte to be sent to the transmit FIFO
+* and updates all the data structures to reflect it.
+*
+* @param	InstancePtr is a pointer to the IIC instance to be operated on.
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mWriteSendByte(XIic *InstancePtr);
+*
+******************************************************************************/
+#define XIic_mWriteSendByte(InstancePtr)                                   \
+{                                                                           \
+    XIo_Out8(InstancePtr->BaseAddress + XIIC_DTR_REG_OFFSET,             \
+        *InstancePtr->SendBufferPtr++);                                     \
+    InstancePtr->SendByteCount--;                                           \
+    InstancePtr->Stats.SendBytes++;                                         \
+}
+
+/******************************************************************************
+*
+* This macro sets up the control register for a master receive operation.
+* A write is necessary if a 10 bit operation is being performed.
+*
+* @param	InstancePtr is a pointer to the IIC instance to be operated on.
+* @param	ControlRegister contains the contents of the IIC device control
+*		register
+* @param	ByteCount contains the number of bytes to be received for the
+*		master receive operation
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mSetControlRegister(XIic *InstancePtr,
+*						u8 ControlRegister,
+*						int ByteCount);
+*
+******************************************************************************/
+#define XIic_mSetControlRegister(InstancePtr, ControlRegister, ByteCount)  \
+{                                                                           \
+    (ControlRegister) &= ~(XIIC_CR_NO_ACK_MASK | XIIC_CR_DIR_IS_TX_MASK);   \
+    if (InstancePtr->Options & XII_SEND_10_BIT_OPTION)                      \
+    {                                                                       \
+        (ControlRegister) |= XIIC_CR_DIR_IS_TX_MASK;                        \
+    }                                                                       \
+    else                                                                    \
+    {                                                                       \
+        if ((ByteCount) == 1)                                               \
+        {                                                                   \
+            (ControlRegister) |= XIIC_CR_NO_ACK_MASK;                       \
+        }                                                                   \
+    }                                                                       \
+}
+
+/******************************************************************************
+*
+* This macro enters a critical region by disabling the global interrupt bit
+* in the Global interrupt register.
+*
+* @param	BaseAddress is the base address of the IIC device.
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mEnterCriticalRegion(u32 BaseAddress)
+*
+******************************************************************************/
+#define XIic_mEnterCriticalRegion(BaseAddress)  \
+	XIIC_GINTR_DISABLE(BaseAddress)
+
+/******************************************************************************
+*
+* This macro exits a critical region by enabling the global interrupt bit
+* in the Global interrupt register.
+*
+* @param	BaseAddress is the base address of the IIC device.
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIic_mExitCriticalRegion(u32 BaseAddress)
+*
+******************************************************************************/
+#define XIic_mExitCriticalRegion(BaseAddress)  \
+	XIIC_GINTR_ENABLE(BaseAddress)
+
+/******************************************************************************
+*
+* This macro clears the statistics of an instance such that it can be common
+* such that some parts of the driver may be optional.
+*
+* @param	InstancePtr is a pointer to the IIC instance to be operated on.
+*
+* @return	None.
+*
+* @note		Signature:
+*		void XIIC_CLEAR_STATS(XIic *InstancePtr)
+*
+******************************************************************************/
+#define XIIC_CLEAR_STATS(InstancePtr)                                   \
+{                                                                       \
+    u8 NumBytes;                                                    \
+    u8 *DestPtr;                                                    \
+                                                                        \
+    DestPtr = (u8 *)&InstancePtr->Stats;                            \
+    for (NumBytes = 0; NumBytes < sizeof(XIicStats); NumBytes++)        \
+    {                                                                   \
+        *DestPtr++ = 0;                                                 \
+    }                                                                   \
+}
+
+/************************** Function Prototypes ******************************/
+
+extern XIic_Config XIic_ConfigTable[];
+
+/* The following variables are shared across files of the driver and
+ * are function pointers that are necessary to break dependencies allowing
+ * optional parts of the driver to be used without condition compilation
+ */
+extern void (*XIic_AddrAsSlaveFuncPtr) (XIic * InstancePtr);
+extern void (*XIic_NotAddrAsSlaveFuncPtr) (XIic * InstancePtr);
+extern void (*XIic_RecvSlaveFuncPtr) (XIic * InstancePtr);
+extern void (*XIic_SendSlaveFuncPtr) (XIic * InstancePtr);
+extern void (*XIic_RecvMasterFuncPtr) (XIic * InstancePtr);
+extern void (*XIic_SendMasterFuncPtr) (XIic * InstancePtr);
+extern void (*XIic_ArbLostFuncPtr) (XIic * InstancePtr);
+extern void (*XIic_BusNotBusyFuncPtr) (XIic * InstancePtr);
+
+void XIic_TransmitFifoFill(XIic * InstancePtr, int Role);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_intr.c linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_intr.c
--- linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_intr.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_intr.c	2010-08-08 17:40:16.483745768 +0200
@@ -0,0 +1,451 @@
+/* $Id: xiic_intr.c,v 1.1 2007/12/03 15:44:58 meinelte Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xiic_intr.c
+*
+* Contains interrupt functions of the XIic driver.  This file is required
+* for the driver.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 1.01a rfp  10/19/01 release
+* 1.01c ecm  12/05/02 new rev
+* 1.01c rmm  05/14/03 Fixed diab compiler warnings relating to asserts.
+* 1.03a ecm  06/22/06 Added a call to the status handler in the TxErrorHandler
+*                     even if the Rx buffer pointer is not set. This fix is as
+*                     a result of a Sony use model which did not set the RX
+*                     pointer while in Master mode so it checks if MSMS == 1.
+* 1.13a wgr  03/22/07 Converted to new coding style.
+* </pre>
+*
+******************************************************************************/
+
+
+/***************************** Include Files *********************************/
+
+#include "xiic.h"
+#include "xiic_i.h"
+#include "xio.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions ******************/
+
+
+/*************** Macros (Inline Functions) Definitions ********************/
+
+
+/************************** Function Prototypes ****************************/
+
+static void StubFunction(XIic * InstancePtr);
+static void TxErrorHandler(XIic * InstancePtr);
+
+/************************** Variable Definitions *****************************/
+
+/* The following function pointers are used to help allow finer partitioning
+ * of the driver such that some parts of it are optional. These pointers are
+ * setup by functions in the optional parts of the driver.
+ */
+void (*XIic_AddrAsSlaveFuncPtr) (XIic * InstancePtr) = StubFunction;
+void (*XIic_NotAddrAsSlaveFuncPtr) (XIic * InstancePtr) = StubFunction;
+void (*XIic_RecvSlaveFuncPtr) (XIic * InstancePtr) = StubFunction;
+void (*XIic_SendSlaveFuncPtr) (XIic * InstancePtr) = StubFunction;
+void (*XIic_RecvMasterFuncPtr) (XIic * InstancePtr) = StubFunction;
+void (*XIic_SendMasterFuncPtr) (XIic * InstancePtr) = StubFunction;
+void (*XIic_ArbLostFuncPtr) (XIic * InstancePtr) = StubFunction;
+void (*XIic_BusNotBusyFuncPtr) (XIic * InstancePtr) = StubFunction;
+
+/*****************************************************************************/
+/**
+*
+* This function is the interrupt handler for the XIic driver. This function
+* should be connected to the interrupt system.
+*
+* Only one interrupt source is handled for each interrupt allowing
+* higher priority system interrupts quicker response time.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @return
+*
+* None.
+*
+* @internal
+*
+* The XIIC_INTR_ARB_LOST_MASK and XIIC_INTR_TX_ERROR_MASK interrupts must have
+* higher priority than the other device interrupts so that the IIC device does
+* not get into a potentially confused state. The remaining interrupts may be
+* rearranged with no harm.
+*
+* All XIic device interrupts are ORed into one device interrupt. This routine
+* reads the pending interrupts via the IpIf interface and masks that with the
+* interrupt mask to evaluate only the interrupts enabled.
+*
+******************************************************************************/
+void XIic_InterruptHandler(void *InstancePtr)
+{
+	u8 Status;
+	u32 IntrStatus;
+	u32 IntrPending;
+	u32 IntrEnable;
+	XIic *IicPtr = NULL;
+	u32 Clear = 0;
+
+	/*
+	 * Verify that each of the inputs are valid.
+	 */
+	XASSERT_VOID(InstancePtr != NULL);
+
+	/*
+	 * Convert the non-typed pointer to an IIC instance pointer
+	 */
+	IicPtr = (XIic *) InstancePtr;
+
+	/* Get the interrupt Status from the IPIF. There is no clearing of
+	 * interrupts in the IPIF. Interrupts must be cleared at the source.
+	 * To find which interrupts are pending; AND interrupts pending with
+	 * interrupts masked.
+	 */
+	IntrPending = XIIC_READ_IISR(IicPtr->BaseAddress);
+	IntrEnable = XIIC_READ_IIER(IicPtr->BaseAddress);
+	IntrStatus = IntrPending & IntrEnable;
+
+	/* Do not processes a devices interrupts if the device has no
+	 * interrupts pending or the global interrupts have been disabled
+	 */
+
+	if ((IntrStatus == 0) |
+	    (XIIC_IS_GINTR_ENABLED(IicPtr->BaseAddress) == FALSE)) {
+		return;
+	}
+
+	/* Update interrupt stats and get the contents of the status register
+	 */
+	IicPtr->Stats.IicInterrupts++;
+	Status = XIo_In8(IicPtr->BaseAddress + XIIC_SR_REG_OFFSET);
+
+	/* Service requesting interrupt
+	 */
+	if (IntrStatus & XIIC_INTR_ARB_LOST_MASK) {
+		/* Bus Arbritration Lost */
+
+		IicPtr->Stats.ArbitrationLost++;
+		XIic_ArbLostFuncPtr(IicPtr);
+
+		Clear = XIIC_INTR_ARB_LOST_MASK;
+	}
+
+	else if (IntrStatus & XIIC_INTR_TX_ERROR_MASK) {
+		/* Transmit errors (no acknowledge) received */
+
+		IicPtr->Stats.TxErrors++;
+		TxErrorHandler(IicPtr);
+
+		Clear = XIIC_INTR_TX_ERROR_MASK;
+	}
+
+	else if (IntrStatus & XIIC_INTR_NAAS_MASK) {
+		/* Not Addressed As Slave */
+
+		XIic_NotAddrAsSlaveFuncPtr(IicPtr);
+		Clear = XIIC_INTR_NAAS_MASK;
+	}
+
+	else if (IntrStatus & XIIC_INTR_RX_FULL_MASK) {
+		/* Receive register/FIFO is full */
+
+		IicPtr->Stats.RecvInterrupts++;
+
+		if (Status & XIIC_SR_ADDR_AS_SLAVE_MASK) {
+			XIic_RecvSlaveFuncPtr(IicPtr);
+		}
+		else {
+			XIic_RecvMasterFuncPtr(IicPtr);
+		}
+
+		Clear = XIIC_INTR_RX_FULL_MASK;
+	}
+
+	else if (IntrStatus & XIIC_INTR_AAS_MASK) {
+		/* Addressed As Slave */
+
+		XIic_AddrAsSlaveFuncPtr(IicPtr);
+		Clear = XIIC_INTR_AAS_MASK;
+	}
+
+	else if (IntrStatus & XIIC_INTR_BNB_MASK) {
+		/* IIC bus has transitioned to not busy */
+
+		/* check if send callback needs to run */
+		if (IicPtr->BNBOnly == TRUE) {
+			XIic_BusNotBusyFuncPtr(IicPtr);
+			IicPtr->BNBOnly = FALSE;
+		}
+		else {
+			IicPtr->SendHandler(IicPtr->SendCallBackRef, 0);
+		}
+
+
+		Clear = XIIC_INTR_BNB_MASK;
+
+		/* The bus is not busy, disable BusNotBusy interrupt */
+		XIic_mDisableIntr(IicPtr->BaseAddress, XIIC_INTR_BNB_MASK);
+
+	}
+
+	else if ((IntrStatus & XIIC_INTR_TX_EMPTY_MASK) ||
+		 (IntrStatus & XIIC_INTR_TX_HALF_MASK)) {
+		/* Transmit register/FIFO is empty or  empty *
+		 */
+		IicPtr->Stats.SendInterrupts++;
+
+		if (Status & XIIC_SR_ADDR_AS_SLAVE_MASK) {
+			XIic_SendSlaveFuncPtr(IicPtr);
+		}
+		else {
+			XIic_SendMasterFuncPtr(IicPtr);
+		}
+
+		/* Clear Interrupts
+		 */
+		IntrStatus = XIIC_READ_IISR(IicPtr->BaseAddress);
+		Clear = IntrStatus & (XIIC_INTR_TX_EMPTY_MASK |
+				      XIIC_INTR_TX_HALF_MASK);
+	}
+
+	XIIC_WRITE_IISR(IicPtr->BaseAddress, Clear);
+}
+
+/******************************************************************************
+*
+* This function fills the FIFO using the occupancy register to determine the
+* available space to be filled. When the repeated start option is on, the last
+* byte is withheld to allow the control register to be properly set on the last
+* byte.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @param    Role indicates the role of this IIC device, a slave or a master, on
+*           the IIC bus (XIIC_SLAVE_ROLE or XIIC_MASTER_ROLE)
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void XIic_TransmitFifoFill(XIic * InstancePtr, int Role)
+{
+	u8 AvailBytes;
+	int LoopCnt;
+	int NumBytesToSend;
+
+	/* Determine number of bytes to write to FIFO. Number of bytes that can be
+	 * put into the FIFO is (FIFO depth) - (current occupancy + 1)
+	 * When more room in FIFO than msg bytes put all of message in the FIFO.
+	 */
+	AvailBytes = IIC_TX_FIFO_DEPTH -
+		(XIo_In8(InstancePtr->BaseAddress + XIIC_TFO_REG_OFFSET) + 1);
+
+	if (InstancePtr->SendByteCount > AvailBytes) {
+		NumBytesToSend = AvailBytes;
+	}
+	else {
+		/* More space in FIFO than bytes in message
+		 */
+		if ((InstancePtr->Options & XII_REPEATED_START_OPTION) ||
+		    (Role == XIIC_SLAVE_ROLE)) {
+			NumBytesToSend = InstancePtr->SendByteCount;
+		}
+		else {
+			NumBytesToSend = InstancePtr->SendByteCount - 1;
+		}
+	}
+
+	/* fill FIFO with amount determined above */
+
+	for (LoopCnt = 0; LoopCnt < NumBytesToSend; LoopCnt++) {
+		XIic_mWriteSendByte(InstancePtr);
+	}
+}
+
+/*****************************************************************************/
+/**
+*
+* This interrupt occurs four different ways: Two as master and two as slave.
+* Master:
+* <pre>
+*  (1) Transmitter (IMPLIES AN ERROR)
+*      The slave receiver did not acknowledge properly.
+*  (2) Receiver (Implies tx complete)
+*      Interrupt caused by setting TxAck high in the IIC to indicate to the
+*      the last byte has been transmitted.
+* </pre>
+*
+* Slave:
+* <pre>
+*  (3) Transmitter (Implies tx complete)
+*      Interrupt caused by master device indicating last byte of the message
+*      has been transmitted.
+*  (4) Receiver (IMPLIES AN ERROR)
+*      Interrupt caused by setting TxAck high in the IIC to indicate Rx
+*      IIC had a problem - set by this device and condition already known
+*      and interrupt is not enabled.
+* </pre>
+*
+* This interrupt is enabled during Master send and receive and disabled
+* when this device knows it is going to send a negative acknowledge (Ack = No).
+*
+* Signals user of Tx error via status callback sending: XII_TX_ERROR_EVENT
+*
+* When MasterRecv has no message to send and only receives one byte of data
+* from the salve device, the TxError must be enabled to catch addressing
+* errors, yet there is not opportunity to disable TxError when there is no
+* data to send allowing disabling on last byte. When the slave sends the
+* only byte the NOAck causes a Tx Error. To disregard this as no real error,
+* when there is data in the Receive FIFO/register then the error was not
+* a device address write error, but a NOACK read error - to be ignored.
+* To work with or without FIFO's, the Rx Data interrupt is used to indicate
+* data is in the rx register.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* No action is required to clear this interrupt in the device as it is a
+* pulse. The interrupt need only be cleared in the IpIf interface.
+*
+******************************************************************************/
+static void TxErrorHandler(XIic * InstancePtr)
+{
+	u32 IntrStatus;
+	u8 CntlReg;
+
+	/* When Sending as a slave, Tx error signals end of msg. Not Addressed As
+	 * Slave will handle the callbacks. this is used to only flush the Tx fifo.
+	 * The addressed as slave bit is gone as soon as the bus has been released
+	 * such that the buffer pointers are used to determine the direction of
+	 * transfer (send or receive).
+	 */
+	if (InstancePtr->RecvBufferPtr == NULL) {
+		/* Master Receiver finished reading message. Flush Tx fifo to remove an
+		 * 0xFF that was written to prevent bus throttling, and disable all
+		 * transmit and receive interrupts
+		 */
+		XIic_mFlushTxFifo(InstancePtr);
+		XIic_mDisableIntr(InstancePtr->BaseAddress,
+				  XIIC_TX_RX_INTERRUPTS);
+
+
+		/* If operating in Master mode, call status handler to indicate
+		 * NOACK occured
+		 */
+		CntlReg =
+			XIo_In8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET);
+		if ((CntlReg & XIIC_CR_MSMS_MASK) != 0) {
+			InstancePtr->StatusHandler(InstancePtr->
+						   StatusCallBackRef,
+						   XII_SLAVE_NO_ACK_EVENT);
+		}
+		return;
+	}
+
+	/* Data in the receive register from either master or slave receive
+	 * When:slave, indicates master sent last byte, message completed.
+	 * When:master, indicates a master Receive with one byte received. When a
+	 * byte is in Rx reg then the Tx error indicates the Rx data was recovered
+	 * normally Tx errors are not enabled such that this should not occur.
+	 */
+	IntrStatus = XIIC_READ_IISR(InstancePtr->BaseAddress);
+	if (IntrStatus & XIIC_INTR_RX_FULL_MASK) {
+		/* Rx Reg/FIFO has data,  Disable tx error interrupts */
+
+		XIic_mDisableIntr(InstancePtr->BaseAddress,
+				  XIIC_INTR_TX_ERROR_MASK);
+		return;
+	}
+
+	XIic_mFlushTxFifo(InstancePtr);
+
+	/* Disable and clear tx empty,  empty, Rx Full or tx error interrupts
+	 */
+	XIic_mDisableIntr(InstancePtr->BaseAddress, XIIC_TX_RX_INTERRUPTS);
+	XIic_mClearIntr(InstancePtr->BaseAddress, XIIC_TX_RX_INTERRUPTS);
+
+	/* Clear MSMS as on TX error when Rxing, the bus will be
+	 * stopped but MSMS bit is still set. Reset to proper state
+	 */
+	CntlReg = XIo_In8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET);
+	CntlReg &= ~XIIC_CR_MSMS_MASK;
+	XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET, CntlReg);
+
+
+	/* set FIFO occupancy depth = 1 so that the first byte will throttle
+	 * next recieve msg
+	 */
+	XIo_Out8(InstancePtr->BaseAddress + XIIC_RFD_REG_OFFSET, 0);
+
+	/* make event callback */
+
+	InstancePtr->StatusHandler(InstancePtr->StatusCallBackRef,
+				   XII_SLAVE_NO_ACK_EVENT);
+}
+
+/*****************************************************************************/
+/**
+*
+* This function is a stub function that is used for the default function for
+* events that are handled optionally only when the appropriate modules are
+* linked in.  Function pointers are used to handle some events to allow
+* some events to be optionally handled.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+******************************************************************************/
+static void StubFunction(XIic * InstancePtr)
+{
+	XASSERT_VOID_ALWAYS();
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_l.c linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_l.c
--- linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_l.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_l.c	2010-08-08 17:40:16.488014049 +0200
@@ -0,0 +1,967 @@
+/* $Id: xiic_l.c,v 1.3 2007/12/17 19:15:38 meinelte Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002-2007 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xiic_l.c
+*
+* This file contains low-level driver functions that can be used to access the
+* device in normal and dynamic controller mode. The user should refer to the
+* hardware device specification for more details of the device operation.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- --- -------   -----------------------------------------------
+* 1.01b jhl 05/13/02  First release
+* 1.01b jhl 10/14/02  Corrected bug in the receive function, the setup of the
+*                     interrupt status mask was not being done in the loop such
+*                     that a read would sometimes fail on the last byte because
+*                     the transmit error which should have been ignored was
+*                     being used.  This would leave an extra byte in the FIFO
+*                     and the bus throttled such that the next operation would
+*                     also fail.  Also updated the receive function to not
+*                     disable the device after the last byte until after the
+*                     bus transitions to not busy which is more consistent
+*                     with the expected behavior.
+* 1.01c ecm  12/05/02 new rev
+* 1.02a mta  03/09/06 Implemented Repeated Start in the Low Level Driver.
+* 1.03a mta  04/04/06 Implemented Dynamic IIC core routines.
+* 1.03a ecm  06/15/06 Fixed the hang in low_level_eeprom_test with -O0
+*                     Added polling loops for BNB to allow the slave to
+*                     respond correctly. Also added polling loop prior
+*                     to reset in _Recv.
+* 1.13a wgr  03/22/07 Converted to new coding style.
+* 1.13b ecm  11/29/07 added BB polling loops to the DynSend and DynRecv
+*					  routines to handle the race condition with BNB in IISR.
+* </pre>
+*
+****************************************************************************/
+
+/***************************** Include Files *******************************/
+
+#include "xbasic_types.h"
+#include "xio.h"
+#include "xiic_l.h"
+
+/************************** Constant Definitions ***************************/
+
+/**************************** Type Definitions *****************************/
+
+/***************** Macros (Inline Functions) Definitions *******************/
+
+/************************** Function Prototypes ****************************/
+
+static unsigned RecvData(u32 BaseAddress, u8 *BufferPtr,
+			 unsigned ByteCount, u8 Option);
+static unsigned SendData(u32 BaseAddress, u8 *BufferPtr,
+			 unsigned ByteCount, u8 Option);
+
+static unsigned DynRecvData(u32 BaseAddress, u8 *BufferPtr, u8 ByteCount);
+static unsigned DynSendData(u32 BaseAddress, u8 *BufferPtr,
+			    u8 ByteCount, u8 Option);
+
+/************************** Variable Definitions **************************/
+
+/****************************************************************************/
+/**
+* Receive data as a master on the IIC bus.  This function receives the data
+* using polled I/O and blocks until the data has been received. It only
+* supports 7 bit addressing mode of operation. The user is responsible for
+* ensuring the bus is not busy if multiple masters are present on the bus.
+*
+* @param    BaseAddress contains the base address of the IIC device.
+* @param    Address contains the 7 bit IIC address of the device to send the
+*           specified data to.
+* @param    BufferPtr points to the data to be sent.
+* @param    ByteCount is the number of bytes to be sent.
+* @param    Option indicates whether to hold or free the bus after reception
+*           of data, XIIC_STOP = end with STOP condition, XIIC_REPEATED_START
+*           = don't end with STOP condition.
+*
+* @return
+*
+* The number of bytes received.
+*
+* @note
+*
+* None
+*
+******************************************************************************/
+unsigned XIic_Recv(u32 BaseAddress, u8 Address,
+		   u8 *BufferPtr, unsigned ByteCount, u8 Option)
+{
+	u8 CntlReg;
+	unsigned RemainingByteCount;
+	volatile u8 StatusReg;
+
+	/* Tx error is enabled incase the address (7 or 10) has no device to answer
+	 * with Ack. When only one byte of data, must set NO ACK before address goes
+	 * out therefore Tx error must not be enabled as it will go off immediately
+	 * and the Rx full interrupt will be checked.  If full, then the one byte
+	 * was received and the Tx error will be disabled without sending an error
+	 * callback msg.
+	 */
+	XIic_mClearIisr(BaseAddress,
+			XIIC_INTR_RX_FULL_MASK | XIIC_INTR_TX_ERROR_MASK |
+			XIIC_INTR_ARB_LOST_MASK);
+
+	/* Set receive FIFO occupancy depth for 1 byte (zero based)
+	 */
+	XIo_Out8(BaseAddress + XIIC_RFD_REG_OFFSET, 0);
+
+
+	/* Check to see if already Master on the Bus.
+	 * If Repeated Start bit is not set send Start bit by setting MSMS bit else
+	 * Send the address.
+	 */
+	CntlReg = XIo_In8(BaseAddress + XIIC_CR_REG_OFFSET);
+	if ((CntlReg & XIIC_CR_REPEATED_START_MASK) == 0) {
+		/* 7 bit slave address, send the address for a read operation
+		 * and set the state to indicate the address has been sent
+		 */
+		XIic_mSend7BitAddress(BaseAddress, Address,
+				      XIIC_READ_OPERATION);
+
+
+		/* MSMS gets set after putting data in FIFO. Start the master receive
+		 * operation by setting CR Bits MSMS to Master, if the buffer is only one
+		 * byte, then it should not be acknowledged to indicate the end of data
+		 */
+		CntlReg = XIIC_CR_MSMS_MASK | XIIC_CR_ENABLE_DEVICE_MASK;
+		if (ByteCount == 1) {
+			CntlReg |= XIIC_CR_NO_ACK_MASK;
+		}
+
+		/* Write out the control register to start receiving data and call the
+		 * function to receive each byte into the buffer
+		 */
+		XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET, CntlReg);
+
+		/* Clear the latched interrupt status for the bus not busy bit which must
+		 * be done while the bus is busy
+		 */
+		StatusReg = XIo_In8(BaseAddress + XIIC_SR_REG_OFFSET);
+
+		while ((StatusReg & XIIC_SR_BUS_BUSY_MASK) == 0) {
+			StatusReg = XIo_In8(BaseAddress + XIIC_SR_REG_OFFSET);
+
+		}
+
+		XIic_mClearIisr(BaseAddress, XIIC_INTR_BNB_MASK);
+	}
+	else {
+		/* Already owns the Bus indicating that its a Repeated Start call.
+		 * 7 bit slave address, send the address for a read operation
+		 * and set the state to indicate the address has been sent
+		 */
+		XIic_mSend7BitAddress(BaseAddress, Address,
+				      XIIC_READ_OPERATION);
+	}
+	/* Try to receive the data from the IIC bus */
+
+	RemainingByteCount =
+		RecvData(BaseAddress, BufferPtr, ByteCount, Option);
+
+	CntlReg = XIo_In8(BaseAddress + XIIC_CR_REG_OFFSET);
+	if ((CntlReg & XIIC_CR_REPEATED_START_MASK) == 0) {
+		/* The receive is complete, disable the IIC device if the Option is
+		 * to release the Bus after Reception of data and return the number of
+		 * bytes that was received
+		 */
+		XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET, 0);
+	}
+
+	/* Return the number of bytes that was received */
+
+	return ByteCount - RemainingByteCount;
+}
+
+/******************************************************************************
+*
+* Receive the specified data from the device that has been previously addressed
+* on the IIC bus.  This function assumes that the 7 bit address has been sent
+* and it should wait for the transmit of the address to complete.
+*
+* @param    BaseAddress contains the base address of the IIC device.
+* @param    BufferPtr points to the buffer to hold the data that is received.
+* @param    ByteCount is the number of bytes to be received.
+* @param    Option indicates whether to hold or free the bus after reception
+*           of data, XIIC_STOP = end with STOP condition, XIIC_REPEATED_START
+*           = don't end with STOP condition.
+*
+* @return
+*
+* The number of bytes remaining to be received.
+*
+* @note
+*
+* This function does not take advantage of the receive FIFO because it is
+* designed for minimal code space and complexity.  It contains loops that
+* that could cause the function not to return if the hardware is not working.
+*
+* This function assumes that the calling function will disable the IIC device
+* after this function returns.
+*
+******************************************************************************/
+static unsigned RecvData(u32 BaseAddress, u8 *BufferPtr,
+			 unsigned ByteCount, u8 Option)
+{
+	u8 CntlReg;
+	u32 IntrStatusMask;
+	u32 IntrStatus;
+
+	/* Attempt to receive the specified number of bytes on the IIC bus */
+
+	while (ByteCount > 0) {
+		/* Setup the mask to use for checking errors because when receiving one
+		 * byte OR the last byte of a multibyte message an error naturally
+		 * occurs when the no ack is done to tell the slave the last byte
+		 */
+		if (ByteCount == 1) {
+			IntrStatusMask =
+				XIIC_INTR_ARB_LOST_MASK | XIIC_INTR_BNB_MASK;
+		}
+		else {
+			IntrStatusMask =
+				XIIC_INTR_ARB_LOST_MASK |
+				XIIC_INTR_TX_ERROR_MASK | XIIC_INTR_BNB_MASK;
+		}
+
+		/* Wait for the previous transmit and the 1st receive to complete
+		 * by checking the interrupt status register of the IPIF
+		 */
+		while (1) {
+			IntrStatus = XIIC_READ_IISR(BaseAddress);
+			if (IntrStatus & XIIC_INTR_RX_FULL_MASK) {
+				break;
+			}
+			/* Check the transmit error after the receive full because when
+			 * sending only one byte transmit error will occur because of the
+			 * no ack to indicate the end of the data
+			 */
+			if (IntrStatus & IntrStatusMask) {
+				return ByteCount;
+			}
+		}
+
+		CntlReg = XIo_In8(BaseAddress + XIIC_CR_REG_OFFSET);
+
+		/* Special conditions exist for the last two bytes so check for them
+		 * Note that the control register must be setup for these conditions
+		 * before the data byte which was already received is read from the
+		 * receive FIFO (while the bus is throttled
+		 */
+		if (ByteCount == 1) {
+			if (Option == XIIC_STOP) {
+
+				/* If the Option is to release the bus after the last data
+				 * byte, it has already been read and no ack has been done, so
+				 * clear MSMS while leaving the device enabled so it can get off
+				 * the IIC bus appropriately with a stop.
+				 */
+				XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET,
+					 XIIC_CR_ENABLE_DEVICE_MASK);
+			}
+		}
+
+		/* Before the last byte is received, set NOACK to tell the slave IIC
+		 * device that it is the end, this must be done before reading the byte
+		 * from the FIFO
+		 */
+		if (ByteCount == 2) {
+			/* Write control reg with NO ACK allowing last byte to
+			 * have the No ack set to indicate to slave last byte read.
+			 */
+			XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET,
+				 CntlReg | XIIC_CR_NO_ACK_MASK);
+		}
+
+		/* Read in data from the FIFO and unthrottle the bus such that the
+		 * next byte is read from the IIC bus
+		 */
+		*BufferPtr++ = XIo_In8(BaseAddress + XIIC_DRR_REG_OFFSET);
+
+		if ((ByteCount == 1) && (Option == XIIC_REPEATED_START)) {
+
+			/* RSTA bit should be set only when the FIFO is completely Empty.
+			 */
+			XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET,
+				 XIIC_CR_ENABLE_DEVICE_MASK | XIIC_CR_MSMS_MASK
+				 | XIIC_CR_REPEATED_START_MASK);
+
+		}
+
+		/* Clear the latched interrupt status so that it will be updated with
+		 * the new state when it changes, this must be done after the receive
+		 * register is read
+		 */
+		XIic_mClearIisr(BaseAddress, XIIC_INTR_RX_FULL_MASK |
+				XIIC_INTR_TX_ERROR_MASK |
+				XIIC_INTR_ARB_LOST_MASK);
+		ByteCount--;
+	}
+
+
+	if (Option == XIIC_STOP) {
+
+		/* If the Option is to release the bus after Reception of data, wait
+		 * for the bus to transition to not busy before returning, the IIC
+		 * device cannot be disabled until this occurs. It should transition as
+		 * the MSMS bit of the control register was cleared before the last byte
+		 * was read from the FIFO.
+		 */
+		while (1) {
+			if (XIIC_READ_IISR(BaseAddress) &
+			    XIIC_INTR_BNB_MASK) {
+				break;
+			}
+		}
+	}
+
+	return ByteCount;
+}
+
+/****************************************************************************/
+/**
+* Send data as a master on the IIC bus.  This function sends the data
+* using polled I/O and blocks until the data has been sent.  It only supports
+* 7 bit addressing mode of operation.  The user is responsible for ensuring
+* the bus is not busy if multiple masters are present on the bus.
+*
+* @param    BaseAddress contains the base address of the IIC device.
+* @param    Address contains the 7 bit IIC address of the device to send the
+*           specified data to.
+* @param    BufferPtr points to the data to be sent.
+* @param    ByteCount is the number of bytes to be sent.
+* @param    Option indicates whether to hold or free the bus after
+*           transmitting the data.
+*
+* @return
+*
+* The number of bytes sent.
+*
+* @note
+*
+* None
+*
+******************************************************************************/
+unsigned XIic_Send(u32 BaseAddress, u8 Address,
+		   u8 *BufferPtr, unsigned ByteCount, u8 Option)
+{
+	unsigned RemainingByteCount;
+	u8 ControlReg;
+	volatile u8 StatusReg;
+
+	/* Check to see if already Master on the Bus.
+	 * If Repeated Start bit is not set send Start bit by setting MSMS bit else
+	 * Send the address.
+	 */
+	ControlReg = XIo_In8(BaseAddress + XIIC_CR_REG_OFFSET);
+	if ((ControlReg & XIIC_CR_REPEATED_START_MASK) == 0) {
+		/* Put the address into the FIFO to be sent and indicate that the operation
+		 * to be performed on the bus is a write operation
+		 */
+		XIic_mSend7BitAddress(BaseAddress, Address,
+				      XIIC_WRITE_OPERATION);
+		/* Clear the latched interrupt status so that it will be updated with the
+		 * new state when it changes, this must be done after the address is put
+		 * in the FIFO
+		 */
+		XIic_mClearIisr(BaseAddress, XIIC_INTR_TX_EMPTY_MASK |
+				XIIC_INTR_TX_ERROR_MASK |
+				XIIC_INTR_ARB_LOST_MASK);
+
+		/* MSMS must be set after putting data into transmit FIFO, indicate the
+		 * direction is transmit, this device is master and enable the IIC device
+		 */
+		XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET,
+			 XIIC_CR_MSMS_MASK | XIIC_CR_DIR_IS_TX_MASK |
+			 XIIC_CR_ENABLE_DEVICE_MASK);
+
+		/* Clear the latched interrupt
+		 * status for the bus not busy bit which must be done while the bus is busy
+		 */
+		StatusReg = XIo_In8(BaseAddress + XIIC_SR_REG_OFFSET);
+		while ((StatusReg & XIIC_SR_BUS_BUSY_MASK) == 0) {
+			StatusReg = XIo_In8(BaseAddress + XIIC_SR_REG_OFFSET);
+		}
+
+		XIic_mClearIisr(BaseAddress, XIIC_INTR_BNB_MASK);
+
+	}
+	else {
+		/* Already owns the Bus indicating that its a Repeated Start call.
+		 * 7 bit slave address, send the address for a write operation
+		 * and set the state to indicate the address has been sent
+		 */
+		XIic_mSend7BitAddress(BaseAddress, Address,
+				      XIIC_WRITE_OPERATION);
+	}
+
+	/* Send the specified data to the device on the IIC bus specified by the
+	 * the address
+	 */
+	RemainingByteCount =
+		SendData(BaseAddress, BufferPtr, ByteCount, Option);
+
+	ControlReg = XIo_In8(BaseAddress + XIIC_CR_REG_OFFSET);
+	if ((ControlReg & XIIC_CR_REPEATED_START_MASK) == 0) {
+		/* The Transmission is completed, disable the IIC device if the Option
+		 * is to release the Bus after transmission of data and return the number
+		 * of bytes that was received. Only wait if master, if addressed as slave
+		 * just reset to release the bus.
+		 */
+		if ((ControlReg & XIIC_CR_MSMS_MASK) != 0) {
+			XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET,
+				 (ControlReg & ~XIIC_CR_MSMS_MASK));
+			StatusReg = XIo_In8(BaseAddress + XIIC_SR_REG_OFFSET);
+			while ((StatusReg & XIIC_SR_BUS_BUSY_MASK) != 0) {
+				StatusReg =
+					XIo_In8(BaseAddress +
+						XIIC_SR_REG_OFFSET);
+			}
+		}
+
+		XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET, 0);
+	}
+
+	return ByteCount - RemainingByteCount;
+}
+
+/******************************************************************************
+*
+* Send the specified buffer to the device that has been previously addressed
+* on the IIC bus.  This function assumes that the 7 bit address has been sent
+* and it should wait for the transmit of the address to complete.
+*
+* @param    BaseAddress contains the base address of the IIC device.
+* @param    BufferPtr points to the data to be sent.
+* @param    ByteCount is the number of bytes to be sent.
+* @param    Option indicates whether to hold or free the bus after
+*           transmitting the data.
+*
+* @return
+*
+* The number of bytes remaining to be sent.
+*
+* @note
+*
+* This function does not take advantage of the transmit FIFO because it is
+* designed for minimal code space and complexity.  It contains loops that
+* that could cause the function not to return if the hardware is not working.
+*
+******************************************************************************/
+static unsigned SendData(u32 BaseAddress, u8 *BufferPtr,
+			 unsigned ByteCount, u8 Option)
+{
+	u32 IntrStatus;
+
+	/* Send the specified number of bytes in the specified buffer by polling
+	 * the device registers and blocking until complete
+	 */
+	while (ByteCount > 0) {
+		/* Wait for the transmit to be empty before sending any more data
+		 * by polling the interrupt status register
+		 */
+		while (1) {
+			IntrStatus = XIIC_READ_IISR(BaseAddress);
+
+			if (IntrStatus & (XIIC_INTR_TX_ERROR_MASK |
+					  XIIC_INTR_ARB_LOST_MASK |
+					  XIIC_INTR_BNB_MASK)) {
+				return ByteCount;
+			}
+
+			if (IntrStatus & XIIC_INTR_TX_EMPTY_MASK) {
+				break;
+			}
+		}
+		/* If there is more than one byte to send then put the next byte to send
+		 * into the transmit FIFO
+		 */
+		if (ByteCount > 1) {
+			XIo_Out8(BaseAddress + XIIC_DTR_REG_OFFSET,
+				 *BufferPtr++);
+		}
+		else {
+			if (Option == XIIC_STOP) {
+				/* If the Option is to release the bus after the last data
+				 * byte, Set the stop Option before sending the last byte
+				 * of data so that the stop Option will be generated
+				 * immediately following the data. This is done by clearing
+				 * the MSMS bit in the control register.
+				 */
+				XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET,
+					 XIIC_CR_ENABLE_DEVICE_MASK |
+					 XIIC_CR_DIR_IS_TX_MASK);
+			}
+
+			/* Put the last byte to send in the transmit FIFO */
+
+			XIo_Out8(BaseAddress + XIIC_DTR_REG_OFFSET,
+				 *BufferPtr++);
+
+			if (Option == XIIC_REPEATED_START) {
+				XIic_mClearIisr(BaseAddress,
+						XIIC_INTR_TX_EMPTY_MASK);
+				/* Wait for the transmit to be empty before setting RSTA bit. */
+				while (1) {
+					IntrStatus =
+						XIIC_READ_IISR
+						(BaseAddress);
+					if (IntrStatus &
+					    XIIC_INTR_TX_EMPTY_MASK) {
+						/* RSTA bit should be set only when the FIFO is completely Empty.
+						 */
+						XIo_Out8(BaseAddress +
+							 XIIC_CR_REG_OFFSET,
+							 XIIC_CR_REPEATED_START_MASK
+							 |
+							 XIIC_CR_ENABLE_DEVICE_MASK
+							 |
+							 XIIC_CR_DIR_IS_TX_MASK
+							 | XIIC_CR_MSMS_MASK);
+						break;
+					}
+				}
+			}
+
+		}
+
+		/* Clear the latched interrupt status register and this must be done after
+		 * the transmit FIFO has been written to or it won't clear
+		 */
+		XIic_mClearIisr(BaseAddress, XIIC_INTR_TX_EMPTY_MASK);
+
+		/* Update the byte count to reflect the byte sent and clear the latched
+		 * interrupt status so it will be updated for the new state
+		 */
+		ByteCount--;
+	}
+
+	if (Option == XIIC_STOP) {
+		/* If the Option is to release the bus after transmission of data,
+		 * Wait for the bus to transition to not busy before returning, the IIC
+		 * device cannot be disabled until this occurs.
+		 * Note that this is different from a receive operation because the stop
+		 * Option causes the bus to go not busy.
+		 */
+		while (1) {
+			if (XIIC_READ_IISR(BaseAddress) &
+			    XIIC_INTR_BNB_MASK) {
+				break;
+			}
+		}
+	}
+
+	return ByteCount;
+}
+
+/*****************************************************************************/
+/**
+* Receive data as a master on the IIC bus. This function receives the data
+* using polled I/O and blocks until the data has been received. It only
+* supports 7 bit addressing. The user is responsible for ensuring the bus is
+* not busy if multiple masters are present on the bus.
+*
+* @param    BaseAddress contains the base address of the IIC Device.
+* @param    Address contains the 7 bit IIC Device address of the device to send
+*           the specified data to.
+* @param    BufferPtr points to the data to be sent.
+* @param    ByteCount is the number of bytes to be sent. This value can't be
+*           greater than 255 and needs to be greater than 0.
+*
+* @return   The number of bytes received.
+*
+* @note     Upon entry to this function, the IIC interface needs to be already
+*           enabled in the CR register.
+*
+******************************************************************************/
+unsigned XIic_DynRecv(u32 BaseAddress, u8 Address, u8 *BufferPtr, u8 ByteCount)
+{
+	unsigned RemainingByteCount;
+	u32 StatusRegister;
+
+	/*
+	 * Clear the latched interrupt status so that it will be updated with
+	 * the new state when it changes.
+	 */
+	XIic_mClearIisr(BaseAddress, XIIC_INTR_TX_EMPTY_MASK |
+			XIIC_INTR_TX_ERROR_MASK | XIIC_INTR_ARB_LOST_MASK);
+
+	/*
+	 * Send the 7 bit slave address for a read operation and set the state
+	 * to indicate the address has been sent. Upon writing the address, a
+	 * start condition is initiated. MSMS is automatically set to master
+	 * when the address is written to the Fifo. If MSMS was already set,
+	 *  then a re-start is sent prior to the address.
+	 */
+	XIic_mDynSend7BitAddress(BaseAddress, Address, XIIC_READ_OPERATION);
+
+	/*
+	 * Wait for the bus to go busy.
+	 */
+	StatusRegister = XIo_In8(BaseAddress + XIIC_SR_REG_OFFSET);
+
+	while (( StatusRegister & XIIC_SR_BUS_BUSY_MASK) != XIIC_SR_BUS_BUSY_MASK)
+	{
+		StatusRegister = XIo_In8(BaseAddress + XIIC_SR_REG_OFFSET);
+	}
+
+	/*
+	 * Clear the latched interrupt status for the bus not busy bit which
+	 * must be done while the bus is busy.
+	 */
+	XIic_mClearIisr(BaseAddress, XIIC_INTR_BNB_MASK);
+
+	/*
+	 * Write to the Tx Fifo the dynamic stop control bit with the number of
+	 * bytes that are to be read over the IIC interface from the presently
+	 * addressed device.
+	 */
+	XIic_mDynSendStop(BaseAddress, ByteCount);
+
+	/*
+	 * Receive the data from the IIC bus.
+	 */
+	RemainingByteCount = DynRecvData(BaseAddress, BufferPtr, ByteCount);
+
+	/*
+	 * The receive is complete. Return the number of bytes that were
+	 * received.
+	 */
+	return ByteCount - RemainingByteCount;
+}
+
+/*****************************************************************************/
+/**
+* Receive the specified data from the device that has been previously addressed
+* on the IIC bus. This function assumes the following:
+*   - The Rx Fifo occupancy depth has been set to its max.
+*   - Upon entry, the Rx Fifo is empty.
+*   - The 7 bit address has been sent.
+*   - The dynamic stop and number of bytes to receive has been written to Tx
+*     Fifo.
+*
+* @param    BaseAddress contains the base address of the IIC Device.
+* @param    BufferPtr points to the buffer to hold the data that is received.
+* @param    ByteCount is the number of bytes to be received. The range of this
+*           value is greater than 0 and not higher than 255.
+*
+* @return   The number of bytes remaining to be received.
+*
+* @note     This function contains loops that could cause the function not
+*           to return if the hardware is not working.
+*
+******************************************************************************/
+static unsigned DynRecvData(u32 BaseAddress, u8 *BufferPtr, u8 ByteCount)
+{
+ 	u8 StatusReg;
+ 	u32 IntrStatus;
+ 	u32 IntrStatusMask;
+
+ 	while (ByteCount > 0) {
+
+ 		/* Setup the mask to use for checking errors because when
+ 		 * receiving one byte OR the last byte of a multibyte message
+ 		 * an error naturally occurs when the no ack is done to tell
+ 		 * the slave the last byte.
+ 		 */
+ 		if (ByteCount == 1) {
+ 			IntrStatusMask =
+ 				XIIC_INTR_ARB_LOST_MASK | XIIC_INTR_BNB_MASK;
+ 		}
+ 		else {
+ 			IntrStatusMask =
+ 				XIIC_INTR_ARB_LOST_MASK |
+ 				XIIC_INTR_TX_ERROR_MASK | XIIC_INTR_BNB_MASK;
+ 		}
+
+ 		/*
+ 		 * Wait for a byte to show up in the Rx Fifo.
+ 		 */
+ 		do {
+ 			StatusReg = XIo_In8(BaseAddress + XIIC_SR_REG_OFFSET);
+ 			IntrStatus = XIIC_READ_IISR(BaseAddress);
+
+ 			/* Check the transmit error after the receive full
+ 			 * because when sending only one byte transmit error
+ 			 * will occur because of the no ack to indicate the end
+ 			 *  of the data.
+ 			 */
+ 			if (IntrStatus & IntrStatusMask) {
+ 				return ByteCount;
+ 			}
+
+ 		} while ((StatusReg & XIIC_SR_RX_FIFO_EMPTY_MASK) ==
+ 			 		XIIC_SR_RX_FIFO_EMPTY_MASK);
+
+ 		/*
+ 		 * Read in byte from the Rx Fifo. If the Fifo reached the
+ 		 * programmed occupancy depth as programmed in the Rx occupancy
+ 		 * reg, this read access will un throttle the bus such that
+ 		 * the next byte is read from the IIC bus.
+ 		 */
+ 		*BufferPtr++ = XIo_In8(BaseAddress + XIIC_DRR_REG_OFFSET);
+ 		ByteCount--;
+ 	}
+
+	return ByteCount;
+}
+
+/*****************************************************************************/
+/**
+* Send data as a master on the IIC bus. This function sends the data using
+* polled I/O and blocks until the data has been sent. It only supports 7 bit
+* addressing. The user is responsible for ensuring the bus is not busy if
+* multiple masters are present on the bus.
+*
+* @param    BaseAddress contains the base address of the IIC Device.
+* @param    Address contains the 7 bit IIC address of the device to send the
+*           specified data to.
+* @param    BufferPtr points to the data to be sent.
+* @param    ByteCount is the number of bytes to be sent.
+* @param    Option: XIIC_STOP = end with STOP condition, XIIC_REPEATED_START
+*           = don't end with STOP condition.
+*
+* @return   The number of bytes sent.
+*
+* @note     None.
+*
+******************************************************************************/
+unsigned XIic_DynSend(u32 BaseAddress, u16 Address, u8 *BufferPtr,
+		      u8 ByteCount, u8 Option)
+{
+	unsigned RemainingByteCount;
+	u32 StatusRegister;
+
+	/*
+	 * Clear the latched interrupt status so that it will be updated with
+	 * the new state when it changes, this must be done after the address
+	 * is put in the FIFO
+	 */
+	XIic_mClearIisr(BaseAddress, XIIC_INTR_TX_EMPTY_MASK |
+			XIIC_INTR_TX_ERROR_MASK | XIIC_INTR_ARB_LOST_MASK);
+
+	/*
+	 * Put the address into the Fifo to be sent and indicate that the
+	 * operation to be performed on the bus is a write operation. Upon
+	 * writing the address, a start condition is initiated. MSMS is
+	 * automatically set to master when the address is written to the Fifo.
+	 * If MSMS was already set, then a re-start is sent prior to the
+	 *  address.
+	 */
+	if(!(Address & XIIC_TX_DYN_STOP_MASK))
+	{
+
+		XIic_mDynSend7BitAddress(BaseAddress, Address,
+		XIIC_WRITE_OPERATION);
+	}
+	else
+	{
+		XIic_mDynSendStartStopAddress(BaseAddress, Address,
+					XIIC_WRITE_OPERATION);
+    }
+
+	/*
+	 * Wait for the bus to go busy.
+	 */
+	StatusRegister = XIo_In8(BaseAddress + XIIC_SR_REG_OFFSET);
+
+	while (( StatusRegister & XIIC_SR_BUS_BUSY_MASK) != XIIC_SR_BUS_BUSY_MASK)
+	{
+		StatusRegister = XIo_In8(BaseAddress + XIIC_SR_REG_OFFSET);
+	}
+
+	/*
+	 * Clear the latched interrupt status for the bus not busy bit which
+	 * must be done while the bus is busy.
+	 */
+	XIic_mClearIisr(BaseAddress, XIIC_INTR_BNB_MASK);
+
+	/*
+	 * Send the specified data to the device on the IIC bus specified by the
+	 * the address.
+	 */
+	RemainingByteCount = DynSendData(BaseAddress, BufferPtr, ByteCount,
+					 Option);
+
+	/*
+	 * The send is complete return the number of bytes that was sent.
+	 */
+	return ByteCount - RemainingByteCount;
+}
+
+/******************************************************************************
+*
+* Send the specified buffer to the device that has been previously addressed
+* on the IIC bus. This function assumes that the 7 bit address has been sent.
+*
+* @param    BaseAddress contains the base address of the IIC Device.
+* @param    BufferPtr points to the data to be sent.
+* @param    ByteCount is the number of bytes to be sent.
+* @param    Option: XIIC_STOP = end with STOP condition, XIIC_REPEATED_START
+*           = don't end with STOP condition.
+*
+* @return   The number of bytes remaining to be sent.
+*
+* @note     This function does not take advantage of the transmit Fifo because
+*           it is designed for minimal code space and complexity.
+*
+******************************************************************************/
+static unsigned DynSendData(u32 BaseAddress, u8 *BufferPtr,
+			    u8 ByteCount, u8 Option)
+{
+	u32 IntrStatus;
+
+	while (ByteCount > 0) {
+		/*
+		 * Wait for the transmit to be empty before sending any more
+		 * data by polling the interrupt status register.
+		 */
+		while (1) {
+			IntrStatus = XIIC_READ_IISR(BaseAddress);
+			if (IntrStatus & (XIIC_INTR_TX_ERROR_MASK |
+					  XIIC_INTR_ARB_LOST_MASK |
+					  XIIC_INTR_BNB_MASK)) {
+				/*
+				 * Error condition (NACK or ARB Lost or BNB
+				 * Error Has occurred. Clear the Control
+				 * register to send a STOP condition on the Bus
+				 * and return the number of bytes still to
+				 * transmit.
+				 */
+
+				XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET,
+					 0x03);
+				XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET,
+					 0x01);
+
+				return ByteCount;
+			}
+
+			/*
+			 * Check for the transmit Fifo to become Empty.
+			 */
+			if (IntrStatus & XIIC_INTR_TX_EMPTY_MASK) {
+				break;
+			}
+		}
+
+		/*
+		 * Send data to Tx Fifo. If a stop condition is specified and
+		 * the last byte is being sent, then set the dynamic stop bit.
+		 */
+		if ((ByteCount == 1) && (Option == XIIC_STOP)) {
+			/*
+			 * The MSMS will be cleared automatically upon setting
+			 *  dynamic stop.
+			 */
+			XIo_Out16(BaseAddress + XIIC_DTR_REG_OFFSET - 1,
+				  	XIIC_TX_DYN_STOP_MASK | *BufferPtr++);
+		}
+		else {
+			XIo_Out8(BaseAddress + XIIC_DTR_REG_OFFSET,
+				 				*BufferPtr++);
+		}
+
+		/*
+		 * Update the byte count to reflect the byte sent.
+		 */
+		ByteCount--;
+	}
+
+	if (Option == XIIC_STOP) {
+		/*
+		 * If the Option is to release the bus after transmission of
+		 * data, Wait for the bus to transition to not busy before
+		 * returning, the IIC device cannot be disabled until this
+		 * occurs.
+		 */
+		while (1) {
+			if (XIIC_READ_IISR(BaseAddress) & XIIC_INTR_BNB_MASK) {
+				break;
+			}
+		}
+	}
+
+	return ByteCount;
+}
+
+/******************************************************************************
+*
+* Initialize the IIC core for Dynamic Functionality.
+*
+* @param    BaseAddress contains the base address of the IIC Device.
+*
+* @return   XST_SUCCESS if Successful else XST_FAILURE.
+*
+* @note     None.
+*
+******************************************************************************/
+int XIic_DynInit(u32 BaseAddress)
+{
+    u8 Status;
+
+	/*
+	 * Reset IIC Core.
+	 */
+	XIIC_RESET(BaseAddress);
+
+    /*
+     * Set receive Fifo depth to maximum (zero based).
+     */
+    XIo_Out8(BaseAddress + XIIC_RFD_REG_OFFSET, IIC_RX_FIFO_DEPTH - 1);
+
+    /*
+     * Reset Tx Fifo.
+     */
+    XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET, XIIC_CR_TX_FIFO_RESET_MASK);
+
+    /*
+     * Enable IIC Device, remove Tx Fifo reset & disable general call.
+     */
+    XIo_Out8(BaseAddress + XIIC_CR_REG_OFFSET, XIIC_CR_ENABLE_DEVICE_MASK);
+
+    /*
+     * Read status register and verify IIC Device is in initial state. Only the
+     * Tx Fifo and Rx Fifo empty bits should be set.
+     */
+    Status = XIo_In8(BaseAddress + XIIC_SR_REG_OFFSET);
+    if(Status == (XIIC_SR_RX_FIFO_EMPTY_MASK | XIIC_SR_TX_FIFO_EMPTY_MASK))
+    {
+        return XST_SUCCESS;
+    }
+
+    return XST_FAILURE;
+}
+
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_l.h linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_l.h
--- linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_l.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_l.h	2010-08-08 17:40:16.488014049 +0200
@@ -0,0 +1,580 @@
+/* $Id: xiic_l.h,v 1.1 2007/12/03 15:44:58 meinelte Exp $ */
+/*****************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002-2007 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+*****************************************************************************/
+/****************************************************************************/
+/**
+*
+* @file xiic_l.h
+*
+* This header file contains identifiers and driver functions (or
+* macros) that can be used to access the device in normal and dynamic
+* controller mode.  High-level driver functions are defined in xiic.h.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 1.00b jhl  05/07/02 First release
+* 1.01c ecm  12/05/02 new rev
+* 1.01d jhl  10/08/03 Added general purpose output feature
+* 1.02a mta  03/09/06 Implemented Repeated Start in the Low Level Driver.
+* 1.03a mta  04/04/06 Implemented Dynamic IIC core routines.
+* 1.03a rpm  09/08/06 Added include of xstatus.h for completeness
+* 1.13a wgr  03/22/07 Converted to new coding style.
+* </pre>
+*
+*****************************************************************************/
+
+#ifndef XIIC_L_H		/* prevent circular inclusions */
+#define XIIC_L_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files ********************************/
+
+#include "xbasic_types.h"
+#include "xstatus.h"
+
+/************************** Constant Definitions ****************************/
+
+#define XIIC_MSB_OFFSET                3
+
+#define XIIC_REG_OFFSET 0x100 + XIIC_MSB_OFFSET
+
+/*
+ * Register offsets in bytes from RegisterBase. Three is added to the
+ * base offset to access LSB (IBM style) of the word
+ */
+#define XIIC_CR_REG_OFFSET   0x00+XIIC_REG_OFFSET	/* Control Register   */
+#define XIIC_SR_REG_OFFSET   0x04+XIIC_REG_OFFSET	/* Status Register    */
+#define XIIC_DTR_REG_OFFSET  0x08+XIIC_REG_OFFSET	/* Data Tx Register   */
+#define XIIC_DRR_REG_OFFSET  0x0C+XIIC_REG_OFFSET	/* Data Rx Register   */
+#define XIIC_ADR_REG_OFFSET  0x10+XIIC_REG_OFFSET	/* Address Register   */
+#define XIIC_TFO_REG_OFFSET  0x14+XIIC_REG_OFFSET	/* Tx FIFO Occupancy  */
+#define XIIC_RFO_REG_OFFSET  0x18+XIIC_REG_OFFSET	/* Rx FIFO Occupancy  */
+#define XIIC_TBA_REG_OFFSET  0x1C+XIIC_REG_OFFSET	/* 10 Bit Address reg */
+#define XIIC_RFD_REG_OFFSET  0x20+XIIC_REG_OFFSET	/* Rx FIFO Depth reg  */
+#define XIIC_GPO_REG_OFFSET  0x24+XIIC_REG_OFFSET	/* Output Register    */
+
+/* Control Register masks */
+
+#define XIIC_CR_ENABLE_DEVICE_MASK        0x01	/* Device enable = 1      */
+#define XIIC_CR_TX_FIFO_RESET_MASK        0x02	/* Transmit FIFO reset=1  */
+#define XIIC_CR_MSMS_MASK                 0x04	/* Master starts Txing=1  */
+#define XIIC_CR_DIR_IS_TX_MASK            0x08	/* Dir of tx. Txing=1     */
+#define XIIC_CR_NO_ACK_MASK               0x10	/* Tx Ack. NO ack = 1     */
+#define XIIC_CR_REPEATED_START_MASK       0x20	/* Repeated start = 1     */
+#define XIIC_CR_GENERAL_CALL_MASK         0x40	/* Gen Call enabled = 1   */
+
+/* Status Register masks */
+
+#define XIIC_SR_GEN_CALL_MASK             0x01	/* 1=a mstr issued a GC   */
+#define XIIC_SR_ADDR_AS_SLAVE_MASK        0x02	/* 1=when addr as slave   */
+#define XIIC_SR_BUS_BUSY_MASK             0x04	/* 1 = bus is busy        */
+#define XIIC_SR_MSTR_RDING_SLAVE_MASK     0x08	/* 1=Dir: mstr <-- slave  */
+#define XIIC_SR_TX_FIFO_FULL_MASK         0x10	/* 1 = Tx FIFO full       */
+#define XIIC_SR_RX_FIFO_FULL_MASK         0x20	/* 1 = Rx FIFO full       */
+#define XIIC_SR_RX_FIFO_EMPTY_MASK        0x40	/* 1 = Rx FIFO empty      */
+#define XIIC_SR_TX_FIFO_EMPTY_MASK        0x80	/* 1 = Tx FIFO empty      */
+
+/* Interrupt Status Register masks    Interrupt occurs when...       */
+
+#define XIIC_INTR_ARB_LOST_MASK           0x01	/* 1 = arbitration lost   */
+#define XIIC_INTR_TX_ERROR_MASK           0x02	/* 1=Tx error/msg complete */
+#define XIIC_INTR_TX_EMPTY_MASK           0x04	/* 1 = Tx FIFO/reg empty  */
+#define XIIC_INTR_RX_FULL_MASK            0x08	/* 1=Rx FIFO/reg=OCY level */
+#define XIIC_INTR_BNB_MASK                0x10	/* 1 = Bus not busy       */
+#define XIIC_INTR_AAS_MASK                0x20	/* 1 = when addr as slave */
+#define XIIC_INTR_NAAS_MASK               0x40	/* 1 = not addr as slave  */
+#define XIIC_INTR_TX_HALF_MASK            0x80	/* 1 = TX FIFO half empty */
+
+#define XIIC_TX_ADDR_SENT             0x00
+#define XIIC_TX_ADDR_MSTR_RECV_MASK   0x02
+
+/* The following constants specify the depth of the FIFOs */
+
+#define IIC_RX_FIFO_DEPTH         16	/* Rx fifo capacity               */
+#define IIC_TX_FIFO_DEPTH         16	/* Tx fifo capacity               */
+
+/* The following constants specify groups of interrupts that are typically
+ * enabled or disables at the same time
+ */
+#define XIIC_TX_INTERRUPTS                                          \
+            (XIIC_INTR_TX_ERROR_MASK | XIIC_INTR_TX_EMPTY_MASK |    \
+             XIIC_INTR_TX_HALF_MASK)
+
+#define XIIC_TX_RX_INTERRUPTS (XIIC_INTR_RX_FULL_MASK | XIIC_TX_INTERRUPTS)
+
+/* The following constants are used with the following macros to specify the
+ * operation, a read or write operation.
+ */
+#define XIIC_READ_OPERATION  1
+#define XIIC_WRITE_OPERATION 0
+
+/* The following constants are used with the transmit FIFO fill function to
+ * specify the role which the IIC device is acting as, a master or a slave.
+ */
+#define XIIC_MASTER_ROLE     1
+#define XIIC_SLAVE_ROLE      0
+
+/*
+ * The following constants are used with Transmit Function (XIic_Send) to
+ * specify whether to STOP after the current transfer of data or own the bus
+ * with a Repeated start.
+ */
+#define XIIC_STOP		0x00
+#define XIIC_REPEATED_START	0x01
+
+ /*
+  * Tx Fifo upper bit masks.
+  */
+
+#define XIIC_TX_DYN_START_MASK            0x0100 /* 1 = Set dynamic start */
+#define XIIC_TX_DYN_STOP_MASK             0x0200 /* 1 = Set dynamic stop */
+
+
+/**************************** Type Definitions ******************************/
+
+
+/***************** Macros (Inline Functions) Definitions ********************/
+
+/************************** Constant Definitions *****************************/
+
+/*
+ * The following constants define the register offsets for the Interrupt
+ * registers. There are some holes in the memory map for reserved addresses
+ * to allow other registers to be added and still match the memory map of the
+ * interrupt controller registers
+ */
+#define XIIC_DGIER_OFFSET    0x1C /* Device Global Interrupt Enable Register */
+#define XIIC_IISR_OFFSET     0x20 /* Interrupt Status Register */
+#define XIIC_IIER_OFFSET     0x28 /* Interrupt Enable Register */
+#define XIIC_RESETR_OFFSET   0x40 /* Reset Register */
+
+
+#define XIIC_RESET_MASK             0xAUL
+
+/*
+ * The following constant is used for the device global interrupt enable
+ * register, to enable all interrupts for the device, this is the only bit
+ * in the register
+ */
+#define XIIC_GINTR_ENABLE_MASK      0x80000000UL
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/******************************************************************************
+*
+* This macro resets the IIC device.
+*
+* @param	RegBaseAddress is the base address of the IIC device.
+*
+* @return	None.
+*
+* @note		C-Style signature:
+*		void XIIC_RESET(u32 RegBaseAddress);
+*
+******************************************************************************/
+#define XIIC_RESET(RegBaseAddress) \
+	XIo_Out32(RegBaseAddress + XIIC_RESETR_OFFSET, XIIC_RESET_MASK)
+
+/******************************************************************************
+*
+* This macro disables all interrupts for the device by writing to the Global
+* interrupt enable register.  This register provides the ability to disable
+* interrupts without any modifications to the interrupt enable register such
+* that it is minimal effort to restore the interrupts to the previous enabled
+* state.  The corresponding function, XIIC_GINTR_ENABLE, is provided to
+* restore the interrupts to the previous enabled state.  This function is
+* designed to be used in critical sections of device drivers such that it is
+* not necessary to disable other device interrupts.
+*
+* @param	RegBaseAddress is the base address of the IIC device.
+*
+* @return	None.
+*
+* @note		C-Style signature:
+*		void XIIC_GINTR_DISABLE(u32 RegBaseAddress);
+*
+******************************************************************************/
+#define XIIC_GINTR_DISABLE(RegBaseAddress)				\
+	XIo_Out32((RegBaseAddress) + XIIC_DGIER_OFFSET, 0)
+
+/******************************************************************************
+*
+* This macro writes to the global interrupt enable register to enable
+* interrupts from the device.  This register provides the ability to enable
+* interrupts without any modifications to the interrupt enable register such
+* that it is minimal effort to restore the interrupts to the previous enabled
+* state. This function does not enable individual interrupts as the interrupt
+* enable register must be set appropriately.  This function is designed to be
+* used in critical sections of device drivers such that it is not necessary to
+* disable other device interrupts.
+*
+* @param	RegBaseAddress is the base address of the IIC device.
+*
+* @return	None.
+*
+* @note		C-Style signature:
+*		void XIIC_GINTR_ENABLE(u32 RegBaseAddress);
+*
+******************************************************************************/
+#define XIIC_GINTR_ENABLE(RegBaseAddress)				\
+	XIo_Out32((RegBaseAddress) + XIIC_DGIER_OFFSET, XIIC_GINTR_ENABLE_MASK)
+
+/******************************************************************************
+*
+* This function determines if interrupts are enabled at the global level by
+* reading the gloabl interrupt register. This register provides the ability to
+* disable interrupts without any modifications to the interrupt enable register
+* such that it is minimal effort to restore the interrupts to the previous
+* enabled state.
+*
+* @param	RegBaseAddress is the base address of the IIC device.
+*
+* @return
+*		- TRUE if global interrupts are enabled.
+*		- FALSE if global interrupts are disabled.
+*
+* @note		C-Style signature:
+*		int XIIC_IS_GINTR_ENABLED(u32 RegBaseAddress);
+*
+******************************************************************************/
+#define XIIC_IS_GINTR_ENABLED(RegBaseAddress)				\
+	(XIo_In32((RegBaseAddress) + XIIC_DGIER_OFFSET) ==		\
+		XIIC_GINTR_ENABLE_MASK)
+
+/******************************************************************************
+*
+*
+* This function sets the Interrupt status register to the specified value.
+* This register indicates the status of interrupt sources for the device.
+* The status is independent of whether interrupts are enabled such that
+* the status register may also be polled when interrupts are not enabled.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* IIC device.  All bits of this register are latched. Setting a bit which is zero
+* within this register causes an interrupt to be generated.  The device global
+* interrupt enable register and the device interrupt enable register must be set
+* appropriately to allow an interrupt to be passed out of the device. The
+* interrupt is cleared by writing to this register with the bits to be
+* cleared set to a one and all others to zero.  This register implements a
+* toggle on write functionality meaning any bits which are set in the value
+* written cause the bits in the register to change to the opposite state.
+*
+* This function writes only the specified value to the register such that
+* some status bits may be set and others cleared.  It is the caller's
+* responsibility to get the value of the register prior to setting the value
+* to prevent an destructive behavior.
+*
+* @param	RegBaseAddress is the base address of the IIC device.
+* @param	Status contains the value to be written to the Interrupt
+*		status register.
+*
+* @return	None.
+*
+* @note		C-Style signature:
+*		void XIIC_WRITE_IISR(u32 RegBaseAddress, u32 Status);
+*
+******************************************************************************/
+#define XIIC_WRITE_IISR(RegBaseAddress, Status)				\
+	XIo_Out32((RegBaseAddress) + XIIC_IISR_OFFSET, (Status))
+
+/******************************************************************************
+*
+*
+* This function gets the contents of the Interrupt Status Register.
+* This register indicates the status of interrupt sources for the device.
+* The status is independent of whether interrupts are enabled such
+* that the status register may also be polled when interrupts are not enabled.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* device.  All bits of this register are latched.  Writing a 1 to a bit within
+* this register causes an interrupt to be generated if enabled in the interrupt
+* enable register and the global interrupt enable is set.  Since the status is
+* latched, each status bit must be acknowledged in order for the bit in the
+* status register to be updated.  Each bit can be acknowledged by writing a
+* 0 to the bit in the status register.
+
+* @param	RegBaseAddress is the base address of the IIC device.
+*
+* @return	A status which contains the value read from the Interrupt
+*		Status Register.
+*
+* @note		C-Style signature:
+*		u32 XIIC_READ_IISR(u32 RegBaseAddress);
+*
+******************************************************************************/
+#define XIIC_READ_IISR(RegBaseAddress) 					\
+	XIo_In32((RegBaseAddress) + XIIC_IISR_OFFSET)
+
+/******************************************************************************
+*
+* This function sets the contents of the Interrupt Enable Register . This
+* register controls which interrupt sources of the IIC device are allowed to
+* generate an interrupt. The global interrupt enable register and the device
+* interrupt enable register must also be set appropriately for an interrupt to be
+* passed out of the device.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* device.  Setting a bit in this register enables the interrupt source to generate
+* an interrupt.  Clearing a bit in this register disables interrupt generation
+* for that interrupt source.
+*
+* This function writes only the specified value to the register such that
+* some interrupt sources may be enabled and others disabled.  It is the
+* caller's responsibility to get the value of the interrupt enable register
+* prior to setting the value to prevent a destructive behavior.
+*
+* @param	RegBaseAddress is the base address of the IIC device.
+* @param	Enable contains the value to be written to the Interrupt Enable
+*		Register.
+*
+* @return 	None
+*
+* @note		C-Style signature:
+*		void XIIC_WRITE_IIER(u32 RegBaseAddress, u32 Enable);
+*
+******************************************************************************/
+#define XIIC_WRITE_IIER(RegBaseAddress, Enable)				\
+	XIo_Out32((RegBaseAddress) + XIIC_IIER_OFFSET, (Enable))
+
+/******************************************************************************
+*
+*
+* This function gets the Interrupt enable register contents.  This register
+* controls which interrupt sources of the device are allowed to generate an
+* interrupt.  The global interrupt enable register and the device interrupt
+* enable register must also be set appropriately for an interrupt to be
+* passed out of the IIC device.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* IIC device. Setting a bit in this register enables the interrupt source to
+* generate an interrupt.  Clearing a bit in this register disables interrupt
+* generation for that interrupt source.
+*
+* @param	RegBaseAddress is the base address of the IIC device.
+*
+* @return	The contents read from the Interrupt Enable Register.
+*
+* @note		C-Style signature:
+*		u32 XIIC_READ_IIER(u32 RegBaseAddress)
+*
+******************************************************************************/
+#define XIIC_READ_IIER(RegBaseAddress)					\
+	XIo_In32((RegBaseAddress) + XIIC_IIER_OFFSET)
+
+/************************** Function Prototypes ******************************/
+
+
+/******************************************************************************
+*
+* This macro reads a register in the IIC device using an 8 bit read operation.
+* This macro does not do any checking to ensure that the register exists if the
+* register may be excluded due to parameterization, such as the GPO Register.
+*
+* @param	BaseAddress of the IIC device.
+* @param	RegisterOffset contains the offset of the register from the
+*		device base address.
+*
+* @return	The value read from the register.
+*
+* @note		C-Style signature:
+* 		u8 XIic_mReadReg(u32 BaseAddress, int RegisterOffset);
+*
+******************************************************************************/
+#define XIic_mReadReg(BaseAddress, RegisterOffset) 			\
+	XIo_In8((BaseAddress) + (RegisterOffset))
+
+/******************************************************************************
+*
+* This macro writes a register in the IIC device using an 8 bit write
+* operation. This macro does not do any checking to ensure that the register
+* exists if the register may be excluded due to parameterization, such as the
+* GPO Register.
+*
+* @param	BaseAddress of the IIC device.
+* @param	RegisterOffset contains the offset of the register from the
+*		device base address.
+* @param	Data contains the data to be written to the register.
+*
+* @return	None.
+*
+* @note		C-Style signature:
+*		void XIic_mWriteReg(u32 BaseAddress, int RegisterOffset,
+					u8 Data);
+*
+******************************************************************************/
+#define XIic_mWriteReg(BaseAddress, RegisterOffset, Data) 		\
+	XIo_Out8((BaseAddress) + (RegisterOffset), (Data))
+
+/******************************************************************************
+*
+* This macro clears the specified interrupt in the Interrupt status
+* register.  It is non-destructive in that the register is read and only the
+* interrupt specified is cleared.  Clearing an interrupt acknowledges it.
+*
+* @param	BaseAddress contains the IIC registers base address.
+* @param	InterruptMask contains the interrupts to be disabled
+*
+* @return	None.
+*
+* @note		C-Style signature:
+*		void XIic_mClearIisr(u32 BaseAddress, u32 InterruptMask);
+*
+******************************************************************************/
+#define XIic_mClearIisr(BaseAddress, InterruptMask)			\
+	XIIC_WRITE_IISR((BaseAddress),					\
+	XIIC_READ_IISR(BaseAddress) & (InterruptMask))
+
+/******************************************************************************
+*
+* This macro sends the address for a 7 bit address during both read and write
+* operations. It takes care of the details to format the address correctly.
+* This macro is designed to be called internally to the drivers.
+*
+* @param	BaseAddress contains the base address of the IIC Device.
+* @param	SlaveAddress contains the address of the slave to send to.
+* @param	Operation indicates XIIC_READ_OPERATION or XIIC_WRITE_OPERATION
+*
+* @return	None.
+*
+* @note		C-Style signature:
+* 		void XIic_mSend7BitAddress(u32 BaseAddress, u8 SlaveAddress,
+*						u8 Operation);
+*
+******************************************************************************/
+#define XIic_mSend7BitAddress(BaseAddress, SlaveAddress, Operation)	\
+{									\
+	u8 LocalAddr = (u8)(SlaveAddress << 1);				\
+	LocalAddr = (LocalAddr & 0xFE) | (Operation);			\
+	XIo_Out8(BaseAddress + XIIC_DTR_REG_OFFSET, LocalAddr);		\
+}
+
+/******************************************************************************
+*
+* This macro sends the address for a 7 bit address during both read and write
+* operations. It takes care of the details to format the address correctly.
+* This macro is designed to be called internally to the drivers.
+*
+* @param	BaseAddress contains the base address of the IIC Device.
+* @param	SlaveAddress contains the address of the slave to send to.
+* @param	Operation indicates XIIC_READ_OPERATION or XIIC_WRITE_OPERATION.
+*
+* @return	None.
+*
+* @note		C-Style signature:
+* 		void XIic_mDynSend7BitAddress(u32 BaseAddress, u8 SlaveAddress,
+*						u8 Operation);
+*
+******************************************************************************/
+#define XIic_mDynSend7BitAddress(BaseAddress, SlaveAddress, Operation)	\
+{									\
+	u8 LocalAddr = (u8)(SlaveAddress << 1);				\
+	LocalAddr = (LocalAddr & 0xFE) | (Operation);			\
+	XIo_Out16(BaseAddress + XIIC_DTR_REG_OFFSET - 1,		\
+			XIIC_TX_DYN_START_MASK | LocalAddr);		\
+}
+
+/******************************************************************************
+*
+* This macro sends the address, start and stop for a 7 bit address during both
+* write operations. It takes care of the details to format the address
+* correctly.
+* This macro is designed to be called internally to the drivers.
+*
+* @param	BaseAddress contains the base address of the IIC Device.
+* @param	SlaveAddress contains the address of the slave to send to.
+* @param	Operation indicates XIIC_WRITE_OPERATION.
+*
+* @return	None.
+*
+* @note		C-Style signature:
+* 		void XIic_mDynSendStartStopAddress(u32 BaseAddress,
+*							u8 SlaveAddress,
+*							u8 Operation);
+*
+******************************************************************************/
+#define XIic_mDynSendStartStopAddress(BaseAddress, SlaveAddress, Operation)  \
+{									     \
+	u8 LocalAddr = (u8)(SlaveAddress << 1);				     \
+	LocalAddr = (LocalAddr & 0xFE) | (Operation);			     \
+	XIo_Out16(BaseAddress + XIIC_DTR_REG_OFFSET - 1,		     \
+		XIIC_TX_DYN_START_MASK | XIIC_TX_DYN_STOP_MASK | LocalAddr); \
+}
+
+/******************************************************************************
+*
+* This macro sends a stop condition on IIC bus for Dynamic logic.
+*
+* @param	BaseAddress contains the base address of the IIC Device.
+* @param	ByteCount is the number of Rx bytes received before the master.
+*		doesn't respond with ACK.
+*
+* @return	None.
+*
+* @note		None.
+*
+******************************************************************************/
+#define XIic_mDynSendStop(BaseAddress, ByteCount)			       \
+{									       \
+	XIo_Out16(BaseAddress + XIIC_DTR_REG_OFFSET-1, XIIC_TX_DYN_STOP_MASK | \
+    		  ByteCount); 						       \
+}
+
+/************************** Function Prototypes *****************************/
+
+unsigned XIic_Recv(u32 BaseAddress, u8 Address,
+		   u8 *BufferPtr, unsigned ByteCount, u8 Option);
+
+unsigned XIic_Send(u32 BaseAddress, u8 Address,
+		   u8 *BufferPtr, unsigned ByteCount, u8 Option);
+
+unsigned XIic_DynRecv(u32 BaseAddress, u8 Address, u8 *BufferPtr, u8 ByteCount);
+
+unsigned XIic_DynSend(u32 BaseAddress, u16 Address, u8 *BufferPtr,
+		      u8 ByteCount, u8 Option);
+
+int XIic_DynInit(u32 BaseAddress);
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
+
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_master.c linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_master.c
--- linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_master.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_master.c	2010-08-08 17:40:16.488014049 +0200
@@ -0,0 +1,710 @@
+/* $Id: xiic_master.c,v 1.1 2007/12/03 15:44:58 meinelte Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xiic_master.c
+*
+* Contains master functions for the XIic component. This file is necessary to
+* send or receive as a master on the IIC bus.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- --- ------- -----------------------------------------------
+* 1.01b jhl 3/27/02 Reparitioned the driver
+* 1.01c ecm 12/05/02 new rev
+* 1.13a wgr  03/22/07 Converted to new coding style.
+* </pre>
+*
+****************************************************************************/
+
+/***************************** Include Files *******************************/
+
+#include "xiic.h"
+#include "xiic_i.h"
+#include "xio.h"
+
+/************************** Constant Definitions ***************************/
+
+
+/**************************** Type Definitions *****************************/
+
+
+/***************** Macros (Inline Functions) Definitions *******************/
+
+/*****************************************************************************
+*
+* This macro includes master code such that master operations, sending
+* and receiving data, may be used.  This function hooks the master processing
+* to the driver such that events are handled properly and allows master
+* processing to be optional.  It must be called before any functions which
+* are contained in this file are called, such as after the driver is
+* initialized.
+*
+* @note
+*
+* None
+*
+******************************************************************************/
+#define XIIC_MASTER_INCLUDE                                             \
+{                                                                       \
+    XIic_RecvMasterFuncPtr = RecvMasterData;                            \
+    XIic_SendMasterFuncPtr = SendMasterData;                            \
+}
+
+/************************** Function Prototypes ****************************/
+
+static void SendSlaveAddr(XIic * InstancePtr);
+static void RecvMasterData(XIic * InstancePtr);
+static void SendMasterData(XIic * InstancePtr);
+static int IsBusBusy(XIic * InstancePtr);
+
+/************************** Variable Definitions **************************/
+
+/****************************************************************************/
+/**
+* This function sends data as a master on the IIC bus. If the bus is busy, it
+* will indicate so and then enable an interrupt such that the status handler
+* will be called when the bus is no longer busy.  The slave address which has
+* been set with the XIic_SetAddress() function is the address to which the
+* specific data is sent.  Sending data on the bus performs a write operation.
+*
+* @param    InstancePtr points to the Iic instance to be worked on.
+* @param    TxMsgPtr points to the data to be transmitted
+* @param    ByteCount is the number of message bytes to be sent
+*
+* @return
+*
+* - XST_SUCCESS indicates the message transmission has been initiated.
+* - XST_IIC_BUS_BUSY indicates the bus was in use and that the BusNotBusy
+*   interrupt is enabled which will update the EventStatus when the bus is no
+*   longer busy.
+*
+* @note
+*
+* None
+*
+******************************************************************************/
+int XIic_MasterSend(XIic * InstancePtr, u8 *TxMsgPtr, int ByteCount)
+{
+	u8 CntlReg;
+
+	XIic_mEnterCriticalRegion(InstancePtr->BaseAddress);
+
+	/* Ensure that the master processing has been included such that events
+	 * will be properly handled
+	 */
+	XIIC_MASTER_INCLUDE;
+	InstancePtr->IsDynamic = FALSE;
+
+	/*
+	 * If the busy is busy, then exit the critical region and wait for the
+	 * bus to not be busy, the function enables the bus not busy interrupt
+	 */
+	if (IsBusBusy(InstancePtr)) {
+		XIic_mExitCriticalRegion(InstancePtr->BaseAddress);
+
+		return XST_IIC_BUS_BUSY;
+	}
+
+	/* If it is already a master on the bus (repeated start), the direction was
+	 * set to tx which is throttling bus.  The control register needs to be set
+	 * before putting data into the FIFO
+	 */
+	CntlReg = XIo_In8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET);
+
+	if (CntlReg & XIIC_CR_MSMS_MASK) {
+		CntlReg &= ~XIIC_CR_NO_ACK_MASK;
+		CntlReg |=
+			(XIIC_CR_DIR_IS_TX_MASK | XIIC_CR_REPEATED_START_MASK);
+
+		XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET,
+			 CntlReg);
+		InstancePtr->Stats.RepeatedStarts++;
+	}
+
+	/* Save message state
+	 */
+	InstancePtr->SendByteCount = ByteCount;
+	InstancePtr->SendBufferPtr = TxMsgPtr;
+
+	/* Put the address into the FIFO to be sent and indicate that the operation
+	 * to be performed on the bus is a write operation, a general call address
+	 * handled the same as a 7 bit address even if 10 bit address is selected
+	 * Set the transmit address state to indicate the address has been sent
+	 */
+	if ((InstancePtr->Options & XII_SEND_10_BIT_OPTION) &&
+	    (InstancePtr->AddrOfSlave != 0)) {
+		XIic_mSend10BitAddrByte1(InstancePtr->AddrOfSlave,
+					 XIIC_WRITE_OPERATION);
+		XIic_mSend10BitAddrByte2(InstancePtr->AddrOfSlave);
+	}
+	else {
+		XIic_mSend7BitAddr(InstancePtr->AddrOfSlave,
+				   XIIC_WRITE_OPERATION);
+	}
+	/* Set the transmit address state to indicate the address has been sent
+	 * for communication with event driven processing
+	 */
+	InstancePtr->TxAddrMode = XIIC_TX_ADDR_SENT;
+
+	/* Fill remaining available FIFO with message data
+	 */
+	if (InstancePtr->SendByteCount > 1) {
+		XIic_TransmitFifoFill(InstancePtr, XIIC_MASTER_ROLE);
+	}
+
+	/* After filling fifo, if data yet to send > 1, enable Tx  empty interrupt
+	 */
+	if (InstancePtr->SendByteCount > 1) {
+		XIic_mClearEnableIntr(InstancePtr->BaseAddress,
+				      XIIC_INTR_TX_HALF_MASK);
+	}
+
+	/* Clear any pending Tx empty, Tx Error and then enable them.
+	 */
+	XIic_mClearEnableIntr(InstancePtr->BaseAddress,
+			      XIIC_INTR_TX_ERROR_MASK |
+			      XIIC_INTR_TX_EMPTY_MASK);
+
+	/* When repeated start not used, MSMS must be set after putting data into
+	 * transmit FIFO, start the transmitter
+	 */
+
+	CntlReg = XIo_In8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET);
+	if ((CntlReg & XIIC_CR_MSMS_MASK) == 0) {
+		CntlReg &= ~XIIC_CR_NO_ACK_MASK;
+		CntlReg |= XIIC_CR_MSMS_MASK | XIIC_CR_DIR_IS_TX_MASK;
+		XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET,
+			 CntlReg);
+	}
+
+	XIic_mExitCriticalRegion(InstancePtr->BaseAddress);
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************/
+/**
+* This function receives data as a master from a slave device on the IIC bus.
+* If the bus is busy, it will indicate so and then enable an interrupt such
+* that the status handler will be called when the bus is no longer busy.  The
+* slave address which has been set with the XIic_SetAddress() function is the
+* address from which data is received. Receiving data on the bus performs a
+* read operation.
+*
+* @param    InstancePtr is a pointer to the Iic instance to be worked on.
+* @param    RxMsgPtr is a pointer to the data to be transmitted
+* @param    ByteCount is the number of message bytes to be sent
+*
+* @return
+*
+* - XST_SUCCESS indicates the message reception processes has been initiated.
+* - XST_IIC_BUS_BUSY indicates the bus was in use and that the BusNotBusy
+*   interrupt is enabled which will update the EventStatus when the bus is no
+*   longer busy.
+* - XST_IIC_GENERAL_CALL_ADDRESS indicates the slave address is set to the
+*   the general call address. This is not allowed for Master receive mode.
+*
+* @internal
+*
+* The receive FIFO threshold is a zero based count such that 1 must be
+* subtracted from the desired count to get the correct value. When receiving
+* data it is also necessary to not receive the last byte with the prior bytes
+* because the acknowledge must be setup before the last byte is received.
+*
+******************************************************************************/
+int XIic_MasterRecv(XIic * InstancePtr, u8 *RxMsgPtr, int ByteCount)
+{
+	u8 CntlReg;
+	u8 Temp;
+
+	/* If the slave address is zero (general call) the master can't perform
+	 * receive operations, indicate an error
+	 */
+	if (InstancePtr->AddrOfSlave == 0) {
+		return XST_IIC_GENERAL_CALL_ADDRESS;
+	}
+
+	XIic_mEnterCriticalRegion(InstancePtr->BaseAddress);
+
+	/* Ensure that the master processing has been included such that events
+	 * will be properly handled
+	 */
+	XIIC_MASTER_INCLUDE;
+	InstancePtr->IsDynamic = FALSE;
+	/*
+	 * If the busy is busy, then exit the critical region and wait for the
+	 * bus to not be busy, the function enables the bus not busy interrupt
+	 */
+	if (IsBusBusy(InstancePtr)) {
+		XIic_mExitCriticalRegion(InstancePtr->BaseAddress);
+
+		return XST_IIC_BUS_BUSY;
+	}
+
+	/* Save message state for event driven processing
+	 */
+	InstancePtr->RecvByteCount = ByteCount;
+	InstancePtr->RecvBufferPtr = RxMsgPtr;
+
+	/* Clear and enable Rx full interrupt if using 7 bit, If 10 bit, wait until
+	 * last address byte sent incase arbitration gets lost while sending out
+	 * address.
+	 */
+	if ((InstancePtr->Options & XII_SEND_10_BIT_OPTION) == 0) {
+		XIic_mClearEnableIntr(InstancePtr->BaseAddress,
+				      XIIC_INTR_RX_FULL_MASK);
+	}
+
+	/* If already a master on the bus, the direction was set by Rx Interrupt
+	 * routine to tx which is throttling bus because during Rxing, Tx reg is
+	 * empty = throttle. CR needs setting before putting data or the address
+	 * written will go out as Tx instead of receive. Start Master Rx by setting
+	 * CR Bits MSMS to Master and msg direction.
+	 */
+	CntlReg = XIo_In8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET);
+
+	if (CntlReg & XIIC_CR_MSMS_MASK) {
+		CntlReg |= XIIC_CR_REPEATED_START_MASK;
+		XIic_mSetControlRegister(InstancePtr, CntlReg, ByteCount);
+
+		InstancePtr->Stats.RepeatedStarts++;	/* increment stats counts */
+		XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET,
+			 CntlReg);
+
+	}
+
+	/* Set receive FIFO occupancy depth which must be done prior to writing the
+	 * address in the FIFO because the transmitter will immediatedly start when
+	 * in repeated start mode followed by the receiver such that the number of
+	 * bytes to receive should be set 1st.
+	 */
+	if (ByteCount == 1) {
+		Temp = 0;
+	}
+	else {
+		if (ByteCount <= IIC_RX_FIFO_DEPTH) {
+			Temp = ByteCount - 2;
+		}
+		else {
+			Temp = IIC_RX_FIFO_DEPTH - 1;
+		}
+	}
+	XIo_Out8(InstancePtr->BaseAddress + XIIC_RFD_REG_OFFSET, Temp);
+
+	if (InstancePtr->Options & XII_SEND_10_BIT_OPTION) {
+		/* Send the 1st and 2nd byte of the 10 bit address of a write
+		 * operation, write because it's a 10 bit address
+		 */
+		XIic_mSend10BitAddrByte1(InstancePtr->AddrOfSlave,
+					 XIIC_WRITE_OPERATION);
+		XIic_mSend10BitAddrByte2(InstancePtr->AddrOfSlave);
+
+		/* Set flag to indicate the next byte of the address needs to be
+		 * send, clear and enable tx empty interrupt
+		 */
+		InstancePtr->TxAddrMode = XIIC_TX_ADDR_MSTR_RECV_MASK;
+		XIic_mClearEnableIntr(InstancePtr->BaseAddress,
+				      XIIC_INTR_TX_EMPTY_MASK);
+	}
+	else {
+		/* 7 bit slave address, send the address for a read operation
+		 * and set the state to indicate the address has been sent
+		 */
+		XIic_mSend7BitAddr(InstancePtr->AddrOfSlave,
+				   XIIC_READ_OPERATION);
+		InstancePtr->TxAddrMode = XIIC_TX_ADDR_SENT;
+	}
+
+	/* Tx error is enabled incase the address (7 or 10) has no device to answer
+	 * with Ack. When only one byte of data, must set NO ACK before address goes
+	 * out therefore Tx error must not be enabled as it will go off immediately
+	 * and the Rx full interrupt will be checked.  If full, then the one byte
+	 * was received and the Tx error will be disabled without sending an error
+	 * callback msg.
+	 */
+	XIic_mClearEnableIntr(InstancePtr->BaseAddress,
+			      XIIC_INTR_TX_ERROR_MASK);
+
+	/*  When repeated start not used, MSMS gets set after putting data
+	 *  in Tx reg. Start Master Rx by setting CR Bits MSMS to Master and
+	 *  msg direction.
+	 */
+	CntlReg = XIo_In8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET);
+	if ((CntlReg & XIIC_CR_MSMS_MASK) == 0) {
+		CntlReg |= XIIC_CR_MSMS_MASK;
+		XIic_mSetControlRegister(InstancePtr, CntlReg, ByteCount);
+		XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET,
+			 CntlReg);
+	}
+
+	XIic_mExitCriticalRegion(InstancePtr->BaseAddress);
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************
+*
+* This function checks to see if the IIC bus is busy.  If so, it will enable
+* the bus not busy interrupt such that the driver is notified when the bus
+* is no longer busy.
+*
+* @param    InstancePtr points to the Iic instance to be worked on.
+*
+* @return
+*
+* - FALSE indicates the IIC bus is not busy.
+* - TRUE indicates the bus was in use and that the BusNotBusy
+*   interrupt is enabled which will update the EventStatus when the bus is no
+*   longer busy.
+*
+* @note
+*
+* None
+*
+******************************************************************************/
+static int IsBusBusy(XIic * InstancePtr)
+{
+	u8 ControlReg;
+	u8 StatusReg;
+
+	ControlReg = XIo_In8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET);
+	StatusReg = XIo_In8(InstancePtr->BaseAddress + XIIC_SR_REG_OFFSET);
+
+	/* If this device is already master of the bus as when using the repeated
+	 * start and the bus is busy setup to wait for it to not be busy
+	 */
+	if (((ControlReg & XIIC_CR_MSMS_MASK) == 0) &&	/* not master */
+	    (StatusReg & XIIC_SR_BUS_BUSY_MASK)) {	/* is busy    */
+		/* The bus is busy, clear pending BNB interrupt incase previously set
+		 * and then enable BusNotBusy interrupt
+		 */
+		InstancePtr->BNBOnly = TRUE;
+		XIic_mClearEnableIntr(InstancePtr->BaseAddress,
+				      XIIC_INTR_BNB_MASK);
+		InstancePtr->Stats.BusBusy++;
+
+		return TRUE;
+	}
+
+	return FALSE;
+}
+
+/******************************************************************************
+*
+* This function sends the proper byte of the address as well as generate the
+* proper address bit fields depending on the address byte required and the
+* direction of the data (write or read).
+*
+* A master receiving has the restriction that the direction must be switched
+* from write to read when the third address byte is transmitted.
+* For the last byte of the 10 bit address, repeated start must be set prior
+* to writing the address. If repeated start options is enabled, the
+* control register is written before the address is written to the tx reg.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* This function does read/modify/write to the device control register. Calling
+* functions must ensure critical sections are used.
+*
+******************************************************************************/
+static void SendSlaveAddr(XIic * InstancePtr)
+{
+	u8 CRreg;
+
+	/* Set the control register for Master Receive, repeated start must be set
+	 * before writing the address, MSMS should be already set, don't set here
+	 * so if arbitration is lost or some other reason we don't want MSMS set
+	 * incase of error
+	 */
+	CRreg = XIo_In8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET);
+
+	CRreg |= XIIC_CR_REPEATED_START_MASK;
+	CRreg &= ~XIIC_CR_DIR_IS_TX_MASK;
+
+	XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET, CRreg);
+
+	/* Send the 1st byte of the 10 bit address as a read operation, enable the
+	 * receive interrupt to know when data is received, assuming that the
+	 * receive FIFO threshold has been previously set
+	 */
+	XIic_mSend10BitAddrByte1(InstancePtr->AddrOfSlave, XIIC_READ_OPERATION);
+
+	XIic_mClearEnableIntr(InstancePtr->BaseAddress, XIIC_INTR_RX_FULL_MASK);
+}
+
+/******************************************************************************
+*
+* When the IIC Tx FIFO/register goes empty, this routine is called by the
+* interrupt service routine to fill the transmit FIFO with data to be sent.
+*
+* This function also is called by the Tx  empty interrupt as the data handling
+* is identical when you don't assume the FIFO is empty but use the Tx_FIFO_OCY
+* register to indicate the available free FIFO bytes.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+static void SendMasterData(XIic * InstancePtr)
+{
+	u8 CntlReg;
+
+	/* The device is a master on the bus.  If there is still more address bytes
+	 * to send when in master receive operation and the slave device is 10 bit
+	 * addressed. This requires the lower 7 bits of address to be resent when
+	 * the mode switches to Read instead of write (while sending addresses).
+	 */
+	if (InstancePtr->TxAddrMode & XIIC_TX_ADDR_MSTR_RECV_MASK) {
+		/* Send the 1st byte of the slave address in the read operation
+		 * and change the state to indicate this has been done
+		 */
+		SendSlaveAddr(InstancePtr);
+		InstancePtr->TxAddrMode = XIIC_TX_ADDR_SENT;
+	}
+
+	/* In between 1st and last byte of message, fill the FIFO with more data
+	 * to send, disable the 1/2 empty interrupt based upon data left to send
+	 */
+	else if (InstancePtr->SendByteCount > 1) {
+		XIic_TransmitFifoFill(InstancePtr, XIIC_MASTER_ROLE);
+
+		if (InstancePtr->SendByteCount < 2) {
+			XIic_mDisableIntr(InstancePtr->BaseAddress,
+					  XIIC_INTR_TX_HALF_MASK);
+		}
+	}
+	/*
+	 * If there is only one byte left to send, processing differs between
+	 * repeated start and normal messages
+	 */
+	else if (InstancePtr->SendByteCount == 1) {
+		/* When using repeated start, another interrupt is expected after the
+		 * last byte has been sent, so the message is not done yet
+		 */
+		if (InstancePtr->Options & XII_REPEATED_START_OPTION) {
+			XIic_mWriteSendByte(InstancePtr);
+		}
+
+		/* When not using repeated start, the stop condition must be generated
+		 * after the last byte is written. The bus is throttled waiting for the last
+		 * byte.
+		 */
+		else {
+			/* Set the stop condition before sending the last byte of data so that
+			 * the stop condition will be generated immediately following the data
+			 * another transmit interrupt is not expected so the message is done
+			 */
+
+			CntlReg =
+				XIo_In8(InstancePtr->BaseAddress +
+					XIIC_CR_REG_OFFSET);
+			CntlReg &= ~XIIC_CR_MSMS_MASK;
+			XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET,
+				 CntlReg);
+
+			XIic_mWriteSendByte(InstancePtr);
+
+			/* Wait for bus to not be busy before declaring message has
+			 * been sent for the no repeated start operation. The callback
+			 * will be called from the BusNotBusy part of the Interrupt
+			 * handler to ensure that the message is completely sent.
+			 * Disable the TX interrupts and enable the BNB interrupt
+			 */
+
+			InstancePtr->BNBOnly = FALSE;
+			XIic_mDisableIntr(InstancePtr->BaseAddress,
+					  XIIC_TX_INTERRUPTS);
+			XIic_mEnableIntr(InstancePtr->BaseAddress,
+					 XIIC_INTR_BNB_MASK);
+
+		}
+	}
+	else {
+		if (InstancePtr->Options & XII_REPEATED_START_OPTION) {
+			/* The message being sent has completed. When using repeated start
+			 * with no more bytes to send repeated start needs to be set in
+			 * the control register so that the bus will still be held by this
+			 * master
+			 */
+
+			CntlReg =
+				XIo_In8(InstancePtr->BaseAddress +
+					XIIC_CR_REG_OFFSET);
+			CntlReg |= XIIC_CR_REPEATED_START_MASK;
+			XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET,
+				 CntlReg);
+
+			/* If the message that was being sent has finished, disable all
+			 *transmit interrupts and call the callback that was setup to
+			 * indicate the message was sent, with 0 bytes remaining
+			 */
+
+			XIic_mDisableIntr(InstancePtr->BaseAddress,
+					  XIIC_TX_INTERRUPTS);
+			InstancePtr->SendHandler(InstancePtr->SendCallBackRef,
+						 0);
+		}
+	}
+
+	return;
+}
+
+/*****************************************************************************/
+/**
+*
+* This function is called when the receive register is full. The number
+* of bytes received to cause the interrupt is adjustable using the Receive FIFO
+* Depth register. The number of bytes in the register is read in the Receive
+* FIFO occupancy register. Both these registers are zero based values (0-15)
+* such that a value of zero indicates 1 byte.
+*
+* For a Master Receiver to properly signal the end of a message, the data must
+* be read in up to the message length - 1, where control register bits will be
+* set for bus controls to occur on reading of the last byte.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+static void RecvMasterData(XIic * InstancePtr)
+{
+	u8 LoopCnt;
+	int BytesInFifo;
+	int BytesToRead;
+	u8 CntlReg;
+
+	/* Device is a master receiving, get the contents of the control register
+	 * and determine the number of bytes in fifo to be read out
+	 */
+	CntlReg = XIo_In8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET);
+	BytesInFifo = XIo_In8(InstancePtr->BaseAddress + XIIC_RFO_REG_OFFSET)
+		+ 1;
+
+	/* If data in FIFO holds all data to be retrieved - 1, set NOACK and
+	 * disable the tx error
+	 */
+	if ((InstancePtr->RecvByteCount - BytesInFifo) == 1) {
+		/* Disable tx error interrupt to prevent interrupt
+		 * as this device will cause it when it set NO ACK next
+		 */
+		XIic_mDisableIntr(InstancePtr->BaseAddress,
+				  XIIC_INTR_TX_ERROR_MASK);
+		XIic_mClearIntr(InstancePtr->BaseAddress,
+				XIIC_INTR_TX_ERROR_MASK);
+
+		/* Write control reg with NO ACK allowing last byte to
+		 * have the No ack set to indicate to slave last byte read.
+		 */
+		XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET,
+			 (CntlReg | XIIC_CR_NO_ACK_MASK));
+
+		/* Read one byte to clear a place for the last byte to be read
+		 * which will set the NO ACK
+		 */
+		XIic_mReadRecvByte(InstancePtr);
+	}
+
+	/* If data in FIFO is all the data to be received then get the data
+	 * and also leave the device in a good state for the next transaction
+	 */
+	else if ((InstancePtr->RecvByteCount - BytesInFifo) == 0) {
+		/* If repeated start option is off then the master should stop
+		 * using the bus, otherwise hold the bus, setting repeated start
+		 * stops the slave from transmitting data when the FIFO is read
+		 */
+		if ((InstancePtr->Options & XII_REPEATED_START_OPTION) == 0) {
+			CntlReg &= ~XIIC_CR_MSMS_MASK;
+		}
+		else {
+			CntlReg |= XIIC_CR_REPEATED_START_MASK;
+		}
+		XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET,
+			 CntlReg);
+
+		/* Read data from the FIFO then set zero based FIFO read depth for a byte
+		 */
+		for (LoopCnt = 0; LoopCnt < BytesInFifo; LoopCnt++) {
+			XIic_mReadRecvByte(InstancePtr);
+		}
+		XIo_Out8(InstancePtr->BaseAddress + XIIC_RFD_REG_OFFSET, 0);
+
+		/* Disable Rx full interrupt and write the control reg with ACK allowing
+		 * next byte sent to be acknowledged automatically
+		 */
+		XIic_mDisableIntr(InstancePtr->BaseAddress,
+				  XIIC_INTR_RX_FULL_MASK);
+
+		XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET,
+			 (CntlReg & ~XIIC_CR_NO_ACK_MASK));
+
+		/* Send notification of msg Rx complete in RecvHandler callback
+		 */
+		InstancePtr->RecvHandler(InstancePtr->RecvCallBackRef, 0);
+	}
+	else {
+		/* Fifo data not at n-1, read all but the last byte of data from the
+		 * slave, if more than a FIFO full yet to receive read a FIFO full
+		 */
+		BytesToRead = InstancePtr->RecvByteCount - BytesInFifo - 1;
+		if (BytesToRead > IIC_RX_FIFO_DEPTH) {
+			BytesToRead = IIC_RX_FIFO_DEPTH;
+		}
+
+		/* Read in data from the FIFO */
+
+		for (LoopCnt = 0; LoopCnt < BytesToRead; LoopCnt++) {
+			XIic_mReadRecvByte(InstancePtr);
+		}
+	}
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_options.c linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_options.c
--- linux-2.6.31.12/drivers/i2c/algos/xilinx_iic/xiic_options.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/i2c/algos/xilinx_iic/xiic_options.c	2010-08-08 17:40:16.488014049 +0200
@@ -0,0 +1,172 @@
+/* $Id: xiic_options.c,v 1.1 2007/12/03 15:44:58 meinelte Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xiic_options.c
+*
+* Contains options functions for the XIic component. This file is not required
+* unless the functions in this file are called.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- --- ------- -----------------------------------------------
+* 1.01b jhl 3/26/02 repartioned the driver
+* 1.01c ecm 12/05/02 new rev
+* 1.13a wgr  03/22/07 Converted to new coding style.
+* </pre>
+*
+****************************************************************************/
+
+/***************************** Include Files *******************************/
+
+#include "xiic.h"
+#include "xiic_i.h"
+#include "xio.h"
+
+/************************** Constant Definitions ***************************/
+
+
+/**************************** Type Definitions *****************************/
+
+
+/***************** Macros (Inline Functions) Definitions *******************/
+
+
+/************************** Function Prototypes ****************************/
+
+
+/************************** Variable Definitions **************************/
+
+
+/*****************************************************************************/
+/**
+*
+* This function sets the options for the IIC device driver. The options control
+* how the device behaves relative to the IIC bus. If an option applies to
+* how messages are sent or received on the IIC bus, it must be set prior to
+* calling functions which send or receive data.
+*
+* To set multiple options, the values must be ORed together. To not change
+* existing options, read/modify/write with the current options using
+* XIic_GetOptions().
+*
+* <b>USAGE EXAMPLE:</b>
+*
+* Read/modify/write to enable repeated start:
+* <pre>
+*   u8 Options;
+*   Options = XIic_GetOptions(&Iic);
+*   XIic_SetOptions(&Iic, Options | XII_REPEATED_START_OPTION);
+* </pre>
+*
+* Disabling General Call:
+* <pre>
+*   Options = XIic_GetOptions(&Iic);
+*   XIic_SetOptions(&Iic, Options &= ~XII_GENERAL_CALL_OPTION);
+* </pre>
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @param    NewOptions are the options to be set.  See xiic.h for a list of
+*           the available options.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* Sending or receiving messages with repeated start enabled, and then
+* disabling repeated start, will not take effect until another master
+* transaction is completed. i.e. After using repeated start, the bus will
+* continue to be throttled after repeated start is disabled until a master
+* transaction occurs allowing the IIC to release the bus.
+* <br><br>
+* Options enabled will have a 1 in its appropriate bit position.
+*
+****************************************************************************/
+void XIic_SetOptions(XIic * InstancePtr, u32 NewOptions)
+{
+	u8 CntlReg;
+
+	XASSERT_VOID(InstancePtr != NULL);
+
+	XIic_mEnterCriticalRegion(InstancePtr->BaseAddress);
+
+	/* Update the options in the instance and get the contents of the control
+	 * register such that the general call option can be modified
+	 */
+	InstancePtr->Options = NewOptions;
+	CntlReg = XIo_In8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET);
+
+	/* The general call option is the only option that maps directly to
+	 * a hardware register feature
+	 */
+	if (NewOptions & XII_GENERAL_CALL_OPTION) {
+		CntlReg |= XIIC_CR_GENERAL_CALL_MASK;
+	}
+	else {
+		CntlReg &= ~XIIC_CR_GENERAL_CALL_MASK;
+	}
+
+	/* Write the new control register value to the register */
+
+	XIo_Out8(InstancePtr->BaseAddress + XIIC_CR_REG_OFFSET, CntlReg);
+
+	XIic_mExitCriticalRegion(InstancePtr->BaseAddress);
+}
+
+/*****************************************************************************/
+/**
+*
+* This function gets the current options for the IIC device. Options control
+* the how the device behaves on the IIC bus. See SetOptions for more information
+* on options.
+*
+* @param    InstancePtr is a pointer to the XIic instance to be worked on.
+*
+* @return
+*
+* The options of the IIC device. See xiic.h for a list of available options.
+*
+* @note
+*
+* Options enabled will have a 1 in its appropriate bit position.
+*
+****************************************************************************/
+u32 XIic_GetOptions(XIic * InstancePtr)
+{
+	XASSERT_NONVOID(InstancePtr != NULL);
+
+	return InstancePtr->Options;
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/Kconfig linux-2.6.31.12-petalinux/drivers/Kconfig
--- linux-2.6.31.12/drivers/Kconfig	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/Kconfig	2010-08-08 17:26:20.344406697 +0200
@@ -104,6 +104,8 @@ source "drivers/dca/Kconfig"
 
 source "drivers/auxdisplay/Kconfig"
 
+source "drivers/xilinx_common/Kconfig"
+
 source "drivers/uio/Kconfig"
 
 source "drivers/vlynq/Kconfig"
diff -purN --exclude=.git linux-2.6.31.12/drivers/Makefile linux-2.6.31.12-petalinux/drivers/Makefile
--- linux-2.6.31.12/drivers/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/Makefile	2010-08-08 17:26:20.344406697 +0200
@@ -110,3 +110,5 @@ obj-$(CONFIG_VLYNQ)		+= vlynq/
 obj-$(CONFIG_STAGING)		+= staging/
 obj-y				+= platform/
 obj-y				+= ieee802154/
+
+obj-y				+= xilinx_common/
diff -purN --exclude=.git linux-2.6.31.12/drivers/mtd/devices/m25p80.c linux-2.6.31.12-petalinux/drivers/mtd/devices/m25p80.c
--- linux-2.6.31.12/drivers/mtd/devices/m25p80.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/mtd/devices/m25p80.c	2010-08-08 17:40:16.533535269 +0200
@@ -479,6 +479,7 @@ struct flash_info {
 
 	u16		flags;
 #define	SECT_4K		0x01		/* OPCODE_BE_4K works uniformly */
+#define	SECT_32K	0x02		/* OPCODE_BE_32K */
 };
 
 
@@ -546,6 +547,12 @@ static struct flash_info __devinitdata m
 	{ "w25x16", 0xef3015, 0, 64 * 1024, 32, SECT_4K, },
 	{ "w25x32", 0xef3016, 0, 64 * 1024, 64, SECT_4K, },
 	{ "w25x64", 0xef3017, 0, 64 * 1024, 128, SECT_4K, },
+	/* Winbond -- w25q "blocks" are 64K, "sectors" are 32KiB */
+	/* w25q64 supports 4KiB, 32KiB and 64KiB sectors erase size. */
+	/* To support JFFS2, the minimum erase size is 8KiB(>4KiB). */
+	/* And thus, the sector size of w25q64 is set to 32KiB for */
+	/* JFFS2 support. */
+	{ "w25q64", 0xef4017, 0, 64 * 1024, 128, SECT_32K, },
 };
 
 static struct flash_info *__devinit jedec_probe(struct spi_device *spi)
@@ -673,6 +680,9 @@ static int __devinit m25p_probe(struct s
 	if (info->flags & SECT_4K) {
 		flash->erase_opcode = OPCODE_BE_4K;
 		flash->mtd.erasesize = 4096;
+	} else if (info->flags & SECT_32K) {
+		flash->erase_opcode = OPCODE_BE_32K;
+		flash->mtd.erasesize = 32768;
 	} else {
 		flash->erase_opcode = OPCODE_SE;
 		flash->mtd.erasesize = info->sector_size;
@@ -710,7 +720,11 @@ static int __devinit m25p_probe(struct s
 		struct mtd_partition	*parts = NULL;
 		int			nr_parts = 0;
 
-		if (mtd_has_cmdlinepart()) {
+#ifdef CONFIG_MTD_OF_PARTS
+		nr_parts = of_mtd_parse_partitions(&spi->dev, spi->dev.archdata.of_node,&parts); 
+#endif
+
+		if (nr_parts <= 0 && mtd_has_cmdlinepart()) {
 			static const char *part_probes[]
 					= { "cmdlinepart", NULL, };
 
diff -purN --exclude=.git linux-2.6.31.12/drivers/mtd/Kconfig linux-2.6.31.12-petalinux/drivers/mtd/Kconfig
--- linux-2.6.31.12/drivers/mtd/Kconfig	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/mtd/Kconfig	2010-08-08 17:26:23.472645754 +0200
@@ -159,7 +159,7 @@ config MTD_AFS_PARTS
 
 config MTD_OF_PARTS
 	tristate "Flash partition map based on OF description"
-	depends on PPC_OF && MTD_PARTITIONS
+	depends on (MICROBLAZE || PPC_OF) && MTD_PARTITIONS
 	help
 	  This provides a partition parsing function which derives
 	  the partition map from the children of the flash node,
diff -purN --exclude=.git linux-2.6.31.12/drivers/mtd/maps/Kconfig linux-2.6.31.12-petalinux/drivers/mtd/maps/Kconfig
--- linux-2.6.31.12/drivers/mtd/maps/Kconfig	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/mtd/maps/Kconfig	2010-08-08 17:26:23.484786124 +0200
@@ -74,7 +74,7 @@ config MTD_PHYSMAP_BANKWIDTH
 
 config MTD_PHYSMAP_OF
 	tristate "Flash device in physical memory map based on OF description"
-	depends on PPC_OF && (MTD_CFI || MTD_JEDECPROBE || MTD_ROM)
+	depends on (MICROBLAZE || PPC_OF) && (MTD_CFI || MTD_JEDECPROBE || MTD_ROM)
 	help
 	  This provides a 'mapping' driver which allows the NOR Flash and
 	  ROM driver code to communicate with chips which are mapped
diff -purN --exclude=.git linux-2.6.31.12/drivers/net/Kconfig linux-2.6.31.12-petalinux/drivers/net/Kconfig
--- linux-2.6.31.12/drivers/net/Kconfig	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/net/Kconfig	2010-08-08 17:40:16.537496107 +0200
@@ -1928,6 +1928,13 @@ config ATL2
 	  To compile this driver as a module, choose M here.  The module
 	  will be called atl2.
 
+config XILINX_EMACLITE
+	tristate "Xilinx 10/100 Ethernet Lite support"
+	depends on PPC32 || MICROBLAZE
+	select PHYLIB
+	help
+	  This driver supports the 10/100 Ethernet Lite from Xilinx.
+
 source "drivers/net/fs_enet/Kconfig"
 
 endif # NET_ETHERNET
@@ -2464,6 +2471,41 @@ config S6GMAC
 	  To compile this driver as a module, choose M here. The module
 	  will be called s6gmac.
 
+config XILINX_LLTEMAC
+	tristate "Xilinx LLTEMAC 10/100/1000 Ethernet MAC driver"
+	depends on XILINX_DRIVERS
+	select XILINX_EDK
+	select NEED_XILINX_LLDMA
+	help
+	  This driver supports the 10/100/1000 LLTEMAC.
+
+choice
+	prompt "Xilinx LLTEMAC PHY Support"
+	default XILINX_LLTEMAC_MARVELL_88E1111_GMII
+	
+config XILINX_LLTEMAC_MARVELL_88E1111_RGMII
+	bool "MARVELL 88E1111 using RGMII"
+   help
+	  This phy is used by many Xilinx boards.  This option includes
+	  code for enabling RGMII over copper.
+
+config XILINX_LLTEMAC_MARVELL_88E1111_GMII
+	bool "MARVELL 88E1111 using GMII"
+   help
+	  This phy is used by many Xilinx boards.  This option includes
+	  code for enabling GMII over copper, and for setting the correct
+	  speed based on whatever the phy is able to autonegotiate.  This is
+	  usually the best option to use on ML40x and ML50x boards.
+
+config XILINX_LLTEMAC_MARVELL_88E1111_MII
+	bool "MARVELL 88E1111 using MII or other PHY"
+   help
+	  If your physical interface is not covered by the other
+	  selections, then choose this option.  This option includes generic
+	  speed autonegotation code.
+
+endchoice
+
 endif # NETDEV_1000
 
 #
diff -purN --exclude=.git linux-2.6.31.12/drivers/net/Makefile linux-2.6.31.12-petalinux/drivers/net/Makefile
--- linux-2.6.31.12/drivers/net/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/net/Makefile	2010-08-08 17:26:23.536617574 +0200
@@ -280,3 +280,7 @@ obj-$(CONFIG_VIRTIO_NET) += virtio_net.o
 obj-$(CONFIG_SFC) += sfc/
 
 obj-$(CONFIG_WIMAX) += wimax/
+
+obj-$(CONFIG_XILINX_EMACLITE) += xilinx_emaclite.o
+obj-$(CONFIG_XILINX_LLTEMAC) += xilinx_lltemac/
+
diff -purN --exclude=.git linux-2.6.31.12/drivers/net/xilinx_emaclite.c linux-2.6.31.12-petalinux/drivers/net/xilinx_emaclite.c
--- linux-2.6.31.12/drivers/net/xilinx_emaclite.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/net/xilinx_emaclite.c	2010-08-08 17:40:16.568735903 +0200
@@ -0,0 +1,1329 @@
+/*
+ * Xilinx EmacLite Linux driver for the Xilinx Ethernet MAC Lite device.
+ *
+ * This is a new flat driver which is based on the original emac_lite
+ * driver from John Williams <john.williams@petalogix.com>.
+ *
+ * 2007-2009 (c) Xilinx, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ */
+
+#include <linux/module.h>
+#include <linux/uaccess.h>
+#include <linux/init.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/io.h>
+
+#include <linux/of_device.h>
+#include <linux/of_platform.h>
+#include <linux/of_mdio.h>
+#include <linux/phy.h>
+
+#define DRIVER_NAME "xilinx_emaclite"
+
+/* Register offsets for the EmacLite Core */
+#define XEL_TXBUFF_OFFSET 	0x0		/* Transmit Buffer */
+#define XEL_MDIOADDR_OFFSET	0x07E4		/* MDIO Address Register */
+#define XEL_MDIOWR_OFFSET	0x07E8		/* MDIO Write Data Register */
+#define XEL_MDIORD_OFFSET	0x07EC		/* MDIO Read Data Register */
+#define XEL_MDIOCTRL_OFFSET	0x07F0		/* MDIO Control Register */
+#define XEL_GIER_OFFSET		0x07F8		/* GIE Register */
+#define XEL_TSR_OFFSET		0x07FC		/* Tx status */
+#define XEL_TPLR_OFFSET		0x07F4		/* Tx packet length */
+
+#define XEL_RXBUFF_OFFSET	0x1000		/* Receive Buffer */
+#define XEL_RPLR_OFFSET		0x100C		/* Rx packet length */
+#define XEL_RSR_OFFSET		0x17FC		/* Rx status */
+
+#define XEL_BUFFER_OFFSET	0x0800		/* Next Tx/Rx buffer's offset */
+
+/* MDIO Address Register Bit Masks */
+#define XEL_MDIOADDR_REGADR_MASK  0x0000001F	/* Register Address */
+#define XEL_MDIOADDR_PHYADR_MASK  0x000003E0	/* PHY Address */
+#define XEL_MDIOADDR_PHYADR_SHIFT 5
+#define XEL_MDIOADDR_OP_MASK	  0x00000400	/* RD/WR Operation */
+
+/* MDIO Write Data Register Bit Masks */
+#define XEL_MDIOWR_WRDATA_MASK	  0x0000FFFF	/* Data to be Written */
+
+/* MDIO Read Data Register Bit Masks */
+#define XEL_MDIORD_RDDATA_MASK	  0x0000FFFF	/* Data to be Read */
+
+/* MDIO Control Register Bit Masks */
+#define XEL_MDIOCTRL_MDIOSTS_MASK 0x00000001	/* MDIO Status Mask */
+#define XEL_MDIOCTRL_MDIOEN_MASK  0x00000008	/* MDIO Enable */
+
+/* Global Interrupt Enable Register (GIER) Bit Masks */
+#define XEL_GIER_GIE_MASK	0x80000000 	/* Global Enable */
+
+/* Transmit Status Register (TSR) Bit Masks */
+#define XEL_TSR_XMIT_BUSY_MASK	 0x00000001 	/* Tx complete */
+#define XEL_TSR_PROGRAM_MASK	 0x00000002 	/* Program the MAC address */
+#define XEL_TSR_XMIT_IE_MASK	 0x00000008 	/* Tx interrupt enable bit */
+#define XEL_TSR_XMIT_ACTIVE_MASK 0x80000000 	/* Buffer is active, SW bit
+						 * only. This is not documented
+						 * in the HW spec */
+
+/* Define for programming the MAC address into the EmacLite */
+#define XEL_TSR_PROG_MAC_ADDR	(XEL_TSR_XMIT_BUSY_MASK | XEL_TSR_PROGRAM_MASK)
+
+/* Receive Status Register (RSR) */
+#define XEL_RSR_RECV_DONE_MASK	0x00000001 	/* Rx complete */
+#define XEL_RSR_RECV_IE_MASK	0x00000008 	/* Rx interrupt enable bit */
+
+/* Transmit Packet Length Register (TPLR) */
+#define XEL_TPLR_LENGTH_MASK	0x0000FFFF 	/* Tx packet length */
+
+/* Receive Packet Length Register (RPLR) */
+#define XEL_RPLR_LENGTH_MASK	0x0000FFFF 	/* Rx packet length */
+
+#define XEL_HEADER_OFFSET	12 		/* Offset to length field */
+#define XEL_HEADER_SHIFT	16 		/* Shift value for length */
+
+/* General Ethernet Definitions */
+#define XEL_ARP_PACKET_SIZE		28 	/* Max ARP packet size */
+#define XEL_HEADER_IP_LENGTH_OFFSET	16 	/* IP Length Offset */
+
+
+
+#define TX_TIMEOUT		(60*HZ)		/* Tx timeout is 60 seconds. */
+#define ALIGNMENT		4
+
+/* BUFFER_ALIGN(adr) calculates the number of bytes to the next alignment. */
+#define BUFFER_ALIGN(adr) ((ALIGNMENT - ((u32) adr)) % ALIGNMENT)
+
+/**
+ * struct net_local - Our private per device data
+ * @ndev:		instance of the network device
+ * @tx_ping_pong:	indicates whether Tx Pong buffer is configured in HW
+ * @rx_ping_pong:	indicates whether Rx Pong buffer is configured in HW
+ * @next_tx_buf_to_use:	next Tx buffer to write to
+ * @next_rx_buf_to_use:	next Rx buffer to read from
+ * @base_addr:		base address of the Emaclite device
+ * @reset_lock:		lock used for synchronization
+ * @deferred_skb:	holds an skb (for transmission at a later time) when the
+ *			Tx buffer is not free
+ * @phy_dev:		pointer to the PHY device
+ * @phy_node:		pointer to the PHY device node
+ * @mii_bus:		pointer to the MII bus
+ * @mdio_irqs:		IRQs table for MDIO bus
+ * @last_link:		last link status
+ * @has_mdio:		indicates whether MDIO is included in the HW
+ */
+struct net_local {
+
+	struct net_device *ndev;
+
+	bool tx_ping_pong;
+	bool rx_ping_pong;
+	u32 next_tx_buf_to_use;
+	u32 next_rx_buf_to_use;
+	void __iomem *base_addr;
+
+	spinlock_t reset_lock;
+	struct sk_buff *deferred_skb;
+
+	struct phy_device *phy_dev;
+	struct device_node *phy_node;
+
+	struct mii_bus *mii_bus;
+	int mdio_irqs[PHY_MAX_ADDR];
+
+	int last_link;
+	bool has_mdio;
+};
+
+
+/*************************/
+/* EmacLite driver calls */
+/*************************/
+
+/**
+ * xemaclite_enable_interrupts - Enable the interrupts for the EmacLite device
+ * @drvdata:	Pointer to the Emaclite device private data
+ *
+ * This function enables the Tx and Rx interrupts for the Emaclite device along
+ * with the Global Interrupt Enable.
+ */
+static void xemaclite_enable_interrupts(struct net_local *drvdata)
+{
+	u32 reg_data;
+
+	/* Enable the Tx interrupts for the first Buffer */
+	reg_data = in_be32(drvdata->base_addr + XEL_TSR_OFFSET);
+	out_be32(drvdata->base_addr + XEL_TSR_OFFSET,
+		 reg_data | XEL_TSR_XMIT_IE_MASK);
+
+	/* Enable the Tx interrupts for the second Buffer if
+	 * configured in HW */
+	if (drvdata->tx_ping_pong != 0) {
+		reg_data = in_be32(drvdata->base_addr +
+				   XEL_BUFFER_OFFSET + XEL_TSR_OFFSET);
+		out_be32(drvdata->base_addr + XEL_BUFFER_OFFSET +
+			 XEL_TSR_OFFSET,
+			 reg_data | XEL_TSR_XMIT_IE_MASK);
+	}
+
+	/* Enable the Rx interrupts for the first buffer */
+	out_be32(drvdata->base_addr + XEL_RSR_OFFSET,
+		 XEL_RSR_RECV_IE_MASK);
+
+	/* Enable the Rx interrupts for the second Buffer if
+	 * configured in HW */
+	if (drvdata->rx_ping_pong != 0) {
+		out_be32(drvdata->base_addr + XEL_BUFFER_OFFSET +
+			 XEL_RSR_OFFSET,
+			 XEL_RSR_RECV_IE_MASK);
+	}
+
+	/* Enable the Global Interrupt Enable */
+	out_be32(drvdata->base_addr + XEL_GIER_OFFSET, XEL_GIER_GIE_MASK);
+}
+
+/**
+ * xemaclite_disable_interrupts - Disable the interrupts for the EmacLite device
+ * @drvdata:	Pointer to the Emaclite device private data
+ *
+ * This function disables the Tx and Rx interrupts for the Emaclite device,
+ * along with the Global Interrupt Enable.
+ */
+static void xemaclite_disable_interrupts(struct net_local *drvdata)
+{
+	u32 reg_data;
+
+	/* Disable the Global Interrupt Enable */
+	out_be32(drvdata->base_addr + XEL_GIER_OFFSET, XEL_GIER_GIE_MASK);
+
+	/* Disable the Tx interrupts for the first buffer */
+	reg_data = in_be32(drvdata->base_addr + XEL_TSR_OFFSET);
+	out_be32(drvdata->base_addr + XEL_TSR_OFFSET,
+		 reg_data & (~XEL_TSR_XMIT_IE_MASK));
+
+	/* Disable the Tx interrupts for the second Buffer
+	 * if configured in HW */
+	if (drvdata->tx_ping_pong != 0) {
+		reg_data = in_be32(drvdata->base_addr + XEL_BUFFER_OFFSET +
+				   XEL_TSR_OFFSET);
+		out_be32(drvdata->base_addr + XEL_BUFFER_OFFSET +
+			 XEL_TSR_OFFSET,
+			 reg_data & (~XEL_TSR_XMIT_IE_MASK));
+	}
+
+	/* Disable the Rx interrupts for the first buffer */
+	reg_data = in_be32(drvdata->base_addr + XEL_RSR_OFFSET);
+	out_be32(drvdata->base_addr + XEL_RSR_OFFSET,
+		 reg_data & (~XEL_RSR_RECV_IE_MASK));
+
+	/* Disable the Rx interrupts for the second buffer
+	 * if configured in HW */
+	if (drvdata->rx_ping_pong != 0) {
+
+		reg_data = in_be32(drvdata->base_addr + XEL_BUFFER_OFFSET +
+				   XEL_RSR_OFFSET);
+		out_be32(drvdata->base_addr + XEL_BUFFER_OFFSET +
+			 XEL_RSR_OFFSET,
+			 reg_data & (~XEL_RSR_RECV_IE_MASK));
+	}
+}
+
+/**
+ * xemaclite_aligned_write - Write from 16-bit aligned to 32-bit aligned address
+ * @src_ptr:	Void pointer to the 16-bit aligned source address
+ * @dest_ptr:	Pointer to the 32-bit aligned destination address
+ * @length:	Number bytes to write from source to destination
+ *
+ * This function writes data from a 16-bit aligned buffer to a 32-bit aligned
+ * address in the EmacLite device.
+ */
+static void xemaclite_aligned_write(void *src_ptr, u32 *dest_ptr,
+				    unsigned length)
+{
+	u32 align_buffer;
+	u32 *to_u32_ptr;
+	u16 *from_u16_ptr, *to_u16_ptr;
+
+	to_u32_ptr = dest_ptr;
+	from_u16_ptr = (u16 *) src_ptr;
+	align_buffer = 0;
+
+	for (; length > 3; length -= 4) {
+		to_u16_ptr = (u16 *) ((void *) &align_buffer);
+		*to_u16_ptr++ = *from_u16_ptr++;
+		*to_u16_ptr++ = *from_u16_ptr++;
+
+		/* Output a word */
+		*to_u32_ptr++ = align_buffer;
+	}
+	if (length) {
+		u8 *from_u8_ptr, *to_u8_ptr;
+
+		/* Set up to output the remaining data */
+		align_buffer = 0;
+		to_u8_ptr = (u8 *) &align_buffer;
+		from_u8_ptr = (u8 *) from_u16_ptr;
+
+		/* Output the remaining data */
+		for (; length > 0; length--)
+			*to_u8_ptr++ = *from_u8_ptr++;
+
+		*to_u32_ptr = align_buffer;
+	}
+}
+
+/**
+ * xemaclite_aligned_read - Read from 32-bit aligned to 16-bit aligned buffer
+ * @src_ptr:	Pointer to the 32-bit aligned source address
+ * @dest_ptr:	Pointer to the 16-bit aligned destination address
+ * @length:	Number bytes to read from source to destination
+ *
+ * This function reads data from a 32-bit aligned address in the EmacLite device
+ * to a 16-bit aligned buffer.
+ */
+static void xemaclite_aligned_read(u32 *src_ptr, u8 *dest_ptr,
+				   unsigned length)
+{
+	u16 *to_u16_ptr, *from_u16_ptr;
+	u32 *from_u32_ptr;
+	u32 align_buffer;
+
+	from_u32_ptr = src_ptr;
+	to_u16_ptr = (u16 *) dest_ptr;
+
+	for (; length > 3; length -= 4) {
+		/* Copy each word into the temporary buffer */
+		align_buffer = *from_u32_ptr++;
+		from_u16_ptr = (u16 *)&align_buffer;
+
+		/* Read data from source */
+		*to_u16_ptr++ = *from_u16_ptr++;
+		*to_u16_ptr++ = *from_u16_ptr++;
+	}
+
+	if (length) {
+		u8 *to_u8_ptr, *from_u8_ptr;
+
+		/* Set up to read the remaining data */
+		to_u8_ptr = (u8 *) to_u16_ptr;
+		align_buffer = *from_u32_ptr++;
+		from_u8_ptr = (u8 *) &align_buffer;
+
+		/* Read the remaining data */
+		for (; length > 0; length--)
+			*to_u8_ptr = *from_u8_ptr;
+	}
+}
+
+/**
+ * xemaclite_send_data - Send an Ethernet frame
+ * @drvdata:	Pointer to the Emaclite device private data
+ * @data:	Pointer to the data to be sent
+ * @byte_count:	Total frame size, including header
+ *
+ * This function checks if the Tx buffer of the Emaclite device is free to send
+ * data. If so, it fills the Tx buffer with data for transmission. Otherwise, it
+ * returns an error.
+ *
+ * Return:	0 upon success or -1 if the buffer(s) are full.
+ *
+ * Note:	The maximum Tx packet size can not be more than Ethernet header
+ *		(14 Bytes) + Maximum MTU (1500 bytes). This is excluding FCS.
+ */
+static int xemaclite_send_data(struct net_local *drvdata, u8 *data,
+			       unsigned int byte_count)
+{
+	u32 reg_data;
+	void __iomem *addr;
+
+	/* Determine the expected Tx buffer address */
+	addr = drvdata->base_addr + drvdata->next_tx_buf_to_use;
+
+	/* If the length is too large, truncate it */
+	if (byte_count > ETH_FRAME_LEN)
+		byte_count = ETH_FRAME_LEN;
+
+	/* Check if the expected buffer is available */
+	reg_data = in_be32(addr + XEL_TSR_OFFSET);
+	if ((reg_data & (XEL_TSR_XMIT_BUSY_MASK |
+	     XEL_TSR_XMIT_ACTIVE_MASK)) == 0) {
+
+		/* Switch to next buffer if configured */
+		if (drvdata->tx_ping_pong != 0)
+			drvdata->next_tx_buf_to_use ^= XEL_BUFFER_OFFSET;
+	} else if (drvdata->tx_ping_pong != 0) {
+		/* If the expected buffer is full, try the other buffer,
+		 * if it is configured in HW */
+
+		addr = (void __iomem __force *)((u32 __force)addr ^
+						 XEL_BUFFER_OFFSET);
+		reg_data = in_be32(addr + XEL_TSR_OFFSET);
+
+		if ((reg_data & (XEL_TSR_XMIT_BUSY_MASK |
+		     XEL_TSR_XMIT_ACTIVE_MASK)) != 0)
+			return -1; /* Buffers were full, return failure */
+	} else
+		return -1; /* Buffer was full, return failure */
+
+	/* Write the frame to the buffer */
+	xemaclite_aligned_write(data, (u32 __force *) addr, byte_count);
+
+	out_be32(addr + XEL_TPLR_OFFSET, (byte_count & XEL_TPLR_LENGTH_MASK));
+
+	/* Update the Tx Status Register to indicate that there is a
+	 * frame to send. Set the XEL_TSR_XMIT_ACTIVE_MASK flag which
+	 * is used by the interrupt handler to check whether a frame
+	 * has been transmitted */
+	reg_data = in_be32(addr + XEL_TSR_OFFSET);
+	reg_data |= (XEL_TSR_XMIT_BUSY_MASK | XEL_TSR_XMIT_ACTIVE_MASK);
+	out_be32(addr + XEL_TSR_OFFSET, reg_data);
+
+	return 0;
+}
+
+/**
+ * xemaclite_recv_data - Receive a frame
+ * @drvdata:	Pointer to the Emaclite device private data
+ * @data:	Address where the data is to be received
+ *
+ * This function is intended to be called from the interrupt context or
+ * with a wrapper which waits for the receive frame to be available.
+ *
+ * Return:	Total number of bytes received
+ */
+static u16 xemaclite_recv_data(struct net_local *drvdata, u8 *data)
+{
+	void __iomem *addr;
+	u16 length, proto_type;
+	u32 reg_data;
+
+	/* Determine the expected buffer address */
+	addr = (drvdata->base_addr + drvdata->next_rx_buf_to_use);
+
+	/* Verify which buffer has valid data */
+	reg_data = in_be32(addr + XEL_RSR_OFFSET);
+
+	if ((reg_data & XEL_RSR_RECV_DONE_MASK) == XEL_RSR_RECV_DONE_MASK) {
+		if (drvdata->rx_ping_pong != 0)
+			drvdata->next_rx_buf_to_use ^= XEL_BUFFER_OFFSET;
+	} else {
+		/* The instance is out of sync, try other buffer if other
+		 * buffer is configured, return 0 otherwise. If the instance is
+		 * out of sync, do not update the 'next_rx_buf_to_use' since it
+		 * will correct on subsequent calls */
+		if (drvdata->rx_ping_pong != 0)
+			addr = (void __iomem __force *)((u32 __force)addr ^
+							 XEL_BUFFER_OFFSET);
+		else
+			return 0;	/* No data was available */
+
+		/* Verify that buffer has valid data */
+		reg_data = in_be32(addr + XEL_RSR_OFFSET);
+		if ((reg_data & XEL_RSR_RECV_DONE_MASK) !=
+		     XEL_RSR_RECV_DONE_MASK)
+			return 0;	/* No data was available */
+	}
+
+	/* Get the protocol type of the ethernet frame that arrived */
+	proto_type = ((in_be32(addr + XEL_HEADER_OFFSET +
+			XEL_RXBUFF_OFFSET) >> XEL_HEADER_SHIFT) &
+			XEL_RPLR_LENGTH_MASK);
+
+	/* Check if received ethernet frame is a raw ethernet frame
+	 * or an IP packet or an ARP packet */
+	if (proto_type > (ETH_FRAME_LEN + ETH_FCS_LEN)) {
+
+		if (proto_type == ETH_P_IP) {
+			length = ((in_be32(addr +
+					XEL_HEADER_IP_LENGTH_OFFSET +
+					XEL_RXBUFF_OFFSET) >>
+					XEL_HEADER_SHIFT) &
+					XEL_RPLR_LENGTH_MASK);
+			length += ETH_HLEN + ETH_FCS_LEN;
+
+		} else if (proto_type == ETH_P_ARP)
+			length = XEL_ARP_PACKET_SIZE + ETH_HLEN + ETH_FCS_LEN;
+		else
+			/* Field contains type other than IP or ARP, use max
+			 * frame size and let user parse it */
+			length = ETH_FRAME_LEN + ETH_FCS_LEN;
+	} else
+		/* Use the length in the frame, plus the header and trailer */
+		length = proto_type + ETH_HLEN + ETH_FCS_LEN;
+
+	/* Read from the EmacLite device */
+	xemaclite_aligned_read((u32 __force *) (addr + XEL_RXBUFF_OFFSET),
+				data, length);
+
+	/* Acknowledge the frame */
+	reg_data = in_be32(addr + XEL_RSR_OFFSET);
+	reg_data &= ~XEL_RSR_RECV_DONE_MASK;
+	out_be32(addr + XEL_RSR_OFFSET, reg_data);
+
+	return length;
+}
+
+/**
+ * xemaclite_update_address - Update the MAC address in the device
+ * @drvdata:	Pointer to the Emaclite device private data
+ * @address_ptr:Pointer to the MAC address (MAC address is a 48-bit value)
+ *
+ * Tx must be idle and Rx should be idle for deterministic results.
+ * It is recommended that this function should be called after the
+ * initialization and before transmission of any packets from the device.
+ * The MAC address can be programmed using any of the two transmit
+ * buffers (if configured).
+ */
+static void xemaclite_update_address(struct net_local *drvdata,
+				     u8 *address_ptr)
+{
+	void __iomem *addr;
+	u32 reg_data;
+
+	/* Determine the expected Tx buffer address */
+	addr = drvdata->base_addr + drvdata->next_tx_buf_to_use;
+
+	xemaclite_aligned_write(address_ptr, (u32 __force *) addr, ETH_ALEN);
+
+	out_be32(addr + XEL_TPLR_OFFSET, ETH_ALEN);
+
+	/* Update the MAC address in the EmacLite */
+	reg_data = in_be32(addr + XEL_TSR_OFFSET);
+	out_be32(addr + XEL_TSR_OFFSET, reg_data | XEL_TSR_PROG_MAC_ADDR);
+
+	/* Wait for EmacLite to finish with the MAC address update */
+	while ((in_be32(addr + XEL_TSR_OFFSET) &
+		XEL_TSR_PROG_MAC_ADDR) != 0)
+		;
+}
+
+/**
+ * xemaclite_set_mac_address - Set the MAC address for this device
+ * @dev:	Pointer to the network device instance
+ * @addr:	Void pointer to the sockaddr structure
+ *
+ * This function copies the HW address from the sockaddr strucutre to the
+ * net_device structure and updates the address in HW.
+ *
+ * Return:	Error if the net device is busy or 0 if the addr is set
+ *		successfully
+ */
+static int xemaclite_set_mac_address(struct net_device *dev, void *address)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	struct sockaddr *addr = address;
+
+	if (netif_running(dev))
+		return -EBUSY;
+
+	memcpy(dev->dev_addr, addr->sa_data, dev->addr_len);
+	xemaclite_update_address(lp, dev->dev_addr);
+	return 0;
+}
+
+/**
+ * xemaclite_tx_timeout - Callback for Tx Timeout
+ * @dev:	Pointer to the network device
+ *
+ * This function is called when Tx time out occurs for Emaclite device.
+ */
+static void xemaclite_tx_timeout(struct net_device *dev)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	unsigned long flags;
+
+	dev_err(&lp->ndev->dev, "Exceeded transmit timeout of %lu ms\n",
+		TX_TIMEOUT * 1000UL / HZ);
+
+	dev->stats.tx_errors++;
+
+	/* Reset the device */
+	spin_lock_irqsave(&lp->reset_lock, flags);
+
+	/* Shouldn't really be necessary, but shouldn't hurt */
+	netif_stop_queue(dev);
+
+	xemaclite_disable_interrupts(lp);
+	xemaclite_enable_interrupts(lp);
+
+	if (lp->deferred_skb) {
+		dev_kfree_skb(lp->deferred_skb);
+		lp->deferred_skb = NULL;
+		dev->stats.tx_errors++;
+	}
+
+	/* To exclude tx timeout */
+	dev->trans_start = 0xffffffff - TX_TIMEOUT - TX_TIMEOUT;
+
+	/* We're all ready to go. Start the queue */
+	netif_wake_queue(dev);
+	spin_unlock_irqrestore(&lp->reset_lock, flags);
+}
+
+/**********************/
+/* Interrupt Handlers */
+/**********************/
+
+/**
+ * xemaclite_tx_handler - Interrupt handler for frames sent
+ * @dev:	Pointer to the network device
+ *
+ * This function updates the number of packets transmitted and handles the
+ * deferred skb, if there is one.
+ */
+static void xemaclite_tx_handler(struct net_device *dev)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+
+	dev->stats.tx_packets++;
+	if (lp->deferred_skb) {
+		if (xemaclite_send_data(lp,
+					(u8 *) lp->deferred_skb->data,
+					lp->deferred_skb->len) != 0)
+			return;
+		else {
+			dev->stats.tx_bytes += lp->deferred_skb->len;
+			dev_kfree_skb_irq(lp->deferred_skb);
+			lp->deferred_skb = NULL;
+			dev->trans_start = jiffies;
+			netif_wake_queue(dev);
+		}
+	}
+}
+
+/**
+ * xemaclite_rx_handler- Interrupt handler for frames received
+ * @dev:	Pointer to the network device
+ *
+ * This function allocates memory for a socket buffer, fills it with data
+ * received and hands it over to the TCP/IP stack.
+ */
+static void xemaclite_rx_handler(struct net_device *dev)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	struct sk_buff *skb;
+	unsigned int align;
+	u32 len;
+
+	len = ETH_FRAME_LEN + ETH_FCS_LEN;
+	skb = dev_alloc_skb(len + ALIGNMENT);
+	if (!skb) {
+		/* Couldn't get memory. */
+		dev->stats.rx_dropped++;
+		dev_err(&lp->ndev->dev, "Could not allocate receive buffer\n");
+		return;
+	}
+
+	/*
+	 * A new skb should have the data halfword aligned, but this code is
+	 * here just in case that isn't true. Calculate how many
+	 * bytes we should reserve to get the data to start on a word
+	 * boundary */
+	align = BUFFER_ALIGN(skb->data);
+	if (align)
+		skb_reserve(skb, align);
+
+	skb_reserve(skb, 2);
+
+	len = xemaclite_recv_data(lp, (u8 *) skb->data);
+
+	if (!len) {
+		dev->stats.rx_errors++;
+		dev_kfree_skb_irq(skb);
+		return;
+	}
+
+	skb_put(skb, len);	/* Tell the skb how much data we got */
+	skb->dev = dev;		/* Fill out required meta-data */
+
+	skb->protocol = eth_type_trans(skb, dev);
+	skb->ip_summed = CHECKSUM_NONE;
+
+	dev->stats.rx_packets++;
+	dev->stats.rx_bytes += len;
+
+	netif_rx(skb);		/* Send the packet upstream */
+}
+
+/**
+ * xemaclite_interrupt - Interrupt handler for this driver
+ * @irq:	Irq of the Emaclite device
+ * @dev_id:	Void pointer to the network device instance used as callback
+ *		reference
+ *
+ * This function handles the Tx and Rx interrupts of the EmacLite device.
+ */
+static irqreturn_t xemaclite_interrupt(int irq, void *dev_id)
+{
+	bool tx_complete = 0;
+	struct net_device *dev = dev_id;
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	void __iomem *base_addr = lp->base_addr;
+	u32 tx_status;
+
+	/* Check if there is Rx Data available */
+	if ((in_be32(base_addr + XEL_RSR_OFFSET) & XEL_RSR_RECV_DONE_MASK) ||
+			(in_be32(base_addr + XEL_BUFFER_OFFSET + XEL_RSR_OFFSET)
+			 & XEL_RSR_RECV_DONE_MASK))
+
+		xemaclite_rx_handler(dev);
+
+	/* Check if the Transmission for the first buffer is completed */
+	tx_status = in_be32(base_addr + XEL_TSR_OFFSET);
+	if (((tx_status & XEL_TSR_XMIT_BUSY_MASK) == 0) &&
+		(tx_status & XEL_TSR_XMIT_ACTIVE_MASK) != 0) {
+
+		tx_status &= ~XEL_TSR_XMIT_ACTIVE_MASK;
+		out_be32(base_addr + XEL_TSR_OFFSET, tx_status);
+
+		tx_complete = 1;
+	}
+
+	/* Check if the Transmission for the second buffer is completed */
+	tx_status = in_be32(base_addr + XEL_BUFFER_OFFSET + XEL_TSR_OFFSET);
+	if (((tx_status & XEL_TSR_XMIT_BUSY_MASK) == 0) &&
+		(tx_status & XEL_TSR_XMIT_ACTIVE_MASK) != 0) {
+
+		tx_status &= ~XEL_TSR_XMIT_ACTIVE_MASK;
+		out_be32(base_addr + XEL_BUFFER_OFFSET + XEL_TSR_OFFSET,
+			 tx_status);
+
+		tx_complete = 1;
+	}
+
+	/* If there was a Tx interrupt, call the Tx Handler */
+	if (tx_complete != 0)
+		xemaclite_tx_handler(dev);
+
+	return IRQ_HANDLED;
+}
+
+/**********************/
+/* MDIO Bus functions */
+/**********************/
+
+/**
+ * xemaclite_mdio_wait - Wait for the MDIO to be ready to use
+ * @lp:		Pointer to the Emaclite device private data
+ *
+ * This function waits till the device is ready to accept a new MDIO
+ * request.
+ *
+ * Return:	0 for success or ETIMEDOUT for a timeout
+ */
+
+static int xemaclite_mdio_wait(struct net_local *lp)
+{
+	long end = jiffies + 2;
+
+	/* wait for the MDIO interface to not be busy or timeout
+	   after some time.
+	*/
+	while (in_be32(lp->base_addr + XEL_MDIOCTRL_OFFSET) &
+			XEL_MDIOCTRL_MDIOSTS_MASK) {
+		if (end - jiffies <= 0) {
+			WARN_ON(1);
+			return -ETIMEDOUT;
+		}
+		msleep(1);
+	}
+	return 0;
+}
+
+/**
+ * xemaclite_mdio_read - Read from a given MII management register
+ * @bus:	the mii_bus struct
+ * @phy_id:	the phy address
+ * @reg:	register number to read from
+ *
+ * This function waits till the device is ready to accept a new MDIO
+ * request and then writes the phy address to the MDIO Address register
+ * and reads data from MDIO Read Data register, when its available.
+ *
+ * Return:	Value read from the MII management register
+ */
+static int xemaclite_mdio_read(struct mii_bus *bus, int phy_id, int reg)
+{
+	struct net_local *lp = bus->priv;
+	u32 ctrl_reg;
+	u32 rc;
+
+	if (xemaclite_mdio_wait(lp))
+		return -ETIMEDOUT;
+
+	/* Write the PHY address, register number and set the OP bit in the
+	 * MDIO Address register. Set the Status bit in the MDIO Control
+	 * register to start a MDIO read transaction.
+	 */
+	ctrl_reg = in_be32(lp->base_addr + XEL_MDIOCTRL_OFFSET);
+	out_be32(lp->base_addr + XEL_MDIOADDR_OFFSET,
+		 XEL_MDIOADDR_OP_MASK |
+		 ((phy_id << XEL_MDIOADDR_PHYADR_SHIFT) | reg));
+	out_be32(lp->base_addr + XEL_MDIOCTRL_OFFSET,
+		 ctrl_reg | XEL_MDIOCTRL_MDIOSTS_MASK);
+
+	if (xemaclite_mdio_wait(lp))
+		return -ETIMEDOUT;
+
+	rc = in_be32(lp->base_addr + XEL_MDIORD_OFFSET);
+
+	dev_dbg(&lp->ndev->dev,
+		"xemaclite_mdio_read(phy_id=%i, reg=%x) == %x\n",
+		phy_id, reg, rc);
+
+	return rc;
+}
+
+/**
+ * xemaclite_mdio_write - Write to a given MII management register
+ * @bus:	the mii_bus struct
+ * @phy_id:	the phy address
+ * @reg:	register number to write to
+ * @val:	value to write to the register number specified by reg
+ *
+ * This fucntion waits till the device is ready to accept a new MDIO
+ * request and then writes the val to the MDIO Write Data register.
+ */
+static int xemaclite_mdio_write(struct mii_bus *bus, int phy_id, int reg,
+				u16 val)
+{
+	struct net_local *lp = bus->priv;
+	u32 ctrl_reg;
+
+	dev_dbg(&lp->ndev->dev,
+		"xemaclite_mdio_write(phy_id=%i, reg=%x, val=%x)\n",
+		phy_id, reg, val);
+
+	if (xemaclite_mdio_wait(lp))
+		return -ETIMEDOUT;
+
+	/* Write the PHY address, register number and clear the OP bit in the
+	 * MDIO Address register and then write the value into the MDIO Write
+	 * Data register. Finally, set the Status bit in the MDIO Control
+	 * register to start a MDIO write transaction.
+	 */
+	ctrl_reg = in_be32(lp->base_addr + XEL_MDIOCTRL_OFFSET);
+	out_be32(lp->base_addr + XEL_MDIOADDR_OFFSET,
+		 ~XEL_MDIOADDR_OP_MASK &
+		 ((phy_id << XEL_MDIOADDR_PHYADR_SHIFT) | reg));
+	out_be32(lp->base_addr + XEL_MDIOWR_OFFSET, val);
+	out_be32(lp->base_addr + XEL_MDIOCTRL_OFFSET,
+		 ctrl_reg | XEL_MDIOCTRL_MDIOSTS_MASK);
+
+	return 0;
+}
+
+/**
+ * xemaclite_mdio_reset - Reset the mdio bus.
+ * @bus:	Pointer to the MII bus
+ *
+ * This function is required(?) as per Documentation/networking/phy.txt.
+ * There is no reset in this device; this function always returns 0.
+ */
+static int xemaclite_mdio_reset(struct mii_bus *bus)
+{
+	return 0;
+}
+
+/**
+ * xemaclite_mdio_setup - Register mii_bus for the Emaclite device
+ * @lp:		Pointer to the Emaclite device private data
+ * @ofdev:	Pointer to OF device structure
+ *
+ * This function enables MDIO bus in the Emaclite device and registers a
+ * mii_bus.
+ *
+ * Return:	0 upon success or a negative error upon failure
+ */
+static int xemaclite_mdio_setup(struct net_local *lp, struct device *dev)
+{
+	struct mii_bus *bus;
+	int rc;
+	struct resource res;
+	struct device_node *np = of_get_parent(lp->phy_node);
+
+	/* Don't register the MDIO bus if the phy_node or its parent node
+	 * can't be found.
+	 */
+	if (!np)
+		return -ENODEV;
+
+	/* Enable the MDIO bus by asserting the enable bit in MDIO Control
+	 * register.
+	 */
+	out_be32(lp->base_addr + XEL_MDIOCTRL_OFFSET,
+		 XEL_MDIOCTRL_MDIOEN_MASK);
+
+	bus = mdiobus_alloc();
+	if (!bus)
+		return -ENOMEM;
+
+	of_address_to_resource(np, 0, &res);
+	snprintf(bus->id, MII_BUS_ID_SIZE, "%.8llx",
+		 (unsigned long long)res.start);
+	bus->priv = lp;
+	bus->name = "Xilinx Emaclite MDIO";
+	bus->read = xemaclite_mdio_read;
+	bus->write = xemaclite_mdio_write;
+	bus->reset = xemaclite_mdio_reset;
+	bus->parent = dev;
+	bus->irq = lp->mdio_irqs; /* preallocated IRQ table */
+
+	lp->mii_bus = bus;
+
+	rc = of_mdiobus_register(bus, np);
+	if (rc)
+		goto err_register;
+
+	return 0;
+
+err_register:
+	mdiobus_free(bus);
+	return rc;
+}
+
+/**
+ * xemaclite_adjust_link - Link state callback for the Emaclite device
+ * @ndev: pointer to net_device struct
+ *
+ * There's nothing in the Emaclite device to be configured when the link
+ * state changes. We just print the status.
+ */
+void xemaclite_adjust_link(struct net_device *ndev)
+{
+	struct net_local *lp = netdev_priv(ndev);
+	struct phy_device *phy = lp->phy_dev;
+	int link_state;
+
+	/* hash together the state values to decide if something has changed */
+	link_state = phy->speed | (phy->duplex << 1) | phy->link;
+
+	if (lp->last_link != link_state) {
+		lp->last_link = link_state;
+		phy_print_status(phy);
+	}
+}
+
+/**
+ * xemaclite_open - Open the network device
+ * @dev:	Pointer to the network device
+ *
+ * This function sets the MAC address, requests an IRQ and enables interrupts
+ * for the Emaclite device and starts the Tx queue.
+ * It also connects to the phy device, if MDIO is included in Emaclite device.
+ */
+static int xemaclite_open(struct net_device *dev)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	int retval;
+
+	/* Just to be safe, stop the device first */
+	xemaclite_disable_interrupts(lp);
+
+	if (lp->phy_node) {
+		u32 bmcr;
+
+		lp->phy_dev = of_phy_connect(lp->ndev, lp->phy_node,
+					     xemaclite_adjust_link, 0,
+					     PHY_INTERFACE_MODE_MII);
+		if (!lp->phy_dev) {
+			dev_err(&lp->ndev->dev, "of_phy_connect() failed\n");
+			return -ENODEV;
+		}
+
+		/* EmacLite doesn't support giga-bit speeds */
+		lp->phy_dev->supported &= (PHY_BASIC_FEATURES);
+		lp->phy_dev->advertising = lp->phy_dev->supported;
+
+		/* Don't advertise 1000BASE-T Full/Half duplex speeds */
+		phy_write(lp->phy_dev, MII_CTRL1000, 0);
+
+		/* Advertise only 10 and 100mbps full/half duplex speeds */
+		phy_write(lp->phy_dev, MII_ADVERTISE, ADVERTISE_ALL);
+
+		/* Restart auto negotiation */
+		bmcr = phy_read(lp->phy_dev, MII_BMCR);
+		bmcr |= (BMCR_ANENABLE | BMCR_ANRESTART);
+		phy_write(lp->phy_dev, MII_BMCR, bmcr);
+
+		phy_start(lp->phy_dev);
+	}
+
+	/* Set the MAC address each time opened */
+	xemaclite_update_address(lp, dev->dev_addr);
+
+	/* Grab the IRQ */
+	retval = request_irq(dev->irq, xemaclite_interrupt, 0, dev->name, dev);
+	if (retval) {
+		dev_err(&lp->ndev->dev, "Could not allocate interrupt %d\n",
+			dev->irq);
+		if (lp->phy_dev)
+			phy_disconnect(lp->phy_dev);
+		lp->phy_dev = NULL;
+
+		return retval;
+	}
+
+	/* Enable Interrupts */
+	xemaclite_enable_interrupts(lp);
+
+	/* We're ready to go */
+	netif_start_queue(dev);
+
+	return 0;
+}
+
+/**
+ * xemaclite_close - Close the network device
+ * @dev:	Pointer to the network device
+ *
+ * This function stops the Tx queue, disables interrupts and frees the IRQ for
+ * the Emaclite device.
+ * It also disconnects the phy device associated with the Emaclite device.
+ */
+static int xemaclite_close(struct net_device *dev)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+
+	netif_stop_queue(dev);
+	xemaclite_disable_interrupts(lp);
+	free_irq(dev->irq, dev);
+
+	if (lp->phy_dev)
+		phy_disconnect(lp->phy_dev);
+	lp->phy_dev = NULL;
+
+	return 0;
+}
+
+/**
+ * xemaclite_get_stats - Get the stats for the net_device
+ * @dev:	Pointer to the network device
+ *
+ * This function returns the address of the 'net_device_stats' structure for the
+ * given network device. This structure holds usage statistics for the network
+ * device.
+ *
+ * Return:	Pointer to the net_device_stats structure.
+ */
+static struct net_device_stats *xemaclite_get_stats(struct net_device *dev)
+{
+	return &dev->stats;
+}
+
+/**
+ * xemaclite_send - Transmit a frame
+ * @orig_skb:	Pointer to the socket buffer to be transmitted
+ * @dev:	Pointer to the network device
+ *
+ * This function checks if the Tx buffer of the Emaclite device is free to send
+ * data. If so, it fills the Tx buffer with data from socket buffer data,
+ * updates the stats and frees the socket buffer. The Tx completion is signaled
+ * by an interrupt. If the Tx buffer isn't free, then the socket buffer is
+ * deferred and the Tx queue is stopped so that the deferred socket buffer can
+ * be transmitted when the Emaclite device is free to transmit data.
+ *
+ * Return:	0, always.
+ */
+static int xemaclite_send(struct sk_buff *orig_skb, struct net_device *dev)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	struct sk_buff *new_skb;
+	unsigned int len;
+	unsigned long flags;
+
+	len = orig_skb->len;
+
+	new_skb = orig_skb;
+
+	spin_lock_irqsave(&lp->reset_lock, flags);
+	if (xemaclite_send_data(lp, (u8 *) new_skb->data, len) != 0) {
+		/* If the Emaclite Tx buffer is busy, stop the Tx queue and
+		 * defer the skb for transmission at a later point when the
+		 * current transmission is complete */
+		netif_stop_queue(dev);
+		lp->deferred_skb = new_skb;
+		spin_unlock_irqrestore(&lp->reset_lock, flags);
+		return 0;
+	}
+	spin_unlock_irqrestore(&lp->reset_lock, flags);
+
+	dev->stats.tx_bytes += len;
+	dev_kfree_skb(new_skb);
+	dev->trans_start = jiffies;
+
+	return 0;
+}
+
+/**
+ * xemaclite_remove_ndev - Free the network device
+ * @ndev:	Pointer to the network device to be freed
+ *
+ * This function un maps the IO region of the Emaclite device and frees the net
+ * device.
+ */
+static void xemaclite_remove_ndev(struct net_device *ndev)
+{
+	if (ndev) {
+		struct net_local *lp = (struct net_local *) netdev_priv(ndev);
+
+		if (lp->base_addr)
+			iounmap((void __iomem __force *) (lp->base_addr));
+		free_netdev(ndev);
+	}
+}
+
+/**
+ * get_bool - Get a parameter from the OF device
+ * @ofdev:	Pointer to OF device structure
+ * @s:		Property to be retrieved
+ *
+ * This function looks for a property in the device node and returns the value
+ * of the property if its found or 0 if the property is not found.
+ *
+ * Return:	Value of the parameter if the parameter is found, or 0 otherwise
+ */
+static bool get_bool(struct of_device *ofdev, const char *s)
+{
+	u32 *p = (u32 *)of_get_property(ofdev->node, s, NULL);
+
+	if (p) {
+		return (bool)*p;
+	} else {
+		dev_warn(&ofdev->dev, "Parameter %s not found,"
+			"defaulting to false\n", s);
+		return 0;
+	}
+}
+
+static struct net_device_ops xemaclite_netdev_ops;
+
+/**
+ * xemaclite_of_probe - Probe method for the Emaclite device.
+ * @ofdev:	Pointer to OF device structure
+ * @match:	Pointer to the structure used for matching a device
+ *
+ * This function probes for the Emaclite device in the device tree.
+ * It initializes the driver data structure and the hardware, sets the MAC
+ * address and registers the network device.
+ * It also registers a mii_bus for the Emaclite device, if MDIO is included
+ * in the device.
+ *
+ * Return:	0, if the driver is bound to the Emaclite device, or
+ *		a negative error if there is failure.
+ */
+static int __devinit xemaclite_of_probe(struct of_device *ofdev,
+					const struct of_device_id *match)
+{
+	struct resource r_irq; /* Interrupt resources */
+	struct resource r_mem; /* IO mem resources */
+	struct net_device *ndev = NULL;
+	struct net_local *lp = NULL;
+	struct device *dev = &ofdev->dev;
+	const void *mac_address;
+
+	int rc = 0;
+
+	dev_info(dev, "Device Tree Probing\n");
+
+	/* Get iospace for the device */
+	rc = of_address_to_resource(ofdev->node, 0, &r_mem);
+	if (rc) {
+		dev_err(dev, "invalid address\n");
+		return rc;
+	}
+
+	/* Get IRQ for the device */
+	rc = of_irq_to_resource(ofdev->node, 0, &r_irq);
+	if (rc == NO_IRQ) {
+		dev_err(dev, "no IRQ found\n");
+		return rc;
+	}
+
+	/* Create an ethernet device instance */
+	ndev = alloc_etherdev(sizeof(struct net_local));
+	if (!ndev) {
+		dev_err(dev, "Could not allocate network device\n");
+		return -ENOMEM;
+	}
+
+	dev_set_drvdata(dev, ndev);
+	SET_NETDEV_DEV(ndev, &ofdev->dev);
+
+	ndev->irq = r_irq.start;
+	ndev->mem_start = r_mem.start;
+	ndev->mem_end = r_mem.end;
+
+	lp = netdev_priv(ndev);
+	lp->ndev = ndev;
+
+	if (!request_mem_region(ndev->mem_start,
+				ndev->mem_end - ndev->mem_start + 1,
+				DRIVER_NAME)) {
+		dev_err(dev, "Couldn't lock memory region at %p\n",
+			(void *)ndev->mem_start);
+		rc = -EBUSY;
+		goto error2;
+	}
+
+	/* Get the virtual base address for the device */
+	lp->base_addr = ioremap(r_mem.start, r_mem.end - r_mem.start + 1);
+	if (NULL == lp->base_addr) {
+		dev_err(dev, "EmacLite: Could not allocate iomem\n");
+		rc = -EIO;
+		goto error1;
+	}
+
+	spin_lock_init(&lp->reset_lock);
+	lp->next_tx_buf_to_use = 0x0;
+	lp->next_rx_buf_to_use = 0x0;
+	lp->tx_ping_pong = get_bool(ofdev, "xlnx,tx-ping-pong");
+	lp->rx_ping_pong = get_bool(ofdev, "xlnx,rx-ping-pong");
+	mac_address = of_get_mac_address(ofdev->node);
+
+	if (mac_address)
+		/* Set the MAC address. */
+		memcpy(ndev->dev_addr, mac_address, 6);
+	else
+		dev_warn(dev, "No MAC address found\n");
+
+	/* Clear the Tx CSR's in case this is a restart */
+	out_be32(lp->base_addr + XEL_TSR_OFFSET, 0);
+	out_be32(lp->base_addr + XEL_BUFFER_OFFSET + XEL_TSR_OFFSET, 0);
+
+	/* Set the MAC address in the EmacLite device */
+	xemaclite_update_address(lp, ndev->dev_addr);
+
+	lp->phy_node = of_parse_phandle(ofdev->node, "phy-handle", 0);
+	rc = xemaclite_mdio_setup(lp, &ofdev->dev);
+	if (rc)
+		dev_warn(&ofdev->dev, "error registering MDIO bus\n");
+
+	dev_info(dev,
+		 "MAC address is now %2x:%2x:%2x:%2x:%2x:%2x\n",
+		 ndev->dev_addr[0], ndev->dev_addr[1],
+		 ndev->dev_addr[2], ndev->dev_addr[3],
+		 ndev->dev_addr[4], ndev->dev_addr[5]);
+
+	ndev->netdev_ops = &xemaclite_netdev_ops;
+	ndev->flags &= ~IFF_MULTICAST;
+	ndev->watchdog_timeo = TX_TIMEOUT;
+
+	/* Finally, register the device */
+	rc = register_netdev(ndev);
+	if (rc) {
+		dev_err(dev,
+			"Cannot register network device, aborting\n");
+		goto error1;
+	}
+
+	dev_info(dev,
+		 "Xilinx EmacLite at 0x%08X mapped to 0x%08X, irq=%d\n",
+		 (unsigned int __force)ndev->mem_start,
+		 (unsigned int __force)lp->base_addr, ndev->irq);
+	return 0;
+
+error1:
+	release_mem_region(ndev->mem_start, r_mem.end - r_mem.start + 1);
+
+error2:
+	xemaclite_remove_ndev(ndev);
+	return rc;
+}
+
+/**
+ * xemaclite_of_remove - Unbind the driver from the Emaclite device.
+ * @of_dev:	Pointer to OF device structure
+ *
+ * This function is called if a device is physically removed from the system or
+ * if the driver module is being unloaded. It frees any resources allocated to
+ * the device.
+ *
+ * Return:	0, always.
+ */
+static int __devexit xemaclite_of_remove(struct of_device *of_dev)
+{
+	struct device *dev = &of_dev->dev;
+	struct net_device *ndev = dev_get_drvdata(dev);
+
+	struct net_local *lp = (struct net_local *) netdev_priv(ndev);
+
+	/* Un-register the mii_bus, if configured */
+	if (lp->has_mdio) {
+		mdiobus_unregister(lp->mii_bus);
+		kfree(lp->mii_bus->irq);
+		mdiobus_free(lp->mii_bus);
+		lp->mii_bus = NULL;
+	}
+
+	unregister_netdev(ndev);
+
+	if (lp->phy_node)
+		of_node_put(lp->phy_node);
+	lp->phy_node = NULL;
+
+	release_mem_region(ndev->mem_start, ndev->mem_end-ndev->mem_start + 1);
+
+	xemaclite_remove_ndev(ndev);
+	dev_set_drvdata(dev, NULL);
+
+	return 0;
+}
+
+static struct net_device_ops xemaclite_netdev_ops = {
+	.ndo_open		= xemaclite_open,
+	.ndo_stop		= xemaclite_close,
+	.ndo_start_xmit		= xemaclite_send,
+	.ndo_set_mac_address	= xemaclite_set_mac_address,
+	.ndo_tx_timeout		= xemaclite_tx_timeout,
+	.ndo_get_stats		= xemaclite_get_stats,
+};
+
+/* Match table for OF platform binding */
+static struct of_device_id xemaclite_of_match[] __devinitdata = {
+	{ .compatible = "xlnx,opb-ethernetlite-1.01.a", },
+	{ .compatible = "xlnx,opb-ethernetlite-1.01.b", },
+	{ .compatible = "xlnx,xps-ethernetlite-1.00.a", },
+	{ .compatible = "xlnx,xps-ethernetlite-2.00.a", },
+	{ .compatible = "xlnx,xps-ethernetlite-2.01.a", },
+	{ .compatible = "xlnx,xps-ethernetlite-3.00.a", },
+	{ /* end of list */ },
+};
+MODULE_DEVICE_TABLE(of, xemaclite_of_match);
+
+static struct of_platform_driver xemaclite_of_driver = {
+	.name		= DRIVER_NAME,
+	.match_table	= xemaclite_of_match,
+	.probe		= xemaclite_of_probe,
+	.remove		= __devexit_p(xemaclite_of_remove),
+};
+
+/**
+ * xgpiopss_init - Initial driver registration call
+ *
+ * Return:	0 upon success, or a negative error upon failure.
+ */
+static int __init xemaclite_init(void)
+{
+	/* No kernel boot options used, we just need to register the driver */
+	return of_register_platform_driver(&xemaclite_of_driver);
+}
+
+/**
+ * xemaclite_cleanup - Driver un-registration call
+ */
+static void __exit xemaclite_cleanup(void)
+{
+	of_unregister_platform_driver(&xemaclite_of_driver);
+}
+
+module_init(xemaclite_init);
+module_exit(xemaclite_cleanup);
+
+MODULE_AUTHOR("Xilinx, Inc.");
+MODULE_DESCRIPTION("Xilinx Ethernet MAC Lite driver");
+MODULE_LICENSE("GPL");
diff -purN --exclude=.git linux-2.6.31.12/drivers/net/xilinx_lltemac/Makefile linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/Makefile
--- linux-2.6.31.12/drivers/net/xilinx_lltemac/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/Makefile	2010-08-08 17:22:50.611911713 +0200
@@ -0,0 +1,10 @@
+#
+# Makefile for the Xilinx Tri-mode ethernet driver
+#
+
+EXTRA_CFLAGS		+= -Idrivers/xilinx_common
+
+# The Linux adapter for the Xilinx driver code.
+xilinx_temac-objs	:= xlltemac_main.o xlltemac.o xlltemac_control.o
+
+obj-$(CONFIG_XILINX_LLTEMAC) := xilinx_temac.o
diff -purN --exclude=.git linux-2.6.31.12/drivers/net/xilinx_lltemac/xlltemac.c linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/xlltemac.c
--- linux-2.6.31.12/drivers/net/xilinx_lltemac/xlltemac.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/xlltemac.c	2010-08-08 17:40:16.568735903 +0200
@@ -0,0 +1,1387 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2005-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+ *
+ * @file xlltemac.c
+ *
+ * The XLlTemac driver. Functions in this file are the minimum required functions
+ * for this driver. See xlltemac.h for a detailed description of the driver.
+ *
+ * <pre>
+ * MODIFICATION HISTORY:
+ *
+ * Ver   Who  Date     Changes
+ * ----- ---- -------- -------------------------------------------------------
+ * 1.00a jvb  11/10/06 First release
+ * </pre>
+ ******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include <linux/dma-mapping.h>
+#include <linux/string.h>
+#include <linux/delay.h>
+
+#include "xlltemac.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+static void InitHw(XLlTemac *InstancePtr);	/* HW reset */
+
+/************************** Variable Definitions *****************************/
+
+xdbg_stmnt(int indent_on = 0;
+
+	)
+	xdbg_stmnt(u32 _xlltemac_rir_value;
+
+	)
+
+/*****************************************************************************/
+/**
+ *
+ * XLlTemac_CfgInitialize initializes a TEMAC channel along with the
+ * <i>InstancePtr</i> that references it. Each TEMAC channel is treated as a
+ * separate device from the point of view of this driver.
+ *
+ * The PHY is setup independently from the TEMAC. Use the MII or whatever other
+ * interface may be present for setup.
+ *
+ * @param  InstancePtr references the memory instance to be associated with
+ *         the TEMAC channel upon initialization.
+ * @param  CfgPtr references the structure holding the hardware configuration
+ *         for the TEMAC channel to initialize.
+ * @param  EffectiveAddress is the processor address used to access the
+ *         base address of the TEMAC channel. In systems with an MMU and virtual
+ *         memory, <i>EffectiveAddress</i> is the virtual address mapped to the
+ *         physical in <code>ConfigPtr->Config.BaseAddress</code>. In systems
+ *         without an active MMU, <i>EffectiveAddress</i> should be set to the
+ *         same value as <code>ConfigPtr->Config.BaseAddress</code>.
+ *        
+ * @return XLlTemac_CfgInitialize returns XST_SUCCESS.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ *
+ ******************************************************************************/
+     int XLlTemac_CfgInitialize(XLlTemac *InstancePtr,
+				XLlTemac_Config *CfgPtr, u32 EffectiveAddress)
+{
+	/* Verify arguments */
+	XASSERT_NONVOID(InstancePtr != NULL);
+
+	/* Clear instance memory and make copy of configuration */
+	memset(InstancePtr, 0, sizeof(XLlTemac));
+	memcpy(&InstancePtr->Config, CfgPtr, sizeof(XLlTemac_Config));
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_CfgInitialize\n");
+	/* Set device base address */
+	InstancePtr->Config.BaseAddress = EffectiveAddress;
+
+	/* Reset the hardware and set default options */
+	InstancePtr->IsReady = XCOMPONENT_IS_READY;
+
+	XLlTemac_Reset(InstancePtr, XTE_NORESET_HARD);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "Temac_CfgInitialize: returning SUCCESS\n");
+	return XST_SUCCESS;
+}
+
+
+/*****************************************************************************/
+/**
+ * XLlTemac_Start starts the TEMAC channel as follows:
+ *   - Enable transmitter if XTE_TRANSMIT_ENABLE_OPTION is set
+ *   - Enable receiver if XTE_RECEIVER_ENABLE_OPTION is set
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ *
+ * @return N/A
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+void XLlTemac_Start(XLlTemac *InstancePtr)
+{
+	u32 Reg;
+
+	/* Assert bad arguments and conditions */
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_VOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				      XTE_RDY_OFFSET) &
+		     XTE_RDY_HARD_ACS_RDY_MASK);
+
+	/* If already started, then there is nothing to do */
+	if (InstancePtr->IsStarted == XCOMPONENT_IS_STARTED) {
+		return;
+	}
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_Start\n");
+	/* Enable transmitter if not already enabled */
+	if (InstancePtr->Options & XTE_TRANSMITTER_ENABLE_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL, "enabling transmitter\n");
+		Reg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					       XTE_TC_OFFSET);
+		if (!(Reg & XTE_TC_TX_MASK)) {
+			xdbg_printf(XDBG_DEBUG_GENERAL,
+				    "transmitter not enabled, enabling now\n");
+			XLlTemac_WriteIndirectReg(InstancePtr->Config.
+						  BaseAddress, XTE_TC_OFFSET,
+						  Reg | XTE_TC_TX_MASK);
+		}
+		xdbg_printf(XDBG_DEBUG_GENERAL, "transmitter enabled\n");
+	}
+
+	/* Enable receiver */
+	if (InstancePtr->Options & XTE_RECEIVER_ENABLE_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL, "enabling receiver\n");
+		Reg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					       XTE_RCW1_OFFSET);
+		if (!(Reg & XTE_RCW1_RX_MASK)) {
+			xdbg_printf(XDBG_DEBUG_GENERAL,
+				    "receiver not enabled, enabling now\n");
+
+			XLlTemac_WriteIndirectReg(InstancePtr->Config.
+						  BaseAddress, XTE_RCW1_OFFSET,
+						  Reg | XTE_RCW1_RX_MASK);
+		}
+		xdbg_printf(XDBG_DEBUG_GENERAL, "receiver enabled\n");
+	}
+
+	/* Mark as started */
+	InstancePtr->IsStarted = XCOMPONENT_IS_STARTED;
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_Start: done\n");
+}
+
+/*****************************************************************************/
+/**
+ * XLlTemac_Stop gracefully stops the TEMAC channel as follows:
+ *   - Disable all interrupts from this device
+ *   - Disable the receiver
+ *
+ * XLlTemac_Stop does not modify any of the current device options.
+ *
+ * Since the transmitter is not disabled, frames currently in internal buffers
+ * or in process by a DMA engine are allowed to be transmitted.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ *
+ * @return N/A
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ * 
+ ******************************************************************************/
+void XLlTemac_Stop(XLlTemac *InstancePtr)
+{
+	u32 Reg;
+
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_VOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				      XTE_RDY_OFFSET) &
+		     XTE_RDY_HARD_ACS_RDY_MASK);
+
+	/* If already stopped, then there is nothing to do */
+	if (InstancePtr->IsStarted == 0) {
+		return;
+	}
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_Stop\n");
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "XLlTemac_Stop: disabling interrupts\n");
+	/* Disable interrupts */
+	XLlTemac_WriteReg(InstancePtr->Config.BaseAddress, XTE_IE_OFFSET, 0);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_Stop: disabling receiver\n");
+	/* Disable the receiver */
+	Reg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+				       XTE_RCW1_OFFSET);
+	Reg &= ~XTE_RCW1_RX_MASK;
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_RCW1_OFFSET, Reg);
+
+	/* Stopping the receiver in mid-packet causes a dropped packet indication
+	 * from HW. Clear it.
+	 */
+	/* get the interrupt pending register */
+	Reg = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress, XTE_IP_OFFSET);
+	if (Reg & XTE_INT_RXRJECT_MASK) {
+		/* set the interrupt status register to clear the interrupt */
+		XLlTemac_WriteReg(InstancePtr->Config.BaseAddress,
+				  XTE_IS_OFFSET, XTE_INT_RXRJECT_MASK);
+	}
+
+	/* Mark as stopped */
+	InstancePtr->IsStarted = 0;
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_Stop: done\n");
+}
+
+
+/*****************************************************************************/
+/**
+ * XLlTemac_Reset performs a reset of the TEMAC channel, specified by
+ * <i>InstancePtr</i>, or both channels if <i>HardCoreAction</i> is set to
+ * XTE_RESET_HARD.
+ *
+ * XLlTemac_Reset also resets the TEMAC channel's options to their default values.
+ *
+ * The calling software is responsible for re-configuring the TEMAC channel
+ * (if necessary) and restarting the MAC after the reset.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param HardCoreAction describes how XLlTemac_Reset should treat the hard core
+ *        block of the TEMAC.<br><br>
+ *
+ *        If XTE_RESET_HARD is set to XTE_RESET_HARD, then XLlTemac_Reset asserts
+ *        the reset signal to the hard core block which will reset both channels
+ *        of the TEMAC. This, of course, will bork any activity that may be
+ *        occuring on the other channel. So, be careful here.<br><br>
+ *
+ *        Otherwise, XLlTemac_Reset resets just the transmitter and receiver of
+ *        this TEMAC channel.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+void XLlTemac_Reset(XLlTemac *InstancePtr, int HardCoreAction)
+{
+	u32 Reg;
+	u32 TimeoutCount = 2;
+
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_VOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				      XTE_RDY_OFFSET) &
+		     XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_Reset\n");
+	/* Stop the device and reset HW */
+	XLlTemac_Stop(InstancePtr);
+	InstancePtr->Options = XTE_DEFAULT_OPTIONS;
+
+	/* Reset the receiver */
+	xdbg_printf(XDBG_DEBUG_GENERAL, "resetting the receiver\n");
+	Reg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+				       XTE_RCW1_OFFSET);
+	Reg |= XTE_RCW1_RST_MASK;
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_RCW1_OFFSET, Reg);
+
+	/* Reset the transmitter */
+	xdbg_printf(XDBG_DEBUG_GENERAL, "resetting the transmitter\n");
+	Reg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+				       XTE_TC_OFFSET);
+	Reg |= XTE_TC_RST_MASK;
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_TC_OFFSET, Reg);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "waiting until reset is done\n");
+	/* Poll until the reset is done */
+	while (Reg & (XTE_RCW1_RST_MASK | XTE_TC_RST_MASK)) {
+		Reg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					       XTE_RCW1_OFFSET);
+		Reg |= XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+						XTE_TC_OFFSET);
+	}
+
+	/* Reset hard core if required */
+	/* Resetting hard core will cause both channels to reset :-( */
+	if (HardCoreAction == XTE_RESET_HARD) {
+		xdbg_printf(XDBG_DEBUG_GENERAL, "hard reset\n");
+		Reg = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				       XTE_RAF_OFFSET);
+		XLlTemac_WriteReg(InstancePtr->Config.BaseAddress,
+				  XTE_RAF_OFFSET, Reg | XTE_RAF_HTRST_MASK);
+		while (TimeoutCount &&
+		       (!(XLlTemac_ReadReg
+			  (InstancePtr->Config.BaseAddress,
+			   XTE_RDY_OFFSET) & XTE_RDY_HARD_ACS_RDY_MASK))) {
+			udelay(XTE_RESET_HARD_DELAY_US);
+			TimeoutCount--;
+		}
+	}
+
+	/* Setup HW */
+	InitHw(InstancePtr);
+}
+
+
+/******************************************************************************
+ * InitHw (internal use only) performs a one-time setup of a TEMAC channel. The
+ * setup performed here only need to occur once after any reset.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+static void InitHw(XLlTemac *InstancePtr)
+{
+	u32 Reg;
+
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_VOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				      XTE_RDY_OFFSET) &
+		     XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac InitHw\n");
+	/* Disable the receiver */
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac InitHw\n");
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "XLlTemac InitHw: disabling receiver\n");
+	Reg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+				       XTE_RCW1_OFFSET);
+	Reg &= ~XTE_RCW1_RX_MASK;
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_RCW1_OFFSET, Reg);
+
+	/*
+	 * Stopping the receiver in mid-packet causes a dropped packet
+	 * indication from HW. Clear it.
+	 */
+	/* get the interrupt pending register */
+	Reg = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress, XTE_IP_OFFSET);
+	if (Reg & XTE_INT_RXRJECT_MASK) {
+		/*
+		 * set the interrupt status register to clear the pending
+		 * interrupt
+		 */
+		XLlTemac_WriteReg(InstancePtr->Config.BaseAddress,
+				  XTE_IS_OFFSET, XTE_INT_RXRJECT_MASK);
+	}
+
+	/* Sync default options with HW but leave receiver and transmitter
+	 * disabled. They get enabled with XLlTemac_Start() if
+	 * XTE_TRANSMITTER_ENABLE_OPTION and XTE_RECEIVER_ENABLE_OPTION are set
+	 */
+	XLlTemac_SetOptions(InstancePtr, InstancePtr->Options &
+			    ~(XTE_TRANSMITTER_ENABLE_OPTION |
+			      XTE_RECEIVER_ENABLE_OPTION));
+
+	XLlTemac_ClearOptions(InstancePtr, ~InstancePtr->Options);
+
+	/* Set default MDIO divisor */
+	XLlTemac_PhySetMdioDivisor(InstancePtr, XTE_MDIO_DIV_DFT);
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac InitHw: done\n");
+}
+
+/*****************************************************************************/
+/**
+ * XLlTemac_SetMacAddress sets the MAC address for the TEMAC channel, specified
+ * by <i>InstancePtr</i> to the MAC address specified by <i>AddressPtr</i>.
+ * The TEMAC channel must be stopped before calling this function.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param AddressPtr is a reference to the 6-byte MAC address to set.
+ *
+ * @return On successful completion, XLlTemac_SetMacAddress returns XST_SUCCESS.
+ *         Otherwise, if the TEMAC channel has not stopped,
+ *         XLlTemac_SetMacAddress returns XST_DEVICE_IS_STARTED.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+int XLlTemac_SetMacAddress(XLlTemac *InstancePtr, void *AddressPtr)
+{
+	u32 MacAddr;
+	u8 *Aptr = (u8 *) AddressPtr;
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	XASSERT_NONVOID(AddressPtr != NULL);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_NONVOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+					 XTE_RDY_OFFSET) &
+			XTE_RDY_HARD_ACS_RDY_MASK);
+
+	/* Be sure device has been stopped */
+	if (InstancePtr->IsStarted == XCOMPONENT_IS_STARTED) {
+		return (XST_DEVICE_IS_STARTED);
+	}
+
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "XLlTemac_SetMacAddress: setting mac address to: 0x%08x%8x%8x%8x%8x%8x\n",
+		    Aptr[0], Aptr[1], Aptr[2], Aptr[3], Aptr[4], Aptr[5]);
+	/*
+	 * Set the MAC bits [31:0] in UAW0
+	 * Having Aptr be unsigned type prevents the following operations from sign extending
+	 */
+	MacAddr = Aptr[0];
+	MacAddr |= Aptr[1] << 8;
+	MacAddr |= Aptr[2] << 16;
+	MacAddr |= Aptr[3] << 24;
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_UAW0_OFFSET, MacAddr);
+
+	/* There are reserved bits in UAW1 so don't affect them */
+	MacAddr = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					   XTE_UAW1_OFFSET);
+	MacAddr &= ~XTE_UAW1_UNICASTADDR_MASK;
+
+	/* Set MAC bits [47:32] in UAW1 */
+	MacAddr |= Aptr[4];
+	MacAddr |= Aptr[5] << 8;
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_UAW1_OFFSET, MacAddr);
+
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * XLlTemac_GetMacAddress gets the MAC address for the TEMAC channel, specified
+ * by <i>InstancePtr</i> into the memory buffer specified by <i>AddressPtr</i>.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param AddressPtr references the memory buffer to store the retrieved MAC
+ *        address. This memory buffer must be at least 6 bytes in length.
+ *
+ * @return N/A
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+void XLlTemac_GetMacAddress(XLlTemac *InstancePtr, void *AddressPtr)
+{
+	u32 MacAddr;
+	u8 *Aptr = (u8 *) AddressPtr;
+
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_VOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				      XTE_RDY_OFFSET) &
+		     XTE_RDY_HARD_ACS_RDY_MASK);
+
+	/* Read MAC bits [31:0] in UAW0 */
+	MacAddr = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					   XTE_UAW0_OFFSET);
+	Aptr[0] = (u8) MacAddr;
+	Aptr[1] = (u8) (MacAddr >> 8);
+	Aptr[2] = (u8) (MacAddr >> 16);
+	Aptr[3] = (u8) (MacAddr >> 24);
+
+	/* Read MAC bits [47:32] in UAW1 */
+	MacAddr = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					   XTE_UAW1_OFFSET);
+	Aptr[4] = (u8) MacAddr;
+	Aptr[5] = (u8) (MacAddr >> 8);
+}
+
+/*****************************************************************************/
+/**
+ * XLlTemac_SetOptions enables the options, <i>Options</i> for the TEMAC channel,
+ * specified by <i>InstancePtr</i>. The TEMAC channel should be stopped with
+ * XLlTemac_Stop() before changing options.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param Options is a bitmask of OR'd XTE_*_OPTION values for options to
+ *        set. Options not specified are not affected.
+ *
+ * @return On successful completion, XLlTemac_SetOptions returns XST_SUCCESS.
+ *         Otherwise, if the device has not been stopped, XLlTemac_SetOptions
+ *         returns XST_DEVICE_IS_STARTED.
+ *
+ * @note
+ * See xlltemac.h for a description of the available options.
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+int XLlTemac_SetOptions(XLlTemac *InstancePtr, u32 Options)
+{
+	u32 Reg;		/* Generic register contents */
+	u32 RegRcw1;		/* Reflects original contents of RCW1 */
+	u32 RegTc;		/* Reflects original contents of TC  */
+	u32 RegNewRcw1;		/* Reflects new contents of RCW1 */
+	u32 RegNewTc;		/* Reflects new contents of TC  */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_NONVOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+					 XTE_RDY_OFFSET) &
+			XTE_RDY_HARD_ACS_RDY_MASK);
+
+	/* Be sure device has been stopped */
+	if (InstancePtr->IsStarted == XCOMPONENT_IS_STARTED) {
+		return (XST_DEVICE_IS_STARTED);
+	}
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_SetOptions\n");
+	/* Many of these options will change the RCW1 or TC registers.
+	 * To reduce the amount of IO to the device, group these options here
+	 * and change them all at once. 
+	 */
+
+	/* Grab current register contents */
+	RegRcw1 = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					   XTE_RCW1_OFFSET);
+	RegTc = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					 XTE_TC_OFFSET);
+	RegNewRcw1 = RegRcw1;
+	RegNewTc = RegTc;
+
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "current control regs: RCW1: 0x%0x; TC: 0x%0x\n", RegRcw1,
+		    RegTc);
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "Options: 0x%0x; default options: 0x%0x\n", Options,
+		    XTE_DEFAULT_OPTIONS);
+
+	/* Turn on jumbo packet support for both Rx and Tx */
+	if (Options & XTE_JUMBO_OPTION) {
+		RegNewTc |= XTE_TC_JUM_MASK;
+		RegNewRcw1 |= XTE_RCW1_JUM_MASK;
+	}
+
+	/* Turn on VLAN packet support for both Rx and Tx */
+	if (Options & XTE_VLAN_OPTION) {
+		RegNewTc |= XTE_TC_VLAN_MASK;
+		RegNewRcw1 |= XTE_RCW1_VLAN_MASK;
+	}
+
+	/* Turn on FCS stripping on receive packets */
+	if (Options & XTE_FCS_STRIP_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "setOptions: enabling fcs stripping\n");
+		RegNewRcw1 &= ~XTE_RCW1_FCS_MASK;
+	}
+
+	/* Turn on FCS insertion on transmit packets */
+	if (Options & XTE_FCS_INSERT_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "setOptions: enabling fcs insertion\n");
+		RegNewTc &= ~XTE_TC_FCS_MASK;
+	}
+
+	/* Turn on length/type field checking on receive packets */
+	if (Options & XTE_LENTYPE_ERR_OPTION) {
+		RegNewRcw1 &= ~XTE_RCW1_LT_DIS_MASK;
+	}
+
+	/* Enable transmitter */
+	if (Options & XTE_TRANSMITTER_ENABLE_OPTION) {
+		RegNewTc |= XTE_TC_TX_MASK;
+	}
+
+	/* Enable receiver */
+	if (Options & XTE_RECEIVER_ENABLE_OPTION) {
+		RegNewRcw1 |= XTE_RCW1_RX_MASK;
+	}
+
+	/* Change the TC or RCW1 registers if they need to be modified */
+	if (RegTc != RegNewTc) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "setOptions: writting tc: 0x%0x\n", RegNewTc);
+		XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+					  XTE_TC_OFFSET, RegNewTc);
+	}
+
+	if (RegRcw1 != RegNewRcw1) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "setOptions: writting rcw1: 0x%0x\n", RegNewRcw1);
+		XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+					  XTE_RCW1_OFFSET, RegNewRcw1);
+	}
+
+	/* Rest of options twiddle bits of other registers. Handle them one at
+	 * a time
+	 */
+
+	/* Turn on flow control */
+	if (Options & XTE_FLOW_CONTROL_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "setOptions: endabling flow control\n");
+		Reg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					       XTE_FCC_OFFSET);
+		Reg |= XTE_FCC_FCRX_MASK;
+		XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+					  XTE_FCC_OFFSET, Reg);
+	}
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "setOptions: rcw1 is now (fcc): 0x%0x\n",
+		    XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					     XTE_RCW1_OFFSET));
+
+	/* Turn on promiscuous frame filtering (all frames are received ) */
+	if (Options & XTE_PROMISC_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "setOptions: endabling promiscuous mode\n");
+		Reg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					       XTE_AFM_OFFSET);
+		Reg |= XTE_AFM_PM_MASK;
+		XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+					  XTE_AFM_OFFSET, Reg);
+	}
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "setOptions: rcw1 is now (afm): 0x%0x\n",
+		    XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					     XTE_RCW1_OFFSET));
+
+	/* Allow broadcast address filtering */
+	if (Options & XTE_BROADCAST_OPTION) {
+		Reg = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				       XTE_RAF_OFFSET);
+		Reg &= ~XTE_RAF_BCSTREJ_MASK;
+		XLlTemac_WriteReg(InstancePtr->Config.BaseAddress,
+				  XTE_RAF_OFFSET, Reg);
+	}
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "setOptions: rcw1 is now (raf): 0x%0x\n",
+		    XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					     XTE_RCW1_OFFSET));
+
+	/* Allow multicast address filtering */
+	if (Options & XTE_MULTICAST_OPTION) {
+		Reg = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				       XTE_RAF_OFFSET);
+		Reg &= ~XTE_RAF_MCSTREJ_MASK;
+		XLlTemac_WriteReg(InstancePtr->Config.BaseAddress,
+				  XTE_RAF_OFFSET, Reg);
+	}
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "setOptions: rcw1 is now (raf2): 0x%0x\n",
+		    XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					     XTE_RCW1_OFFSET));
+
+	/* The remaining options not handled here are managed elsewhere in the
+	 * driver. No register modifications are needed at this time. Reflecting the
+	 * option in InstancePtr->Options is good enough for now.
+	 */
+
+	/* Set options word to its new value */
+	InstancePtr->Options |= Options;
+
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "setOptions: rcw1 is now (end): 0x%0x\n",
+		    XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					     XTE_RCW1_OFFSET));
+	xdbg_printf(XDBG_DEBUG_GENERAL, "setOptions: returning SUCCESS\n");
+	return (XST_SUCCESS);
+}
+
+/*****************************************************************************/
+/**
+ * XLlTemac_ClearOptions clears the options, <i>Options</i> for the TEMAC channel,
+ * specified by <i>InstancePtr</i>. The TEMAC channel should be stopped with
+ * XLlTemac_Stop() before changing options.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param Options is a bitmask of OR'd XTE_*_OPTION values for options to
+ *        clear. Options not specified are not affected.
+ *
+ * @return On successful completion, XLlTemac_ClearOptions returns XST_SUCCESS.
+ *         Otherwise, if the device has not been stopped, XLlTemac_ClearOptions
+ *         returns XST_DEVICE_IS_STARTED.
+ *
+ * @note
+ * See xlltemac.h for a description of the available options.
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+int XLlTemac_ClearOptions(XLlTemac *InstancePtr, u32 Options)
+{
+	u32 Reg;		/* Generic */
+	u32 RegRcw1;		/* Reflects original contents of RCW1 */
+	u32 RegTc;		/* Reflects original contents of TC  */
+	u32 RegNewRcw1;		/* Reflects new contents of RCW1 */
+	u32 RegNewTc;		/* Reflects new contents of TC  */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_NONVOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+					 XTE_RDY_OFFSET) &
+			XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "Xtemac_ClearOptions: 0x%08x\n",
+		    Options);
+	/* Be sure device has been stopped */
+	if (InstancePtr->IsStarted == XCOMPONENT_IS_STARTED) {
+		return (XST_DEVICE_IS_STARTED);
+	}
+
+	/* Many of these options will change the RCW1 or TC registers.
+	 * Group these options here and change them all at once. What we are
+	 * trying to accomplish is to reduce the amount of IO to the device
+	 */
+
+	/* Grab current register contents */
+	RegRcw1 = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					   XTE_RCW1_OFFSET);
+	RegTc = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					 XTE_TC_OFFSET);
+	RegNewRcw1 = RegRcw1;
+	RegNewTc = RegTc;
+
+	/* Turn off jumbo packet support for both Rx and Tx */
+	if (Options & XTE_JUMBO_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "Xtemac_ClearOptions: disabling jumbo\n");
+		RegNewTc &= ~XTE_TC_JUM_MASK;
+		RegNewRcw1 &= ~XTE_RCW1_JUM_MASK;
+	}
+
+	/* Turn off VLAN packet support for both Rx and Tx */
+	if (Options & XTE_VLAN_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "Xtemac_ClearOptions: disabling vlan\n");
+		RegNewTc &= ~XTE_TC_VLAN_MASK;
+		RegNewRcw1 &= ~XTE_RCW1_VLAN_MASK;
+	}
+
+	/* Turn off FCS stripping on receive packets */
+	if (Options & XTE_FCS_STRIP_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "Xtemac_ClearOptions: disabling fcs strip\n");
+		RegNewRcw1 |= XTE_RCW1_FCS_MASK;
+	}
+
+	/* Turn off FCS insertion on transmit packets */
+	if (Options & XTE_FCS_INSERT_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "Xtemac_ClearOptions: disabling fcs insert\n");
+		RegNewTc |= XTE_TC_FCS_MASK;
+	}
+
+	/* Turn off length/type field checking on receive packets */
+	if (Options & XTE_LENTYPE_ERR_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "Xtemac_ClearOptions: disabling lentype err\n");
+		RegNewRcw1 |= XTE_RCW1_LT_DIS_MASK;
+	}
+
+	/* Disable transmitter */
+	if (Options & XTE_TRANSMITTER_ENABLE_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "Xtemac_ClearOptions: disabling transmitter\n");
+		RegNewTc &= ~XTE_TC_TX_MASK;
+	}
+
+	/* Disable receiver */
+	if (Options & XTE_RECEIVER_ENABLE_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "Xtemac_ClearOptions: disabling receiver\n");
+		RegNewRcw1 &= ~XTE_RCW1_RX_MASK;
+	}
+
+	/* Change the TC and RCW1 registers if they need to be
+	 * modified
+	 */
+	if (RegTc != RegNewTc) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "Xtemac_ClearOptions: setting TC: 0x%0x\n",
+			    RegNewTc);
+		XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+					  XTE_TC_OFFSET, RegNewTc);
+	}
+
+	if (RegRcw1 != RegNewRcw1) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "Xtemac_ClearOptions: setting RCW1: 0x%0x\n",
+			    RegNewRcw1);
+		XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+					  XTE_RCW1_OFFSET, RegNewRcw1);
+	}
+
+	/* Rest of options twiddle bits of other registers. Handle them one at
+	 * a time
+	 */
+
+	/* Turn off flow control */
+	if (Options & XTE_FLOW_CONTROL_OPTION) {
+		Reg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					       XTE_FCC_OFFSET);
+		Reg &= ~XTE_FCC_FCRX_MASK;
+		XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+					  XTE_FCC_OFFSET, Reg);
+	}
+
+	/* Turn off promiscuous frame filtering */
+	if (Options & XTE_PROMISC_OPTION) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "Xtemac_ClearOptions: disabling promiscuous mode\n");
+		Reg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					       XTE_AFM_OFFSET);
+		Reg &= ~XTE_AFM_PM_MASK;
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "Xtemac_ClearOptions: setting AFM: 0x%0x\n", Reg);
+		XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+					  XTE_AFM_OFFSET, Reg);
+	}
+
+	/* Disable broadcast address filtering */
+	if (Options & XTE_BROADCAST_OPTION) {
+		Reg = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				       XTE_RAF_OFFSET);
+		Reg |= XTE_RAF_BCSTREJ_MASK;
+		XLlTemac_WriteReg(InstancePtr->Config.BaseAddress,
+				  XTE_RAF_OFFSET, Reg);
+	}
+
+	/* Disable multicast address filtering */
+	if (Options & XTE_MULTICAST_OPTION) {
+		Reg = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				       XTE_RAF_OFFSET);
+		Reg |= XTE_RAF_MCSTREJ_MASK;
+		XLlTemac_WriteReg(InstancePtr->Config.BaseAddress,
+				  XTE_RAF_OFFSET, Reg);
+	}
+
+	/* The remaining options not handled here are managed elsewhere in the
+	 * driver. No register modifications are needed at this time. Reflecting the
+	 * option in InstancePtr->Options is good enough for now.
+	 */
+
+	/* Set options word to its new value */
+	InstancePtr->Options &= ~Options;
+
+	return (XST_SUCCESS);
+}
+
+/*****************************************************************************/
+/**
+ * XLlTemac_GetOptions returns the current option settings.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ *
+ * @return XLlTemac_GetOptions returns a bitmask of XTE_*_OPTION constants,
+ *         each bit specifying an option that is currently active.
+ *
+ * @note
+ * See xlltemac.h for a description of the available options.
+ *
+ ******************************************************************************/
+u32 XLlTemac_GetOptions(XLlTemac *InstancePtr)
+{
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	return (InstancePtr->Options);
+}
+
+/*****************************************************************************/
+/**
+ * XLlTemac_GetOperatingSpeed gets the current operating link speed. This may be
+ * the value set by XLlTemac_SetOperatingSpeed() or a hardware default.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ *
+ * @return XLlTemac_GetOperatingSpeed returns the link speed in units of megabits
+ *         per second.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+u16 XLlTemac_GetOperatingSpeed(XLlTemac *InstancePtr)
+{
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_NONVOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+					 XTE_RDY_OFFSET) &
+			XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_GetOperatingSpeed\n");
+	switch (XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					 XTE_EMMC_OFFSET) &
+		XTE_EMMC_LINKSPEED_MASK) {
+	case XTE_EMMC_LINKSPD_1000:
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "XLlTemac_GetOperatingSpeed: returning 1000\n");
+		return (1000);
+
+	case XTE_EMMC_LINKSPD_100:
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "XLlTemac_GetOperatingSpeed: returning 100\n");
+		return (100);
+
+	case XTE_EMMC_LINKSPD_10:
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			    "XLlTemac_GetOperatingSpeed: returning 10\n");
+		return (10);
+
+	default:
+		return (0);
+	}
+}
+
+
+/*****************************************************************************/
+/**
+ * XLlTemac_SetOperatingSpeed sets the current operating link speed. For any
+ * traffic to be passed, this speed must match the current MII/GMII/SGMII/RGMII
+ * link speed.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param Speed is the speed to set in units of Mbps. Valid values are 10, 100,
+ *        or 1000. XLlTemac_SetOperatingSpeed ignores invalid values.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+void XLlTemac_SetOperatingSpeed(XLlTemac *InstancePtr, u16 Speed)
+{
+	u32 EmmcReg;
+
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	XASSERT_VOID((Speed == 10) || (Speed == 100) || (Speed == 1000));
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_VOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				      XTE_RDY_OFFSET) &
+		     XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_SetOperatingSpeed\n");
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "XLlTemac_SetOperatingSpeed: setting speed to: %d (0x%0x)\n",
+		    Speed, Speed);
+	/* Get the current contents of the EMAC config register and zero out
+	 * speed bits
+	 */
+	EmmcReg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+					   XTE_EMMC_OFFSET) &
+		~XTE_EMMC_LINKSPEED_MASK;
+
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "XLlTemac_SetOperatingSpeed: current speed: 0x%0x\n",
+		    EmmcReg);
+	switch (Speed) {
+	case 10:
+		break;
+
+	case 100:
+		EmmcReg |= XTE_EMMC_LINKSPD_100;
+		break;
+
+	case 1000:
+		EmmcReg |= XTE_EMMC_LINKSPD_1000;
+		break;
+
+	default:
+		return;
+	}
+
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "XLlTemac_SetOperatingSpeed: new speed: 0x%0x\n", EmmcReg);
+	/* Set register and return */
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_EMMC_OFFSET, EmmcReg);
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_SetOperatingSpeed: done\n");
+}
+
+/*****************************************************************************/
+/**
+ * XLlTemac_PhySetMdioDivisor sets the MDIO clock divisor in the TEMAC channel,
+ * specified by <i>InstancePtr</i> to the value, <i>Divisor</i>. This function
+ * must be called once after each reset prior to accessing MII PHY registers.
+ *
+ * From the Virtex-4 Embedded Tri-Mode Ethernet MAC User's Guide, the
+ * following equation governs the MDIO clock to the PHY:
+ *
+ * <pre>
+ *              f[HOSTCLK]
+ *   f[MDC] = -----------------
+ *            (1 + Divisor) * 2
+ * </pre>
+ *
+ * where f[HOSTCLK] is the bus clock frequency in MHz, and f[MDC] is the
+ * MDIO clock frequency in MHz to the PHY. Typically, f[MDC] should not
+ * exceed 2.5 MHz. Some PHYs can tolerate faster speeds which means faster
+ * access.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param Divisor is the divisor value to set within the range of 0 to
+ *        XTE_MC_CLK_DVD_MAX.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+void XLlTemac_PhySetMdioDivisor(XLlTemac *InstancePtr, u8 Divisor)
+{
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY)
+		XASSERT_VOID(Divisor <= XTE_MC_CLOCK_DIVIDE_MAX);
+
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_VOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				      XTE_RDY_OFFSET) &
+		     XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_PhySetMdioDivisor\n");
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_MC_OFFSET,
+				  (u32) Divisor | XTE_MC_MDIOEN_MASK);
+}
+
+/*****************************************************************************/
+/*
+ * XLlTemac_PhyRead reads the specified PHY register, <i>RegiseterNum</i> on the
+ * PHY specified by <i>PhyAddress</i> into <i>PhyDataPtr</i>. This Ethernet
+ * driver does not require the device to be stopped before reading from the PHY.
+ * It is the responsibility of the calling code to stop the device if it is
+ * deemed necessary.
+ *
+ * Note that the TEMAC hardware provides the ability to talk to a PHY that
+ * adheres to the Media Independent Interface (MII) as defined in the IEEE 802.3
+ * standard.
+ *
+ * <b>It is important that calling code set up the MDIO clock with
+ * XLlTemac_PhySetMdioDivisor() prior to accessing the PHY with this function.</b>
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param PhyAddress is the address of the PHY to be written (multiple
+ *        PHYs supported).
+ * @param RegisterNum is the register number, 0-31, of the specific PHY register
+ *        to write.
+ * @param PhyDataPtr is a reference to the location where the 16-bit result
+ *        value is stored.
+ *
+ * @return N/A
+ *
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.<br><br>
+ *
+ * There is the possibility that this function will not return if the hardware
+ * is broken (i.e., it never sets the status bit indicating that the write is
+ * done). If this is of concern, the calling code should provide a mechanism
+ * suitable for recovery.
+ *
+ ******************************************************************************/
+void XLlTemac_PhyRead(XLlTemac *InstancePtr, u32 PhyAddress,
+		      u32 RegisterNum, u16 *PhyDataPtr)
+{
+	u32 MiiReg;
+	u32 Rdy;
+	u32 Ie;
+	u32 Tis;
+
+	XASSERT_VOID(InstancePtr != NULL);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_VOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				      XTE_RDY_OFFSET) &
+		     XTE_RDY_HARD_ACS_RDY_MASK);
+
+
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "XLlTemac_PhyRead: BaseAddress: 0x%08x\n",
+		    InstancePtr->Config.BaseAddress);
+	/*
+	 * XLlTemac_PhyRead saves the state of the IE register so that it can
+	 * clear the HardAcsCmplt bit and later restore the state of the IE
+	 * register. Since XLlTemac_PhyRead will poll for the status already, the
+	 * HardAcsCmplt bit is cleared in the IE register so that the
+	 * application code above doesn't also receive the interrupt.
+	 */
+	Ie = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress, XTE_IE_OFFSET);
+	XLlTemac_WriteReg(InstancePtr->Config.BaseAddress, XTE_IE_OFFSET,
+			  Ie & ~XTE_INT_HARDACSCMPLT_MASK);
+
+	/*
+	 * This is a double indirect mechanism. We indirectly write the
+	 * PHYAD and REGAD so we can read the PHY register back out in
+	 * the LSW register.
+	 *
+	 * In this case, the method of reading the data is a little unusual.
+	 * Normally to write to a TEMAC register, one would set the WEN bit
+	 * in the CTL register so that the values of the LSW will be written.
+	 *
+	 * In this case, the WEN bit is not set, and the PHYAD and REGAD
+	 * values in the LSW will still get sent to the PHY before actually
+	 * reading the result in the LSW.
+	 *
+	 * What needs to be done, is the following:
+	 * 1) Write lsw reg with the phyad, and the regad
+	 * 2) write the ctl reg with the miimai value (BUT WEN bit set to 0!!!)
+	 * 3) poll the ready bit
+	 * 4) get the value out of lsw
+	 */
+	MiiReg = RegisterNum & XTE_MIIM_REGAD_MASK;
+	MiiReg |= ((PhyAddress << XTE_MIIM_PHYAD_SHIFT) & XTE_MIIM_PHYAD_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "XLlTemac_PhyRead: Mii Reg: 0x%0x; Value written: 0x%0x\n",
+		    RegisterNum, MiiReg);
+	XLlTemac_WriteReg(InstancePtr->Config.BaseAddress, XTE_LSW_OFFSET,
+			  MiiReg);
+	XLlTemac_WriteReg(InstancePtr->Config.BaseAddress, XTE_CTL_OFFSET,
+			  XTE_MIIMAI_OFFSET);
+
+	/*
+	 * Wait here polling, until the value is ready to be read.
+	 */
+	do {
+		Rdy = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				       XTE_RDY_OFFSET);
+	} while (!(Rdy & XTE_RSE_MIIM_RR_MASK));
+
+	/* Read data */
+	*PhyDataPtr = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				       XTE_LSW_OFFSET);
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "XLlTemac_PhyRead: Value retrieved: 0x%0x\n", *PhyDataPtr);
+
+	/*
+	 * Clear MII status bits. The TIS register in the hard TEMAC doesn't
+	 * use the 'write a 1 to clear' method, so we need to read the TIS
+	 * register, clear the MIIM RST bit, and then write it back out.
+	 */
+	Tis = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+				       XTE_TIS_OFFSET);
+	Tis &= ~XTE_RSE_MIIM_RR_MASK;
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_TIS_OFFSET, Tis);
+
+	/*
+	 * restore the state of the IE reg
+	 */
+	XLlTemac_WriteReg(InstancePtr->Config.BaseAddress, XTE_IE_OFFSET, Ie);
+}
+
+
+/*****************************************************************************/
+/*
+ * XLlTemac_PhyWrite writes <i>PhyData</i> to the specified PHY register,
+ * <i>RegiseterNum</i> on the PHY specified by <i>PhyAddress</i>. This Ethernet
+ * driver does not require the device to be stopped before writing to the PHY.
+ * It is the responsibility of the calling code to stop the device if it is
+ * deemed necessary.
+ *
+ * Note that the TEMAC hardware provides the ability to talk to a PHY that
+ * adheres to the Media Independent Interface (MII) as defined in the IEEE 802.3
+ * standard.
+ *
+ * <b>It is important that calling code set up the MDIO clock with
+ * XLlTemac_PhySetMdioDivisor() prior to accessing the PHY with this function.</b>
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param PhyAddress is the address of the PHY to be written (multiple
+ *        PHYs supported).
+ * @param RegisterNum is the register number, 0-31, of the specific PHY register
+ *        to write.
+ * @param PhyData is the 16-bit value that will be written to the register.
+ *
+ * @return N/A
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.<br><br>
+ *
+ * There is the possibility that this function will not return if the hardware
+ * is broken (i.e., it never sets the status bit indicating that the write is
+ * done). If this is of concern, the calling code should provide a mechanism
+ * suitable for recovery.
+ *
+ ******************************************************************************/
+void XLlTemac_PhyWrite(XLlTemac *InstancePtr, u32 PhyAddress,
+		       u32 RegisterNum, u16 PhyData)
+{
+	u32 MiiReg;
+	u32 Rdy;
+	u32 Ie;
+	u32 Tis;
+
+	XASSERT_VOID(InstancePtr != NULL);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_VOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				      XTE_RDY_OFFSET) &
+		     XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_PhyWrite\n");
+	/*
+	 * XLlTemac_PhyWrite saves the state of the IE register so that it can
+	 * clear the HardAcsCmplt bit and later restore the state of the IE
+	 * register. Since XLlTemac_PhyWrite will poll for the status already, the
+	 * HardAcsCmplt bit is cleared in the IE register so that the
+	 * application code above doesn't also receive the interrupt.
+	 */
+	Ie = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress, XTE_IE_OFFSET);
+	XLlTemac_WriteReg(InstancePtr->Config.BaseAddress, XTE_IE_OFFSET,
+			  Ie & ~XTE_INT_HARDACSCMPLT_MASK);
+
+	/*
+	 * This is a double indirect mechanism. We indirectly write the
+	 * PhyData to the MIIMWD register, and then indirectly write PHYAD and
+	 * REGAD so the value in MIIMWD will get written to the PHY.
+	 */
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_MIIMWD_OFFSET, PhyData);
+
+	MiiReg = RegisterNum & XTE_MIIM_REGAD_MASK;
+	MiiReg |= ((PhyAddress << XTE_MIIM_PHYAD_SHIFT) & XTE_MIIM_PHYAD_MASK);
+
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_MIIMAI_OFFSET, MiiReg);
+
+	/*
+	 * Wait here polling, until the value is ready to be read.
+	 */
+	do {
+		Rdy = XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+				       XTE_RDY_OFFSET);
+	} while (!(Rdy & XTE_RSE_MIIM_WR_MASK));
+
+	/*
+	 * Clear MII status bits. The TIS register in the hard TEMAC doesn't
+	 * use the 'write a 1 to clear' method, so we need to read the TIS
+	 * register, clear the MIIM WST bit, and then write it back out.
+	 */
+	Tis = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+				       XTE_TIS_OFFSET);
+	Tis &= XTE_RSE_MIIM_WR_MASK;
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+				  XTE_TIS_OFFSET, Tis);
+
+	/*
+	 * restore the state of the IE reg
+	 */
+	XLlTemac_WriteReg(InstancePtr->Config.BaseAddress, XTE_IE_OFFSET, Ie);
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/net/xilinx_lltemac/xlltemac_control.c linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/xlltemac_control.c
--- linux-2.6.31.12/drivers/net/xilinx_lltemac/xlltemac_control.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/xlltemac_control.c	2010-08-08 17:22:50.611911713 +0200
@@ -0,0 +1,679 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2005-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+ *
+ * @file xlltemac_control.c
+ *
+ * Functions in this file implement general purpose command and control related
+ * functionality. See xlltemac.h for a detailed description of the driver.
+ *
+ * <pre>
+ * MODIFICATION HISTORY:
+ *
+ * Ver   Who  Date     Changes
+ * ----- ---- -------- -------------------------------------------------------
+ * 1.00a jvb  11/10/06 First release
+ * </pre>
+ *****************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include "xlltemac.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+
+/************************** Variable Definitions *****************************/
+
+
+/*****************************************************************************/
+/**
+ * in the TEMAC channel's multicast filter list.
+ *
+ * XLlTemac_MulticastAdd adds the Ethernet address, <i>AddressPtr</i> to the
+ * TEMAC channel's multicast filter list, at list index <i>Entry</i>. The
+ * address referenced by <i>AddressPtr</i> may be of any unicast, multicast, or
+ * broadcast address form. The harware for the TEMAC channel can hold up to
+ * XTE_MULTI_MAT_ENTRIES addresses in this filter list.<br><br>
+ *
+ * The device must be stopped to use this function.<br><br>
+ *
+ * Once an Ethernet address is programmed, the TEMAC channel will begin
+ * receiving data sent from that address. The TEMAC hardware does not have a
+ * control bit to disable multicast filtering. The only way to prevent the
+ * TEMAC channel from receiving messages from an Ethernet address in the
+ * Multicast Address Table (MAT) is to clear it with XLlTemac_MulticastClear().
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param AddressPtr is a pointer to the 6-byte Ethernet address to set. The
+ *        previous address at the location <i>Entry</i> (if any) is overwritten
+ *        with the value at <i>AddressPtr</i>.
+ * @param Entry is the hardware storage location to program this address and
+ *        must be between 0..XTE_MULTI_MAT_ENTRIES-1. 
+ *
+ * @return On successful completion, XLlTemac_MulticastAdd returns XST_SUCCESS.
+ *         Otherwise, if the TEMAC channel is not stopped, XLlTemac_MulticastAdd
+ *         returns XST_DEVICE_IS_STARTED.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+int XLlTemac_MulticastAdd(XLlTemac *InstancePtr, void *AddressPtr, int Entry)
+{
+	u32 Maw0Reg;
+	u32 Maw1Reg;
+	u8 *Aptr = (u8 *) AddressPtr;
+	u32 Rdy;
+	int MaxWait = 100;
+	u32 BaseAddress = InstancePtr->Config.BaseAddress;
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	XASSERT_NONVOID(AddressPtr != NULL);
+	XASSERT_NONVOID(Entry < XTE_MULTI_MAT_ENTRIES);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_NONVOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+			XTE_RDY_OFFSET) & XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_MulticastAdd\n");
+
+	/* The device must be stopped before clearing the multicast hash table */
+	if (InstancePtr->IsStarted == XCOMPONENT_IS_STARTED) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			   "XLlTemac_MulticastAdd: returning DEVICE_IS_STARTED\n");
+
+		return (XST_DEVICE_IS_STARTED);
+	}
+
+	/* Set MAC bits [31:0] */
+	Maw0Reg = Aptr[0];
+	Maw0Reg |= Aptr[1] << 8;
+	Maw0Reg |= Aptr[2] << 16;
+	Maw0Reg |= Aptr[3] << 24;
+
+	/* Set MAC bits [47:32] */
+	Maw1Reg = Aptr[4];
+	Maw1Reg |= Aptr[5] << 8;
+
+	/* Add in MAT address */
+	Maw1Reg |= (Entry << XTE_MAW1_MATADDR_SHIFT_MASK);
+
+	/* Program HW */
+	xdbg_printf(XDBG_DEBUG_GENERAL, "Setting MAT entry: %d\n", Entry);
+	XLlTemac_WriteReg(BaseAddress, XTE_LSW_OFFSET, Maw0Reg);
+	XLlTemac_WriteReg(BaseAddress, XTE_CTL_OFFSET,
+			XTE_MAW0_OFFSET | XTE_CTL_WEN_MASK);
+	Rdy = XLlTemac_ReadReg(BaseAddress, XTE_RDY_OFFSET);
+	while (MaxWait && (!(Rdy & XTE_RDY_HARD_ACS_RDY_MASK))) {
+		Rdy = XLlTemac_ReadReg(BaseAddress, XTE_RDY_OFFSET);
+		xdbg_stmnt(
+			if (MaxWait == 100) {
+				xdbg_printf(XDBG_DEBUG_GENERAL,
+					    "RDY reg not initially ready\n");
+			}
+		);
+		MaxWait--;
+		xdbg_stmnt(
+			if (MaxWait == 0) {
+				xdbg_printf (XDBG_DEBUG_GENERAL,
+					     "RDY reg never showed ready\n");
+			}
+		)
+	}
+	XLlTemac_WriteReg(BaseAddress, XTE_LSW_OFFSET,
+			Maw1Reg);
+	XLlTemac_WriteReg(BaseAddress, XTE_CTL_OFFSET,
+			XTE_MAW1_OFFSET | XTE_CTL_WEN_MASK);
+	Rdy = XLlTemac_ReadReg(BaseAddress, XTE_RDY_OFFSET);
+	while (MaxWait && (!(Rdy & XTE_RDY_HARD_ACS_RDY_MASK))) {
+		Rdy = XLlTemac_ReadReg(BaseAddress, XTE_RDY_OFFSET);
+		xdbg_stmnt(
+			if (MaxWait == 100) {
+				xdbg_printf(XDBG_DEBUG_GENERAL,
+					    "RDY reg not initially ready\n");
+			}
+		);
+		MaxWait--;
+		xdbg_stmnt(
+			if (MaxWait == 0) {
+				xdbg_printf (XDBG_DEBUG_GENERAL,
+					     "RDY reg never showed ready\n");
+			}
+		)
+	}
+	
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_MulticastAdd: returning SUCCESS\n");
+
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * XLlTemac_MulticastGet gets the Ethernet address stored at index <i>Entry</i>
+ * in the TEMAC channel's multicast filter list.<br><br>
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param AddressPtr references the memory buffer to store the retrieved
+ *        Ethernet address. This memory buffer must be at least 6 bytes in
+ *        length.
+ * @param Entry is the hardware storage location from which to retrieve the
+ *        address and must be between 0..XTE_MULTI_MAT_ENTRIES-1. 
+ *
+ * @return N/A
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+void XLlTemac_MulticastGet(XLlTemac *InstancePtr, void *AddressPtr, int Entry)
+{
+	u32 Maw0Reg;
+	u32 Maw1Reg;
+	u8 *Aptr = (u8 *) AddressPtr;
+	u32 Rdy;
+	int MaxWait = 100;
+	u32 BaseAddress = InstancePtr->Config.BaseAddress;
+
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	XASSERT_VOID(Entry < XTE_MULTI_MAT_ENTRIES);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_VOID(XLlTemac_ReadReg(BaseAddress, XTE_RDY_OFFSET) &
+			XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_MulticastGet\n");
+
+	/*
+	 * Tell HW to provide address stored in given entry.
+	 * In this case, the Access is a little weird, becuase we need to
+	 * write the LSW register first, then initiate a write operation,
+	 * even though it's a read operation.
+	 */
+	xdbg_printf(XDBG_DEBUG_GENERAL, "Getting MAT entry: %d\n", Entry);
+	XLlTemac_WriteReg(BaseAddress, XTE_LSW_OFFSET,
+			 Entry << XTE_MAW1_MATADDR_SHIFT_MASK | XTE_MAW1_RNW_MASK);
+	XLlTemac_WriteReg(BaseAddress, XTE_CTL_OFFSET,
+			 XTE_MAW1_OFFSET | XTE_CTL_WEN_MASK);
+	Rdy = XLlTemac_ReadReg(BaseAddress, XTE_RDY_OFFSET);
+	while (MaxWait && (!(Rdy & XTE_RDY_HARD_ACS_RDY_MASK))) {
+		Rdy = XLlTemac_ReadReg(BaseAddress, XTE_RDY_OFFSET);
+		xdbg_stmnt(
+			if (MaxWait == 100) {
+				xdbg_printf(XDBG_DEBUG_GENERAL,
+					    "RDY reg not initially ready\n");
+			}
+		);
+		MaxWait--;
+		xdbg_stmnt(
+			if (MaxWait == 0) {
+				xdbg_printf(XDBG_DEBUG_GENERAL,
+					     "RDY reg never showed ready\n");
+			}
+		)
+
+	}
+	Maw0Reg = XLlTemac_ReadReg(BaseAddress, XTE_LSW_OFFSET);
+	Maw1Reg = XLlTemac_ReadReg(BaseAddress, XTE_MSW_OFFSET);
+	
+	/* Copy the address to the user buffer */
+	Aptr[0] = (u8) Maw0Reg;
+	Aptr[1] = (u8) (Maw0Reg >> 8);
+	Aptr[2] = (u8) (Maw0Reg >> 16);
+	Aptr[3] = (u8) (Maw0Reg >> 24);
+	Aptr[4] = (u8) Maw1Reg;
+	Aptr[5] = (u8) (Maw1Reg >> 8);
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_MulticastGet: done\n");
+}
+
+/*****************************************************************************/
+/**
+ * XLlTemac_MulticastClear clears the Ethernet address stored at index <i>Entry</i>
+ * in the TEMAC channel's multicast filter list.<br><br>
+ *
+ * The device must be stopped to use this function.<br><br>
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param Entry is the HW storage location used when this address was added.
+ *        It must be between 0..XTE_MULTI_MAT_ENTRIES-1.
+ * @param Entry is the hardware storage location to clear and must be between
+ *        0..XTE_MULTI_MAT_ENTRIES-1. 
+ *
+ * @return On successful completion, XLlTemac_MulticastClear returns XST_SUCCESS.
+ *         Otherwise, if the TEMAC channel is not stopped, XLlTemac_MulticastClear
+ *         returns XST_DEVICE_IS_STARTED.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+int XLlTemac_MulticastClear(XLlTemac *InstancePtr, int Entry)
+{
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	XASSERT_NONVOID(Entry < XTE_MULTI_MAT_ENTRIES);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_NONVOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+			XTE_RDY_OFFSET) & XTE_RDY_HARD_ACS_RDY_MASK);
+	
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_MulticastClear\n");
+
+	/* The device must be stopped before clearing the multicast hash table */
+	if (InstancePtr->IsStarted == XCOMPONENT_IS_STARTED) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			   "XLlTemac_MulticastClear: returning DEVICE_IS_STARTED\n");
+		return (XST_DEVICE_IS_STARTED);
+	}
+
+	/* Clear the entry by writing 0:0:0:0:0:0 to it */
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+			XTE_MAW0_OFFSET, 0);
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+			XTE_MAW1_OFFSET, Entry << XTE_MAW1_MATADDR_SHIFT_MASK);
+	
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		    "XLlTemac_MulticastClear: returning SUCCESS\n");
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * XLlTemac_SetMacPauseAddress sets the MAC address used for pause frames to
+ * <i>AddressPtr</i>. <i>AddressPtr</i> will be the address the TEMAC channel
+ * will recognize as being for pause frames. Pause frames transmitted with
+ * XLlTemac_SendPausePacket() will also use this address.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param AddressPtr is a pointer to the 6-byte Ethernet address to set.
+ *
+ * @return On successful completion, XLlTemac_SetMacPauseAddress returns
+ *         XST_SUCCESS. Otherwise, if the TEMAC channel is not stopped,
+ *         XLlTemac_SetMacPauseAddress returns XST_DEVICE_IS_STARTED.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+int XLlTemac_SetMacPauseAddress(XLlTemac *InstancePtr, void *AddressPtr)
+{
+	u32 MacAddr;
+	u8 *Aptr = (u8 *) AddressPtr;
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_NONVOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+			XTE_RDY_OFFSET) & XTE_RDY_HARD_ACS_RDY_MASK);
+	
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_SetMacPauseAddress\n");
+	/* Be sure device has been stopped */
+	if (InstancePtr->IsStarted == XCOMPONENT_IS_STARTED) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			   "XLlTemac_SetMacPauseAddress: returning DEVICE_IS_STARTED\n");
+		return (XST_DEVICE_IS_STARTED);
+	}
+
+	/* Set the MAC bits [31:0] in ERXC0 */
+	MacAddr = Aptr[0];
+	MacAddr |= Aptr[1] << 8;
+	MacAddr |= Aptr[2] << 16;
+	MacAddr |= Aptr[3] << 24;
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+			XTE_RCW0_OFFSET, MacAddr);
+
+	/* ERCW1 contains other info that must be preserved */
+	MacAddr = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+			XTE_RCW1_OFFSET);
+	MacAddr &= ~XTE_RCW1_PAUSEADDR_MASK;
+
+	/* Set MAC bits [47:32] */
+	MacAddr |= Aptr[4];
+	MacAddr |= Aptr[5] << 8;
+	XLlTemac_WriteIndirectReg(InstancePtr->Config.BaseAddress,
+			XTE_RCW1_OFFSET, MacAddr);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		   "XLlTemac_SetMacPauseAddress: returning SUCCESS\n");
+
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * XLlTemac_GetMacPauseAddress gets the MAC address used for pause frames for the
+ * TEMAC channel specified by <i>InstancePtr</i>. 
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param AddressPtr references the memory buffer to store the retrieved MAC
+ *        address. This memory buffer must be at least 6 bytes in length.
+ *
+ * @return N/A
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+void XLlTemac_GetMacPauseAddress(XLlTemac *InstancePtr, void *AddressPtr)
+{
+	u32 MacAddr;
+	u8 *Aptr = (u8 *) AddressPtr;
+
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_VOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+			XTE_RDY_OFFSET) & XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_SetMacPauseAddress\n");
+	
+	/* Read MAC bits [31:0] in ERXC0 */
+	MacAddr = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+			XTE_RCW0_OFFSET);
+	Aptr[0] = (u8) MacAddr;
+	Aptr[1] = (u8) (MacAddr >> 8);
+	Aptr[2] = (u8) (MacAddr >> 16);
+	Aptr[3] = (u8) (MacAddr >> 24);
+
+	/* Read MAC bits [47:32] in RCW1 */
+	MacAddr = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+			XTE_RCW1_OFFSET);
+	Aptr[4] = (u8) MacAddr;
+	Aptr[5] = (u8) (MacAddr >> 8);
+	
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_SetMacPauseAddress: done\n");
+}
+
+/*****************************************************************************/
+/**
+ * XLlTemac_SendPausePacket sends a pause packet with the value of
+ * <i>PauseValue</i>.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param PauseValue is the pause value in units of 512 bit times.
+ *
+ * @return On successful completion, XLlTemac_SendPausePacket returns
+ *         XST_SUCCESS. Otherwise, if the TEMAC channel is not started,
+ *         XLlTemac_SendPausePacket returns XST_DEVICE_IS_STOPPED.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+int XLlTemac_SendPausePacket(XLlTemac *InstancePtr, u16 PauseValue)
+{
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_NONVOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+			XTE_RDY_OFFSET) & XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_SetMacPauseAddress\n");
+
+	/* Make sure device is ready for this operation */
+	if (InstancePtr->IsStarted != XCOMPONENT_IS_STARTED) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			   "XLlTemac_SendPausePacket: returning DEVICE_IS_STOPPED\n");
+		return (XST_DEVICE_IS_STOPPED);
+	}
+
+	/* Send flow control frame */
+	XLlTemac_WriteReg(InstancePtr->Config.BaseAddress, XTE_TPF_OFFSET,
+			     (u32) PauseValue & XTE_TPF_TPFV_MASK);
+	
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		   "XLlTemac_SendPausePacket: returning SUCCESS\n");
+	return (XST_SUCCESS);
+}
+
+/*****************************************************************************/
+/**
+ * XLlTemac_GetSgmiiStatus get the state of the link when using the SGMII media
+ * interface.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param SpeedPtr references the location to store the result, which is the
+ *        autonegotiated link speed in units of Mbits/sec, either 0, 10, 100,
+ *        or 1000.
+ *
+ * @return On successful completion, XLlTemac_GetSgmiiStatus returns XST_SUCCESS.
+ *         Otherwise, if TEMAC channel is not using an SGMII interface,
+ *         XLlTemac_GetSgmiiStatus returns XST_NO_FEATURE.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+int XLlTemac_GetSgmiiStatus(XLlTemac *InstancePtr, u16 *SpeedPtr)
+{
+	int PhyType;
+	u32 EgmicReg;
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_NONVOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+			XTE_RDY_OFFSET) & XTE_RDY_HARD_ACS_RDY_MASK);
+
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_GetSgmiiStatus\n");
+	/* Make sure PHY is SGMII */
+	PhyType = XLlTemac_GetPhysicalInterface(InstancePtr);
+	if (PhyType != XTE_PHY_TYPE_SGMII) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			   "XLlTemac_GetSgmiiStatus: returning NO_FEATURE\n");
+		return (XST_NO_FEATURE);
+	}
+
+	/* Get the current contents of RGMII/SGMII config register */
+	EgmicReg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+			XTE_PHYC_OFFSET);
+
+	/* Extract speed */
+	switch (EgmicReg & XTE_PHYC_SGMIILINKSPEED_MASK) {
+	case XTE_PHYC_SGLINKSPD_10:
+		*SpeedPtr = 10;
+		break;
+
+	case XTE_PHYC_SGLINKSPD_100:
+		*SpeedPtr = 100;
+		break;
+
+	case XTE_PHYC_SGLINKSPD_1000:
+		*SpeedPtr = 1000;
+		break;
+
+	default:
+		*SpeedPtr = 0;
+	}
+		
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		   "XLlTemac_GetSgmiiStatus: returning SUCCESS\n");
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * XLlTemac_GetRgmiiStatus get the state of the link when using the RGMII media
+ * interface.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ * @param SpeedPtr references the location to store the result, which is the
+ *        autonegotiaged link speed in units of Mbits/sec, either 0, 10, 100,
+ *        or 1000.
+ * @param IsFullDuplexPtr references the value to set to indicate full duplex
+ *        operation. XLlTemac_GetRgmiiStatus sets <i>IsFullDuplexPtr</i> to TRUE
+ *        when the RGMII link is operating in full duplex mode. Otherwise,
+ *        XLlTemac_GetRgmiiStatus sets <i>IsFullDuplexPtr</i> to FALSE.
+ * @param IsLinkUpPtr references the value to set to indicate the link status.
+ *        XLlTemac_GetRgmiiStatus sets <i>IsLinkUpPtr</i> to TRUE when the RGMII
+ *        link up. Otherwise, XLlTemac_GetRgmiiStatus sets <i>IsLinkUpPtr</i> to
+ *        FALSE.
+ *
+ * @return On successful completion, XLlTemac_GetRgmiiStatus returns XST_SUCCESS.
+ *         Otherwise, if TEMAC channel is not using an RGMII interface,
+ *         XLlTemac_GetRgmiiStatus returns XST_NO_FEATURE.
+ *
+ * @note
+ *
+ * This routine accesses the hard TEMAC registers through a shared interface
+ * between both channels of the TEMAC. Becuase of this, the application/OS code
+ * must provide mutual exclusive access to this routine with any of the other
+ * routines in this TEMAC driverr.
+ *
+ ******************************************************************************/
+int XLlTemac_GetRgmiiStatus(XLlTemac *InstancePtr, u16 *SpeedPtr,
+			      int *IsFullDuplexPtr, int *IsLinkUpPtr)
+{
+	int PhyType;
+	u32 EgmicReg;
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+	/*
+	 * If the mutual exclusion is enforced properly in the calling code, we
+	 * should never get into the following case.
+	 */
+	XASSERT_NONVOID(XLlTemac_ReadReg(InstancePtr->Config.BaseAddress,
+			XTE_RDY_OFFSET) & XTE_RDY_HARD_ACS_RDY_MASK);
+		
+	xdbg_printf(XDBG_DEBUG_GENERAL, "XLlTemac_GetRgmiiStatus\n");
+	/* Make sure PHY is RGMII */
+	PhyType = XLlTemac_GetPhysicalInterface(InstancePtr);
+	if ((PhyType != XTE_PHY_TYPE_RGMII_1_3) &&
+	    (PhyType != XTE_PHY_TYPE_RGMII_2_0)) {
+		xdbg_printf(XDBG_DEBUG_GENERAL,
+			   "XLlTemac_GetRgmiiStatus: returning NO_FEATURE\n");
+		return (XST_NO_FEATURE);
+	}
+
+	/* Get the current contents of RGMII/SGMII config register */
+	EgmicReg = XLlTemac_ReadIndirectReg(InstancePtr->Config.BaseAddress,
+			XTE_PHYC_OFFSET);
+
+	/* Extract speed */
+	switch (EgmicReg & XTE_PHYC_RGMIILINKSPEED_MASK) {
+	case XTE_PHYC_RGLINKSPD_10:
+		*SpeedPtr = 10;
+		break;
+
+	case XTE_PHYC_RGLINKSPD_100:
+		*SpeedPtr = 100;
+		break;
+
+	case XTE_PHYC_RGLINKSPD_1000:
+		*SpeedPtr = 1000;
+		break;
+
+	default:
+		*SpeedPtr = 0;
+	}
+
+	/* Extract duplex and link status */
+	if (EgmicReg & XTE_PHYC_RGMIIHD_MASK) {
+		*IsFullDuplexPtr = FALSE;
+	}
+	else {
+		*IsFullDuplexPtr = TRUE;
+	}
+
+	if (EgmicReg & XTE_PHYC_RGMIILINK_MASK) {
+		*IsLinkUpPtr = TRUE;
+	}
+	else {
+		*IsLinkUpPtr = FALSE;
+	}
+
+	xdbg_printf(XDBG_DEBUG_GENERAL,
+		   "XLlTemac_GetRgmiiStatus: returning SUCCESS\n");
+	return (XST_SUCCESS);
+}
+
diff -purN --exclude=.git linux-2.6.31.12/drivers/net/xilinx_lltemac/xlltemac.h linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/xlltemac.h
--- linux-2.6.31.12/drivers/net/xilinx_lltemac/xlltemac.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/xlltemac.h	2010-08-08 17:22:50.611911713 +0200
@@ -0,0 +1,785 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2005-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+ *
+ * @file xlltemac.h
+ *
+ * The Xilinx Tri-Mode Ethernet driver component. This driver supports the
+ * Virtex-5(TM) and Virtex-4(TM) 10/100/1000 MAC (TEMAC).
+ *
+ * For a full description of TEMAC features, please see the hardware spec. This driver
+ * supports the following features:
+ *   - Memory mapped access to host interface registers
+ *   - Virtual memory support
+ *   - Unicast, broadcast, and multicast receive address filtering
+ *   - Full duplex operation (half duplex not supported)
+ *   - Automatic source address insertion or overwrite (programmable)
+ *   - Automatic PAD & FCS insertion and stripping (programmable)
+ *   - Flow control
+ *   - VLAN frame support
+ *   - Pause frame support
+ *   - Jumbo frame support
+ *   - Checksum offload
+ *
+ * <h2>Driver Description</h2>
+ *
+ * The device driver enables higher layer software (e.g., an application) to
+ * configure a TEMAC channel. It is intended that this driver be used in
+ * cooperation with another driver (FIFO or DMA) for data communication. This
+ * device driver can support multiple devices even when those devices have
+ * significantly different configurations.
+ *
+ * <h2>Initialization & Configuration</h2>
+ *
+ * The XLlTemac_Config structure can be used by the driver to configure itself.
+ * This configuration structure is typically created by the tool-chain based on
+ * hardware build properties, although, other methods are allowed and currently
+ * used in some systems.
+ *
+ * To support multiple runtime loading and initialization strategies employed
+ * by various operating systems, the driver instance can be initialized using
+ * the XLlTemac_CfgInitialze() routine.
+ *
+ * <h2>Interrupts and Asynchronous Callbacks</h2>
+ *
+ * The driver has no dependencies on the interrupt controller. It provides
+ * no interrupt handlers. The application/OS software should set up its own
+ * interrupt handlers if required.
+ *
+ * <h2>Device Reset</h2>
+ *
+ * When a TEMAC channel is connected up to a FIFO or DMA core in hardware,
+ * errors may be reported on one of those cores (FIFO or DMA) such that it can
+ * be determined that the TEMAC channel needs to be reset. If a reset is
+ * performed, the calling code should also reconfigure and reapply the proper
+ * settings in the TEMAC channel.
+ *
+ * When a TEMAC channel reset is required, XLlTemac_Reset() should be utilized.
+ *
+ * <h2>Virtual Memory</h2>
+ *
+ * This driver may be used in systems with virtual memory support by passing
+ * the appropriate value for the <i>EffectiveAddress</i> parameter to the
+ * XLlTemac_CfgInitialize() routine.
+ *
+ * <h2>Transfering Data</h2>
+ *
+ * The TEMAC core by itself is not cabable of transmitting or receiving data in
+ * any meaninful way. Instead one or both TEMAC channels need to be connected
+ * to a FIFO or DMA core in hardware.
+ *
+ * This TEMAC driver is modeled in a similar fashion where the application code
+ * or O/S adapter driver needs to make use of a separte FIFO or DMA driver in
+ * connection with this driver to establish meaningful communication over
+ * ethernet.
+ *
+ * <h2>Checksum Offloading</h2>
+ *
+ * If configured, the device can compute a 16-bit checksum from frame data. In
+ * most circumstances this can lead to a substantial gain in throughput.
+ *
+ * The checksum offload settings for each frame sent or recieved are
+ * transmitted through the LocalLink interface in hardware. What this means is
+ * that the checksum offload feature is indirectly controlled in the TEMAC
+ * channel through the driver for the FIFO or DMA core connected to the TEMAC
+ * channel.
+ *
+ * Refer to the documentation for the FIFO or DMA driver used for data
+ * communication on how to set the values for the relevant LocalLink header
+ * words.
+ *
+ * Since this hardware implementation is general purpose in nature system software must
+ * perform pre and post frame processing to obtain the desired results for the
+ * types of packets being transferred. Most of the time this will be TCP/IP
+ * traffic.
+ *
+ * TCP/IP and UDP/IP frames contain separate checksums for the IP header and
+ * UDP/TCP header+data. With this hardware implementation, the IP header checksum
+ * cannot be offloaded. Many stacks that support offloading will compute the IP
+ * header if required and use hardware to compute the UDP/TCP header+data checksum.
+ * There are other complications concerning the IP pseudo header that must be
+ * taken into consideration. Readers should consult a TCP/IP design reference
+ * for more details.
+ *
+ * There are certain device options that will affect the checksum calculation
+ * performed by hardware for Tx:
+ *
+ *   - FCS insertion disabled (XTE_FCS_INSERT_OPTION): software is required to
+ *     calculate and insert the FCS value at the end of the frame, but the
+ *     checksum must be known ahead of time prior to calculating the FCS.
+ *     Therefore checksum offloading cannot be used in this situation.
+ *
+ * And for Rx:
+ *
+ *   - FCS/PAD stripping disabled (XTE_FCS_STRIP_OPTION): The 4 byte FCS at the
+ *     end of frame will be included in the hardware calculated checksum. software must
+ *     subtract out this data.
+ *
+ *   - FCS/PAD stripping disabled (XTE_FCS_STRIP_OPTION): For frames smaller
+ *     than 64 bytes, padding will be included in the hardware calculated checksum.
+ *     software must subtract out this data. It may be better to allow the TCP/IP
+ *     stack verify checksums for this type of packet.
+ *
+ *   - VLAN enabled (XTE_VLAN_OPTION): The 4 extra bytes in the Ethernet header
+ *     affect the hardware calculated checksum. software must subtract out the 1st two
+ *     16-bit words starting at the 15th byte.
+ *
+ * <h3>Transmit Checksum Offloading</h3>
+ *
+ * For transmit, the software can specify where in the frame the checksum
+ * calculation is to start, where the result should be inserted, and a seed
+ * value. The checksum is calculated from the start point through the end of
+ * frame.
+ *
+ * The checsum offloading settings are sent in the transmit LocalLink header
+ * words. The relevant LocalLink header words are described in brief below.
+ * Refer to the XPS_LL_TEMAC v1.00a hardware specification for more details.
+ *
+ *   <h4>LocalLink header word 3:</h4>
+ *   <pre>
+ *   Bits    31 (MSB): Transmit Checksum Enable: 1 - enabled, 0 - disabled
+ *   Bits  0-30 (LSB): Reserved
+ *   </pre>
+ *
+ *   <h4>LocalLink header word 4:</h4>
+ *   <pre>
+ *   Bits 16-31 (MSB): Transmit Checksum Insertion Point: Frame offset where the
+ *                     computed checksum value is stored, which should be in the
+ *                     TCP or UDP header
+ *   Bits  0-15 (LSB): Transmit Checksum Calculation Starting Point: Offset
+ *                     in the frame where checksum calculation should begin
+ *   </pre>
+ *
+ *   <h4>LocalLink header word 5:</h4>
+ *   <pre>
+ *   Bits 16-31 (MSB): Transmit Checksum Calculation Initial Value: Checksum
+ *                     seed value
+ *   Bits  0-15 (LSB): Reserved
+ *   </pre>
+ *
+ * <h3>Receive Checksum Offloading</h3>
+ *
+ * For Receive, the 15th byte to end of frame is checksummed. This range of
+ * bytes is the entire Ethernet payload (for non-VLAN frames).
+ *
+ * The checsum offloading information is sent in the receive LocalLink header
+ * words. The relevant LocalLink header words are described in brief below.
+ * Refer to the XPS_LL_TEMAC v1.00a hardware specification for more details.
+ *
+ *   <h4>LocalLink header word 6:</h4>
+ *   <pre>
+ *   Bits 16-31 (MSB): Receive Raw Checksum: Computed checksum value
+ *   Bits  0-15 (LSB): Reserved
+ *   </pre>
+ *
+ * <h2>PHY Communication</h2>
+ *
+ * Prior to PHY access, the MDIO clock must be setup. This driver will set a
+ * safe default that should work with PLB bus speeds of up to 150 MHz and keep
+ * the MDIO clock below 2.5 MHz. If the user wishes faster access to the PHY
+ * then the clock divisor can be set to a different value (see
+ * XLlTemac_PhySetMdioDivisor()).
+ *
+ * MII register access is performed through the functions XLlTemac_PhyRead() and
+ * XLlTemac_PhyWrite().
+ *
+ * <h2>Link Sync</h2>
+ *
+ * When the device is used in a multispeed environment, the link speed must be
+ * explicitly set using XLlTemac_SetOperatingSpeed() and must match the speed the
+ * PHY has negotiated. If the speeds are mismatched, then the MAC will not pass
+ * traffic.
+ *
+ * The application/OS software may use the AutoNegotiation interrupt to be
+ * notified when the PHY has completed auto-negotiation.
+ *
+ * <h2>Asserts</h2>
+ *
+ * Asserts are used within all Xilinx drivers to enforce constraints on argument
+ * values. Asserts can be turned off on a system-wide basis by defining, at
+ * compile time, the NDEBUG identifier. By default, asserts are turned on and it
+ * is recommended that users leave asserts on during development. For deployment
+ * use -DNDEBUG compiler switch to remove assert code.
+ *
+ * <h2>Driver Errata</h2>
+ *
+ *   - A dropped receive frame indication may be reported by the driver after
+ *     calling XLlTemac_Stop() followed by XLlTemac_Start(). This can occur if a
+ *     frame is arriving when stop is called.
+ *   - On Rx with checksum offloading enabled and FCS/PAD stripping disabled,
+ *     FCS and PAD data will be included in the checksum result.
+ *   - On Tx with checksum offloading enabled and auto FCS insertion disabled,
+ *     the user calculated FCS will be included in the checksum result.
+ *
+ * @note
+ *
+ * Xilinx drivers are typically composed of two components, one is the driver
+ * and the other is the adapter.  The driver is independent of OS and processor
+ * and is intended to be highly portable.  The adapter is OS-specific and
+ * facilitates communication between the driver and an OS.
+ * <br><br>
+ * This driver is intended to be RTOS and processor independent. Any needs for
+ * dynamic memory management, threads or thread mutual exclusion, or cache
+ * control must be satisfied by the layer above this driver.
+ *
+ * <pre>
+ * MODIFICATION HISTORY:
+ *
+ * Ver   Who  Date     Changes
+ * ----- ---- -------- -------------------------------------------------------
+ * 1.00a jvb  11/10/06 First release
+ * 1.00a rpm  06/08/07 Added interrupt IDs to config structure for convenience
+ * </pre>
+ *
+ *****************************************************************************/
+
+#ifndef XTEMAC_H		/* prevent circular inclusions */
+#define XTEMAC_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xenv.h"
+#include "xbasic_types.h"
+#include "xstatus.h"
+#include "xlltemac_hw.h"
+
+/************************** Constant Definitions *****************************/
+
+/*
+ * Device information
+ */
+#define XTE_DEVICE_NAME     "xlltemac"
+#define XTE_DEVICE_DESC     "Xilinx Tri-speed 10/100/1000 MAC"
+
+/* LocalLink TYPE Enumerations */
+#define XPAR_LL_FIFO    1
+#define XPAR_LL_DMA     2
+
+/** @name Configuration options
+ *
+ * The following are device configuration options. See the
+ * <i>XLlTemac_SetOptions</i>, <i>XLlTemac_ClearOptions</i> and
+ * <i>XLlTemac_GetOptions</i> routines for information on how to use options.
+ *
+ * The default state of the options are also noted below.
+ *
+ * @{
+ */
+
+#define XTE_PROMISC_OPTION               0x00000001
+/**< XTE_PROMISC_OPTION specifies the TEMAC channel to accept all incoming
+ *   packets.
+ *   This driver sets this option to disabled (cleared) by default. */
+
+#define XTE_JUMBO_OPTION                 0x00000002
+/**< XTE_JUMBO_OPTION specifies the TEMAC channel to accept jumbo frames
+ *   for transmit and receive.
+ *   This driver sets this option to disabled (cleared) by default. */
+
+#define XTE_VLAN_OPTION                  0x00000004
+/**< XTE_VLAN_OPTION specifies the TEMAC channel to enable VLAN support for
+ *   transmit and receive.
+ *   This driver sets this option to disabled (cleared) by default. */
+
+#define XTE_FLOW_CONTROL_OPTION          0x00000008
+/**< XTE_FLOW_CONTROL_OPTION specifies the TEMAC channel to recognize
+ *   received flow control frames.
+ *   This driver sets this option to enabled (set) by default. */
+
+#define XTE_FCS_STRIP_OPTION             0x00000010
+/**< XTE_FCS_STRIP_OPTION specifies the TEMAC channel to strip FCS and PAD
+ *   from received frames. Note that PAD from VLAN frames is not stripped.
+ *   This driver sets this option to enabled (set) by default. */
+
+#define XTE_FCS_INSERT_OPTION            0x00000020
+/**< XTE_FCS_INSERT_OPTION specifies the TEMAC channel to generate the FCS
+ *   field and add PAD automatically for outgoing frames.
+ *   This driver sets this option to enabled (set) by default. */
+
+#define XTE_LENTYPE_ERR_OPTION           0x00000040
+/**< XTE_LENTYPE_ERR_OPTION specifies the TEMAC channel to enable
+ *   Length/Type error checking (mismatched type/length field) for received
+ *   frames.
+ *   This driver sets this option to enabled (set) by default. */
+
+#define XTE_TRANSMITTER_ENABLE_OPTION    0x00000080
+/**< XTE_TRANSMITTER_ENABLE_OPTION specifies the TEMAC channel transmitter
+ *   to be enabled.
+ *   This driver sets this option to enabled (set) by default. */
+
+#define XTE_RECEIVER_ENABLE_OPTION       0x00000100
+/**< XTE_RECEIVER_ENABLE_OPTION specifies the TEMAC channel receiver to be
+ *   enabled.
+ *   This driver sets this option to enabled (set) by default. */
+
+#define XTE_BROADCAST_OPTION             0x00000200
+/**< XTE_BROADCAST_OPTION specifies the TEMAC channel to receive frames
+ *   sent to the broadcast Ethernet address.
+ *   This driver sets this option to enabled (set) by default. */
+
+#define XTE_MULTICAST_OPTION         0x00000400
+/**< XTE_MULTICAST_OPTION specifies the TEMAC channel to receive frames
+ *   sent to Ethernet addresses that are programmed into the Multicast Address
+ *   Table (MAT).
+ *   This driver sets this option to disabled (cleared) by default. */
+
+#define XTE_DEFAULT_OPTIONS                     \
+    (XTE_FLOW_CONTROL_OPTION |                  \
+     XTE_BROADCAST_OPTION |                     \
+     XTE_FCS_INSERT_OPTION |                    \
+     XTE_FCS_STRIP_OPTION |                     \
+     XTE_LENTYPE_ERR_OPTION |                   \
+     XTE_TRANSMITTER_ENABLE_OPTION |            \
+     XTE_RECEIVER_ENABLE_OPTION)
+/**< XTE_DEFAULT_OPTIONS specify the options set in XLlTemac_Reset() and
+ *   XLlTemac_CfgInitialize() */
+
+/*@}*/
+
+/** @name Reset parameters
+ *
+ *  These are used by function XLlTemac_Reset().
+ * @{
+ */
+#define XTE_RESET_HARD    1
+#define XTE_NORESET_HARD  0
+/*@}*/
+
+#define XTE_MULTI_MAT_ENTRIES       4	/* Number of storable addresses in
+					   the Multicast Address Table */
+
+#define XTE_MDIO_DIV_DFT            29	/* Default MDIO clock divisor */
+
+/* The next few constants help upper layers determine the size of memory
+ * pools used for Ethernet buffers and descriptor lists.
+ */
+#define XTE_MAC_ADDR_SIZE   6		/* MAC addresses are 6 bytes */
+#define XTE_MTU             1500	/* max MTU size of an Ethernet frame */
+#define XTE_JUMBO_MTU       8982	/* max MTU size of a jumbo Ethernet frame */
+#define XTE_HDR_SIZE        14	/* size of an Ethernet header */
+#define XTE_HDR_VLAN_SIZE   18	/* size of an Ethernet header with VLAN */
+#define XTE_TRL_SIZE        4	/* size of an Ethernet trailer (FCS) */
+#define XTE_MAX_FRAME_SIZE       (XTE_MTU + XTE_HDR_SIZE + XTE_TRL_SIZE)
+#define XTE_MAX_VLAN_FRAME_SIZE  (XTE_MTU + XTE_HDR_VLAN_SIZE + XTE_TRL_SIZE)
+#define XTE_MAX_JUMBO_FRAME_SIZE (XTE_JUMBO_MTU + XTE_HDR_SIZE + XTE_TRL_SIZE)
+
+/* Constant values returned by XLlTemac_mGetPhysicalInterface(). Note that these
+ * values match design parameters from the PLB_TEMAC spec
+ */
+#define XTE_PHY_TYPE_MII         0
+#define XTE_PHY_TYPE_GMII        1
+#define XTE_PHY_TYPE_RGMII_1_3   2
+#define XTE_PHY_TYPE_RGMII_2_0   3
+#define XTE_PHY_TYPE_SGMII       4
+#define XTE_PHY_TYPE_1000BASE_X  5
+
+/**************************** Type Definitions *******************************/
+
+
+/**
+ * This typedef contains configuration information for a TEMAC channel.
+ * Each channel is treated as a separate device from the point of view of this
+ * driver.
+ */
+typedef struct {
+        /** u16 DeviceId;	< DeviceId is the unique ID  of the device */
+	u32 BaseAddress;/**< BaseAddress is the physical base address of the
+                          *  channel's registers
+                          */
+	u8 TxCsum;	/**< TxCsum indicates that the channel has checksum
+	                  *  offload on the Tx channel or not.
+	                  */
+	u8 RxCsum;	/**< RxCsum indicates that the channel has checksum
+	                  *  offload on the Rx channel or not.
+	                  */
+	u8 PhyType;	/**< PhyType indicates which type of PHY interface is
+	                  *  used (MII, GMII, RGMII, ect.
+	                  */
+	u8 TemacIntr;	/**< TEMAC interrupt ID */
+
+	int LLDevType;	/**< LLDevType is the type of device attached to the
+			 *   temac's local link interface.
+			 */
+	u32 LLDevBaseAddress; /**< LLDevBaseAddress is the base address of then
+			       *   device attached to the temac's local link
+			       *   interface.
+			       */
+	u8 LLFifoIntr;	/**< LL FIFO interrupt ID (unused if DMA) */
+	u8 LLDmaRxIntr;	/**< LL DMA RX interrupt ID (unused if FIFO) */
+	u8 LLDmaTxIntr;	/**< LL DMA TX interrupt ID (unused if FIFO) */
+
+} XLlTemac_Config;
+
+
+/**
+ * struct XLlTemac is the type for TEMAC driver instance data. The calling code
+ * is required to use a unique instance of this structure for every TEMAC
+ * channel used in the system. Each channel is treated as a separate device
+ * from the point of view of this driver. A reference to a structure of this
+ * type is then passed to the driver API functions.
+ */
+typedef struct XLlTemac {
+	XLlTemac_Config Config;	/* hardware configuration */
+	u32 IsStarted;		/* Device is currently started */
+	u32 IsReady;		/* Device is initialized and ready */
+	u32 Options;		/* Current options word */
+	u32 Flags;		/* Internal driver flags */
+} XLlTemac;
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/*****************************************************************************/
+/**
+ *
+ * XLlTemac_IsStarted reports if the device is in the started or stopped state. To
+ * be in the started state, the calling code must have made a successful call to
+ * <i>XLlTemac_Start</i>. To be in the stopped state, <i>XLlTemac_Stop</i> or
+ * <i>XLlTemac_CfgInitialize</i> function must have been called.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ *
+ * @return XLlTemac_IsStarted returns TRUE if the device has been started.
+ *         Otherwise, XLlTemac_IsStarted returns FALSE.
+ *
+ * @note
+ *
+ * Signature: u32 XLlTemac_IsStarted(XLlTemac *InstancePtr)
+ *
+ ******************************************************************************/
+#define XLlTemac_IsStarted(InstancePtr) \
+	(((InstancePtr)->IsStarted == XCOMPONENT_IS_STARTED) ? TRUE : FALSE)
+
+/*****************************************************************************/
+/**
+*
+* XLlTemac_IsDma reports if the device is currently connected to DMA.
+*
+* @param InstancePtr references the TEMAC channel on which to operate.
+*
+* @return XLlTemac_IsDma returns TRUE if the device is connected DMA. Otherwise,
+*         XLlTemac_IsDma returns FALSE.
+*
+* @note
+*
+* Signature: u32 XLlTemac_IsDma(XLlTemac *InstancePtr)
+*
+******************************************************************************/
+#define XLlTemac_IsDma(InstancePtr) \
+	(((InstancePtr)->Config.LLDevType == XPAR_LL_DMA) ? TRUE: FALSE)
+
+/*****************************************************************************/
+/**
+*
+* XLlTemac_IsFifo reports if the device is currently connected to a fifo core.
+*
+* @param InstancePtr references the TEMAC channel on which to operate.
+*
+* @return XLlTemac_IsFifo returns TRUE if the device is connected to a fifo core.
+*         Otherwise, XLlTemac_IsFifo returns FALSE.
+*
+* @note
+*
+* Signature: u32 XLlTemac_IsFifo(XLlTemac *InstancePtr)
+*
+******************************************************************************/
+#define XLlTemac_IsFifo(InstancePtr) \
+	(((InstancePtr)->Config.LLDevType == XPAR_LL_FIFO) ? TRUE: FALSE)
+
+/*****************************************************************************/
+/**
+*
+* XLlTemac_LlDevBaseAddress reports the base address of the core connected to
+* the TEMAC's local link interface.
+*
+* @param InstancePtr references the TEMAC channel on which to operate.
+*
+* @return XLlTemac_IsFifo returns the base address of the core connected to
+* the TEMAC's local link interface.
+*
+* @note
+*
+* Signature: u32 XLlTemac_LlDevBaseAddress(XLlTemac *InstancePtr)
+*
+******************************************************************************/
+#define XLlTemac_LlDevBaseAddress(InstancePtr) \
+	((InstancePtr)->Config.LLDevBaseAddress)
+
+/*****************************************************************************/
+/**
+ *
+ * XLlTemac_IsRecvFrameDropped determines if the device thinks it has dropped a
+ * receive frame.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ *
+ * @return XLlTemac_IsRecvFrameDropped returns TRUE if the device interrupt
+ * status register reports that a frame has been dropped. Otherwise,
+ * XLlTemac_IsRecvFrameDropped returns FALSE.
+ *
+ * @note
+ *
+ * Signature: u32 XLlTemac_IsRecvFrameDropped(XLlTemac *InstancePtr)
+ *
+ ******************************************************************************/
+#define XLlTemac_IsRecvFrameDropped(InstancePtr)                     \
+	((XLlTemac_ReadReg((InstancePtr)->Config.BaseAddress, XTE_IS_OFFSET) \
+	& XTE_INT_RXRJECT_MASK) ? TRUE : FALSE)
+
+/*****************************************************************************/
+/**
+ *
+ * XLlTemac_IsRxCsum determines if the device is configured with checksum
+ * offloading on the receive channel.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ *
+ * @return XLlTemac_IsRxCsum returns TRUE if the device is configured with
+ *         checksum offloading on the receive channel. Otherwise,
+ *         XLlTemac_IsRxCsum returns FALSE.
+ *
+ * @note
+ *
+ * Signature: u32 XLlTemac_IsRxCsum(XLlTemac *InstancePtr)
+ *
+ ******************************************************************************/
+#define XLlTemac_IsRxCsum(InstancePtr) (((InstancePtr)->Config.RxCsum) ?  \
+                                       TRUE : FALSE)
+
+/*****************************************************************************/
+/**
+ *
+ * XLlTemac_IsTxCsum determines if the device is configured with checksum
+ * offloading on the transmit channel.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ *
+ * @return XLlTemac_IsTxCsum returns TRUE if the device is configured with
+ *         checksum offloading on the transmit channel. Otherwise,
+ *         XLlTemac_IsTxCsum returns FALSE.
+ *
+ * @note
+ *
+ * Signature: u32 XLlTemac_IsTxCsum(XLlTemac *InstancePtr)
+ *
+ ******************************************************************************/
+#define XLlTemac_IsTxCsum(InstancePtr) (((InstancePtr)->Config.TxCsum) ?  \
+                                       TRUE : FALSE)
+
+/*****************************************************************************/
+/**
+ *
+ * XLlTemac_GetPhysicalInterface returns the type of PHY interface being used by
+ * the given instance, specified by <i>InstancePtr</i>.
+ *
+ * @param InstancePtr references the TEMAC channel on which to operate.
+ *
+ * @return XLlTemac_GetPhysicalInterface returns one of XTE_PHY_TYPE_<x> where
+ * <x> is MII, GMII, RGMII_1_3, RGMII_2_0, SGMII, or 1000BASE_X (defined in
+ * xlltemac.h).
+ *
+ * @note
+ *
+ * Signature: int XLlTemac_GetPhysicalInterface(XLlTemac *InstancePtr)
+ *
+ ******************************************************************************/
+#define XLlTemac_GetPhysicalInterface(InstancePtr)       \
+	((InstancePtr)->Config.PhyType)
+
+/****************************************************************************/
+/**
+*
+* XLlTemac_Status returns a bit mask of the interrupt status register (ISR).
+* XLlTemac_Status can be used to query the status without having to have
+* interrupts enabled.
+*
+* @param    InstancePtr references the TEMAC channel on which to operate.
+*
+* @return   XLlTemac_IntStatus returns a bit mask of the status conditions.
+*           The mask will be a set of bitwise or'd values from the
+*           <code>XTE_INT_*_MASK</code> preprocessor symbols.
+*
+* @note
+* C-style signature:
+*    u32 XLlTemac_IntStatus(XLlTemac *InstancePtr)
+*
+*****************************************************************************/
+#define XLlTemac_Status(InstancePtr) \
+	 XLlTemac_ReadReg((InstancePtr)->Config.BaseAddress, XTE_IS_OFFSET)
+
+/****************************************************************************/
+/**
+*
+* XLlTemac_IntEnable enables the interrupts specified in <i>Mask</i>. The
+* corresponding interrupt for each bit set to 1 in <i>Mask</i>, will be
+* enabled.
+*
+* @param    InstancePtr references the TEMAC channel on which to operate.
+*
+* @param    Mask contains a bit mask of the interrupts to enable. The mask
+*           can be formed using a set of bitwise or'd values from the
+*           <code>XTE_INT_*_MASK</code> preprocessor symbols.
+*
+* @return   N/A
+*
+* @note
+* C-style signature:
+*    void XLlTemac_IntEnable(XLlTemac *InstancePtr, u32 Mask)
+*
+*****************************************************************************/
+#define XLlTemac_IntEnable(InstancePtr, Mask) \
+	XLlTemac_WriteReg((InstancePtr)->Config.BaseAddress, XTE_IE_OFFSET, \
+		XLlTemac_ReadReg((InstancePtr)->Config.BaseAddress, \
+				XTE_IE_OFFSET) | ((Mask) & XTE_INT_ALL_MASK)); \
+
+/****************************************************************************/
+/**
+*
+* XLlTemac_IntDisable disables the interrupts specified in <i>Mask</i>. The
+* corresponding interrupt for each bit set to 1 in <i>Mask</i>, will be
+* disabled. In other words, XLlTemac_IntDisable uses the "set a bit to clear it"
+* scheme.
+*
+* @param    InstancePtr references the TEMAC channel on which to operate.
+*
+* @param    Mask contains a bit mask of the interrupts to disable. The mask
+*           can be formed using a set of bitwise or'd values from the
+*           <code>XTE_INT_*_MASK</code> preprocessor symbols.
+*
+* @return   N/A
+*
+* @note
+* C-style signature:
+*    void XLlTemac_IntDisable(XLlTemac *InstancePtr, u32 Mask)
+*
+*****************************************************************************/
+#define XLlTemac_IntDisable(InstancePtr, Mask) \
+	XLlTemac_WriteReg((InstancePtr)->Config.BaseAddress, XTE_IE_OFFSET, \
+		XLlTemac_ReadReg((InstancePtr)->Config.BaseAddress, \
+				XTE_IE_OFFSET) & ~((Mask) & XTE_INT_ALL_MASK)); \
+
+/****************************************************************************/
+/**
+*
+* XLlTemac_IntPending returns a bit mask of the pending interrupts. Each bit
+* set to 1 in the return value represents a pending interrupt.
+*
+* @param    InstancePtr references the TEMAC channel on which to operate.
+*
+* @return   XLlTemac_IntPending returns a bit mask of the interrupts that are
+*           pending. The mask will be a set of bitwise or'd values from the
+*           <code>XTE_INT_*_MASK</code> preprocessor symbols.
+*
+* @note
+* C-style signature:
+*    u32 XLlTemac_IntPending(XLlTemac *InstancePtr)
+*
+*****************************************************************************/
+#define XLlTemac_IntPending(InstancePtr) \
+	XLlTemac_ReadReg((InstancePtr)->Config.BaseAddress, XTE_IP_OFFSET)
+
+/****************************************************************************/
+/**
+*
+* XLlTemac_IntClear clears pending interrupts specified in <i>Mask</i>.
+* The corresponding pending interrupt for each bit set to 1 in <i>Mask</i>,
+* will be cleared. In other words, XLlTemac_IntClear uses the "set a bit to
+* clear it" scheme.
+*
+* @param    InstancePtr references the TEMAC channel on which to operate.
+*
+* @param    Mask contains a bit mask of the pending interrupts to clear. The
+*           mask can be formed using a set of bitwise or'd values from the
+*           <code>XTE_INT_*_MASK</code> preprocessor symbols.
+*
+* @note
+* C-style signature:
+*    void XLlTemac_IntClear(XLlTemac *InstancePtr, u32 Mask)
+*
+*****************************************************************************/
+#define XLlTemac_IntClear(InstancePtr, Mask) \
+	XLlTemac_WriteReg((InstancePtr)->Config.BaseAddress, XTE_IS_OFFSET, \
+			((Mask) & XTE_INT_ALL_MASK))
+
+/************************** Function Prototypes ******************************/
+
+/*
+ * Initialization functions in xlltemac.c
+ */
+int XLlTemac_CfgInitialize(XLlTemac *InstancePtr, XLlTemac_Config *CfgPtr,
+			   u32 VirtualAddress);
+void XLlTemac_Start(XLlTemac *InstancePtr);
+void XLlTemac_Stop(XLlTemac *InstancePtr);
+void XLlTemac_Reset(XLlTemac *InstancePtr, int HardCoreAction);
+
+/*
+ * Initialization functions in xlltemac_sinit.c
+ */
+XLlTemac_Config *XLlTemac_LookupConfig(u16 DeviceId);
+
+/*
+ * MAC configuration/control functions in xlltemac_control.c
+ */
+int XLlTemac_SetOptions(XLlTemac *InstancePtr, u32 Options);
+int XLlTemac_ClearOptions(XLlTemac *InstancePtr, u32 Options);
+u32 XLlTemac_GetOptions(XLlTemac *InstancePtr);
+
+int XLlTemac_SetMacAddress(XLlTemac *InstancePtr, void *AddressPtr);
+void XLlTemac_GetMacAddress(XLlTemac *InstancePtr, void *AddressPtr);
+
+int XLlTemac_SetMacPauseAddress(XLlTemac *InstancePtr, void *AddressPtr);
+void XLlTemac_GetMacPauseAddress(XLlTemac *InstancePtr, void *AddressPtr);
+int XLlTemac_SendPausePacket(XLlTemac *InstancePtr, u16 PauseValue);
+
+int XLlTemac_GetSgmiiStatus(XLlTemac *InstancePtr, u16 *SpeedPtr);
+int XLlTemac_GetRgmiiStatus(XLlTemac *InstancePtr, u16 *SpeedPtr,
+			    int *IsFullDuplexPtr, int *IsLinkUpPtr);
+u16 XLlTemac_GetOperatingSpeed(XLlTemac *InstancePtr);
+void XLlTemac_SetOperatingSpeed(XLlTemac *InstancePtr, u16 Speed);
+
+void XLlTemac_PhySetMdioDivisor(XLlTemac *InstancePtr, u8 Divisor);
+void XLlTemac_PhyRead(XLlTemac *InstancePtr, u32 PhyAddress, u32 RegisterNum,
+		      u16 *PhyDataPtr);
+void XLlTemac_PhyWrite(XLlTemac *InstancePtr, u32 PhyAddress, u32 RegisterNum,
+		       u16 PhyData);
+int XLlTemac_MulticastAdd(XLlTemac *InstancePtr, void *AddressPtr, int Entry);
+void XLlTemac_MulticastGet(XLlTemac *InstancePtr, void *AddressPtr, int Entry);
+int XLlTemac_MulticastClear(XLlTemac *InstancePtr, int Entry);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/net/xilinx_lltemac/xlltemac_hw.h linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/xlltemac_hw.h
--- linux-2.6.31.12/drivers/net/xilinx_lltemac/xlltemac_hw.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/xlltemac_hw.h	2010-08-08 17:22:50.611911713 +0200
@@ -0,0 +1,562 @@
+/* iId: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2005-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+
+/*****************************************************************************/
+/**
+ *
+ * @file xlltemac_hw.h
+ *
+ * This header file contains identifiers and low-level driver functions (or
+ * macros) that can be used to access the Tri-Mode MAC Ethernet (TEMAC) device.
+ * High-level driver functions are defined in xlltemac.h.
+ *
+ * @note
+ *
+ * Some registers are not accessible when a HW instance is configured for SGDMA.
+ *
+ * <pre>
+ * MODIFICATION HISTORY:
+ *
+ * Ver   Who  Date     Changes
+ * ----- ---- -------- -------------------------------------------------------
+ * 1.00a jvb  11/10/06 First release
+ * </pre>
+ *
+ ******************************************************************************/
+
+#ifndef XTEMAC_HW_H		/* prevent circular inclusions */
+#define XTEMAC_HW_H		/* by using protection macros */
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xio.h"
+#include "xdebug.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/************************** Constant Definitions *****************************/
+
+#define XTE_RESET_HARD_DELAY_US 4    /**< Us to delay for hard core reset */
+
+/* Register offset definitions. Unless otherwise noted, register access is
+ * 32 bit.
+ */
+
+/** @name Direct registers
+ *  @{
+ */
+#define XTE_RAF_OFFSET  0x00000000  /**< Reset and address filter */
+#define XTE_TPF_OFFSET  0x00000004  /**< Transmit pause frame */
+#define XTE_IFGP_OFFSET 0x00000008  /**< Transmit inter-frame gap adjustment */
+#define XTE_IS_OFFSET   0x0000000C  /**< Interrupt status */
+#define XTE_IP_OFFSET   0x00000010  /**< Interrupt pending */
+#define XTE_IE_OFFSET   0x00000014  /**< Interrupt enable */
+
+#define XTE_MSW_OFFSET  0x00000020  /**< Most significant word data */
+#define XTE_LSW_OFFSET  0x00000024  /**< Least significant word data */
+#define XTE_CTL_OFFSET  0x00000028  /**< Control */
+#define XTE_RDY_OFFSET  0x0000002C  /**< Ready status */
+/*@}*/
+
+
+/** @name HARD_TEMAC Core Registers
+ * These are registers defined within the device's hard core located in the
+ * processor block. They are accessed indirectly through the registers, MSW,
+ * LSW, and CTL.
+ *
+ * Access to these registers should go through macros XLlTemac_ReadIndirectReg()
+ * and XLlTemac_WriteIndirectReg() to guarantee proper access.
+ * @{
+ */
+#define XTE_RCW0_OFFSET         0x00000200  /**< Rx configuration word 0 */
+#define XTE_RCW1_OFFSET         0x00000240  /**< Rx configuration word 1 */
+#define XTE_TC_OFFSET           0x00000280  /**< Tx configuration */
+#define XTE_FCC_OFFSET          0x000002C0  /**< Flow control configuration */
+#define XTE_EMMC_OFFSET         0x00000300  /**< EMAC mode configuration */
+#define XTE_PHYC_OFFSET         0x00000320  /**< RGMII/SGMII configuration */
+#define XTE_MC_OFFSET           0x00000340  /**< Management configuration */
+#define XTE_UAW0_OFFSET         0x00000380  /**< Unicast address word 0 */
+#define XTE_UAW1_OFFSET         0x00000384  /**< Unicast address word 1 */
+#define XTE_MAW0_OFFSET         0x00000388  /**< Multicast address word 0 */
+#define XTE_MAW1_OFFSET         0x0000038C  /**< Multicast address word 1 */
+#define XTE_AFM_OFFSET          0x00000390  /**< Address Filter (promiscuous) mode */
+#define XTE_TIS_OFFSET          0x000003A0  /**< Interrupt status */
+#define XTE_TIE_OFFSET          0x000003A4  /**< Interrupt enable */
+#define XTE_MIIMWD_OFFSET       0x000003B0  /**< MII management write data */
+#define XTE_MIIMAI_OFFSET       0x000003B4  /**< MII management access initiate */
+/*@}*/
+
+
+/* Register masks. The following constants define bit locations of various
+ * control bits in the registers. Constants are not defined for those registers
+ * that have a single bit field representing all 32 bits. For further
+ * information on the meaning of the various bit masks, refer to the HW spec.
+ */
+
+/** @name Reset and Address Filter bits
+ *  These bits are associated with the XTE_RAF_OFFSET register.
+ * @{
+ */
+#define XTE_RAF_HTRST_MASK       0x00000001 /**< Hard TEMAC Reset */
+#define XTE_RAF_MCSTREJ_MASK     0x00000002 /**< Reject receive multicast destination address */
+#define XTE_RAF_BCSTREJ_MASK     0x00000004 /**< Reject receive broadcast destination address */
+/*@}*/
+
+/** @name Transmit Pause Frame Register (TPF)
+ *  @{
+ */
+#define XTE_TPF_TPFV_MASK        0x0000FFFF   /**< Tx pause frame value */
+/*@}*/
+
+/** @name Transmit Inter-Frame Gap Adjustement Register (TFGP)
+ *  @{
+ */
+#define XTE_TFGP_IFGP_MASK       0x0000007F   /**< Transmit inter-frame gap adjustment value */
+/*@}*/
+
+/** @name Interrupt bits
+ *  These bits are associated with the XTE_IS_OFFSET, XTE_IP_OFFSET, and
+ *  XTE_IE_OFFSET registers.
+ * @{
+ */
+#define XTE_INT_HARDACSCMPLT_MASK 0x00000001 /**< Hard register access complete */
+#define XTE_INT_AUTONEG_MASK      0x00000002 /**< Auto negotiation complete */
+#define XTE_INT_RC_MASK           0x00000004 /**< Receive complete */
+#define XTE_INT_RXRJECT_MASK      0x00000008 /**< Receive frame rejected */
+#define XTE_INT_RXFIFOOVR_MASK    0x00000010 /**< Receive fifo overrun */
+#define XTE_INT_TC_MASK           0x00000020 /**< Transmit complete */
+#define XTE_INT_ALL_MASK          0x0000003f /**< All the ints */
+/*@}*/
+
+
+#define XTE_INT_RECV_ERROR_MASK \
+    (XTE_INT_RXRJECT_MASK | XTE_INT_RXFIFOOVR_MASK) /**< INT bits that indicate receive errors */
+/*@}*/
+
+
+/** @name Control Register (CTL)
+ *  @{
+ */
+#define XTE_CTL_WEN_MASK          0x00008000   /**< Write Enable */
+/*@}*/
+
+
+/** @name Ready Status, TEMAC Interrupt Status, TEMAC Interrupt Enable Registers
+ * (RDY, TIS, TIE)
+ *  @{
+ */
+#define XTE_RSE_FABR_RR_MASK      0x00000001   /**< Fabric read ready */
+#define XTE_RSE_MIIM_RR_MASK      0x00000002   /**< MII management read ready */
+#define XTE_RSE_MIIM_WR_MASK      0x00000004   /**< MII management write ready */
+#define XTE_RSE_AF_RR_MASK        0x00000008   /**< Address filter read ready*/
+#define XTE_RSE_AF_WR_MASK        0x00000010   /**< Address filter write ready*/
+#define XTE_RSE_CFG_RR_MASK       0x00000020   /**< Configuration register read ready*/
+#define XTE_RSE_CFG_WR_MASK       0x00000040   /**< Configuration register write ready*/
+#define XTE_RDY_HARD_ACS_RDY_MASK 0x00010000   /**< Hard register access ready */
+#define XTE_RDY_ALL               (XTE_RSE_FABR_RR_MASK | \
+                                   XTE_RSE_MIIM_RR_MASK | \
+                                   XTE_RSE_MIIM_WR_MASK | \
+                                   XTE_RSE_AF_RR_MASK | \
+                                   XTE_RSE_AF_WR_MASK | \
+                                   XTE_RSE_CFG_RR_MASK | \
+                                   XTE_RSE_CFG_WR_MASK | \
+                                   XTE_RDY_HARD_ACS_RDY_MASK)
+/*@}*/
+
+
+/** @name Receive Configuration Word 1 (RCW1)
+ *  @{
+ */
+#define XTE_RCW1_RST_MASK         0x80000000   /**< Reset */
+#define XTE_RCW1_JUM_MASK         0x40000000   /**< Jumbo frame enable */
+#define XTE_RCW1_FCS_MASK         0x20000000   /**< In-Band FCS enable (FCS not stripped) */
+#define XTE_RCW1_RX_MASK          0x10000000   /**< Receiver enable */
+#define XTE_RCW1_VLAN_MASK        0x08000000   /**< VLAN frame enable */
+#define XTE_RCW1_HD_MASK          0x04000000   /**< Half duplex mode */
+#define XTE_RCW1_LT_DIS_MASK      0x02000000   /**< Length/type field valid check disable */
+#define XTE_RCW1_PAUSEADDR_MASK   0x0000FFFF   /**< Pause frame source address
+                                                    bits [47:32]. Bits [31:0]
+                                                    are stored in register
+                                                    RCW0 */
+/*@}*/
+
+
+/** @name Transmitter Configuration (TC)
+ *  @{
+ */
+#define XTE_TC_RST_MASK           0x80000000   /**< reset */
+#define XTE_TC_JUM_MASK           0x40000000   /**< Jumbo frame enable */
+#define XTE_TC_FCS_MASK           0x20000000   /**< In-Band FCS enable (FCS not generated) */
+#define XTE_TC_TX_MASK            0x10000000   /**< Transmitter enable */
+#define XTE_TC_VLAN_MASK          0x08000000   /**< VLAN frame enable */
+#define XTE_TC_HD_MASK            0x04000000   /**< Half duplex mode */
+#define XTE_TC_IFG_MASK           0x02000000   /**< Inter-frame gap adjustment enable */
+/*@}*/
+
+
+/** @name Flow Control Configuration (FCC)
+ *  @{
+ */
+#define XTE_FCC_FCRX_MASK         0x20000000   /**< Rx flow control enable */
+#define XTE_FCC_FCTX_MASK         0x40000000   /**< Tx flow control enable */
+/*@}*/
+
+
+/** @name EMAC Configuration (EMMC)
+ * @{
+ */
+#define XTE_EMMC_LINKSPEED_MASK   0xC0000000  /**< Link speed */
+#define XTE_EMMC_RGMII_MASK       0x20000000  /**< RGMII mode enable */
+#define XTE_EMMC_SGMII_MASK       0x10000000  /**< SGMII mode enable */
+#define XTE_EMMC_GPCS_MASK        0x08000000  /**< 1000BaseX mode enable */
+#define XTE_EMMC_HOST_MASK        0x04000000  /**< Host interface enable */
+#define XTE_EMMC_TX16BIT          0x02000000  /**< 16 bit Tx client enable */
+#define XTE_EMMC_RX16BIT          0x01000000  /**< 16 bit Rx client enable */
+
+#define XTE_EMMC_LINKSPD_10       0x00000000   /**< XTE_EMCFG_LINKSPD_MASK for
+                                                     10 Mbit */
+#define XTE_EMMC_LINKSPD_100      0x40000000   /**< XTE_EMCFG_LINKSPD_MASK for
+                                                     100 Mbit */
+#define XTE_EMMC_LINKSPD_1000     0x80000000   /**< XTE_EMCFG_LINKSPD_MASK for
+                                                     1000 Mbit */
+/*@}*/
+
+
+/** @name EMAC RGMII/SGMII Configuration (PHYC)
+ * @{
+ */
+#define XTE_PHYC_SGMIILINKSPEED_MASK 0xC0000000	  /**< SGMII link speed */
+#define XTE_PHYC_RGMIILINKSPEED_MASK 0x0000000C	  /**< RGMII link speed */
+#define XTE_PHYC_RGMIIHD_MASK        0x00000002	  /**< RGMII Half-duplex mode */
+#define XTE_PHYC_RGMIILINK_MASK      0x00000001	  /**< RGMII link status */
+
+#define XTE_PHYC_RGLINKSPD_10        0x00000000	  /**< XTE_GMIC_RGLINKSPD_MASK
+                                                       for 10 Mbit */
+#define XTE_PHYC_RGLINKSPD_100       0x00000004	  /**< XTE_GMIC_RGLINKSPD_MASK
+                                                       for 100 Mbit */
+#define XTE_PHYC_RGLINKSPD_1000      0x00000008	  /**< XTE_GMIC_RGLINKSPD_MASK
+                                                       for 1000 Mbit */
+#define XTE_PHYC_SGLINKSPD_10        0x00000000	  /**< XTE_SGMIC_RGLINKSPD_MASK
+                                                       for 10 Mbit */
+#define XTE_PHYC_SGLINKSPD_100       0x40000000	  /**< XTE_SGMIC_RGLINKSPD_MASK
+                                                       for 100 Mbit */
+#define XTE_PHYC_SGLINKSPD_1000      0x80000000	  /**< XTE_SGMIC_RGLINKSPD_MASK
+                                                       for 1000 Mbit */
+/*@}*/
+
+
+/** @name EMAC Management Configuration (MC)
+ * @{
+ */
+#define XTE_MC_MDIOEN_MASK        0x00000040   /**< MII management enable */
+#define XTE_MC_CLOCK_DIVIDE_MAX   0x3F	       /**< Maximum MDIO divisor */
+/*@}*/
+
+
+/** @name EMAC Unicast Address Register Word 1 (UAW1)
+ * @{
+ */
+#define XTE_UAW1_UNICASTADDR_MASK 0x0000FFFF   /**< Station address bits [47:32]
+                                                    Station address bits [31:0] 
+                                                    are stored in register
+                                                    UAW0 */
+/*@}*/
+
+
+/** @name EMAC Multicast Address Register Word 1 (MAW1)
+ * @{
+ */
+#define XTE_MAW1_RNW_MASK         0x00800000   /**< Multicast address table register read enable */
+#define XTE_MAW1_ADDR_MASK        0x00030000   /**< Multicast address table register address */
+#define XTE_MAW1_MULTICADDR_MASK  0x0000FFFF   /**< Multicast address bits [47:32]
+                                                    Multicast address bits [31:0] 
+                                                    are stored in register
+                                                    MAW0 */
+#define XTE_MAW1_MATADDR_SHIFT_MASK 16	       /**< Number of bits to shift right
+                                                    to align with
+                                                    XTE_MAW1_CAMADDR_MASK */
+/*@}*/
+
+
+/** @name EMAC Address Filter Mode (AFM)
+ * @{
+ */
+#define XTE_AFM_PM_MASK           0x80000000   /**< Promiscuous mode enable */
+/*@}*/
+
+
+/** @name Media Independent Interface Management (MIIM)
+ * @{
+ */
+#define XTE_MIIM_REGAD_MASK     0x1F	/**< MII Phy register address (REGAD) */
+#define XTE_MIIM_PHYAD_MASK     0x03E0	/**< MII Phy address (PHYAD) */
+#define XTE_MIIM_PHYAD_SHIFT    5	/**< MII Shift bits for PHYAD */
+/*@}*/
+
+
+/** @name Checksum offload buffer descriptor extensions
+ * @{
+ */
+/** Byte offset where checksum should begin (16 bit word) */
+#define XTE_BD_TX_CSBEGIN_OFFSET  XDMAV3_BD_USR0_OFFSET
+
+/** Offset where checksum should be inserted (16 bit word) */
+#define XTE_BD_TX_CSINSERT_OFFSET (XDMAV3_BD_USR0_OFFSET + 2)
+
+/** Checksum offload control for transmit (16 bit word) */
+#define XTE_BD_TX_CSCNTRL_OFFSET  XDMAV3_BD_USR1_OFFSET
+
+/** Seed value for checksum calculation (16 bit word) */
+#define XTE_BD_TX_CSINIT_OFFSET   (XDMAV3_BD_USR1_OFFSET + 2)
+
+/** Receive frame checksum calculation (16 bit word) */
+#define XTE_BD_RX_CSRAW_OFFSET    (XDMAV3_BD_USR5_OFFSET + 2)
+
+/*@}*/
+
+/** @name TX_CSCNTRL bit mask
+ * @{
+ */
+#define XTE_BD_TX_CSCNTRL_CALC_MASK  0x0001  /**< Enable/disable Tx
+                                                  checksum */
+/*@}*/
+
+/**************************** Type Definitions *******************************/
+
+/***************** Macros (Inline Functions) Definitions *********************/
+xdbg_stmnt(extern int indent_on);
+
+#define XLlTemac_indent(RegOffset) \
+ ((indent_on && ((RegOffset) >= XTE_RAF_OFFSET) && ((RegOffset) <= XTE_RDY_OFFSET)) ? "\t" : "")
+
+#define XLlTemac_reg_name(RegOffset) \
+	(((RegOffset) == XTE_RAF_OFFSET) ? "XTE_RAF_OFFSET": \
+	((RegOffset) == XTE_TPF_OFFSET) ? "XTE_TPF_OFFSET": \
+	((RegOffset) == XTE_IFGP_OFFSET) ? "XTE_IFGP_OFFSET": \
+	((RegOffset) == XTE_IS_OFFSET) ? "XTE_IS_OFFSET": \
+	((RegOffset) == XTE_IP_OFFSET) ? "XTE_IP_OFFSET": \
+	((RegOffset) == XTE_IE_OFFSET) ? "XTE_IE_OFFSET": \
+	((RegOffset) == XTE_MSW_OFFSET) ? "XTE_MSW_OFFSET": \
+	((RegOffset) == XTE_LSW_OFFSET) ? "XTE_LSW_OFFSET": \
+	((RegOffset) == XTE_CTL_OFFSET) ? "XTE_CTL_OFFSET": \
+	((RegOffset) == XTE_RDY_OFFSET) ? "XTE_RDY_OFFSET": \
+	((RegOffset) == XTE_RCW0_OFFSET) ? "XTE_RCW0_OFFSET": \
+	((RegOffset) == XTE_RCW1_OFFSET) ? "XTE_RCW1_OFFSET": \
+	((RegOffset) == XTE_TC_OFFSET) ? "XTE_TC_OFFSET": \
+	((RegOffset) == XTE_FCC_OFFSET) ? "XTE_FCC_OFFSET": \
+	((RegOffset) == XTE_EMMC_OFFSET) ? "XTE_EMMC_OFFSET": \
+	((RegOffset) == XTE_PHYC_OFFSET) ? "XTE_PHYC_OFFSET": \
+	((RegOffset) == XTE_MC_OFFSET) ? "XTE_MC_OFFSET": \
+	((RegOffset) == XTE_UAW0_OFFSET) ? "XTE_UAW0_OFFSET": \
+	((RegOffset) == XTE_UAW1_OFFSET) ? "XTE_UAW1_OFFSET": \
+	((RegOffset) == XTE_MAW0_OFFSET) ? "XTE_MAW0_OFFSET": \
+	((RegOffset) == XTE_MAW1_OFFSET) ? "XTE_MAW1_OFFSET": \
+	((RegOffset) == XTE_AFM_OFFSET) ? "XTE_AFM_OFFSET": \
+	((RegOffset) == XTE_TIS_OFFSET) ? "XTE_TIS_OFFSET": \
+	((RegOffset) == XTE_TIE_OFFSET) ? "XTE_TIE_OFFSET": \
+	((RegOffset) == XTE_MIIMWD_OFFSET) ? "XTE_MIIMWD_OFFSET": \
+	((RegOffset) == XTE_MIIMAI_OFFSET) ? "XTE_MIIMAI_OFFSET": \
+	"unknown")
+
+#define XLlTemac_print_reg_o(BaseAddress, RegOffset, Value) \
+	xdbg_printf(XDBG_DEBUG_TEMAC_REG, "%s0x%0x -> %s(0x%0x)\n", \
+			XLlTemac_indent(RegOffset), (Value), \
+			XLlTemac_reg_name(RegOffset), (RegOffset)) \
+
+#define XLlTemac_print_reg_i(BaseAddress, RegOffset, Value) \
+	xdbg_printf(XDBG_DEBUG_TEMAC_REG, "%s%s(0x%0x) -> 0x%0x\n", \
+			XLlTemac_indent(RegOffset), XLlTemac_reg_name(RegOffset), \
+			(RegOffset), (Value)) \
+
+/****************************************************************************/
+/**
+ *
+ * XLlTemac_ReadReg returns the value read from the register specified by
+ * <i>RegOffset</i>.
+ *
+ * @param    BaseAddress is the base address of the TEMAC channel.
+ * @param    RegOffset is the offset of the register to be read.
+ *
+ * @return   XLlTemac_ReadReg returns the 32-bit value of the register.
+ *
+ * @note
+ * C-style signature:
+ *    u32 XLlTemac_mReadReg(u32 BaseAddress, u32 RegOffset)
+ *
+ *****************************************************************************/
+#ifdef DEBUG
+#define XLlTemac_ReadReg(BaseAddress, RegOffset) \
+({ \
+	u32 value; \
+	if ((RegOffset) > 0x2c) { \
+		printf ("readreg: Woah! wrong reg addr: 0x%0x\n", (RegOffset)); \
+	} \
+	value = XIo_In32(((BaseAddress) + (RegOffset))); \
+	XLlTemac_print_reg_i((BaseAddress), (RegOffset), value); \
+	value; \
+})
+#else
+#define XLlTemac_ReadReg(BaseAddress, RegOffset) \
+	(XIo_In32(((BaseAddress) + (RegOffset))))
+#endif
+
+/****************************************************************************/
+/**
+ *
+ * XLlTemac_WriteReg, writes <i>Data</i> to the register specified by
+ * <i>RegOffset</i>.
+ *
+ * @param    BaseAddress is the base address of the TEMAC channel.
+ * @param    RegOffset is the offset of the register to be written.
+ * @param    Data is the 32-bit value to write to the register.
+ *
+ * @return   N/A
+ *
+ * @note
+ * C-style signature:
+ *    void XLlTemac_mWriteReg(u32 BaseAddress, u32 RegOffset, u32 Data)
+ *
+ *****************************************************************************/
+#ifdef DEBUG
+#define XLlTemac_WriteReg(BaseAddress, RegOffset, Data) \
+({ \
+	if ((RegOffset) > 0x2c) { \
+		printf ("writereg: Woah! wrong reg addr: 0x%0x\n", (RegOffset)); \
+	} \
+	XLlTemac_print_reg_o((BaseAddress), (RegOffset), (Data)); \
+	XIo_Out32(((BaseAddress) + (RegOffset)), (Data)); \
+})
+#else
+#define XLlTemac_WriteReg(BaseAddress, RegOffset, Data) \
+	XIo_Out32(((BaseAddress) + (RegOffset)), (Data))
+#endif
+
+/****************************************************************************/
+/**
+ *
+ * XLlTemac_ReadIndirectReg returns the value read from the hard TEMAC register
+ * specified by <i>RegOffset</i>.
+ *
+ * @param    BaseAddress is the base address of the TEMAC channel.
+ * @param    RegOffset is the offset of the hard TEMAC register to be read.
+ *
+ * @return   XLlTemac_ReadIndirectReg returns the 32-bit value of the register.
+ *
+ * @note
+ * C-style signature:
+ *    u32 XLlTemac_mReadIndirectReg(u32 BaseAddress, u32 RegOffset)
+ *
+ *****************************************************************************/
+#ifdef DEBUG
+extern u32 _xlltemac_rir_value;
+
+#define XLlTemac_ReadIndirectReg(BaseAddress, RegOffset) \
+( \
+	indent_on = 1, \
+	(((RegOffset) < 0x200) ? \
+		xdbg_printf(XDBG_DEBUG_ERROR, \
+			"readindirect: Woah! wrong reg addr: 0x%0x\n", \
+			(RegOffset)) : 0), \
+	(((RegOffset) > 0x3b4) ? \
+		xdbg_printf(XDBG_DEBUG_ERROR, \
+			"readindirect: Woah! wrong reg addr: 0x%0x\n", \
+			(RegOffset)) : 0), \
+	XLlTemac_WriteReg((BaseAddress), XTE_CTL_OFFSET, (RegOffset)), \
+	_xlltemac_rir_value = XLlTemac_ReadReg((BaseAddress), XTE_LSW_OFFSET), \
+	XLlTemac_print_reg_i((BaseAddress), (RegOffset), _xlltemac_rir_value), \
+	indent_on = 0, \
+	_xlltemac_rir_value \
+)
+#else
+#define XLlTemac_ReadIndirectReg(BaseAddress, RegOffset) \
+( \
+	XLlTemac_WriteReg((BaseAddress), XTE_CTL_OFFSET, (RegOffset)), \
+	XLlTemac_ReadReg((BaseAddress), XTE_LSW_OFFSET) \
+)
+#endif
+
+/****************************************************************************/
+/**
+ *
+ * XLlTemac_WriteIndirectReg, writes <i>Data</i> to the hard TEMAC register
+ * specified by <i>RegOffset</i>.
+ *
+ * @param    BaseAddress is the base address of the TEMAC channel.
+ * @param    RegOffset is the offset of the hard TEMAC register to be written.
+ * @param    Data is the 32-bit value to write to the register.
+ *
+ * @return   N/A
+ *
+ * @note
+ * C-style signature:
+ *    void XLlTemac_WriteIndirectReg(u32 BaseAddress, u32 RegOffset, u32 Data)
+ *
+ *****************************************************************************/
+#ifdef DEBUG
+#define XLlTemac_WriteIndirectReg(BaseAddress, RegOffset, Data) \
+( \
+	indent_on = 1, \
+	(((RegOffset) < 0x200) ? \
+		xdbg_printf(XDBG_DEBUG_ERROR, \
+			"readindirect: Woah! wrong reg addr: 0x%0x\n", \
+			(RegOffset)) : 0), \
+	(((RegOffset) > 0x3b4) ? \
+		xdbg_printf(XDBG_DEBUG_ERROR, \
+			"readindirect: Woah! wrong reg addr: 0x%0x\n", \
+			(RegOffset)) : 0), \
+	XLlTemac_print_reg_o((BaseAddress), (RegOffset), (Data)), \
+	XLlTemac_WriteReg((BaseAddress), XTE_LSW_OFFSET, (Data)), \
+	XLlTemac_WriteReg((BaseAddress), XTE_CTL_OFFSET, \
+		((RegOffset) | XTE_CTL_WEN_MASK)), \
+	((XLlTemac_ReadReg((BaseAddress), XTE_RDY_OFFSET) & \
+			XTE_RDY_HARD_ACS_RDY_MASK) ? \
+		((XLlTemac_ReadIndirectReg((BaseAddress), (RegOffset)) != (Data)) ? \
+			xdbg_printf(XDBG_DEBUG_ERROR, \
+				"data written is not read back: Reg: 0x%0x\n", \
+				(RegOffset)) \
+			: 0) \
+		: xdbg_printf(XDBG_DEBUG_ERROR, "(temac_wi) RDY reg not initially ready\n")), \
+	indent_on = 0 \
+)
+#else
+#define XLlTemac_WriteIndirectReg(BaseAddress, RegOffset, Data) \
+	XLlTemac_WriteReg((BaseAddress), XTE_LSW_OFFSET, (Data)), \
+	XLlTemac_WriteReg((BaseAddress), XTE_CTL_OFFSET, \
+		((RegOffset) | XTE_CTL_WEN_MASK))
+#endif
+
+#ifdef __cplusplus
+  }
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/net/xilinx_lltemac/xlltemac_main.c linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/xlltemac_main.c
--- linux-2.6.31.12/drivers/net/xilinx_lltemac/xlltemac_main.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/net/xilinx_lltemac/xlltemac_main.c	2010-08-08 17:40:16.568735903 +0200
@@ -0,0 +1,3705 @@
+/*
+ * Xilinx Ethernet: Linux driver for the XPS_LLTEMAC core.
+ *
+ * Author: Xilinx, Inc.
+ *
+ * 2006-2007 (c) Xilinx, Inc. This file is licensed uner the terms of the GNU
+ * General Public License version 2.1. This program is licensed "as is" without
+ * any warranty of any kind, whether express or implied.
+ *
+ * <pre>
+ * MODIFICATION HISTORY:
+ *
+ * Ver   Who  Date     Changes
+ * ----- ---- -------- -------------------------------------------------------
+ * 1.00a jvb  05/08/05 First release
+ * </pre>
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/mm.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/mii.h>
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/xilinx_devices.h>
+#include <asm/io.h>
+#include <linux/ethtool.h>
+#include <linux/vmalloc.h>
+
+#ifdef CONFIG_OF
+// For open firmware.
+#include <linux/of_device.h>
+#include <linux/of_platform.h>
+#endif
+
+#include "xbasic_types.h"
+#include "xlltemac.h"
+#include "xllfifo.h"
+#include "xlldma.h"
+#include "xlldma_bdring.h"
+
+#define LOCAL_FEATURE_RX_CSUM   0x01
+
+/*
+ * Default SEND and RECV buffer descriptors (BD) numbers.
+ * BD Space needed is (XTE_SEND_BD_CNT+XTE_RECV_BD_CNT)*Sizeof(XLlDma_Bd).
+ * Each XLlDma_Bd instance currently takes 40 bytes.
+ */
+#define XTE_SEND_BD_CNT 256
+#define XTE_RECV_BD_CNT 256
+
+/* Must be shorter than length of ethtool_drvinfo.driver field to fit */
+#define DRIVER_NAME         "xilinx_lltemac"
+#define DRIVER_DESCRIPTION  "Xilinx Tri-Mode Ethernet MAC driver"
+#define DRIVER_VERSION      "1.00a"
+
+#define TX_TIMEOUT   (3*HZ)	/* Transmission timeout is 3 seconds. */
+
+/*
+ * This version of the Xilinx TEMAC uses external DMA or FIFO cores.
+ * Currently neither the DMA or FIFO cores used require any memory alignment
+ * restrictions.
+ */
+/*
+ * ALIGNMENT_RECV = the alignement required to receive
+ * ALIGNMENT_SEND = the alignement required to send
+ * ALIGNMENT_SEND_PERF = tx alignment for better performance
+ *
+ * ALIGNMENT_SEND is used to see if we *need* to copy the data to re-align.
+ * ALIGNMENT_SEND_PERF is used if we've decided we need to copy anyway, we just
+ * copy to this alignment for better performance.
+ */
+
+#define ALIGNMENT_RECV          34
+#define ALIGNMENT_SEND          8
+#define ALIGNMENT_SEND_PERF     32
+
+#define XTE_SEND  1
+#define XTE_RECV  2
+
+/* SGDMA buffer descriptors must be aligned on a 8-byte boundary. */
+#define ALIGNMENT_BD            XLLDMA_BD_MINIMUM_ALIGNMENT
+
+/* BUFFER_ALIGN(adr) calculates the number of bytes to the next alignment. */
+#define BUFFER_ALIGNSEND(adr) ((ALIGNMENT_SEND - ((u32) adr)) % ALIGNMENT_SEND)
+#define BUFFER_ALIGNSEND_PERF(adr) ((ALIGNMENT_SEND_PERF - ((u32) adr)) % 32)
+#define BUFFER_ALIGNRECV(adr) ((ALIGNMENT_RECV - ((u32) adr)) % 32)
+
+/* Default TX/RX Threshold and waitbound values for SGDMA mode */
+#define DFT_TX_THRESHOLD  24
+#define DFT_TX_WAITBOUND  254
+#define DFT_RX_THRESHOLD  4
+#define DFT_RX_WAITBOUND  254
+
+#define XTE_AUTOSTRIPPING 1
+
+/* Put Buffer Descriptors in BRAM?
+ * NOTE:
+ *   Putting BDs in BRAM only works if there is only ONE instance of the TEMAC
+ *   in hardware.  The code does not handle multiple instances, e.g. it does
+ *   not manage the memory in BRAM.
+ */
+#define BD_IN_BRAM        0
+#define BRAM_BASEADDR     0xffff8000
+
+
+/*
+ * Checksum offload macros
+ */
+#define BdCsumEnable(BdPtr) \
+	XLlDma_mBdWrite((BdPtr), XLLDMA_BD_STSCTRL_USR0_OFFSET,             \
+		(XLlDma_mBdRead((BdPtr), XLLDMA_BD_STSCTRL_USR0_OFFSET)) | 1 )
+
+/* Used for debugging */
+#define BdCsumEnabled(BdPtr) \
+	((XLlDma_mBdRead((BdPtr), XLLDMA_BD_STSCTRL_USR0_OFFSET)) & 1)
+
+#define BdCsumDisable(BdPtr) \
+	XLlDma_mBdWrite((BdPtr), XLLDMA_BD_STSCTRL_USR0_OFFSET,             \
+		(XLlDma_mBdRead((BdPtr), XLLDMA_BD_STSCTRL_USR0_OFFSET)) & 0xFFFFFFFE )
+
+#define BdCsumSetup(BdPtr, Start, Insert) \
+    XLlDma_mBdWrite((BdPtr), XLLDMA_BD_USR1_OFFSET, ((Start) << 16) | (Insert))
+
+/* Used for debugging */
+#define BdCsumInsert(BdPtr) \
+    (XLlDma_mBdRead((BdPtr), XLLDMA_BD_USR1_OFFSET) & 0xffff)
+
+#define BdCsumSeed(BdPtr, Seed) \
+    XLlDma_mBdWrite((BdPtr), XLLDMA_BD_USR2_OFFSET, 0)
+
+#define BdCsumGet(BdPtr) \
+    (XLlDma_mBdRead((BdPtr), XLLDMA_BD_USR3_OFFSET) & 0xffff)
+
+#define BdGetRxLen(BdPtr) \
+    (XLlDma_mBdRead((BdPtr), XLLDMA_BD_USR4_OFFSET) & 0x3fff)
+
+/*
+ * Our private per device data.  When a net_device is allocated we will
+ * ask for enough extra space for this.
+ */
+struct net_local {
+	struct list_head rcv;
+	struct list_head xmit;
+
+	struct net_device *ndev;	/* this device */
+	struct net_device *next_dev;	/* The next device in dev_list */
+	struct net_device_stats stats;	/* Statistics for this device */
+	struct timer_list phy_timer;	/* PHY monitoring timer */
+
+	u32 index;		/* Which interface is this */
+#if 0
+	XInterruptHandler Isr;	/* Pointer to the XLlTemac ISR routine */
+#endif
+	u8 gmii_addr;		/* The GMII address of the PHY */
+	u32 virt_dma_addr;	/* Virtual address to mapped dma */
+
+	/* The underlying OS independent code needs space as well.  A
+	 * pointer to the following XLlTemac structure will be passed to
+	 * any XLlTemac_ function that requires it.  However, we treat the
+	 * data as an opaque object in this file (meaning that we never
+	 * reference any of the fields inside of the structure). */
+	XLlFifo Fifo;
+	XLlDma Dma;
+	XLlTemac Emac;
+
+	unsigned int fifo_irq;	/* fifo irq */
+	unsigned int dma_irq_s;	/* send irq */
+	unsigned int dma_irq_r;	/* recv irq */
+	unsigned int frame_size; /* actual frame size = mtu + padding */
+
+	int cur_speed;
+
+	/* Buffer Descriptor space for both TX and RX BD ring */
+	void *desc_space;	/* virtual address of BD space */
+	dma_addr_t desc_space_handle;	/* physical address of BD space */
+	int desc_space_size;	/* size of BD space */
+
+	/* buffer for one skb in case no room is available for transmission */
+	struct sk_buff *deferred_skb;
+
+	/* send buffers for non tx-dre hw */
+	void **tx_orig_buffers;	/* Buffer addresses as returned by
+				   dma_alloc_coherent() */
+	void **tx_buffers;	/* Buffers addresses aligned for DMA */
+	dma_addr_t *tx_phys_buffers;	/* Buffer addresses in physical memory */
+	size_t tx_buffers_cur;	/* Index of current buffer used */
+
+	/* stats */
+	int max_frags_in_a_packet;
+	unsigned long realignments;
+	unsigned long tx_hw_csums;
+	unsigned long rx_hw_csums;
+	unsigned long local_features;
+#if ! XTE_AUTOSTRIPPING
+	unsigned long stripping;
+#endif
+};
+
+u32 dma_rx_int_mask = XLLDMA_CR_IRQ_ALL_EN_MASK;
+u32 dma_tx_int_mask = XLLDMA_CR_IRQ_ALL_EN_MASK;
+
+/* for exclusion of all program flows (processes, ISRs and BHs) */
+spinlock_t XTE_spinlock = SPIN_LOCK_UNLOCKED;
+spinlock_t XTE_tx_spinlock = SPIN_LOCK_UNLOCKED;
+spinlock_t XTE_rx_spinlock = SPIN_LOCK_UNLOCKED;
+
+/*
+ * ethtool has a status reporting feature where we can report any sort of
+ * status information we'd like. This is the list of strings used for that
+ * status reporting. ETH_GSTRING_LEN is defined in ethtool.h
+ */
+static char xenet_ethtool_gstrings_stats[][ETH_GSTRING_LEN] = {
+	"txpkts", "txdropped", "txerr", "txfifoerr",
+	"rxpkts", "rxdropped", "rxerr", "rxfifoerr",
+	"rxrejerr", "max_frags", "tx_hw_csums", "rx_hw_csums",
+};
+
+#define XENET_STATS_LEN sizeof(xenet_ethtool_gstrings_stats) / ETH_GSTRING_LEN
+
+/* Helper function to determine if a given XLlTemac error warrants a reset. */
+extern inline int status_requires_reset(int s)
+{
+	return (s == XST_FIFO_ERROR ||
+		s == XST_PFIFO_DEADLOCK ||
+		s == XST_DMA_ERROR || s == XST_IPIF_ERROR);
+}
+
+/* Queues with locks */
+static LIST_HEAD(receivedQueue);
+static spinlock_t receivedQueueSpin = SPIN_LOCK_UNLOCKED;
+
+static LIST_HEAD(sentQueue);
+static spinlock_t sentQueueSpin = SPIN_LOCK_UNLOCKED;
+
+
+/* from mii.h
+ *
+ * Items in mii.h but not in gmii.h
+ */
+#define ADVERTISE_100FULL       0x0100
+#define ADVERTISE_100HALF       0x0080
+#define ADVERTISE_10FULL        0x0040
+#define ADVERTISE_10HALF        0x0020
+#define ADVERTISE_CSMA          0x0001
+
+#define EX_ADVERTISE_1000FULL   0x0200
+#define EX_ADVERTISE_1000HALF   0x0100
+
+/*
+ * items not in mii.h nor gmii.h but should be
+ */
+#define MII_EXADVERTISE 0x09
+
+/*
+ * Wrap certain temac routines with a lock, so access to the shared hard temac
+ * interface is accessed mutually exclusive for dual channel temac support.
+ */
+
+static inline void _XLlTemac_Start(XLlTemac *InstancePtr)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	XLlTemac_Start(InstancePtr);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+}
+
+static inline void _XLlTemac_Stop(XLlTemac *InstancePtr)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	XLlTemac_Stop(InstancePtr);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+}
+
+static inline void _XLlTemac_Reset(XLlTemac *InstancePtr, int HardCoreAction)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	XLlTemac_Reset(InstancePtr, HardCoreAction);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+}
+
+static inline int _XLlTemac_SetMacAddress(XLlTemac *InstancePtr,
+					  void *AddressPtr)
+{
+	int status;
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	status = XLlTemac_SetMacAddress(InstancePtr, AddressPtr);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+
+	return status;
+}
+
+static inline void _XLlTemac_GetMacAddress(XLlTemac *InstancePtr,
+					   void *AddressPtr)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	XLlTemac_GetMacAddress(InstancePtr, AddressPtr);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+}
+
+static inline int _XLlTemac_SetOptions(XLlTemac *InstancePtr, u32 Options)
+{
+	int status;
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	status = XLlTemac_SetOptions(InstancePtr, Options);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+
+	return status;
+}
+
+static inline int _XLlTemac_ClearOptions(XLlTemac *InstancePtr, u32 Options)
+{
+	int status;
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	status = XLlTemac_ClearOptions(InstancePtr, Options);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+
+	return status;
+}
+
+static inline u16 _XLlTemac_GetOperatingSpeed(XLlTemac *InstancePtr)
+{
+	u16 speed;
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	speed = XLlTemac_GetOperatingSpeed(InstancePtr);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+
+	return speed;
+}
+
+static inline void _XLlTemac_SetOperatingSpeed(XLlTemac *InstancePtr, u16 Speed)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	XLlTemac_SetOperatingSpeed(InstancePtr, Speed);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+
+	/* We need a delay after we set the speed. Otherwise the PHY will not be ready. */
+	udelay(10000);
+}
+
+static inline void _XLlTemac_PhySetMdioDivisor(XLlTemac *InstancePtr, u8 Divisor)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	XLlTemac_PhySetMdioDivisor(InstancePtr, Divisor);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+}
+
+static inline void _XLlTemac_PhyRead(XLlTemac *InstancePtr, u32 PhyAddress,
+				     u32 RegisterNum, u16 *PhyDataPtr)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	XLlTemac_PhyRead(InstancePtr, PhyAddress, RegisterNum, PhyDataPtr);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+}
+
+static inline void _XLlTemac_PhyWrite(XLlTemac *InstancePtr, u32 PhyAddress,
+				      u32 RegisterNum, u16 PhyData)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	XLlTemac_PhyWrite(InstancePtr, PhyAddress, RegisterNum, PhyData);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+}
+
+
+static inline int _XLlTemac_MulticastClear(XLlTemac *InstancePtr, int Entry)
+{
+	int status;
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	status = XLlTemac_MulticastClear(InstancePtr, Entry);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+
+	return status;
+}
+
+static inline int _XLlTemac_SetMacPauseAddress(XLlTemac *InstancePtr, void *AddressPtr)
+{
+	int status;
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	status = XLlTemac_SetMacPauseAddress(InstancePtr, AddressPtr);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+
+	return status;
+}
+
+static inline void _XLlTemac_GetMacPauseAddress(XLlTemac *InstancePtr, void *AddressPtr)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	XLlTemac_GetMacPauseAddress(InstancePtr, AddressPtr);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+}
+
+static inline int _XLlTemac_GetSgmiiStatus(XLlTemac *InstancePtr, u16 *SpeedPtr)
+{
+	int status;
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	status = XLlTemac_GetSgmiiStatus(InstancePtr, SpeedPtr);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+
+	return status;
+}
+
+static inline int _XLlTemac_GetRgmiiStatus(XLlTemac *InstancePtr,
+					   u16 *SpeedPtr,
+					   int *IsFullDuplexPtr,
+					   int *IsLinkUpPtr)
+{
+	int status;
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_spinlock, flags);
+	status = XLlTemac_GetRgmiiStatus(InstancePtr, SpeedPtr, IsFullDuplexPtr, IsLinkUpPtr);
+	spin_unlock_irqrestore(&XTE_spinlock, flags);
+
+	return status;
+}
+
+
+#ifdef CONFIG_XILINX_LLTEMAC_MARVELL_88E1111_RGMII
+#define MARVELL_88E1111_EXTENDED_PHY_CTL_REG_OFFSET  20
+#define MARVELL_88E1111_EXTENDED_PHY_STATUS_REG_OFFSET  27
+#endif
+
+#define DEBUG_ERROR KERN_ERR
+#define DEBUG_LOG(level, ...) printk(level __VA_ARGS__)
+
+/*
+ * Perform any necessary special phy setup. In the gmii case, nothing needs to
+ * be done.
+ */
+static void phy_setup(struct net_local *lp)
+{
+#ifdef CONFIG_XILINX_LLTEMAC_MARVELL_88E1111_RGMII
+	u16 Register;
+
+	/*
+	 * Set up MAC interface
+	 *
+	 * Write 0x0cc3 to reg 20 in PHY
+	 *      5432 1098 7654 3210
+	 *      ---- ---- ---- ----
+	 * 0cc3=0000 1100 1100 0011
+	 *           downshift counter (bits 11-9): 110 = 7 times
+	 *              downshift enable (bit 8): 0 = enable
+	 *                RGMII timing control (bit 7): 1 = add delay to rx clk ro rxd
+	 *                outputs
+	 *                 Default Mac interface speed (bits 6-4): 100 = 10mbps 2.5 mhz
+	 *                 (between phy and temac - gets renegotiated)
+	 *                     reserved (bit 3)
+	 *                      DTE detect (bit 2): 0 disabled
+	 *                       RGMII transmit timing control (bit 1): 1 = add delay
+	 *                       to tx clk ro txd outputs
+	 *                        Transmitter Disable (bit 0): 1 = enabled
+	 */
+	_XLlTemac_PhyWrite(&lp->Emac, lp->gmii_addr, MARVELL_88E1111_EXTENDED_PHY_CTL_REG_OFFSET, 0x0cc3);
+
+	/*
+	 * Set RGMII to copper with correct hysterisis and correct mode
+	 * Disable fiber/copper auto sel, choose copper
+	 * RGMII /Modified MII to copper mode
+	 *
+	 * Write 0x848b to reg 27
+	 *      5432 1098 7654 3210
+	 *      ---- ---- ---- ----
+	 * 848b=1000 0100 1000 1011
+	 *      Fiber/Copper Auto Selection (bit 15): 1 = disable auto selection
+	 *            Interrupt Polarity (bit 10): 1 = int active low
+	 *              DTE detect status drop hysteresis (bts 8-5): 0100 = report 20s after DTE power status drop
+	 *                     HWCFG mode (bits 3-0): 1011 = RGMII/Modified MII to Copper
+	 */
+	_XLlTemac_PhyWrite(&lp->Emac, lp->gmii_addr, MARVELL_88E1111_EXTENDED_PHY_STATUS_REG_OFFSET, 0x848b);
+
+	/*
+	 * Reset the PHY
+	 */
+	_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, MII_BMCR, &Register);
+	Register |= BMCR_RESET;
+	_XLlTemac_PhyWrite(&lp->Emac, lp->gmii_addr, MII_BMCR, Register);
+
+#endif /* CONFIG_XILINX_LLTEMAC_MARVELL_88E1111_RGMII */
+}
+
+
+typedef enum DUPLEX { UNKNOWN_DUPLEX, HALF_DUPLEX, FULL_DUPLEX } DUPLEX;
+
+int renegotiate_speed(struct net_device *dev, int speed, DUPLEX duplex)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	int retries = 2;
+	int wait_count;
+	u16 phy_reg0 = BMCR_ANENABLE | BMCR_ANRESTART;
+	u16 phy_reg1;
+	u16 phy_reg4;
+	u16 phy_reg9 = 0;
+
+
+	/*
+	 * It appears that the 10baset full and half duplex settings
+	 * are overloaded for gigabit ethernet
+	 */
+	if ((duplex == FULL_DUPLEX) && (speed == 10)) {
+		phy_reg4 = ADVERTISE_10FULL | ADVERTISE_CSMA;
+	}
+	else if ((duplex == FULL_DUPLEX) && (speed == 100)) {
+		phy_reg4 = ADVERTISE_100FULL | ADVERTISE_CSMA;
+	}
+	else if ((duplex == FULL_DUPLEX) && (speed == 1000)) {
+		phy_reg4 = ADVERTISE_CSMA;
+		phy_reg9 = EX_ADVERTISE_1000FULL;
+	}
+	else if (speed == 10) {
+		phy_reg4 = ADVERTISE_10HALF | ADVERTISE_CSMA;
+	}
+	else if (speed == 100) {
+		phy_reg4 = ADVERTISE_100HALF | ADVERTISE_CSMA;
+	}
+	else if (speed == 1000) {
+		phy_reg4 = ADVERTISE_CSMA;
+		phy_reg9 = EX_ADVERTISE_1000HALF;
+	}
+	else {
+		printk(KERN_ERR
+		       "%s: XLlTemac: unsupported speed requested: %d\n",
+		       dev->name, speed);
+		return -1;
+	}
+
+	/*
+	 * link status in register 1:
+	 * first read / second read:
+	 * 0               0           link is down
+	 * 0               1           link is up (but it was down earlier)
+	 * 1               0           link is down (but it was just up)
+	 * 1               1           link is up
+	 *
+	 */
+	_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, MII_BMSR, &phy_reg1);
+	_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, MII_BMSR, &phy_reg1);
+	_XLlTemac_PhyWrite(&lp->Emac, lp->gmii_addr, MII_ADVERTISE, phy_reg4);
+	_XLlTemac_PhyWrite(&lp->Emac, lp->gmii_addr, MII_EXADVERTISE, phy_reg9);
+
+	while (retries--) {
+		/* initiate an autonegotiation of the speed */
+		_XLlTemac_PhyWrite(&lp->Emac, lp->gmii_addr, MII_BMCR, phy_reg0);
+
+		wait_count = 10;	/* so we don't loop forever */
+		while (wait_count--) {
+			/* wait a bit for the negotiation to complete */
+			mdelay(500);
+			_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, MII_BMSR,
+					  &phy_reg1);
+			_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, MII_BMSR,
+					  &phy_reg1);
+
+			if ((phy_reg1 & BMSR_LSTATUS) &&
+			    (phy_reg1 & BMSR_ANEGCOMPLETE))
+				break;
+
+		}
+
+		if (phy_reg1 & BMSR_LSTATUS) {
+			printk(KERN_INFO
+			       "%s: XLlTemac: We renegotiated the speed to: %d\n",
+			       dev->name, speed);
+			return 0;
+		}
+		else {
+			printk(KERN_ERR
+			       "%s: XLlTemac: Not able to set the speed to %d (status: 0x%0x)\n",
+			       dev->name, speed, phy_reg1);
+			return -1;
+		}
+	}
+
+	printk(KERN_ERR
+	       "%s: XLlTemac: Not able to set the speed to %d\n", dev->name,
+	       speed);
+	return -1;
+}
+
+/*
+ * This function sets up MAC's speed according to link speed of PHY
+ */
+void set_mac_speed(struct net_local *lp)
+{
+	u16 phylinkspeed;
+	struct net_device *dev = lp->ndev;
+
+#ifdef CONFIG_XILINX_LLTEMAC_MARVELL_88E1111_GMII
+	/*
+	 * This function is specific to MARVELL 88E1111 PHY chip on
+	 * many Xilinx boards and assumes GMII interface is being used
+	 * by the TEMAC.
+	 */
+
+#define MARVELL_88E1111_PHY_SPECIFIC_STATUS_REG_OFFSET  17
+#define MARVELL_88E1111_LINKSPEED_MARK                  0xC000
+#define MARVELL_88E1111_LINKSPEED_SHIFT                 14
+#define MARVELL_88E1111_LINKSPEED_1000M                 0x0002
+#define MARVELL_88E1111_LINKSPEED_100M                  0x0001
+#define MARVELL_88E1111_LINKSPEED_10M                   0x0000
+	u16 RegValue;
+
+	_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr,
+			MARVELL_88E1111_PHY_SPECIFIC_STATUS_REG_OFFSET,
+			&RegValue);
+	/* Get current link speed */
+	phylinkspeed = (RegValue & MARVELL_88E1111_LINKSPEED_MARK)
+		>> MARVELL_88E1111_LINKSPEED_SHIFT;
+
+	/* Update TEMAC speed accordingly */
+	switch (phylinkspeed) {
+	case (MARVELL_88E1111_LINKSPEED_1000M):
+		_XLlTemac_SetOperatingSpeed(&lp->Emac, 1000);
+		printk(KERN_INFO "%s: XLlTemac: speed set to 1000Mb/s\n",
+		       dev->name);
+		lp->cur_speed = 1000;
+		break;
+	case (MARVELL_88E1111_LINKSPEED_100M):
+		_XLlTemac_SetOperatingSpeed(&lp->Emac, 100);
+		printk(KERN_INFO "%s: XLlTemac: speed set to 100Mb/s\n",
+		       dev->name);
+		lp->cur_speed = 100;
+		break;
+	case (MARVELL_88E1111_LINKSPEED_10M):
+		_XLlTemac_SetOperatingSpeed(&lp->Emac, 10);
+		printk(KERN_INFO "%s: XLlTemac: speed set to 10Mb/s\n",
+		       dev->name);
+		lp->cur_speed = 10;
+		break;
+	default:
+		_XLlTemac_SetOperatingSpeed(&lp->Emac, 1000);
+		printk(KERN_INFO "%s: XLlTemac: speed defaults to 1000Mb/s\n",
+		       dev->name);
+		lp->cur_speed = 1000;
+		break;
+	}
+
+#else	/* generic PHY, there have been issues with 10Mbit with this code */
+	int ret;
+	int retry_count = 1;
+
+	if (XLlTemac_GetPhysicalInterface(&lp->Emac) == XTE_PHY_TYPE_MII) {
+		phylinkspeed = 100;
+	}
+	else {
+		phylinkspeed = 1000;
+	}
+
+	/*
+	 * Try to renegotiate the speed until something sticks
+	 */
+	while (phylinkspeed > 1) {
+		ret = renegotiate_speed(dev, phylinkspeed, FULL_DUPLEX);
+		/*
+		 * ret == 1 - try it again
+		 * ret == 0 - it worked
+		 * ret <  0 - there was some failure negotiating the speed
+		 */
+		if (ret == 0) {
+			/* it worked, get out of the loop */
+			break;
+		}
+
+		/* it didn't work this time, but it may work if we try again */
+		if ((ret == 1) && (retry_count)) {
+			retry_count--;
+			printk("trying again...\n");
+			continue;
+		}
+		/* reset the retry_count, becuase we're about to try a lower speed */
+		retry_count = 1;
+		phylinkspeed /= 10;
+	}
+	if (phylinkspeed == 1) {
+		printk(KERN_INFO "%s: XLlTemac: could not negotiate speed\n",
+		       dev->name);
+		lp->cur_speed = 0;
+
+		return;
+	}
+
+	_XLlTemac_SetOperatingSpeed(&lp->Emac, phylinkspeed);
+	printk(KERN_INFO "%s: XLlTemac: speed set to %dMb/s\n", dev->name,
+	       phylinkspeed);
+	lp->cur_speed = phylinkspeed;
+#endif
+}
+
+/*
+ * Helper function to reset the underlying hardware.  This is called
+ * when we get into such deep trouble that we don't know how to handle
+ * otherwise.
+ */
+static void reset(struct net_device *dev, u32 line_num)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	u32 TxThreshold, TxWaitBound, RxThreshold, RxWaitBound;
+	u32 Options;
+	static u32 reset_cnt = 0;
+	int status;
+
+	printk(KERN_INFO "%s: XLlTemac: resets (#%u) from adapter code line %d\n",
+	       dev->name, ++reset_cnt, line_num);
+
+	/* Shouldn't really be necessary, but shouldn't hurt. */
+	netif_stop_queue(dev);
+
+	/* Stop device */
+	_XLlTemac_Stop(&lp->Emac);
+
+	/*
+	 * XLlTemac_Reset puts the device back to the default state.  We need
+	 * to save all the settings we don't already know, reset, restore
+	 * the settings, and then restart the TEMAC.
+	 */
+	Options = XLlTemac_GetOptions(&lp->Emac);
+
+	/*
+	 * Capture the dma coalesce settings (if needed) and reset the
+	 * connected core, dma or fifo
+	 */
+	if (XLlTemac_IsDma(&lp->Emac)) {
+		XLlDma_BdRingGetCoalesce(&XLlDma_mGetRxRing(&lp->Dma),
+					 &RxThreshold, &RxWaitBound);
+		XLlDma_BdRingGetCoalesce(&XLlDma_mGetTxRing(&lp->Dma),
+					 &TxThreshold, &TxWaitBound);
+
+		XLlDma_Reset(&lp->Dma);
+	} else {
+		XLlFifo_Reset(&lp->Fifo);
+	}
+
+	/* now we can reset the device */
+	_XLlTemac_Reset(&lp->Emac, XTE_NORESET_HARD);
+
+	/* Reset on TEMAC also resets PHY. Give it some time to finish negotiation
+	 * before we move on */
+	mdelay(2000);
+
+	/*
+	 * The following four functions will return an error if the
+	 * EMAC is already started.  We just stopped it by calling
+	 * _XLlTemac_Reset() so we can safely ignore the return values.
+	 */
+	(int) _XLlTemac_SetMacAddress(&lp->Emac, dev->dev_addr);
+	(int) _XLlTemac_SetOptions(&lp->Emac, Options);
+	(int) _XLlTemac_ClearOptions(&lp->Emac, ~Options);
+	Options = XLlTemac_GetOptions(&lp->Emac);
+	printk(KERN_INFO "%s: XLlTemac: Options: 0x%x\n", dev->name, Options);
+
+	phy_setup(lp);
+	set_mac_speed(lp);
+
+	if (XLlTemac_IsDma(&lp->Emac)) {	/* SG DMA mode */
+		status = XLlDma_BdRingSetCoalesce(&lp->Dma.RxBdRing,
+						  RxThreshold, RxWaitBound);
+		status |= XLlDma_BdRingSetCoalesce(&lp->Dma.TxBdRing,
+						   TxThreshold, TxWaitBound);
+		if (status != XST_SUCCESS) {
+			/* Print the error, but keep on going as it's not a fatal error. */
+			printk(KERN_ERR "%s: XLlTemac: error setting coalesce values (probably out of range). status: %d\n",
+			       dev->name, status);
+		}
+		XLlDma_mBdRingIntEnable(&lp->Dma.RxBdRing, dma_rx_int_mask);
+		XLlDma_mBdRingIntEnable(&lp->Dma.TxBdRing, dma_tx_int_mask);
+	} else {			/* FIFO interrupt mode */
+		XLlFifo_IntEnable(&lp->Fifo, XLLF_INT_TC_MASK |
+				XLLF_INT_RC_MASK | XLLF_INT_RXERROR_MASK |
+				XLLF_INT_TXERROR_MASK);
+	}
+	XLlTemac_IntDisable(&lp->Emac, XTE_INT_ALL_MASK);
+
+	if (lp->deferred_skb) {
+		dev_kfree_skb_any(lp->deferred_skb);
+		lp->deferred_skb = NULL;
+		lp->stats.tx_errors++;
+	}
+
+	/*
+	 * XLlTemac_Start returns an error when: if configured for
+	 * scatter-gather DMA and a descriptor list has not yet been created
+	 * for the send or receive channel, or if no receive buffer descriptors
+	 * have been initialized. Those are not happening. so ignore the returned
+	 * result checking.
+	 */
+	_XLlTemac_Start(&lp->Emac);
+
+	/* We're all ready to go.  Start the queue in case it was stopped. */
+	netif_wake_queue(dev);
+}
+
+/*
+ * The PHY registers read here should be standard registers in all PHY chips
+ */
+static int get_phy_status(struct net_device *dev, DUPLEX * duplex, int *linkup)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	u16 reg;
+
+	_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, MII_BMCR, &reg);
+	*duplex = FULL_DUPLEX;
+
+	_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, MII_BMSR, &reg);
+	*linkup = (reg & BMSR_LSTATUS) != 0;
+
+	return 0;
+}
+
+/*
+ * This routine is used for two purposes.  The first is to keep the
+ * EMAC's duplex setting in sync with the PHY's.  The second is to keep
+ * the system apprised of the state of the link.  Note that this driver
+ * does not configure the PHY.  Either the PHY should be configured for
+ * auto-negotiation or it should be handled by something like mii-tool. */
+static void poll_gmii(unsigned long data)
+{
+	struct net_device *dev;
+	struct net_local *lp;
+	DUPLEX phy_duplex;
+	int phy_carrier;
+	int netif_carrier;
+
+	dev = (struct net_device *) data;
+	lp = (struct net_local *) netdev_priv(dev);
+
+	/* First, find out what's going on with the PHY. */
+	if (get_phy_status(dev, &phy_duplex, &phy_carrier)) {
+		printk(KERN_ERR "%s: XLlTemac: terminating link monitoring.\n",
+		       dev->name);
+		return;
+	}
+	netif_carrier = netif_carrier_ok(dev) != 0;
+	if (phy_carrier != netif_carrier) {
+		if (phy_carrier) {
+			set_mac_speed(lp);
+			printk(KERN_INFO
+			       "%s: XLlTemac: PHY Link carrier restored.\n",
+			       dev->name);
+			netif_carrier_on(dev);
+		}
+		else {
+			printk(KERN_INFO "%s: XLlTemac: PHY Link carrier lost.\n",
+			       dev->name);
+			netif_carrier_off(dev);
+		}
+	}
+
+	/* Set up the timer so we'll get called again in 2 seconds. */
+	lp->phy_timer.expires = jiffies + 2 * HZ;
+	add_timer(&lp->phy_timer);
+}
+
+static irqreturn_t xenet_temac_interrupt(int irq, void *dev_id)
+{
+	struct net_device *dev = dev_id;
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+
+	/*
+	 * All we care about here is the RxRject interrupts. Explanation below:
+	 *
+	 * Interrupt     Usage Description
+	 * ---------     -----------------
+	 * TxCmplt:      Fifo or DMA will have completion interrupts. We'll use
+	 *               those and not the TEMAC ones.
+	 * RxFifoOvr:    if the RX fifo is overflowing, the last thing we need
+	 *               is more interrupts to handle.
+	 * RxRJect:      We're keeping stats on rejected packets (we could
+	 *               choose not to).
+	 * RxCmplt:      Fifo or DMA will have completion interrupts. We'll use
+	 *               those and not the TEMAC ones.
+	 * AutoNeg:      This driver doesn't make use of the autonegotation
+	 *               completion interrupt.
+	 * HardAcsCmplt: This driver just polls the RDY register for this
+	 *               information instead of using an interrupt handler.
+	 * CfgWst, CfgRst,
+	 * AfWst, AfRst,
+	 * MiimWst, MiimRst,
+	 * FabrRst:      All of these registers indicate when access (read or
+	 *               write) to one or other of the Hard Temac Core
+	 *               registers is complete. Instead of relying on an
+	 *               interrupt context switch to be notified that the
+	 *               access is complete, this driver instead polls for the
+	 *               status, which, in most cases, should be faster.
+	 */
+	XLlTemac_IntClear(&lp->Emac, XTE_INT_ALL_MASK);
+
+	lp->stats.rx_errors++;
+	lp->stats.rx_crc_errors++;
+
+
+	return IRQ_HANDLED;
+}
+
+static void FifoSendHandler(struct net_device *dev);
+static void FifoRecvHandler(unsigned long p /*struct net_device *dev*/);
+
+DECLARE_TASKLET(FifoRecvBH, FifoRecvHandler, 0);
+
+static irqreturn_t xenet_fifo_interrupt(int irq, void *dev_id)
+{
+	struct net_device *dev = dev_id;
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	u32 irq_status;
+
+	unsigned long flags;
+
+	/*
+	 * Need to:
+	 * 1) Read the FIFO IS register
+	 * 2) clear all bits in the FIFO IS register
+	 * 3) loop on each bit in the IS register, and handle each interrupt event
+	 *
+	 */
+	irq_status = XLlFifo_IntPending(&lp->Fifo);
+	XLlFifo_IntClear(&lp->Fifo, irq_status);
+	while (irq_status) {
+		if (irq_status & XLLF_INT_RC_MASK) {
+			/* handle the receive completion */
+			struct list_head *cur_lp;
+			spin_lock_irqsave(&receivedQueueSpin, flags);
+			list_for_each(cur_lp, &receivedQueue) {
+				if (cur_lp == &(lp->rcv)) {
+					break;
+				}
+			}
+			if (cur_lp != &(lp->rcv)) {
+				list_add_tail(&lp->rcv, &receivedQueue);
+				XLlFifo_IntDisable(&lp->Fifo, XLLF_INT_ALL_MASK);
+				tasklet_schedule(&FifoRecvBH);
+			}
+			spin_unlock_irqrestore(&receivedQueueSpin, flags);
+			irq_status &= ~XLLF_INT_RC_MASK;
+		} else if (irq_status & XLLF_INT_TC_MASK) {
+			/* handle the transmit completion */
+			FifoSendHandler(dev);
+			irq_status &= ~XLLF_INT_TC_MASK;
+		} else if (irq_status & XLLF_INT_TXERROR_MASK) {
+			lp->stats.tx_errors++;
+			lp->stats.tx_fifo_errors++;
+			XLlFifo_Reset(&lp->Fifo);
+			irq_status &= ~XLLF_INT_TXERROR_MASK;
+		} else if (irq_status & XLLF_INT_RXERROR_MASK) {
+			lp->stats.rx_errors++;
+			XLlFifo_Reset(&lp->Fifo);
+			irq_status &= ~XLLF_INT_RXERROR_MASK;
+		} else {
+			/* debug
+			 * if (irq_status == 0) printk("Temac: spurious fifo int\n");
+			 */
+		}
+	}
+
+	return IRQ_HANDLED;
+}
+
+/* The callback function for completed frames sent in SGDMA mode. */
+static void DmaSendHandlerBH(unsigned long p);
+static void DmaRecvHandlerBH(unsigned long p);
+
+DECLARE_TASKLET(DmaSendBH, DmaSendHandlerBH, 0);
+DECLARE_TASKLET(DmaRecvBH, DmaRecvHandlerBH, 0);
+
+static irqreturn_t xenet_dma_rx_interrupt(int irq, void *dev_id)
+{
+	u32 irq_status;
+	struct net_device *dev = dev_id;
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	struct list_head *cur_lp;
+
+        unsigned long flags;
+
+	/* Read pending interrupts */
+	irq_status = XLlDma_mBdRingGetIrq(&lp->Dma.RxBdRing);
+
+	XLlDma_mBdRingAckIrq(&lp->Dma.RxBdRing, irq_status);
+
+	if ((irq_status & XLLDMA_IRQ_ALL_ERR_MASK)) {
+		XLlDma_Reset(&lp->Dma);
+		return IRQ_HANDLED;
+	}
+	if ((irq_status & (XLLDMA_IRQ_DELAY_MASK | XLLDMA_IRQ_COALESCE_MASK))) {
+		spin_lock_irqsave(&receivedQueueSpin, flags);
+		list_for_each(cur_lp, &receivedQueue) {
+			if (cur_lp == &(lp->rcv)) {
+				break;
+			}
+		}
+		if (cur_lp != &(lp->rcv)) {
+			list_add_tail(&lp->rcv, &receivedQueue);
+			XLlDma_mBdRingIntDisable(&lp->Dma.RxBdRing,
+						 XLLDMA_CR_IRQ_ALL_EN_MASK);
+			tasklet_schedule(&DmaRecvBH);
+		}
+		spin_unlock_irqrestore(&receivedQueueSpin, flags);
+	}
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t xenet_dma_tx_interrupt(int irq, void *dev_id)
+{
+	u32 irq_status;
+	struct net_device *dev = dev_id;
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	struct list_head *cur_lp;
+
+	unsigned long flags;
+
+	/* Read pending interrupts */
+	irq_status = XLlDma_mBdRingGetIrq(&(lp->Dma.TxBdRing));
+
+	XLlDma_mBdRingAckIrq(&(lp->Dma.TxBdRing), irq_status);
+
+	if ((irq_status & XLLDMA_IRQ_ALL_ERR_MASK)) {
+		XLlDma_Reset(&lp->Dma);
+		return IRQ_HANDLED;
+	}
+
+	if ((irq_status & (XLLDMA_IRQ_DELAY_MASK | XLLDMA_IRQ_COALESCE_MASK))) {
+		spin_lock_irqsave(&sentQueueSpin, flags);
+		list_for_each(cur_lp, &sentQueue) {
+			if (cur_lp == &(lp->xmit)) {
+ 				break;
+			}
+		}
+		if (cur_lp != &(lp->xmit)) {
+			list_add_tail(&lp->xmit, &sentQueue);
+			XLlDma_mBdRingIntDisable(&lp->Dma.TxBdRing,
+						 XLLDMA_CR_IRQ_ALL_EN_MASK);
+			tasklet_schedule(&DmaSendBH);
+		}
+		spin_unlock_irqrestore(&sentQueueSpin, flags);
+	}
+	return IRQ_HANDLED;
+}
+
+/*
+ * Q:
+ * Why doesn't this linux driver use an interrupt handler for the TEMAC itself?
+ *
+ * A:
+ * Let's take a look at all the possible events that could be signaled by the
+ * TEMAC core.
+ *
+ * possible events:
+ *    Transmit Complete (TxCmplt) [not handled by this driver]
+ *        The TEMAC TxCmplt interrupt status is ignored by software in favor of
+ *        paying attention to the transmit complete status in the connected DMA
+ *        or FIFO core.
+ *    Receive Fifo Overflow (RxFifoOver) [not handled by this driver]
+ *        We have discovered that the overhead of an interrupt context switch
+ *        to attempt to handle this sort of event actually worsens the
+ *        condition, and cuases further dropped packets further increasing the
+ *        time spent in this interrupt handler.
+ *    Receive Frame Rejected (RxRject) [not handled by this driver]
+ *        We could possibly handle this interrupt and gather statistics
+ *        information based on these events that occur. However it is not that
+ *        critical.
+ *    Receive Complete (RxCmplt) [not handled by this driver]
+ *        The TEMAC RxCmplt interrupt status is ignored by software in favor of
+ *        paying attention to the receive complete status in the connected DMA
+ *        or FIFO core.
+ *    Autonegotiaion Complete (AutoNeg) [not handled by this driver]
+ *        Autonegotiation on the TEMAC is a bit complicated, and is handled in
+ *        a way that does not require the use of this interrupt event.
+ *    Hard Temac Core Access Complete (HardAcsCmplt) [not handled by this driver]
+ *        This event really just indicates if there are any events in the TIS
+ *        register. As can be seen below, none of the events from the TIS
+ *        register are handled, so there is no need to handle this event
+ *        either.
+ *    Configuration Write Complete (CfgWst) [not handled by this driver]
+ *    Configuration Read Complete (CfgRst) [not handled by this driver]
+ *    Address Filter Write Complete (AfWst) [not handled by this driver]
+ *    Address Filter Read Complete (AfRst) [not handled by this driver]
+ *    MII Management Write Complete (MiimWst) [not handled by this driver]
+ *    MII Management Read Complete (MiimRst) [not handled by this driver]
+ *    Fabric Read Complete (FabrRst) [not handled by this driver]
+ *        All of the above registers indicate when access (read or write) to
+ *        one or other of the Hard Temac Core registers is complete. Instead of
+ *        relying on an interrupt context switch to be notified that the access
+ *        is complete, this driver instead polls for the status, which, in most
+ *        cases, should be faster.
+ */
+
+static int xenet_open(struct net_device *dev)
+{
+	struct net_local *lp;
+	u32 Options;
+	int irqval = 0;
+
+	/*
+	 * Just to be safe, stop TX queue and the device first.  If the device is
+	 * already stopped, an error will be returned.  In this case, we don't
+	 * really care.
+	 */
+	netif_stop_queue(dev);
+	lp = (struct net_local *) netdev_priv(dev);
+	_XLlTemac_Stop(&lp->Emac);
+
+	INIT_LIST_HEAD(&(lp->rcv));
+	INIT_LIST_HEAD(&(lp->xmit));
+
+	/* Set the MAC address each time opened. */
+	if (_XLlTemac_SetMacAddress(&lp->Emac, dev->dev_addr) != XST_SUCCESS) {
+		printk(KERN_ERR "%s: XLlTemac: could not set MAC address.\n",
+		       dev->name);
+		return -EIO;
+	}
+
+	/*
+	 * If the device is not configured for polled mode, connect to the
+	 * interrupt controller and enable interrupts.  Currently, there
+	 * isn't any code to set polled mode, so this check is probably
+	 * superfluous.
+	 */
+	Options = XLlTemac_GetOptions(&lp->Emac);
+	Options |= XTE_FLOW_CONTROL_OPTION;
+	/* Enabling jumbo packets shouldn't be a problem if MTU is smaller */
+	Options |= XTE_JUMBO_OPTION;
+	Options |= XTE_TRANSMITTER_ENABLE_OPTION;
+	Options |= XTE_RECEIVER_ENABLE_OPTION;
+#if XTE_AUTOSTRIPPING
+	Options |= XTE_FCS_STRIP_OPTION;
+#endif
+
+	(int) _XLlTemac_SetOptions(&lp->Emac, Options);
+	(int) _XLlTemac_ClearOptions(&lp->Emac, ~Options);
+	Options = XLlTemac_GetOptions(&lp->Emac);
+	printk(KERN_INFO "%s: XLlTemac: Options: 0x%x\n", dev->name, Options);
+
+	/* Just use interrupt driven methods - no polled mode */
+
+	irqval = request_irq(dev->irq, &xenet_temac_interrupt, IRQF_DISABLED, dev->name, dev);
+	if (irqval) {
+		printk(KERN_ERR
+		       "%s: XLlTemac: could not allocate interrupt %d.\n",
+		       dev->name, dev->irq);
+		return irqval;
+	}
+	if (XLlTemac_IsDma(&lp->Emac)) {
+		printk(KERN_INFO
+		       "%s: XLlTemac: allocating interrupt %d for dma mode tx.\n",
+		       dev->name, lp->dma_irq_s);
+		irqval = request_irq(lp->dma_irq_s,
+			&xenet_dma_tx_interrupt, 0, "xilinx_dma_tx_int", dev);
+		if (irqval) {
+			printk(KERN_ERR
+			       "%s: XLlTemac: could not allocate interrupt %d.\n",
+			       dev->name, lp->dma_irq_s);
+			return irqval;
+		}
+		printk(KERN_INFO
+		       "%s: XLlTemac: allocating interrupt %d for dma mode rx.\n",
+		       dev->name, lp->dma_irq_r);
+		irqval = request_irq(lp->dma_irq_r,
+			&xenet_dma_rx_interrupt, 0, "xilinx_dma_rx_int", dev);
+		if (irqval) {
+			printk(KERN_ERR
+			       "%s: XLlTemac: could not allocate interrupt %d.\n",
+			       dev->name, lp->dma_irq_r);
+			return irqval;
+		}
+	} else {
+		printk(KERN_INFO
+		       "%s: XLlTemac: allocating interrupt %d for fifo mode.\n",
+		       dev->name, lp->fifo_irq);
+		/* With the way interrupts are issued on the fifo core, this needs to be
+		 * fast interrupt handler.
+		 */
+		irqval = request_irq(lp->fifo_irq,
+			&xenet_fifo_interrupt, IRQF_DISABLED, "xilinx_fifo_int", dev);
+		if (irqval) {
+			printk(KERN_ERR
+			       "%s: XLlTemac: could not allocate interrupt %d.\n",
+			       dev->name, lp->fifo_irq);
+			return irqval;
+		}
+	}
+
+	/* give the system enough time to establish a link */
+	mdelay(2000);
+
+	phy_setup(lp);
+	set_mac_speed(lp);
+
+	/* Enable interrupts  - no polled mode */
+	if (XLlTemac_IsFifo(&lp->Emac)) { /* fifo direct interrupt driver mode */
+		XLlFifo_IntEnable(&lp->Fifo, XLLF_INT_TC_MASK |
+			XLLF_INT_RC_MASK | XLLF_INT_RXERROR_MASK |
+			XLLF_INT_TXERROR_MASK);
+	} else {		/* SG DMA mode */
+		XLlDma_mBdRingIntEnable(&lp->Dma.RxBdRing, dma_rx_int_mask);
+		XLlDma_mBdRingIntEnable(&lp->Dma.TxBdRing, dma_tx_int_mask);
+	}
+	/*
+	 * Make sure all temac interrupts are disabled. These
+	 * interrupts are not data flow releated.
+	 */
+	XLlTemac_IntDisable(&lp->Emac, XTE_INT_ALL_MASK);
+
+	/* Start TEMAC device */
+	_XLlTemac_Start(&lp->Emac);
+	if (XLlTemac_IsDma(&lp->Emac)) {
+		u32 threshold_s, timer_s, threshold_r, timer_r;
+
+		XLlDma_BdRingGetCoalesce(&lp->Dma.TxBdRing, &threshold_s, &timer_s);
+		XLlDma_BdRingGetCoalesce(&lp->Dma.RxBdRing, &threshold_r, &timer_r);
+		printk(KERN_INFO
+		       "%s: XLlTemac: Send Threshold = %d, Receive Threshold = %d\n",
+		       dev->name, threshold_s, threshold_r);
+		printk(KERN_INFO
+		       "%s: XLlTemac: Send Wait bound = %d, Receive Wait bound = %d\n",
+		       dev->name, timer_s, timer_r);
+		if (XLlDma_BdRingStart(&lp->Dma.TxBdRing) == XST_FAILURE) {
+			printk(KERN_ERR "%s: XLlTemac: could not start dma tx channel\n", dev->name);
+			return -EIO;
+		}
+		if (XLlDma_BdRingStart(&lp->Dma.RxBdRing) == XST_FAILURE) {
+			printk(KERN_ERR "%s: XLlTemac: could not start dma rx channel\n", dev->name);
+			return -EIO;
+		}
+	}
+
+	/* We're ready to go. */
+	netif_start_queue(dev);
+
+	/* Set up the PHY monitoring timer. */
+	lp->phy_timer.expires = jiffies + 2 * HZ;
+	lp->phy_timer.data = (unsigned long) dev;
+	lp->phy_timer.function = &poll_gmii;
+	init_timer(&lp->phy_timer);
+	add_timer(&lp->phy_timer);
+	return 0;
+}
+
+static int xenet_close(struct net_device *dev)
+{
+	struct net_local *lp;
+	unsigned long flags;
+
+	lp = (struct net_local *) netdev_priv(dev);
+
+	/* Shut down the PHY monitoring timer. */
+	del_timer_sync(&lp->phy_timer);
+
+	/* Stop Send queue */
+	netif_stop_queue(dev);
+
+	/* Now we could stop the device */
+	_XLlTemac_Stop(&lp->Emac);
+
+	/*
+	 * Free the interrupt - not polled mode.
+	 */
+	free_irq(dev->irq, dev);
+	if (XLlTemac_IsDma(&lp->Emac)) {
+		free_irq(lp->dma_irq_s, dev);
+		free_irq(lp->dma_irq_r, dev);
+	} else {
+		free_irq(lp->fifo_irq, dev);
+	}
+
+	spin_lock_irqsave(&receivedQueueSpin, flags);
+	list_del(&(lp->rcv));
+	spin_unlock_irqrestore(&receivedQueueSpin, flags);
+
+	spin_lock_irqsave(&sentQueueSpin, flags);
+	list_del(&(lp->xmit));
+	spin_unlock_irqrestore(&sentQueueSpin, flags);
+
+	return 0;
+}
+
+static struct net_device_stats *xenet_get_stats(struct net_device *dev)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+
+	return &lp->stats;
+}
+
+static int descriptor_init(struct net_device *dev);
+static void free_descriptor_skb(struct net_device *dev);
+
+static int xenet_change_mtu(struct net_device *dev, int new_mtu)
+{
+	int result;
+	int device_enable = 0;
+#ifdef CONFIG_XILINX_GIGE_VLAN
+	int head_size = XTE_HDR_VLAN_SIZE;
+#else
+	int head_size = XTE_HDR_SIZE;
+#endif
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	int max_frame = new_mtu + head_size + XTE_TRL_SIZE;
+	int min_frame = 1 + head_size + XTE_TRL_SIZE;
+
+	if (max_frame < min_frame)
+		return -EINVAL;
+
+	if (max_frame > XTE_MAX_JUMBO_FRAME_SIZE) {
+		printk(KERN_INFO "Wrong MTU packet size. Use %d size\n",
+							XTE_JUMBO_MTU);
+		new_mtu = XTE_JUMBO_MTU;
+	}
+
+	dev->mtu = new_mtu;	/* change mtu in net_device structure */
+
+	/* stop driver */
+	if (netif_running(dev)) {
+		device_enable = 1;
+		xenet_close(dev);
+	}
+	/* free all created descriptors for previous size */
+	free_descriptor_skb(dev);
+	/* setup new frame size */
+	lp->frame_size = dev->mtu + XTE_HDR_SIZE + XTE_TRL_SIZE;
+	XLlDma_Initialize(&lp->Dma, lp->virt_dma_addr); /* initialize dma */
+
+	result = descriptor_init(dev); /* create new skb with new size */
+	if (result) {
+		printk(KERN_ERR "Descriptor initialization failed.\n");
+		return -EINVAL;
+	}
+
+	if (device_enable)
+		xenet_open(dev); /* open the device */
+	return 0;
+}
+
+static int xenet_FifoSend(struct sk_buff *skb, struct net_device *dev)
+{
+	struct net_local *lp;
+	unsigned long flags, fifo_free_bytes;
+	int total_frags = skb_shinfo(skb)->nr_frags + 1;
+	unsigned int total_len;
+	skb_frag_t *frag;
+	int i;
+	void *virt_addr;
+
+	total_len = skb_headlen(skb);
+
+	frag = &skb_shinfo(skb)->frags[0];
+	for (i = 1; i < total_frags; i++, frag++) {
+		total_len += frag->size;
+	}
+
+	/* The following lock is used to protect TxVacancy, Write
+	 * and TxSetLen sequence which could happen from FifoSendHandler
+	 * or other processor in SMP case.
+	 */
+	spin_lock_irqsave(&XTE_tx_spinlock, flags);
+	lp = (struct net_local *) netdev_priv(dev);
+
+	fifo_free_bytes = XLlFifo_TxVacancy(&lp->Fifo) * 4;
+	if (fifo_free_bytes < total_len) {
+		netif_stop_queue(dev);	/* stop send queue */
+		lp->deferred_skb = skb;	/* buffer the sk_buffer and will send
+					   it in interrupt context */
+		spin_unlock_irqrestore(&XTE_tx_spinlock, flags);
+		return 0;
+	}
+
+	/* Write frame data to FIFO */
+	XLlFifo_Write(&lp->Fifo, (void *) skb->data, skb_headlen(skb));
+
+	frag = &skb_shinfo(skb)->frags[0];
+	for (i = 1; i < total_frags; i++, frag++) {
+		virt_addr =
+			(void *) page_address(frag->page) + frag->page_offset;
+		XLlFifo_Write(&lp->Fifo, virt_addr, frag->size);
+	}
+
+	/* Initiate transmit */
+	XLlFifo_TxSetLen(&lp->Fifo, total_len);
+	lp->stats.tx_bytes += total_len;
+	spin_unlock_irqrestore(&XTE_tx_spinlock, flags);
+
+	dev_kfree_skb(skb);	/* free skb */
+	dev->trans_start = jiffies;
+	return 0;
+}
+
+/* Callback function for completed frames sent in FIFO interrupt driven mode */
+static void FifoSendHandler(struct net_device *dev)
+{
+	struct net_local *lp;
+	struct sk_buff *skb;
+	unsigned long flags;
+
+	spin_lock_irqsave(&XTE_tx_spinlock, flags);
+	lp = (struct net_local *) netdev_priv(dev);
+	lp->stats.tx_packets++;
+
+	/*Send out the deferred skb and wake up send queue if a deferred skb exists */
+	if (lp->deferred_skb) {
+		int total_frags;
+		unsigned int total_len;
+		unsigned long fifo_free_bytes;
+		skb_frag_t *frag;
+		int i;
+		void *virt_addr;
+
+		skb = lp->deferred_skb;
+		total_frags = skb_shinfo(skb)->nr_frags + 1;
+		total_len = skb_headlen(skb);
+
+		frag = &skb_shinfo(skb)->frags[0];
+		for (i = 1; i < total_frags; i++, frag++) {
+			total_len += frag->size;
+		}
+
+		fifo_free_bytes = XLlFifo_TxVacancy(&lp->Fifo) * 4;
+		if (fifo_free_bytes < total_len) {
+			/* If still no room for the deferred packet, return */
+			spin_unlock_irqrestore(&XTE_tx_spinlock, flags);
+			return;
+		}
+
+		/* Write frame data to FIFO */
+		XLlFifo_Write(&lp->Fifo, (void *) skb->data, skb_headlen(skb));
+
+		frag = &skb_shinfo(skb)->frags[0];
+		for (i = 1; i < total_frags; i++, frag++) {
+			virt_addr =
+				(void *) page_address(frag->page) + frag->page_offset;
+			XLlFifo_Write(&lp->Fifo, virt_addr, frag->size);
+		}
+
+		/* Initiate transmit */
+		XLlFifo_TxSetLen(&lp->Fifo, total_len);
+
+		dev_kfree_skb(skb);	/* free skb */
+		lp->deferred_skb = NULL;
+		lp->stats.tx_packets++;
+		lp->stats.tx_bytes += total_len;
+		dev->trans_start = jiffies;
+		netif_wake_queue(dev);	/* wake up send queue */
+	}
+	spin_unlock_irqrestore(&XTE_tx_spinlock, flags);
+}
+
+#if 0
+/*
+ * These are used for debugging purposes, left here in case they are useful
+ * for further debugging
+ */
+static unsigned int _xenet_tx_csum(struct sk_buff *skb)
+{
+	unsigned int csum = 0;
+	long csstart = skb_transport_header(skb) - skb->data;
+
+	if (csstart != skb->len) {
+		csum = skb_checksum(skb, csstart, skb->len - csstart, 0);
+	}
+
+	return csum;
+}
+
+static inline unsigned int _xenet_rx_csum(struct sk_buff *skb)
+{
+	return skb_checksum(skb, 0, skb->len, 0);
+}
+#endif
+
+/*
+ * xenet_DmaSend_internal is an internal use, send routine.
+ * Any locks that need to be acquired, should be acquired
+ * prior to calling this routine.
+ */
+static int xenet_DmaSend_internal(struct sk_buff *skb, struct net_device *dev)
+{
+	struct net_local *lp;
+	XLlDma_Bd *bd_ptr;
+	int result;
+	int total_frags;
+	int i;
+	void *virt_addr;
+	size_t len;
+	dma_addr_t phy_addr;
+	XLlDma_Bd *first_bd_ptr;
+	XLlDma_Bd *last_bd_ptr;
+	skb_frag_t *frag;
+
+	lp = (struct net_local *) netdev_priv(dev);
+
+	/* get skb_shinfo(skb)->nr_frags + 1 buffer descriptors */
+	total_frags = skb_shinfo(skb)->nr_frags + 1;
+
+	/* stats */
+	if (lp->max_frags_in_a_packet < total_frags) {
+		lp->max_frags_in_a_packet = total_frags;
+	}
+
+	if (total_frags < XTE_SEND_BD_CNT) {
+		result = XLlDma_BdRingAlloc(&lp->Dma.TxBdRing, total_frags,
+					    &bd_ptr);
+
+		if (result != XST_SUCCESS) {
+			netif_stop_queue(dev);	/* stop send queue */
+			lp->deferred_skb = skb;	/* buffer the sk_buffer and will send
+						   it in interrupt context */
+			return result;
+		}
+	} else {
+		dev_kfree_skb(skb);
+		lp->stats.tx_dropped++;
+		printk(KERN_ERR
+		       "%s: XLlTemac: could not send TX socket buffers (too many fragments).\n",
+		       dev->name);
+		return XST_FAILURE;
+	}
+
+	len = skb_headlen(skb);
+
+	/* get the physical address of the header */
+	phy_addr = (u32) dma_map_single(dev->dev.parent, skb->data, len,
+								DMA_TO_DEVICE);
+
+	/* get the header fragment, it's in the skb differently */
+	XLlDma_mBdSetBufAddr(bd_ptr, phy_addr);
+	XLlDma_mBdSetLength(bd_ptr, len);
+	XLlDma_mBdSetId(bd_ptr, skb);
+
+	/*
+	 * if tx checksum offloading is enabled, when the ethernet stack
+	 * wants us to perform the checksum in hardware,
+	 * skb->ip_summed is CHECKSUM_PARTIAL. Otherwise skb->ip_summed is
+	 * CHECKSUM_NONE, meaning the checksum is already done, or
+	 * CHECKSUM_UNNECESSARY, meaning checksumming is turned off (e.g.
+	 * loopback interface)
+	 *
+	 * skb->csum is an overloaded value. On send, skb->csum is the offset
+	 * into the buffer (skb_transport_header(skb)) to place the csum value.
+	 * On receive this feild gets set to the actual csum value, before it's
+	 * passed up the stack.
+	 *
+	 * When we get here, the ethernet stack above will have already
+	 * computed the pseudoheader csum value and have placed it in the
+	 * TCP/UDP header.
+	 *
+	 * The IP header csum has also already been computed and inserted.
+	 *
+	 * Since the IP header with it's own csum should compute to a null
+	 * csum, it should be ok to include it in the hw csum. If it is decided
+	 * to change this scheme, skb should be examined before dma_map_single()
+	 * is called, which flushes the page from the cpu's cache.
+	 *
+	 * skb->data points to the beginning of the whole packet
+	 * skb_transport_header(skb) points to the beginning of the ip header
+	 *
+	 */
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+
+		unsigned int csum_start_off = skb_transport_offset(skb);
+		unsigned int csum_index_off = csum_start_off + skb->csum_offset;
+
+#if 0
+		{
+			unsigned int csum = _xenet_tx_csum(skb);
+
+			*((unsigned short *) (raw + skb->csum)) =
+				csum_fold(csum);
+			BdCsumDisable(bd_ptr);
+		}
+#else
+		BdCsumEnable(bd_ptr);
+		BdCsumSetup(bd_ptr, csum_start_off, csum_index_off);
+
+#endif
+		lp->tx_hw_csums++;
+	}
+	else {
+		/*
+		 * This routine will do no harm even if hardware checksum capability is
+		 * off.
+		 */
+		BdCsumDisable(bd_ptr);
+	}
+
+	first_bd_ptr = bd_ptr;
+	last_bd_ptr = bd_ptr;
+
+	frag = &skb_shinfo(skb)->frags[0];
+
+	for (i = 1; i < total_frags; i++, frag++) {
+		bd_ptr = XLlDma_mBdRingNext(&lp->Dma.TxBdRing, bd_ptr);
+		last_bd_ptr = bd_ptr;
+
+		virt_addr =
+			(void *) page_address(frag->page) + frag->page_offset;
+		phy_addr =
+			(u32) dma_map_single(dev->dev.parent, virt_addr,
+					frag->size, DMA_TO_DEVICE);
+
+		XLlDma_mBdSetBufAddr(bd_ptr, phy_addr);
+		XLlDma_mBdSetLength(bd_ptr, frag->size);
+		XLlDma_mBdSetId(bd_ptr, NULL);
+		BdCsumDisable(bd_ptr);
+		XLlDma_mBdSetStsCtrl(bd_ptr, 0);
+	}
+
+	if (first_bd_ptr == last_bd_ptr) {
+		XLlDma_mBdSetStsCtrl(last_bd_ptr,
+				     XLLDMA_BD_STSCTRL_SOP_MASK |
+				     XLLDMA_BD_STSCTRL_EOP_MASK);
+	} else {
+		XLlDma_mBdSetStsCtrl(first_bd_ptr, XLLDMA_BD_STSCTRL_SOP_MASK);
+		XLlDma_mBdSetStsCtrl(last_bd_ptr, XLLDMA_BD_STSCTRL_EOP_MASK);
+	}
+
+
+	/* Enqueue to HW */
+	result = XLlDma_BdRingToHw(&lp->Dma.TxBdRing, total_frags,
+				   first_bd_ptr);
+	if (result != XST_SUCCESS) {
+		netif_stop_queue(dev);	/* stop send queue */
+		dev_kfree_skb(skb);
+		XLlDma_mBdSetId(first_bd_ptr, NULL);
+		lp->stats.tx_dropped++;
+		printk(KERN_ERR
+		       "%s: XLlTemac: could not send commit TX buffer descriptor (%d).\n",
+		       dev->name, result);
+		reset(dev, __LINE__);
+
+		return XST_FAILURE;
+	}
+
+	dev->trans_start = jiffies;
+
+	return XST_SUCCESS;
+}
+
+/* The send function for frames sent in DMA mode */
+static int xenet_DmaSend(struct sk_buff *skb, struct net_device *dev)
+{
+	/* The following spin_lock protects
+	 * SgAlloc, SgCommit sequence, which also exists in DmaSendHandlerBH Bottom
+	 * Half, or triggered by other processor in SMP case.
+	 */
+	spin_lock_bh(&XTE_tx_spinlock);
+
+	xenet_DmaSend_internal(skb, dev);
+
+	spin_unlock_bh(&XTE_tx_spinlock);
+
+	return 0;
+}
+
+
+static void DmaSendHandlerBH(unsigned long p)
+{
+	struct net_device *dev;
+	struct net_local *lp;
+	XLlDma_Bd *BdPtr, *BdCurPtr;
+	unsigned long len;
+	unsigned long flags;
+	struct sk_buff *skb;
+	dma_addr_t skb_dma_addr;
+	int result = XST_SUCCESS;
+	unsigned int bd_processed, bd_processed_save;
+
+	while (1) {
+		spin_lock_irqsave(&sentQueueSpin, flags);
+		if (list_empty(&sentQueue)) {
+			spin_unlock_irqrestore(&sentQueueSpin, flags);
+			break;
+		}
+
+		lp = list_entry(sentQueue.next, struct net_local, xmit);
+
+		list_del_init(&(lp->xmit));
+		spin_unlock_irqrestore(&sentQueueSpin, flags);
+
+		spin_lock_irqsave(&XTE_tx_spinlock, flags);
+		dev = lp->ndev;
+		bd_processed_save = 0;
+		while ((bd_processed =
+			XLlDma_BdRingFromHw(&lp->Dma.TxBdRing, XTE_SEND_BD_CNT,
+					    &BdPtr)) > 0) {
+
+			bd_processed_save = bd_processed;
+			BdCurPtr = BdPtr;
+			do {
+				len = XLlDma_mBdGetLength(BdCurPtr);
+				skb_dma_addr = (dma_addr_t) XLlDma_mBdGetBufAddr(BdCurPtr);
+				dma_unmap_single(dev->dev.parent, skb_dma_addr,
+						len, DMA_TO_DEVICE);
+
+				/* get ptr to skb */
+				skb = (struct sk_buff *)
+					XLlDma_mBdGetId(BdCurPtr);
+				if (skb)
+					dev_kfree_skb(skb);
+
+				/* reset BD id */
+				XLlDma_mBdSetId(BdCurPtr, NULL);
+
+				lp->stats.tx_bytes += len;
+				if (XLlDma_mBdGetStsCtrl(BdCurPtr) & XLLDMA_BD_STSCTRL_EOP_MASK) {
+					lp->stats.tx_packets++;
+				}
+
+				BdCurPtr = XLlDma_mBdRingNext(&lp->Dma.TxBdRing, BdCurPtr);
+				bd_processed--;
+			} while (bd_processed > 0);
+
+			result = XLlDma_BdRingFree(&lp->Dma.TxBdRing,
+						   bd_processed_save, BdPtr);
+			if (result != XST_SUCCESS) {
+				printk(KERN_ERR
+				       "%s: XLlDma: BdRingFree() error %d.\n",
+				       dev->name, result);
+				reset(dev, __LINE__);
+				spin_unlock_irqrestore(&XTE_tx_spinlock, flags);
+				return;
+			}
+		}
+		XLlDma_mBdRingIntEnable(&lp->Dma.TxBdRing, dma_tx_int_mask);
+
+		/* Send out the deferred skb if it exists */
+		if ((lp->deferred_skb) && bd_processed_save) {
+			skb = lp->deferred_skb;
+			lp->deferred_skb = NULL;
+
+			result = xenet_DmaSend_internal(skb, dev);
+		}
+
+		if (result == XST_SUCCESS) {
+			netif_wake_queue(dev);	/* wake up send queue */
+		}
+		spin_unlock_irqrestore(&XTE_tx_spinlock, flags);
+	}
+}
+
+static void xenet_tx_timeout(struct net_device *dev)
+{
+	struct net_local *lp;
+	unsigned long flags;
+
+	/*
+	 * Make sure that no interrupts come in that could cause reentrancy
+	 * problems in reset.
+	 */
+	spin_lock_irqsave(&XTE_tx_spinlock, flags);
+
+	lp = (struct net_local *) netdev_priv(dev);
+	printk(KERN_ERR
+	       "%s: XLlTemac: exceeded transmit timeout of %lu ms.  Resetting emac.\n",
+	       dev->name, TX_TIMEOUT * 1000UL / HZ);
+	lp->stats.tx_errors++;
+
+	reset(dev, __LINE__);
+
+	spin_unlock_irqrestore(&XTE_tx_spinlock, flags);
+}
+
+/* The callback function for frames received when in FIFO mode. */
+static void FifoRecvHandler(unsigned long p)
+{
+	struct net_local *lp;
+	struct sk_buff *skb;
+	u32 len;
+
+	struct net_device *dev;
+	unsigned long flags;
+	spin_lock_irqsave(&receivedQueueSpin, flags);
+	if (list_empty(&receivedQueue)) {
+		spin_unlock_irqrestore(&receivedQueueSpin, flags);
+		return;
+	}
+	lp = list_entry(receivedQueue.next, struct net_local, rcv);
+
+	list_del_init(&(lp->rcv));
+	spin_unlock_irqrestore(&receivedQueueSpin, flags);
+	dev = lp->ndev;
+
+	while (XLlFifo_RxOccupancy(&lp->Fifo) != 0) {
+
+		len = XLlFifo_RxGetLen(&lp->Fifo);
+
+		/*
+		 * TODO: Hm this is odd, if we can't allocate the skb, we throw away the next packet. Why?
+		 */
+		if (!(skb = /*dev_ */ alloc_skb(len + ALIGNMENT_RECV, GFP_ATOMIC))) {
+#define XTE_RX_SINK_BUFFER_SIZE 1024
+			static u32 rx_buffer_sink[XTE_RX_SINK_BUFFER_SIZE / sizeof(u32)];
+
+			/* Couldn't get memory. */
+			lp->stats.rx_dropped++;
+			printk(KERN_ERR
+			       "%s: XLlTemac: could not allocate receive buffer.\n",
+			       dev->name);
+
+			/* consume data in Xilinx TEMAC RX data fifo so it is sync with RX length fifo */
+			for (; len > XTE_RX_SINK_BUFFER_SIZE;
+					len -= XTE_RX_SINK_BUFFER_SIZE) {
+				XLlFifo_Read(&lp->Fifo, rx_buffer_sink,
+					       XTE_RX_SINK_BUFFER_SIZE);
+			}
+			XLlFifo_Read(&lp->Fifo, rx_buffer_sink, len);
+			break;
+		}
+
+		/* Read the packet data */
+		XLlFifo_Read(&lp->Fifo, skb->data, len);
+		lp->stats.rx_packets++;
+		lp->stats.rx_bytes += len;
+
+		skb_put(skb, len);	/* Tell the skb how much data we got. */
+		skb->dev = dev;		/* Fill out required meta-data. */
+		skb->protocol = eth_type_trans(skb, dev);
+		skb->ip_summed = CHECKSUM_NONE;
+		netif_rx(skb);		/* Send the packet upstream. */
+	}
+	XLlFifo_IntEnable(&lp->Fifo, XLLF_INT_TC_MASK | XLLF_INT_RC_MASK |
+			XLLF_INT_RXERROR_MASK | XLLF_INT_TXERROR_MASK);
+
+}
+
+
+/*
+ * _xenet_DmaSetupRecvBuffers allocates as many socket buffers (sk_buff's) as it
+ * can up to the number of free RX buffer descriptors. Then it sets up the RX
+ * buffer descriptors to DMA into the socket_buffers.
+ *
+ * The net_device, dev, indcates on which device to operate for buffer
+ * descriptor allocation.
+ */
+static void _xenet_DmaSetupRecvBuffers(struct net_device *dev)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+
+	int free_bd_count = XLlDma_mBdRingGetFreeCnt(&lp->Dma.RxBdRing);
+	int num_sk_buffs;
+	struct sk_buff_head sk_buff_list;
+	struct sk_buff *new_skb;
+	u32 new_skb_baddr;
+	XLlDma_Bd *BdPtr, *BdCurPtr;
+	u32 align;
+	int result;
+
+#if 0
+	int align_max = ALIGNMENT_RECV;
+#else
+	int align_max = 0;
+#endif
+
+
+	skb_queue_head_init(&sk_buff_list);
+	for (num_sk_buffs = 0; num_sk_buffs < free_bd_count; num_sk_buffs++) {
+		new_skb = alloc_skb(lp->frame_size + align_max, GFP_ATOMIC);
+		if (new_skb == NULL) {
+			break;
+		}
+		/*
+		 * I think the XTE_spinlock, and Recv DMA int disabled will protect this
+		 * list as well, so we can use the __ version just fine
+		 */
+		__skb_queue_tail(&sk_buff_list, new_skb);
+	}
+	if (!num_sk_buffs) {
+		printk(KERN_ERR "%s: XLlTemac: alloc_skb unsuccessful\n",
+		       dev->name);
+		return;
+	}
+
+	/* now we got a bunch o' sk_buffs */
+	result = XLlDma_BdRingAlloc(&lp->Dma.RxBdRing, num_sk_buffs, &BdPtr);
+	if (result != XST_SUCCESS) {
+		/* we really shouldn't get this */
+		skb_queue_purge(&sk_buff_list);
+		printk(KERN_ERR "%s: XLlDma: BdRingAlloc unsuccessful (%d)\n",
+		       dev->name, result);
+		reset(dev, __LINE__);
+		return;
+	}
+
+	BdCurPtr = BdPtr;
+
+	new_skb = skb_dequeue(&sk_buff_list);
+	while (new_skb) {
+		/* make sure we're long-word aligned */
+		align = BUFFER_ALIGNRECV(new_skb->data);
+		if (align) {
+			skb_reserve(new_skb, align);
+		}
+
+		/* Get dma handle of skb->data */
+		new_skb_baddr = (u32) dma_map_single(dev->dev.parent,
+					new_skb->data, lp->frame_size,
+						     DMA_FROM_DEVICE);
+		XLlDma_mBdSetBufAddr(BdCurPtr, new_skb_baddr);
+		XLlDma_mBdSetLength(BdCurPtr, lp->frame_size);
+		XLlDma_mBdSetId(BdCurPtr, new_skb);
+		XLlDma_mBdSetStsCtrl(BdCurPtr,
+				     XLLDMA_BD_STSCTRL_SOP_MASK |
+				     XLLDMA_BD_STSCTRL_EOP_MASK);
+
+		BdCurPtr = XLlDma_mBdRingNext(&lp->Dma.RxBdRing, BdCurPtr);
+
+		new_skb = skb_dequeue(&sk_buff_list);
+	}
+
+	/* enqueue RxBD with the attached skb buffers such that it is
+	 * ready for frame reception */
+	result = XLlDma_BdRingToHw(&lp->Dma.RxBdRing, num_sk_buffs, BdPtr);
+	if (result != XST_SUCCESS) {
+		printk(KERN_ERR
+		       "%s: XLlDma: (DmaSetupRecvBuffers) BdRingToHw unsuccessful (%d)\n",
+		       dev->name, result);
+		skb_queue_purge(&sk_buff_list);
+		BdCurPtr = BdPtr;
+		while (num_sk_buffs > 0) {
+			XLlDma_mBdSetId(BdCurPtr, NULL);
+			BdCurPtr = XLlDma_mBdRingNext(&lp->Dma.RxBdRing,
+						      BdCurPtr);
+			num_sk_buffs--;
+		}
+		reset(dev, __LINE__);
+		return;
+	}
+}
+
+static void DmaRecvHandlerBH(unsigned long p)
+{
+	struct net_device *dev;
+	struct net_local *lp;
+	struct sk_buff *skb;
+	u32 len, skb_baddr;
+	int result;
+	unsigned long flags;
+	XLlDma_Bd *BdPtr, *BdCurPtr;
+	unsigned int bd_processed, bd_processed_saved;
+
+	while (1) {
+		spin_lock_irqsave(&receivedQueueSpin, flags);
+		if (list_empty(&receivedQueue)) {
+			spin_unlock_irqrestore(&receivedQueueSpin, flags);
+			break;
+		}
+		lp = list_entry(receivedQueue.next, struct net_local, rcv);
+
+		list_del_init(&(lp->rcv));
+		spin_unlock_irqrestore(&receivedQueueSpin, flags);
+		dev = lp->ndev;
+
+		spin_lock_irqsave(&XTE_rx_spinlock, flags);
+		if ((bd_processed =
+		     XLlDma_BdRingFromHw(&lp->Dma.RxBdRing, XTE_RECV_BD_CNT, &BdPtr)) > 0) {
+
+			bd_processed_saved = bd_processed;
+			BdCurPtr = BdPtr;
+			do {
+				/*
+				 * Regular length field not updated on rx,
+				 * USR4 updated instead.
+				 */
+				len = BdGetRxLen(BdCurPtr);
+
+				/* get ptr to skb */
+				skb = (struct sk_buff *)
+					XLlDma_mBdGetId(BdCurPtr);
+
+				/* get and free up dma handle used by skb->data */
+				skb_baddr = (dma_addr_t) XLlDma_mBdGetBufAddr(BdCurPtr);
+				dma_unmap_single(dev->dev.parent, skb_baddr,
+						 lp->frame_size,
+						 DMA_FROM_DEVICE);
+
+				/* reset ID */
+				XLlDma_mBdSetId(BdCurPtr, NULL);
+
+				/* setup received skb and send it upstream */
+				skb_put(skb, len);	/* Tell the skb how much data we got. */
+				skb->dev = dev;
+
+				/* this routine adjusts skb->data to skip the header */
+				skb->protocol = eth_type_trans(skb, dev);
+
+				/* default the ip_summed value */
+				skb->ip_summed = CHECKSUM_NONE;
+
+				/* if we're doing rx csum offload, set it up */
+				if (((lp->local_features & LOCAL_FEATURE_RX_CSUM) != 0) &&
+				    (skb->protocol == __constant_htons(ETH_P_IP)) &&
+				    (skb->len > 64)) {
+					unsigned int csum;
+
+					/*
+					 * This hardware only supports proper checksum calculations
+					 * on TCP/UDP packets.
+					 *
+					 * skb->csum is an overloaded value. On send, skb->csum is
+					 * the offset into the buffer (skb_transport_header(skb))
+					 * to place the csum value. On receive this feild gets set
+					 * to the actual csum value, before it's passed up the stack.
+					 *
+					 * If we set skb->ip_summed to CHECKSUM_COMPLETE, the ethernet
+					 * stack above will compute the pseudoheader csum value and
+					 * add it to the partial checksum already computed (to be
+					 * placed in skb->csum) and verify it.
+					 *
+					 * Setting skb->ip_summed to CHECKSUM_NONE means that the
+					 * cheksum didn't verify and the stack will (re)check it.
+					 *
+					 * Setting skb->ip_summed to CHECKSUM_UNNECESSARY means
+					 * that the cheksum was verified/assumed to be good and the
+					 * stack does not need to (re)check it.
+					 *
+					 * The ethernet stack above will (re)compute the checksum
+					 * under the following conditions:
+					 * 1) skb->ip_summed was set to CHECKSUM_NONE
+					 * 2) skb->len does not match the length of the ethernet
+					 *    packet determined by parsing the packet. In this case
+					 *    the ethernet stack will assume any prior checksum
+					 *    value was miscomputed and throw it away.
+					 * 3) skb->ip_summed was set to CHECKSUM_COMPLETE, skb->csum was
+					 *    set, but the result does not check out ok by the
+					 *    ethernet stack.
+					 *
+					 * If the TEMAC hardware stripping feature is off, each
+					 * packet will contain an FCS feild which will have been
+					 * computed by the hardware checksum operation. This 4 byte
+					 * FCS value needs to be subtracted back out of the checksum
+					 * value computed by hardware as it's not included in a
+					 * normal ethernet packet checksum.
+					 *
+					 * The minimum transfer packet size over the wire is 64
+					 * bytes. If the packet is sent as exactly 64 bytes, then
+					 * it probably contains some random padding bytes. It's
+					 * somewhat difficult to determine the actual length of the
+					 * real packet data, so we just let the stack recheck the
+					 * checksum for us.
+					 *
+					 * After the call to eth_type_trans(), the following holds
+					 * true:
+					 *    skb->data points to the beginning of the ip header
+					 */
+					csum = BdCsumGet(BdCurPtr);
+
+#if ! XTE_AUTOSTRIPPING
+					if (!lp->stripping) {
+						/* take off the FCS */
+						u16 *data;
+
+						/* FCS is 4 bytes */
+						skb_put(skb, -4);
+
+						data = (u16 *) (&skb->
+								data[skb->len]);
+
+						/* subtract out the FCS from the csum value */
+						csum = csum_sub(csum, *data /* & 0xffff */);
+						data++;
+						csum = csum_sub(csum, *data /* & 0xffff */);
+					}
+#endif
+					skb->csum = csum;
+					skb->ip_summed = CHECKSUM_COMPLETE;
+
+					lp->rx_hw_csums++;
+				}
+
+				lp->stats.rx_packets++;
+				lp->stats.rx_bytes += len;
+				netif_rx(skb);	/* Send the packet upstream. */
+
+				BdCurPtr =
+					XLlDma_mBdRingNext(&lp->Dma.RxBdRing,
+							   BdCurPtr);
+				bd_processed--;
+			} while (bd_processed > 0);
+
+			/* give the descriptor back to the driver */
+			result = XLlDma_BdRingFree(&lp->Dma.RxBdRing,
+						   bd_processed_saved, BdPtr);
+			if (result != XST_SUCCESS) {
+				printk(KERN_ERR
+				       "%s: XLlDma: BdRingFree unsuccessful (%d)\n",
+				       dev->name, result);
+				reset(dev, __LINE__);
+				spin_unlock_irqrestore(&XTE_rx_spinlock, flags);
+				return;
+			}
+
+			_xenet_DmaSetupRecvBuffers(dev);
+		}
+		XLlDma_mBdRingIntEnable(&lp->Dma.RxBdRing, dma_rx_int_mask);
+		spin_unlock_irqrestore(&XTE_rx_spinlock, flags);
+	}
+}
+
+static int descriptor_init(struct net_device *dev)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	int recvsize, sendsize;
+	int dftsize;
+	u32 *recvpoolptr, *sendpoolptr;
+	void *recvpoolphy, *sendpoolphy;
+	int result;
+
+/*
+ * Buffer Descriptr
+ * word	byte	description
+ * 0	0h	next ptr
+ * 1	4h	buffer addr
+ * 2	8h	buffer len
+ * 3	ch	sts/ctrl | app data (0) [tx csum enable (bit 31 LSB)]
+ * 4	10h	app data (1) [tx csum begin (bits 0-15 MSB) | csum insert (bits 16-31 LSB)]
+ * 5	14h	app data (2) [tx csum seed (bits 16-31 LSB)]
+ * 6	18h	app data (3) [rx raw csum (bits 16-31 LSB)]
+ * 7	1ch	app data (4) [rx recv length (bits 18-31 LSB)]
+ */
+#if 0
+	int XferType = XDMAV3_DMACR_TYPE_BFBURST_MASK;
+	int XferWidth = XDMAV3_DMACR_DSIZE_64_MASK;
+#endif
+
+	/* calc size of descriptor space pool; alloc from non-cached memory */
+	dftsize = XLlDma_mBdRingMemCalc(ALIGNMENT_BD,
+					XTE_RECV_BD_CNT + XTE_SEND_BD_CNT);
+	printk(KERN_INFO "XLlTemac: buffer descriptor size: %d (0x%0x)\n",
+	       dftsize, dftsize);
+
+#if BD_IN_BRAM == 0
+	/*
+	 * Allow buffer descriptors to be cached.
+	 * Old method w/cache on buffer descriptors disabled:
+	 *     lp->desc_space = dma_alloc_coherent(NULL, dftsize,
+	 *         &lp->desc_space_handle, GFP_KERNEL);
+	 * (note if going back to dma_alloc_coherent() the CACHE macros in
+	 * xenv_linux.h need to be disabled.
+	 */
+
+        printk(KERN_INFO "XLlTemac: Allocating DMA descriptors with kmalloc");
+        lp->desc_space = kmalloc(dftsize, GFP_KERNEL);
+	lp->desc_space_handle = (dma_addr_t) page_to_phys(virt_to_page(lp->desc_space));
+#else
+        printk(KERN_INFO "XLlTemac: Allocating DMA descriptors in Block Ram");
+	lp->desc_space_handle = BRAM_BASEADDR;
+	lp->desc_space = ioremap(lp->desc_space_handle, dftsize);
+#endif
+	if (lp->desc_space == 0) {
+		return -1;
+	}
+
+	lp->desc_space_size = dftsize;
+
+	printk(KERN_INFO
+	       "XLlTemac: (buffer_descriptor_init) phy: 0x%x, virt: 0x%x, size: 0x%x\n",
+	       lp->desc_space_handle, (unsigned int) lp->desc_space,
+	       lp->desc_space_size);
+
+	/* calc size of send and recv descriptor space */
+	recvsize = XLlDma_mBdRingMemCalc(ALIGNMENT_BD, XTE_RECV_BD_CNT);
+	sendsize = XLlDma_mBdRingMemCalc(ALIGNMENT_BD, XTE_SEND_BD_CNT);
+
+	recvpoolptr = lp->desc_space;
+	sendpoolptr = (void *) ((u32) lp->desc_space + recvsize);
+
+	recvpoolphy = (void *) lp->desc_space_handle;
+	sendpoolphy = (void *) ((u32) lp->desc_space_handle + recvsize);
+
+	result = XLlDma_BdRingCreate(&lp->Dma.RxBdRing, (u32) recvpoolphy,
+				     (u32) recvpoolptr, ALIGNMENT_BD,
+				     XTE_RECV_BD_CNT);
+	if (result != XST_SUCCESS) {
+		printk(KERN_ERR "XLlTemac: DMA Ring Create (RECV). Error: %d\n", result);
+		return -EIO;
+	}
+
+	result = XLlDma_BdRingCreate(&lp->Dma.TxBdRing, (u32) sendpoolphy,
+				     (u32) sendpoolptr, ALIGNMENT_BD,
+				     XTE_SEND_BD_CNT);
+	if (result != XST_SUCCESS) {
+		printk(KERN_ERR "XLlTemac: DMA Ring Create (SEND). Error: %d\n", result);
+		return -EIO;
+	}
+
+	_xenet_DmaSetupRecvBuffers(dev);
+	return 0;
+}
+
+static void free_descriptor_skb(struct net_device *dev)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	XLlDma_Bd *BdPtr;
+	struct sk_buff *skb;
+	dma_addr_t skb_dma_addr;
+	u32 len, i;
+
+	/* Unmap and free skb's allocated and mapped in descriptor_init() */
+
+	/* Get the virtual address of the 1st BD in the DMA RX BD ring */
+	BdPtr = (XLlDma_Bd *) lp->Dma.RxBdRing.FirstBdAddr;
+
+	for (i = 0; i < XTE_RECV_BD_CNT; i++) {
+		skb = (struct sk_buff *) XLlDma_mBdGetId(BdPtr);
+		if (skb) {
+			skb_dma_addr = (dma_addr_t) XLlDma_mBdGetBufAddr(BdPtr);
+			dma_unmap_single(dev->dev.parent, skb_dma_addr,
+					lp->frame_size, DMA_FROM_DEVICE);
+			dev_kfree_skb(skb);
+		}
+		/* find the next BD in the DMA RX BD ring */
+		BdPtr = XLlDma_mBdRingNext(&lp->Dma.RxBdRing, BdPtr);
+	}
+
+	/* Unmap and free TX skb's that have not had a chance to be freed
+	 * in DmaSendHandlerBH(). This could happen when TX Threshold is larger
+	 * than 1 and TX waitbound is 0
+	 */
+
+	/* Get the virtual address of the 1st BD in the DMA TX BD ring */
+	BdPtr = (XLlDma_Bd *) lp->Dma.TxBdRing.FirstBdAddr;
+
+	for (i = 0; i < XTE_SEND_BD_CNT; i++) {
+		skb = (struct sk_buff *) XLlDma_mBdGetId(BdPtr);
+		if (skb) {
+			skb_dma_addr = (dma_addr_t) XLlDma_mBdGetBufAddr(BdPtr);
+			len = XLlDma_mBdGetLength(BdPtr);
+			dma_unmap_single(dev->dev.parent, skb_dma_addr, len,
+					 DMA_TO_DEVICE);
+			dev_kfree_skb(skb);
+		}
+		/* find the next BD in the DMA TX BD ring */
+		BdPtr = XLlDma_mBdRingNext(&lp->Dma.TxBdRing, BdPtr);
+	}
+
+#if BD_IN_BRAM == 0
+	kfree(lp->desc_space);
+/* this is old approach which was removed */
+/*	dma_free_coherent(NULL,
+			  lp->desc_space_size,
+			  lp->desc_space, lp->desc_space_handle); */
+#else
+	iounmap(lp->desc_space);
+#endif
+}
+
+static int
+xenet_ethtool_get_settings(struct net_device *dev, struct ethtool_cmd *ecmd)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	u32 mac_options;
+	u32 threshold, timer;
+	u16 gmii_cmd, gmii_status, gmii_advControl;
+
+	memset(ecmd, 0, sizeof(struct ethtool_cmd));
+
+	mac_options = XLlTemac_GetOptions(&(lp->Emac));
+	_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, MII_BMCR, &gmii_cmd);
+	_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, MII_BMSR, &gmii_status);
+
+	_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, MII_ADVERTISE, &gmii_advControl);
+
+	ecmd->duplex = DUPLEX_FULL;
+
+	ecmd->supported |= SUPPORTED_MII;
+
+	ecmd->port = PORT_MII;
+
+	ecmd->speed = lp->cur_speed;
+
+	if (gmii_status & BMSR_ANEGCAPABLE) {
+		ecmd->supported |= SUPPORTED_Autoneg;
+	}
+	if (gmii_status & BMSR_ANEGCOMPLETE) {
+		ecmd->autoneg = AUTONEG_ENABLE;
+		ecmd->advertising |= ADVERTISED_Autoneg;
+	}
+	else {
+		ecmd->autoneg = AUTONEG_DISABLE;
+	}
+	ecmd->phy_address = lp->Emac.Config.BaseAddress;
+	ecmd->transceiver = XCVR_INTERNAL;
+	if (XLlTemac_IsDma(&lp->Emac)) {
+		/* get TX threshold */
+
+		XLlDma_BdRingGetCoalesce(&lp->Dma.TxBdRing, &threshold, &timer);
+		ecmd->maxtxpkt = threshold;
+
+		/* get RX threshold */
+		XLlDma_BdRingGetCoalesce(&lp->Dma.RxBdRing, &threshold, &timer);
+		ecmd->maxrxpkt = threshold;
+	}
+
+	ecmd->supported |= SUPPORTED_10baseT_Full | SUPPORTED_100baseT_Full |
+		SUPPORTED_1000baseT_Full | SUPPORTED_Autoneg;
+
+	return 0;
+}
+
+static int
+xenet_ethtool_set_settings(struct net_device *dev, struct ethtool_cmd *ecmd)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+
+	if ((ecmd->duplex != DUPLEX_FULL) ||
+	    (ecmd->transceiver != XCVR_INTERNAL) ||
+	    (ecmd->phy_address &&
+	     (ecmd->phy_address != lp->Emac.Config.BaseAddress))) {
+		return -EOPNOTSUPP;
+	}
+
+	if ((ecmd->speed != 1000) && (ecmd->speed != 100) &&
+	    (ecmd->speed != 10)) {
+		printk(KERN_ERR
+		       "%s: XLlTemac: xenet_ethtool_set_settings speed not supported: %d\n",
+		       dev->name, ecmd->speed);
+		return -EOPNOTSUPP;
+	}
+
+	if (ecmd->speed != lp->cur_speed) {
+		renegotiate_speed(dev, ecmd->speed, FULL_DUPLEX);
+		_XLlTemac_SetOperatingSpeed(&lp->Emac, ecmd->speed);
+		lp->cur_speed = ecmd->speed;
+	}
+	return 0;
+}
+
+static int
+xenet_ethtool_get_coalesce(struct net_device *dev, struct ethtool_coalesce *ec)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	u32 threshold, waitbound;
+
+	memset(ec, 0, sizeof(struct ethtool_coalesce));
+
+	if (!(XLlTemac_IsDma(&lp->Emac))) {
+		return -EIO;
+	}
+
+	XLlDma_BdRingGetCoalesce(&lp->Dma.RxBdRing, &threshold, &waitbound);
+	ec->rx_max_coalesced_frames = threshold;
+	ec->rx_coalesce_usecs = waitbound;
+
+	XLlDma_BdRingGetCoalesce(&lp->Dma.TxBdRing, &threshold, &waitbound);
+	ec->tx_max_coalesced_frames = threshold;
+	ec->tx_coalesce_usecs = waitbound;
+
+	return 0;
+}
+
+void disp_bd_ring(XLlDma_BdRing *bd_ring)
+{
+	int num_bds = bd_ring->AllCnt;
+	u32 *cur_bd_ptr = (u32 *) bd_ring->FirstBdAddr;
+	int idx;
+
+	printk("ChanBase: %p\n", (void *) bd_ring->ChanBase);
+	printk("FirstBdPhysAddr: %p\n", (void *) bd_ring->FirstBdPhysAddr);
+	printk("FirstBdAddr: %p\n", (void *) bd_ring->FirstBdAddr);
+	printk("LastBdAddr: %p\n", (void *) bd_ring->LastBdAddr);
+	printk("Length: %d (0x%0x)\n", bd_ring->Length, bd_ring->Length);
+	printk("RunState: %d (0x%0x)\n", bd_ring->RunState, bd_ring->RunState);
+	printk("Separation: %d (0x%0x)\n", bd_ring->Separation,
+	       bd_ring->Separation);
+	printk("BD Count: %d\n", bd_ring->AllCnt);
+
+	printk("\n");
+
+	printk("FreeHead: %p\n", (void *) bd_ring->FreeHead);
+	printk("PreHead: %p\n", (void *) bd_ring->PreHead);
+	printk("HwHead: %p\n", (void *) bd_ring->HwHead);
+	printk("HwTail: %p\n", (void *) bd_ring->HwTail);
+	printk("PostHead: %p\n", (void *) bd_ring->PostHead);
+	printk("BdaRestart: %p\n", (void *) bd_ring->BdaRestart);
+
+	printk("Ring Contents:\n");
+/*
+ * Buffer Descriptr
+ * word	byte	description
+ * 0	0h	next ptr
+ * 1	4h	buffer addr
+ * 2	8h	buffer len
+ * 3	ch	sts/ctrl | app data (0) [tx csum enable (bit 31 LSB)]
+ * 4	10h	app data (1) [tx csum begin (bits 0-15 MSB) | csum insert (bits 16-31 LSB)]
+ * 5	14h	app data (2) [tx csum seed (bits 16-31 LSB)]
+ * 6	18h	app data (3) [rx raw csum (bits 16-31 LSB)]
+ * 7	1ch	app data (4) [rx recv length (bits 18-31 LSB)]
+ * 8	20h	sw app data (0) [id]
+ */
+	printk("Idx   NextBD BuffAddr   Length  CTL/CSE CSUM B/I CSUMSeed Raw CSUM  RecvLen       ID\n");
+	printk("--- -------- -------- -------- -------- -------- -------- -------- -------- --------\n");
+
+	for (idx = 0; idx < num_bds; idx++) {
+		printk("%3d %08x %08x %08x %08x %08x %08x %08x %08x %08x\n",
+		       idx,
+		       cur_bd_ptr[XLLDMA_BD_NDESC_OFFSET / sizeof(*cur_bd_ptr)],
+		       cur_bd_ptr[XLLDMA_BD_BUFA_OFFSET / sizeof(*cur_bd_ptr)],
+		       cur_bd_ptr[XLLDMA_BD_BUFL_OFFSET / sizeof(*cur_bd_ptr)],
+		       cur_bd_ptr[XLLDMA_BD_STSCTRL_USR0_OFFSET /
+				  sizeof(*cur_bd_ptr)],
+		       cur_bd_ptr[XLLDMA_BD_USR1_OFFSET / sizeof(*cur_bd_ptr)],
+		       cur_bd_ptr[XLLDMA_BD_USR2_OFFSET / sizeof(*cur_bd_ptr)],
+		       cur_bd_ptr[XLLDMA_BD_USR3_OFFSET / sizeof(*cur_bd_ptr)],
+		       cur_bd_ptr[XLLDMA_BD_USR4_OFFSET / sizeof(*cur_bd_ptr)],
+		       cur_bd_ptr[XLLDMA_BD_ID_OFFSET / sizeof(*cur_bd_ptr)]);
+
+		cur_bd_ptr += bd_ring->Separation / sizeof(int);
+	}
+	printk("--------------------------------------- Done ---------------------------------------\n");
+}
+
+static int
+xenet_ethtool_set_coalesce(struct net_device *dev, struct ethtool_coalesce *ec)
+{
+	int ret;
+	struct net_local *lp;
+
+	lp = (struct net_local *) netdev_priv(dev);
+
+	if (!(XLlTemac_IsDma(&lp->Emac))) {
+		return -EIO;
+	}
+
+	if (ec->rx_coalesce_usecs == 0) {
+		ec->rx_coalesce_usecs = 1;
+		dma_rx_int_mask = XLLDMA_CR_IRQ_ALL_EN_MASK & ~XLLDMA_CR_IRQ_DELAY_EN_MASK;
+	}
+	if ((ret = XLlDma_BdRingSetCoalesce(&lp->Dma.RxBdRing,
+			(u16) (ec->rx_max_coalesced_frames),
+			(u16) (ec->rx_coalesce_usecs))) != XST_SUCCESS) {
+		printk(KERN_ERR "%s: XLlDma: BdRingSetCoalesce error %d\n",
+		       dev->name, ret);
+		return -EIO;
+	}
+	XLlDma_mBdRingIntEnable(&lp->Dma.RxBdRing, dma_rx_int_mask);
+
+	if (ec->tx_coalesce_usecs == 0) {
+		ec->tx_coalesce_usecs = 1;
+		dma_tx_int_mask = XLLDMA_CR_IRQ_ALL_EN_MASK & ~XLLDMA_CR_IRQ_DELAY_EN_MASK;
+	}
+	if ((ret = XLlDma_BdRingSetCoalesce(&lp->Dma.TxBdRing,
+			(u16) (ec->tx_max_coalesced_frames),
+			(u16) (ec->tx_coalesce_usecs))) != XST_SUCCESS) {
+		printk(KERN_ERR "%s: XLlDma: BdRingSetCoalesce error %d\n",
+		       dev->name, ret);
+		return -EIO;
+	}
+	XLlDma_mBdRingIntEnable(&lp->Dma.TxBdRing, dma_tx_int_mask);
+
+	return 0;
+}
+
+static void
+xenet_ethtool_get_ringparam(struct net_device *dev,
+			    struct ethtool_ringparam *erp)
+{
+	memset(erp, 0, sizeof(struct ethtool_ringparam));
+
+	erp->rx_max_pending = XTE_RECV_BD_CNT;
+	erp->tx_max_pending = XTE_SEND_BD_CNT;
+	erp->rx_pending = XTE_RECV_BD_CNT;
+	erp->tx_pending = XTE_SEND_BD_CNT;
+}
+
+static void
+xenet_ethtool_get_pauseparam(struct net_device *dev,
+			     struct ethtool_pauseparam *epp)
+{
+	u32 Options;
+	u16 gmii_status;
+	struct net_local *lp = netdev_priv(dev);
+
+	_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, MII_BMSR, &gmii_status);
+
+	/* I suspect that the expected value is that autonegotiation is
+	 * enabled,  not completed.  
+	 * As seen in xenet_do_ethtool_ioctl() */
+        if (gmii_status & BMSR_ANEGCOMPLETE) {
+                epp->autoneg = AUTONEG_ENABLE;
+        }
+        else {
+                epp->autoneg = AUTONEG_DISABLE;
+        }
+
+	Options = XLlTemac_GetOptions(&lp->Emac);
+	if (Options & XTE_FLOW_CONTROL_OPTION) {
+		epp->rx_pause = 1;
+		epp->tx_pause = 1;
+	}
+	else {
+		epp->rx_pause = 0;
+		epp->tx_pause = 0;
+	}
+}
+
+static u32
+xenet_ethtool_get_rx_csum(struct net_device *dev)
+{
+	struct net_local *lp = netdev_priv(dev);
+	u32 retval;
+   
+ 	retval = (lp->local_features & LOCAL_FEATURE_RX_CSUM) != 0;
+
+ 	return retval;
+}
+
+static int
+xenet_ethtool_set_rx_csum(struct net_device *dev, u32 onoff)
+{
+	struct net_local *lp = netdev_priv(dev);
+
+	if (onoff) {
+		if (XLlTemac_IsRxCsum(&lp->Emac) == TRUE) {
+			lp->local_features |=
+				LOCAL_FEATURE_RX_CSUM;
+		}
+	}
+	else {
+		lp->local_features &= ~LOCAL_FEATURE_RX_CSUM;
+	}
+
+	return 0;
+}
+
+static u32
+xenet_ethtool_get_tx_csum(struct net_device *dev)
+{
+	u32 retval;
+
+	retval = (dev->features & NETIF_F_IP_CSUM) != 0;
+	return retval;
+}
+
+static int
+xenet_ethtool_set_tx_csum(struct net_device *dev, u32 onoff)
+{
+	struct net_local *lp = netdev_priv(dev);
+
+	if (onoff) {
+		if (XLlTemac_IsTxCsum(&lp->Emac) == TRUE) {
+			dev->features |= NETIF_F_IP_CSUM;
+		}
+	}
+	else {
+		dev->features &= ~NETIF_F_IP_CSUM;
+	}
+
+	return 0;
+}
+
+static u32
+xenet_ethtool_get_sg(struct net_device *dev)
+{
+	u32 retval;
+
+	retval = (dev->features & NETIF_F_SG) != 0;
+
+	return retval;
+}
+
+static int
+xenet_ethtool_set_sg(struct net_device *dev, u32 onoff)
+{
+	struct net_local *lp = netdev_priv(dev);
+
+	if (onoff) {
+		if (XLlTemac_IsDma(&lp->Emac)) {
+			dev->features |=
+				NETIF_F_SG | NETIF_F_FRAGLIST;
+		}
+	}
+	else {
+		dev->features &=
+			~(NETIF_F_SG | NETIF_F_FRAGLIST);
+	}
+
+	return 0;
+}
+
+static void
+xenet_ethtool_get_strings(struct net_device *dev, u32 stringset, u8 *strings)
+{
+	*strings = 0;
+
+	switch (stringset) {
+	case ETH_SS_STATS:
+		memcpy(strings,
+			&xenet_ethtool_gstrings_stats,
+			sizeof(xenet_ethtool_gstrings_stats));
+
+		break;
+
+	default:
+		break;
+	}
+}
+
+static void
+xenet_ethtool_get_ethtool_stats(struct net_device *dev,
+	struct ethtool_stats *stats, u64 *data)
+{
+	struct net_local *lp = netdev_priv(dev);
+
+	data[0] = lp->stats.tx_packets;
+	data[1] = lp->stats.tx_dropped;
+	data[2] = lp->stats.tx_errors;
+	data[3] = lp->stats.tx_fifo_errors;
+	data[4] = lp->stats.rx_packets;
+	data[5] = lp->stats.rx_dropped;
+	data[6] = lp->stats.rx_errors;
+	data[7] = lp->stats.rx_fifo_errors;
+	data[8] = lp->stats.rx_crc_errors;
+	data[9] = lp->max_frags_in_a_packet;
+	data[10] = lp->tx_hw_csums;
+	data[11] = lp->rx_hw_csums;
+}
+
+static int
+xenet_ethtool_get_sset_count(struct net_device *netdev, int sset)
+{
+	switch (sset) {
+	case ETH_SS_STATS:
+		return XENET_STATS_LEN;
+	default:
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+
+#define EMAC_REGS_N 32
+struct mac_regsDump {
+	struct ethtool_regs hd;
+	u16 data[EMAC_REGS_N];
+};
+
+int
+xenet_ethtool_get_regs_len(struct net_device *dev)
+{
+	return (sizeof(u16) * EMAC_REGS_N);
+}
+
+static void
+xenet_ethtool_get_regs(struct net_device *dev, struct ethtool_regs *regs,
+		       void *ret)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	struct mac_regsDump *dump = (struct mac_regsDump *) regs;
+	int i;
+
+	dump->hd.version = 0;
+	dump->hd.len = sizeof(dump->data);
+	memset(dump->data, 0, sizeof(dump->data));
+
+	for (i = 0; i < EMAC_REGS_N; i++) {
+		_XLlTemac_PhyRead(&lp->Emac, lp->gmii_addr, i, &(dump->data[i]));
+	}
+
+	*(int *) ret = 0;
+}
+
+static void
+xenet_ethtool_get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *ed)
+{
+	memset(ed, 0, sizeof(struct ethtool_drvinfo));
+	strncpy(ed->driver, DRIVER_NAME, sizeof(ed->driver) - 1);
+	strncpy(ed->version, DRIVER_VERSION, sizeof(ed->version) - 1);
+	/* Also tell how much memory is needed for dumping register values */
+	ed->regdump_len = sizeof(u16) * EMAC_REGS_N;
+	ed->n_stats = XENET_STATS_LEN;
+}
+
+/*
+ * xenet_do_ethtool_ioctl:
+ * DEPRECATED
+ */
+static int xenet_do_ethtool_ioctl(struct net_device *dev, struct ifreq *rq)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+	struct ethtool_cmd ecmd;
+	struct ethtool_coalesce eco;
+	struct ethtool_drvinfo edrv;
+	struct ethtool_ringparam erp;
+	struct ethtool_pauseparam epp;
+	struct mac_regsDump regs;
+	int ret = -EOPNOTSUPP;
+	u32 Options;
+
+	if (copy_from_user(&ecmd, rq->ifr_data, sizeof(ecmd)))
+		return -EFAULT;
+	switch (ecmd.cmd) {
+	case ETHTOOL_GSET:	/* Get setting. No command option needed w/ ethtool */
+		ret = xenet_ethtool_get_settings(dev, &ecmd);
+		if (ret < 0)
+			return -EIO;
+		if (copy_to_user(rq->ifr_data, &ecmd, sizeof(ecmd)))
+			return -EFAULT;
+		ret = 0;
+		break;
+	case ETHTOOL_SSET:	/* Change setting. Use "-s" command option w/ ethtool */
+		ret = xenet_ethtool_set_settings(dev, &ecmd);
+		break;
+	case ETHTOOL_GPAUSEPARAM:	/* Get pause parameter information. Use "-a" w/ ethtool */
+		ret = xenet_ethtool_get_settings(dev, &ecmd);
+		if (ret < 0)
+			return ret;
+		epp.cmd = ecmd.cmd;
+		epp.autoneg = ecmd.autoneg;
+		Options = XLlTemac_GetOptions(&lp->Emac);
+		if (Options & XTE_FCS_INSERT_OPTION) {
+			epp.rx_pause = 1;
+			epp.tx_pause = 1;
+		}
+		else {
+			epp.rx_pause = 0;
+			epp.tx_pause = 0;
+		}
+		if (copy_to_user
+		    (rq->ifr_data, &epp, sizeof(struct ethtool_pauseparam)))
+			return -EFAULT;
+		ret = 0;
+		break;
+	case ETHTOOL_SPAUSEPARAM:	/* Set pause parameter. Use "-A" w/ ethtool */
+		return -EOPNOTSUPP;	/* TODO: To support in next version */
+	case ETHTOOL_GRXCSUM:{	/* Get rx csum offload info. Use "-k" w/ ethtool */
+			struct ethtool_value edata = { ETHTOOL_GRXCSUM };
+
+			edata.data =
+				(lp->local_features & LOCAL_FEATURE_RX_CSUM) !=
+				0;
+			if (copy_to_user(rq->ifr_data, &edata, sizeof(edata)))
+				return -EFAULT;
+			ret = 0;
+			break;
+		}
+	case ETHTOOL_SRXCSUM:{	/* Set rx csum offload info. Use "-K" w/ ethtool */
+			struct ethtool_value edata;
+
+			if (copy_from_user(&edata, rq->ifr_data, sizeof(edata)))
+				return -EFAULT;
+
+			if (edata.data) {
+				if (XLlTemac_IsRxCsum(&lp->Emac) == TRUE) {
+					lp->local_features |=
+						LOCAL_FEATURE_RX_CSUM;
+				}
+			}
+			else {
+				lp->local_features &= ~LOCAL_FEATURE_RX_CSUM;
+			}
+
+			ret = 0;
+			break;
+		}
+	case ETHTOOL_GTXCSUM:{	/* Get tx csum offload info. Use "-k" w/ ethtool */
+			struct ethtool_value edata = { ETHTOOL_GTXCSUM };
+
+			edata.data = (dev->features & NETIF_F_IP_CSUM) != 0;
+			if (copy_to_user(rq->ifr_data, &edata, sizeof(edata)))
+				return -EFAULT;
+			ret = 0;
+			break;
+		}
+	case ETHTOOL_STXCSUM:{	/* Set tx csum offload info. Use "-K" w/ ethtool */
+			struct ethtool_value edata;
+
+			if (copy_from_user(&edata, rq->ifr_data, sizeof(edata)))
+				return -EFAULT;
+
+			if (edata.data) {
+				if (XLlTemac_IsTxCsum(&lp->Emac) == TRUE) {
+					dev->features |= NETIF_F_IP_CSUM;
+				}
+			}
+			else {
+				dev->features &= ~NETIF_F_IP_CSUM;
+			}
+
+			ret = 0;
+			break;
+		}
+	case ETHTOOL_GSG:{	/* Get ScatterGather info. Use "-k" w/ ethtool */
+			struct ethtool_value edata = { ETHTOOL_GSG };
+
+			edata.data = (dev->features & NETIF_F_SG) != 0;
+			if (copy_to_user(rq->ifr_data, &edata, sizeof(edata)))
+				return -EFAULT;
+			ret = 0;
+			break;
+		}
+	case ETHTOOL_SSG:{	/* Set ScatterGather info. Use "-K" w/ ethtool */
+			struct ethtool_value edata;
+
+			if (copy_from_user(&edata, rq->ifr_data, sizeof(edata)))
+				return -EFAULT;
+
+			if (edata.data) {
+				if (XLlTemac_IsDma(&lp->Emac)) {
+					dev->features |=
+						NETIF_F_SG | NETIF_F_FRAGLIST;
+				}
+			}
+			else {
+				dev->features &=
+					~(NETIF_F_SG | NETIF_F_FRAGLIST);
+			}
+
+			ret = 0;
+			break;
+		}
+	case ETHTOOL_GCOALESCE:	/* Get coalescing info. Use "-c" w/ ethtool */
+		if (!(XLlTemac_IsDma(&lp->Emac)))
+			break;
+		eco.cmd = ecmd.cmd;
+		ret = xenet_ethtool_get_coalesce(dev, &eco);
+		if (ret < 0) {
+			return -EIO;
+		}
+		if (copy_to_user
+		    (rq->ifr_data, &eco, sizeof(struct ethtool_coalesce))) {
+			return -EFAULT;
+		}
+		ret = 0;
+		break;
+	case ETHTOOL_SCOALESCE:	/* Set coalescing info. Use "-C" w/ ethtool */
+		if (!(XLlTemac_IsDma(&lp->Emac)))
+			break;
+		if (copy_from_user
+		    (&eco, rq->ifr_data, sizeof(struct ethtool_coalesce)))
+			return -EFAULT;
+		ret = xenet_ethtool_set_coalesce(dev, &eco);
+		break;
+	case ETHTOOL_GDRVINFO:	/* Get driver information. Use "-i" w/ ethtool */
+		edrv.cmd = edrv.cmd;
+		xenet_ethtool_get_drvinfo(dev, &edrv);
+		edrv.n_stats = XENET_STATS_LEN;
+		if (copy_to_user
+		    (rq->ifr_data, &edrv, sizeof(struct ethtool_drvinfo))) {
+			return -EFAULT;
+		}
+		ret = 0;
+		break;
+	case ETHTOOL_GREGS:	/* Get register values. Use "-d" with ethtool */
+		regs.hd.cmd = edrv.cmd;
+		xenet_ethtool_get_regs(dev, &(regs.hd), &ret);
+		if (ret < 0) {
+			return ret;
+		}
+		if (copy_to_user
+		    (rq->ifr_data, &regs, sizeof(struct mac_regsDump))) {
+			return -EFAULT;
+		}
+		ret = 0;
+		break;
+	case ETHTOOL_GRINGPARAM:	/* Get RX/TX ring parameters. Use "-g" w/ ethtool */
+		erp.cmd = edrv.cmd;
+		xenet_ethtool_get_ringparam(dev, &(erp));
+		if (copy_to_user
+		    (rq->ifr_data, &erp, sizeof(struct ethtool_ringparam))) {
+			return -EFAULT;
+		}
+		ret = 0;
+		break;
+	case ETHTOOL_NWAY_RST:	/* Restart auto negotiation if enabled. Use "-r" w/ ethtool */
+		return -EOPNOTSUPP;	/* TODO: To support in next version */
+	case ETHTOOL_GSTRINGS:{
+			struct ethtool_gstrings gstrings = { ETHTOOL_GSTRINGS };
+			void *addr = rq->ifr_data;
+			char *strings = NULL;
+
+			if (copy_from_user(&gstrings, addr, sizeof(gstrings))) {
+				return -EFAULT;
+			}
+			switch (gstrings.string_set) {
+			case ETH_SS_STATS:
+				gstrings.len = XENET_STATS_LEN;
+				strings = *xenet_ethtool_gstrings_stats;
+				break;
+			default:
+				return -EOPNOTSUPP;
+			}
+			if (copy_to_user(addr, &gstrings, sizeof(gstrings))) {
+				return -EFAULT;
+			}
+			addr += offsetof(struct ethtool_gstrings, data);
+			if (copy_to_user
+			    (addr, strings, gstrings.len * ETH_GSTRING_LEN)) {
+				return -EFAULT;
+			}
+			ret = 0;
+			break;
+		}
+	case ETHTOOL_GSTATS:{
+			struct {
+				struct ethtool_stats cmd;
+				uint64_t data[XENET_STATS_LEN];
+			} stats = { {
+			ETHTOOL_GSTATS, XENET_STATS_LEN}};
+
+			stats.data[0] = lp->stats.tx_packets;
+			stats.data[1] = lp->stats.tx_dropped;
+			stats.data[2] = lp->stats.tx_errors;
+			stats.data[3] = lp->stats.tx_fifo_errors;
+			stats.data[4] = lp->stats.rx_packets;
+			stats.data[5] = lp->stats.rx_dropped;
+			stats.data[6] = lp->stats.rx_errors;
+			stats.data[7] = lp->stats.rx_fifo_errors;
+			stats.data[8] = lp->stats.rx_crc_errors;
+			stats.data[9] = lp->max_frags_in_a_packet;
+			stats.data[10] = lp->tx_hw_csums;
+			stats.data[11] = lp->rx_hw_csums;
+
+			if (copy_to_user(rq->ifr_data, &stats, sizeof(stats))) {
+				return -EFAULT;
+			}
+			ret = 0;
+			break;
+		}
+	default:
+		return -EOPNOTSUPP;	/* All other operations not supported */
+	}
+	return ret;
+}
+
+static int xenet_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
+{
+	struct net_local *lp = (struct net_local *) netdev_priv(dev);
+
+	/* gmii_ioctl_data has 4 u16 fields: phy_id, reg_num, val_in & val_out */
+	struct mii_ioctl_data *data = (struct mii_ioctl_data *) &rq->ifr_data;
+	struct {
+		__u16 threshold;
+		__u32 direction;
+	} thr_arg;
+	struct {
+		__u16 waitbound;
+		__u32 direction;
+	} wbnd_arg;
+
+	int ret;
+	u32 threshold, timer;
+	XLlDma_BdRing *RingPtr;
+	u32 *dma_int_mask_ptr;
+
+	switch (cmd) {
+	case SIOCETHTOOL:
+		/* DEPRECATED */
+		return xenet_do_ethtool_ioctl(dev, rq);
+	case SIOCGMIIPHY:	/* Get address of GMII PHY in use. */
+	case SIOCDEVPRIVATE:	/* for binary compat, remove in 2.5 */
+		data->phy_id = lp->gmii_addr;
+		/* Fall Through */
+
+	case SIOCGMIIREG:	/* Read GMII PHY register. */
+	case SIOCDEVPRIVATE + 1:	/* for binary compat, remove in 2.5 */
+		if (data->phy_id > 31 || data->reg_num > 31)
+			return -ENXIO;
+
+		/* Stop the PHY timer to prevent reentrancy. */
+		del_timer_sync(&lp->phy_timer);
+
+		_XLlTemac_PhyRead(&lp->Emac, data->phy_id, data->reg_num,
+				  &data->val_out);
+
+		/* Start the PHY timer up again. */
+		lp->phy_timer.expires = jiffies + 2 * HZ;
+		add_timer(&lp->phy_timer);
+		return 0;
+
+	case SIOCSMIIREG:	/* Write GMII PHY register. */
+	case SIOCDEVPRIVATE + 2:	/* for binary compat, remove in 2.5 */
+		if (!capable(CAP_NET_ADMIN))
+			return -EPERM;
+
+		if (data->phy_id > 31 || data->reg_num > 31)
+			return -ENXIO;
+
+		/* Stop the PHY timer to prevent reentrancy. */
+		del_timer_sync(&lp->phy_timer);
+
+		_XLlTemac_PhyWrite(&lp->Emac, data->phy_id, data->reg_num,
+				   data->val_in);
+
+		/* Start the PHY timer up again. */
+		lp->phy_timer.expires = jiffies + 2 * HZ;
+		add_timer(&lp->phy_timer);
+		return 0;
+
+	case SIOCDEVPRIVATE + 3:	/* set THRESHOLD */
+		if (XLlTemac_IsFifo(&lp->Emac))
+			return -EFAULT;
+
+		if (copy_from_user(&thr_arg, rq->ifr_data, sizeof(thr_arg)))
+			return -EFAULT;
+
+		if (thr_arg.direction == XTE_SEND) {
+			RingPtr = &lp->Dma.TxBdRing;
+		} else {
+			RingPtr = &lp->Dma.RxBdRing;
+		}
+		XLlDma_BdRingGetCoalesce(RingPtr, &threshold, &timer);
+		if (thr_arg.direction == XTE_SEND) {
+			RingPtr = &lp->Dma.TxBdRing;
+		} else {
+			RingPtr = &lp->Dma.RxBdRing;
+		}
+		if ((ret = XLlDma_BdRingSetCoalesce(RingPtr, thr_arg.threshold,
+						    timer)) != XST_SUCCESS) {
+			return -EIO;
+		}
+		return 0;
+
+	case SIOCDEVPRIVATE + 4:	/* set WAITBOUND */
+		if (!(XLlTemac_IsDma(&lp->Emac)))
+			return -EFAULT;
+
+		if (copy_from_user(&wbnd_arg, rq->ifr_data, sizeof(wbnd_arg)))
+			return -EFAULT;
+
+		if (wbnd_arg.direction == XTE_SEND) {
+			RingPtr = &lp->Dma.TxBdRing;
+		} else {
+			RingPtr = &lp->Dma.RxBdRing;
+		}
+		XLlDma_BdRingGetCoalesce(RingPtr, &threshold, &timer);
+		if (wbnd_arg.direction == XTE_SEND) {
+			RingPtr = &lp->Dma.TxBdRing;
+			dma_int_mask_ptr = &dma_tx_int_mask;
+		} else {
+			RingPtr = &lp->Dma.RxBdRing;
+			dma_int_mask_ptr = &dma_rx_int_mask;
+		}
+		if (wbnd_arg.waitbound == 0) {
+			wbnd_arg.waitbound = 1;
+			*dma_int_mask_ptr = XLLDMA_CR_IRQ_ALL_EN_MASK & ~XLLDMA_CR_IRQ_DELAY_EN_MASK;
+		}
+		if ((ret = XLlDma_BdRingSetCoalesce(RingPtr, threshold,
+					wbnd_arg.waitbound)) != XST_SUCCESS) {
+			return -EIO;
+		}
+		XLlDma_mBdRingIntEnable(RingPtr, *dma_int_mask_ptr);
+
+		return 0;
+
+	case SIOCDEVPRIVATE + 5:	/* get THRESHOLD */
+		if (!(XLlTemac_IsDma(&lp->Emac)))
+			return -EFAULT;
+
+		if (copy_from_user(&thr_arg, rq->ifr_data, sizeof(thr_arg)))
+			return -EFAULT;
+
+		if (thr_arg.direction == XTE_SEND) {
+			RingPtr = &lp->Dma.TxBdRing;
+		} else {
+			RingPtr = &lp->Dma.RxBdRing;
+		}
+		XLlDma_BdRingGetCoalesce(RingPtr,
+				(u32 *) &(thr_arg.threshold), &timer);
+		if (copy_to_user(rq->ifr_data, &thr_arg, sizeof(thr_arg))) {
+			return -EFAULT;
+		}
+		return 0;
+
+	case SIOCDEVPRIVATE + 6:	/* get WAITBOUND */
+		if (!(XLlTemac_IsDma(&lp->Emac)))
+			return -EFAULT;
+
+		if (copy_from_user(&wbnd_arg, rq->ifr_data, sizeof(wbnd_arg))) {
+			return -EFAULT;
+		}
+		if (thr_arg.direction == XTE_SEND) {
+			RingPtr = &lp->Dma.TxBdRing;
+		} else {
+			RingPtr = &lp->Dma.RxBdRing;
+		}
+		XLlDma_BdRingGetCoalesce(RingPtr, &threshold,
+					 (u32 *) &(wbnd_arg.waitbound));
+		if (copy_to_user(rq->ifr_data, &wbnd_arg, sizeof(wbnd_arg))) {
+			return -EFAULT;
+		}
+		return 0;
+
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+
+/******************************************************************************
+ *
+ * NEW FUNCTIONS FROM LINUX 2.6
+ *
+ ******************************************************************************/
+
+static void xtenet_remove_ndev(struct net_device *ndev)
+{
+	if (ndev) {
+		struct net_local *lp = netdev_priv(ndev);
+
+		if (XLlTemac_IsDma(&lp->Emac) && (lp->desc_space))
+			free_descriptor_skb(ndev);
+
+		iounmap((void *) (lp->Emac.Config.BaseAddress));
+		free_netdev(ndev);
+	}
+}
+
+static int xtenet_remove(struct device *dev)
+{
+	struct net_device *ndev = dev_get_drvdata(dev);
+
+	unregister_netdev(ndev);
+	xtenet_remove_ndev(ndev);
+
+	return 0;		/* success */
+}
+
+/* Detect the PHY address by scanning addresses 0 to 31 and
+ * looking at the MII status register (register 1) and assuming
+ * the PHY supports 10Mbps full/half duplex. Feel free to change
+ * this code to match your PHY, or hardcode the address if needed.
+ */
+/* Use MII register 1 (MII status register) to detect PHY */
+#define PHY_DETECT_REG  1
+
+/* Mask used to verify certain PHY features (or register contents)
+ * in the register above:
+ *  0x1000: 10Mbps full duplex support
+ *  0x0800: 10Mbps half duplex support
+ *  0x0008: Auto-negotiation support
+ */
+#define PHY_DETECT_MASK 0x1808
+
+static int detect_phy(struct net_local *lp, char *dev_name)
+{
+	u16 phy_reg;
+	u32 phy_addr;
+
+	for (phy_addr = 31; phy_addr > 0; phy_addr--) {
+		_XLlTemac_PhyRead(&lp->Emac, phy_addr, PHY_DETECT_REG, &phy_reg);
+
+		if ((phy_reg != 0xFFFF) &&
+		    ((phy_reg & PHY_DETECT_MASK) == PHY_DETECT_MASK)) {
+			/* Found a valid PHY address */
+			printk(KERN_INFO "XTemac: PHY detected at address %d.\n", phy_addr);
+			return phy_addr;
+		}
+	}
+
+	printk(KERN_WARNING "XTemac: No PHY detected.  Assuming a PHY at address 0\n");
+	return 0;		/* default to zero */
+}
+
+static struct net_device_ops xilinx_netdev_ops;
+
+/* From include/linux/ethtool.h */
+static struct ethtool_ops ethtool_ops = {
+	.get_settings = xenet_ethtool_get_settings,
+	.set_settings = xenet_ethtool_set_settings,
+	.get_drvinfo  = xenet_ethtool_get_drvinfo,
+	.get_regs_len = xenet_ethtool_get_regs_len,
+	.get_regs     = xenet_ethtool_get_regs,
+	.get_coalesce = xenet_ethtool_get_coalesce,
+	.set_coalesce = xenet_ethtool_set_coalesce,
+	.get_ringparam  = xenet_ethtool_get_ringparam,
+	.get_pauseparam = xenet_ethtool_get_pauseparam,
+	.get_rx_csum  = xenet_ethtool_get_rx_csum,
+	.set_rx_csum  = xenet_ethtool_set_rx_csum,
+	.get_tx_csum  = xenet_ethtool_get_tx_csum,
+	.set_tx_csum  = xenet_ethtool_set_tx_csum,
+	.get_sg       = xenet_ethtool_get_sg,
+	.set_sg       = xenet_ethtool_set_sg,
+	.get_strings  = xenet_ethtool_get_strings,
+	.get_ethtool_stats = xenet_ethtool_get_ethtool_stats,
+	.get_sset_count    = xenet_ethtool_get_sset_count,
+};
+
+/** Shared device initialization code */
+static int xtenet_setup(
+		struct device *dev,
+		struct resource *r_mem,
+		struct resource *r_irq,
+		struct xlltemac_platform_data *pdata) {
+	int xs;
+	u32 virt_baddr;		/* virtual base address of TEMAC */
+
+	XLlTemac_Config Temac_Config;
+
+	struct net_device *ndev = NULL;
+	struct net_local *lp = NULL;
+
+	int rc = 0;
+
+	/* Create an ethernet device instance */
+	ndev = alloc_etherdev(sizeof(struct net_local));
+	if (!ndev) {
+		dev_err(dev, "Could not allocate net device.\n");
+		rc = -ENOMEM;
+		goto error;
+	}
+	dev_set_drvdata(dev, ndev);
+
+	SET_NETDEV_DEV(ndev, &dev->parent);
+	ndev->irq = r_irq->start;
+
+	/* Initialize the private data used by XEmac_LookupConfig().
+	 * The private data are zeroed out by alloc_etherdev() already.
+	 */
+	lp = netdev_priv(ndev);
+	lp->ndev = ndev;
+	lp->dma_irq_r = pdata->ll_dev_dma_rx_irq;
+	lp->dma_irq_s = pdata->ll_dev_dma_tx_irq;
+	lp->fifo_irq = pdata->ll_dev_fifo_irq;
+
+	/* Setup the Config structure for the XLlTemac_CfgInitialize() call. */
+	Temac_Config.BaseAddress = r_mem->start;
+#if 0
+	Config.RxPktFifoDepth = pdata->rx_pkt_fifo_depth;
+	Config.TxPktFifoDepth = pdata->tx_pkt_fifo_depth;
+	Config.MacFifoDepth = pdata->mac_fifo_depth;
+	Config.IpIfDmaConfig = pdata->dma_mode;
+#endif
+	Temac_Config.TxCsum = pdata->tx_csum;
+	Temac_Config.RxCsum = pdata->rx_csum;
+	Temac_Config.LLDevType = pdata->ll_dev_type;
+	Temac_Config.LLDevBaseAddress = pdata->ll_dev_baseaddress;
+	Temac_Config.PhyType = pdata->phy_type;
+
+	/* Get the virtual base address for the device */
+	virt_baddr = (u32) ioremap(r_mem->start, r_mem->end - r_mem->start + 1);
+	if (0 == virt_baddr) {
+		dev_err(dev, "XLlTemac: Could not allocate iomem.\n");
+		rc = -EIO;
+		goto error;
+	}
+
+	if (XLlTemac_CfgInitialize(&lp->Emac, &Temac_Config, virt_baddr) !=
+	    XST_SUCCESS) {
+		dev_err(dev, "XLlTemac: Could not initialize device.\n");
+
+		rc = -ENODEV;
+		goto error;
+	}
+
+	/* Set the MAC address from platform data */
+        memcpy(ndev->dev_addr, pdata->mac_addr, 6);
+
+	if (_XLlTemac_SetMacAddress(&lp->Emac, ndev->dev_addr) != XST_SUCCESS) {
+		/* should not fail right after an initialize */
+		dev_err(dev, "XLlTemac: could not set MAC address.\n");
+		rc = -EIO;
+		goto error;
+	}
+
+	dev_info(dev,
+			"MAC address is now %2x:%2x:%2x:%2x:%2x:%2x\n",
+			pdata->mac_addr[0], pdata->mac_addr[1],
+			pdata->mac_addr[2], pdata->mac_addr[3],
+			pdata->mac_addr[4], pdata->mac_addr[5]);
+
+	if (ndev->mtu > XTE_JUMBO_MTU)
+		ndev->mtu = XTE_JUMBO_MTU;
+
+	lp->frame_size = ndev->mtu + XTE_HDR_SIZE + XTE_TRL_SIZE;
+
+	if (XLlTemac_IsDma(&lp->Emac)) {
+		int result;
+
+		dev_err(dev, "XLlTemac: using DMA mode.\n");
+
+		if (pdata->dcr_host) {
+			printk("XLlTemac: DCR address: 0x%0x\n", pdata->ll_dev_baseaddress);
+			XLlDma_Initialize(&lp->Dma, pdata->ll_dev_baseaddress);
+		} else {
+		        virt_baddr = (u32) ioremap(pdata->ll_dev_baseaddress, 4096);
+			lp->virt_dma_addr = virt_baddr;
+			if (0 == virt_baddr) {
+			        dev_err(dev,
+					"XLlTemac: Could not allocate iomem for local link connected device.\n");
+				rc = -EIO;
+				goto error;
+			}
+			printk("XLlTemac: Dma base address: phy: 0x%x, virt: 0x%x\n", pdata->ll_dev_baseaddress, virt_baddr);
+			XLlDma_Initialize(&lp->Dma, virt_baddr);
+		}
+
+		xilinx_netdev_ops.ndo_start_xmit = xenet_DmaSend;
+
+		result = descriptor_init(ndev);
+		if (result) {
+			rc = -EIO;
+			goto error;
+		}
+
+		/* set the packet threshold and wait bound for both TX/RX directions */
+		if (DFT_TX_WAITBOUND == 0) {
+			dma_tx_int_mask = XLLDMA_CR_IRQ_ALL_EN_MASK & ~XLLDMA_CR_IRQ_DELAY_EN_MASK;
+			xs = XLlDma_BdRingSetCoalesce(&lp->Dma.TxBdRing, DFT_TX_THRESHOLD, 1);
+		} else {
+			xs = XLlDma_BdRingSetCoalesce(&lp->Dma.TxBdRing, DFT_TX_THRESHOLD, DFT_TX_WAITBOUND);
+		}
+		if (xs != XST_SUCCESS) {
+			dev_err(dev,
+			       "XLlTemac: could not set SEND pkt threshold/waitbound, ERROR %d",
+			       xs);
+		}
+		XLlDma_mBdRingIntEnable(&lp->Dma.TxBdRing, dma_tx_int_mask);
+
+		if (DFT_RX_WAITBOUND == 0) {
+			dma_rx_int_mask = XLLDMA_CR_IRQ_ALL_EN_MASK & ~XLLDMA_CR_IRQ_DELAY_EN_MASK;
+			xs = XLlDma_BdRingSetCoalesce(&lp->Dma.RxBdRing, DFT_RX_THRESHOLD, 1);
+		} else {
+			xs = XLlDma_BdRingSetCoalesce(&lp->Dma.RxBdRing, DFT_RX_THRESHOLD, DFT_RX_WAITBOUND);
+		}
+		if (xs != XST_SUCCESS) {
+			dev_err(dev,
+			       "XLlTemac: Could not set RECV pkt threshold/waitbound ERROR %d",
+			       xs);
+		}
+		XLlDma_mBdRingIntEnable(&lp->Dma.RxBdRing, dma_rx_int_mask);
+	}
+	else {
+		dev_err(dev,
+		       "XLlTemac: using FIFO direct interrupt driven mode.\n");
+
+		virt_baddr = (u32) ioremap(pdata->ll_dev_baseaddress, 4096);
+		if (0 == virt_baddr) {
+			dev_err(dev,
+			       "XLlTemac: Could not allocate iomem for local link connected device.\n");
+			rc = -EIO;
+			goto error;
+		}
+		printk("XLlTemac: Fifo base address: 0x%0x\n", virt_baddr);
+		XLlFifo_Initialize(&lp->Fifo, virt_baddr);
+
+		xilinx_netdev_ops.ndo_start_xmit = xenet_FifoSend;
+	}
+
+	/** Scan to find the PHY */
+	lp->gmii_addr = detect_phy(lp, ndev->name);
+
+
+	/* initialize the netdev structure */
+
+	ndev->netdev_ops = &xilinx_netdev_ops;
+	ndev->flags &= ~IFF_MULTICAST;
+
+	if (XLlTemac_IsDma(&lp->Emac)) {
+		ndev->features = NETIF_F_SG | NETIF_F_FRAGLIST;
+
+		if (XLlTemac_IsTxCsum(&lp->Emac) == TRUE) {
+			/*
+			 * This hardware only supports proper checksum calculations
+			 * on TCP/UDP packets.
+			 */
+			ndev->features |= NETIF_F_IP_CSUM;
+		}
+		if (XLlTemac_IsRxCsum(&lp->Emac) == TRUE) {
+			lp->local_features |= LOCAL_FEATURE_RX_CSUM;
+		}
+	}
+
+	ndev->watchdog_timeo = TX_TIMEOUT;
+
+	/* init the stats */
+	lp->max_frags_in_a_packet = 0;
+	lp->tx_hw_csums = 0;
+	lp->rx_hw_csums = 0;
+
+#if ! XTE_AUTOSTRIPPING
+	lp->stripping =
+		(XLlTemac_GetOptions(&(lp->Emac)) & XTE_FCS_STRIP_OPTION) != 0;
+#endif
+
+	/* Set ethtool IOCTL handler vectors.
+	 * xenet_do_ethtool_ioctl() is deprecated.
+	 */
+	SET_ETHTOOL_OPS(ndev, &ethtool_ops);
+
+	rc = register_netdev(ndev);
+	if (rc) {
+		dev_err(dev,
+		       "%s: Cannot register net device, aborting.\n",
+		       ndev->name);
+		goto error;	/* rc is already set here... */
+	}
+
+	dev_info(dev,
+		"%s: Xilinx TEMAC at 0x%08X mapped to 0x%08X, irq=%d\n",
+		ndev->name,
+		(unsigned int)r_mem->start,
+		lp->Emac.Config.BaseAddress,
+		ndev->irq);
+
+	return 0;
+
+error:
+	if (ndev) {
+		xtenet_remove_ndev(ndev);
+	}
+	return rc;
+}
+
+static int xtenet_probe(struct device *dev)
+{
+	struct resource *r_irq = NULL;	/* Interrupt resources */
+	struct resource *r_mem = NULL;	/* IO mem resources */
+	struct xlltemac_platform_data *pdata;
+	struct platform_device *pdev = to_platform_device(dev);
+
+	/* param check */
+	if (!pdev) {
+		dev_err(dev, "Probe called with NULL param.\n");
+		return -ENODEV;
+	}
+
+	pdata = (struct xlltemac_platform_data *) pdev->dev.platform_data;
+	if (!pdata) {
+		dev_err(dev, "Couldn't find platform data.\n");
+
+		return -ENODEV;
+	}
+
+	/* Get iospace and an irq for the device */
+	r_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
+	r_mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!r_irq || !r_mem) {
+		dev_err(dev, "IO resource(s) not found.\n");
+		return -ENODEV;
+	}
+
+        return xtenet_setup(dev, r_mem, r_irq, pdata);
+}
+
+static struct device_driver xtenet_driver = {
+	.name = DRIVER_NAME,
+	.bus = &platform_bus_type,
+
+	.probe = xtenet_probe,
+	.remove = xtenet_remove
+};
+
+#ifdef CONFIG_OF
+static u32 get_u32(struct of_device *ofdev, const char *s) {
+	u32 *p = (u32 *)of_get_property(ofdev->node, s, NULL);
+	if(p) {
+		return *p;
+	} else {
+		dev_warn(&ofdev->dev, "Parameter %s not found, defaulting to false.\n", s);
+		return FALSE;
+	}
+}
+
+static struct net_device_ops xilinx_netdev_ops = {
+	.ndo_open 	= xenet_open,
+	.ndo_stop	= xenet_close,
+	.ndo_start_xmit	= 0,
+	.ndo_do_ioctl	= xenet_ioctl,
+	.ndo_change_mtu	= xenet_change_mtu,
+	.ndo_tx_timeout	= xenet_tx_timeout,
+	.ndo_get_stats	= xenet_get_stats,
+	.ndo_set_mac_address	= eth_mac_addr,
+	.ndo_validate_addr	= eth_validate_addr,
+};
+
+static struct of_device_id xtenet_fifo_of_match[] = {
+	{ .compatible = "xlnx,xps-ll-fifo-1.00.a", },
+	{ .compatible = "xlnx,xps-ll-fifo-1.00.b", },
+	{ .compatible = "xlnx,xps-ll-fifo-1.01.a", },
+	{ /* end of list */ },
+};
+
+static struct of_device_id xtenet_sdma_of_match[] = {
+	{ .compatible = "xlnx,ll-dma-1.00.a", },
+	{ /* end of list */ },
+};
+
+static int __devinit xtenet_of_probe(struct of_device *ofdev, const struct of_device_id *match)
+{
+	struct resource r_irq_struct;
+	struct resource r_mem_struct;
+	struct resource r_connected_mem_struct;
+	struct resource r_connected_irq_struct;
+	struct xlltemac_platform_data pdata_struct;
+
+	struct resource *r_irq = &r_irq_struct;	/* Interrupt resources */
+	struct resource *r_mem = &r_mem_struct;	/* IO mem resources */
+	struct xlltemac_platform_data *pdata = &pdata_struct;
+        const void *mac_address;
+	int rc = 0;
+	const phandle *llink_connected_handle;
+	struct device_node *llink_connected_node;
+	u32 *dcrreg_property;
+
+	printk(KERN_INFO "Device Tree Probing \'%s\'\n",
+                        ofdev->node->name);
+
+	/* Get iospace for the device */
+	rc = of_address_to_resource(ofdev->node, 0, r_mem);
+	if(rc) {
+		dev_warn(&ofdev->dev, "invalid address\n");
+		return rc;
+	}
+
+	/* Get IRQ for the device */
+	rc = of_irq_to_resource(ofdev->node, 0, r_irq);
+	if(rc == NO_IRQ) {
+		dev_warn(&ofdev->dev, "no IRQ found.\n");
+		return rc;
+	}
+
+	pdata_struct.tx_csum		= get_u32(ofdev, "xlnx,txcsum");
+	pdata_struct.rx_csum		= get_u32(ofdev, "xlnx,rxcsum");
+	pdata_struct.phy_type           = get_u32(ofdev, "xlnx,phy-type");
+        llink_connected_handle =
+		of_get_property(ofdev->node, "llink-connected", NULL);
+        if(!llink_connected_handle) {
+            dev_warn(&ofdev->dev, "no Locallink connection found.\n");
+            return rc;
+        }
+
+	llink_connected_node =
+		of_find_node_by_phandle(*llink_connected_handle);
+	rc = of_address_to_resource(
+			llink_connected_node,
+			0,
+			&r_connected_mem_struct);
+
+        /** Get the right information from whatever the locallink is
+	    connected to. */
+	if(of_match_node(xtenet_fifo_of_match, llink_connected_node)) {
+		/** Connected to a fifo. */
+
+		if(rc) {
+			dev_warn(&ofdev->dev, "invalid address\n");
+			return rc;
+		}
+
+	        pdata_struct.ll_dev_baseaddress	= r_connected_mem_struct.start;
+		pdata_struct.ll_dev_type = XPAR_LL_FIFO;
+		pdata_struct.ll_dev_dma_rx_irq	= NO_IRQ;
+		pdata_struct.ll_dev_dma_tx_irq	= NO_IRQ;
+
+		rc = of_irq_to_resource(
+				llink_connected_node,
+				0,
+				&r_connected_irq_struct);
+		if(rc == NO_IRQ) {
+			dev_warn(&ofdev->dev, "no IRQ found.\n");
+			return rc;
+		}
+		pdata_struct.ll_dev_fifo_irq	= r_connected_irq_struct.start;
+		pdata_struct.dcr_host = 0x0;
+        } else if(of_match_node(xtenet_sdma_of_match, llink_connected_node)) {
+		/** Connected to a dma port, default to 405 type dma */
+
+		pdata->dcr_host = 0;
+		if(rc) {
+			/* no address was found, might be 440, check for dcr reg */
+
+			dcrreg_property = (u32 *)of_get_property(llink_connected_node, "dcr-reg", 									NULL);
+			if(dcrreg_property) {
+			        r_connected_mem_struct.start = *dcrreg_property;
+				pdata->dcr_host = 0xFF;
+			} else {
+				dev_warn(&ofdev->dev, "invalid address\n");
+				return rc;
+			}			
+		}
+
+        	pdata_struct.ll_dev_baseaddress	= r_connected_mem_struct.start;
+		pdata_struct.ll_dev_type = XPAR_LL_DMA;
+
+		rc = of_irq_to_resource(
+				llink_connected_node,
+				0,
+				&r_connected_irq_struct);
+		if(rc == NO_IRQ) {
+			dev_warn(&ofdev->dev, "First IRQ not found.\n");
+			return rc;
+		}
+		pdata_struct.ll_dev_dma_rx_irq	= r_connected_irq_struct.start;
+
+		rc = of_irq_to_resource(
+				llink_connected_node,
+				1,
+				&r_connected_irq_struct);
+		if(rc == NO_IRQ) {
+			dev_warn(&ofdev->dev, "Second IRQ not found.\n");
+			return rc;
+		}
+		pdata_struct.ll_dev_dma_tx_irq	= r_connected_irq_struct.start;
+
+		pdata_struct.ll_dev_fifo_irq	= NO_IRQ;
+        } else {
+		dev_warn(&ofdev->dev, "Locallink connection not matched.\n");
+		return rc;
+        }
+
+	of_node_put(llink_connected_node);
+        mac_address = of_get_mac_address(ofdev->node);
+        if(mac_address) {
+            memcpy(pdata_struct.mac_addr, mac_address, 6);
+        } else {
+            dev_warn(&ofdev->dev, "No MAC address found.\n");
+        }
+
+	return xtenet_setup(&ofdev->dev, r_mem, r_irq, pdata);
+}
+
+static int __devexit xtenet_of_remove(struct of_device *dev)
+{
+	return xtenet_remove(&dev->dev);
+}
+
+static struct of_device_id xtenet_of_match[] = {
+	{ .compatible = "xlnx,xps-ll-temac-1.00.a", },
+	{ .compatible = "xlnx,xps-ll-temac-1.00.b", },
+	{ .compatible = "xlnx,xps-ll-temac-1.01.a", },
+	{ .compatible = "xlnx,xps-ll-temac-1.01.b", },
+	{ /* end of list */ },
+};
+
+MODULE_DEVICE_TABLE(of, xtenet_of_match);
+
+static struct of_platform_driver xtenet_of_driver = {
+	.name		= DRIVER_NAME,
+	.match_table	= xtenet_of_match,
+	.probe		= xtenet_of_probe,
+	.remove		= __devexit_p(xtenet_of_remove),
+};
+#endif
+
+static int __init xtenet_init(void)
+{
+	int status;
+
+	/*
+	 * Make sure the locks are initialized
+	 */
+	spin_lock_init(&XTE_spinlock);
+	spin_lock_init(&XTE_tx_spinlock);
+	spin_lock_init(&XTE_rx_spinlock);
+
+	INIT_LIST_HEAD(&sentQueue);
+	INIT_LIST_HEAD(&receivedQueue);
+
+	spin_lock_init(&sentQueueSpin);
+	spin_lock_init(&receivedQueueSpin);
+
+	/*
+	 * No kernel boot options used,
+	 * so we just need to register the driver
+	 */
+	status = driver_register(&xtenet_driver);
+#ifdef CONFIG_OF
+	status |= of_register_platform_driver(&xtenet_of_driver);
+#endif
+        return status;
+
+}
+
+static void __exit xtenet_cleanup(void)
+{
+	driver_unregister(&xtenet_driver);
+#ifdef CONFIG_OF
+	of_unregister_platform_driver(&xtenet_of_driver);
+#endif
+}
+
+module_init(xtenet_init);
+module_exit(xtenet_cleanup);
+
+MODULE_AUTHOR("Xilinx, Inc.");
+MODULE_DESCRIPTION(DRIVER_DESCRIPTION);
+MODULE_LICENSE("GPL");
diff -purN --exclude=.git linux-2.6.31.12/drivers/pci/Makefile linux-2.6.31.12-petalinux/drivers/pci/Makefile
--- linux-2.6.31.12/drivers/pci/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/pci/Makefile	2010-08-08 17:40:16.573535116 +0200
@@ -44,6 +44,7 @@ obj-$(CONFIG_PPC) += setup-bus.o
 obj-$(CONFIG_MIPS) += setup-bus.o setup-irq.o
 obj-$(CONFIG_X86_VISWS) += setup-irq.o
 obj-$(CONFIG_MN10300) += setup-bus.o
+obj-$(CONFIG_MICROBLAZE) += setup-bus.o
 
 #
 # ACPI Related PCI FW Functions
diff -purN --exclude=.git linux-2.6.31.12/drivers/pci/pci-sysfs.c linux-2.6.31.12-petalinux/drivers/pci/pci-sysfs.c
--- linux-2.6.31.12/drivers/pci/pci-sysfs.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/pci/pci-sysfs.c	2010-08-08 17:40:16.573535116 +0200
@@ -911,10 +911,12 @@ static struct bin_attribute pcie_config_
 	.write = pci_write_config,
 };
 
+/*
 int __attribute__ ((weak)) pcibios_add_platform_entries(struct pci_dev *dev)
 {
 	return 0;
 }
+*/
 
 static int pci_create_capabilities_sysfs(struct pci_dev *dev)
 {
diff -purN --exclude=.git linux-2.6.31.12/drivers/spi/xilinx_spi.c linux-2.6.31.12-petalinux/drivers/spi/xilinx_spi.c
--- linux-2.6.31.12/drivers/spi/xilinx_spi.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/spi/xilinx_spi.c	2010-08-08 17:40:16.592837709 +0200
@@ -148,7 +148,8 @@ static int xilinx_spi_setup_transfer(str
 {
 	u8 bits_per_word;
 
-	bits_per_word = (t) ? t->bits_per_word : spi->bits_per_word;
+	bits_per_word = (t && t->bits_per_word) 
+			 ? t->bits_per_word : spi->bits_per_word;
 	if (bits_per_word != 8) {
 		dev_err(&spi->dev, "%s, unsupported bits_per_word=%d\n",
 			__func__, bits_per_word);
diff -purN --exclude=.git linux-2.6.31.12/drivers/uio/Kconfig linux-2.6.31.12-petalinux/drivers/uio/Kconfig
--- linux-2.6.31.12/drivers/uio/Kconfig	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/uio/Kconfig	2010-08-08 17:40:16.592837709 +0200
@@ -46,6 +46,12 @@ config UIO_PDRV_GENIRQ
 
 	  If you don't know what to do here, say N.
 
+config UIO_OF_GENIRQ
+	tristate "Userspace I/O OF driver with generic IRQ handling"
+	depends on UIO_PDRV_GENIRQ && OF
+	help
+	  OF wrapper for the above platform driver.
+
 config UIO_SMX
 	tristate "SMX cryptengine UIO interface"
 	default n
diff -purN --exclude=.git linux-2.6.31.12/drivers/uio/Makefile linux-2.6.31.12-petalinux/drivers/uio/Makefile
--- linux-2.6.31.12/drivers/uio/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/uio/Makefile	2010-08-08 17:40:16.592837709 +0200
@@ -2,6 +2,7 @@ obj-$(CONFIG_UIO)	+= uio.o
 obj-$(CONFIG_UIO_CIF)	+= uio_cif.o
 obj-$(CONFIG_UIO_PDRV)	+= uio_pdrv.o
 obj-$(CONFIG_UIO_PDRV_GENIRQ)	+= uio_pdrv_genirq.o
+obj-$(CONFIG_UIO_OF_GENIRQ)	+= uio_of_genirq.o
 obj-$(CONFIG_UIO_SMX)	+= uio_smx.o
 obj-$(CONFIG_UIO_AEC)	+= uio_aec.o
 obj-$(CONFIG_UIO_SERCOS3)	+= uio_sercos3.o
diff -purN --exclude=.git linux-2.6.31.12/drivers/uio/uio_of_genirq.c linux-2.6.31.12-petalinux/drivers/uio/uio_of_genirq.c
--- linux-2.6.31.12/drivers/uio/uio_of_genirq.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/uio/uio_of_genirq.c	2010-08-08 17:40:16.592837709 +0200
@@ -0,0 +1,98 @@
+/*
+ * OF wrapper to make use of the uio_pdrv_genirq-driver.
+ *
+ * Copyright (C) 2009 Wolfram Sang, Pengutronix
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published by
+ * the Free Software Foundation.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/uio_driver.h>
+#include <linux/of_device.h>
+#include <linux/of_platform.h>
+#include <linux/uio_pdrv_genirq.h>
+
+#define OF_DRIVER_VERSION "1"
+
+static __devinit int uio_of_genirq_probe(struct of_device *op,
+		const struct of_device_id *match)
+{
+	struct uio_info *uioinfo;
+	struct resource resources[MAX_UIO_MAPS];
+	int i, ret;
+
+	uioinfo = kzalloc(sizeof(*uioinfo), GFP_KERNEL);
+	if (!uioinfo)
+		return -ENOMEM;
+
+	uioinfo->name = op->node->name;
+	uioinfo->version = OF_DRIVER_VERSION;
+	uioinfo->irq = irq_of_parse_and_map(op->node, 0);
+	if (!uioinfo->irq)
+		uioinfo->irq = UIO_IRQ_NONE;
+
+	for (i = 0; i < MAX_UIO_MAPS; ++i)
+		if (of_address_to_resource(op->node, i, &resources[i]))
+			break;
+
+	ret = __uio_pdrv_genirq_probe(&op->dev, uioinfo, &resources, i);
+	if (ret)
+		goto err_cleanup;
+
+	return 0;
+
+err_cleanup:
+	if (uioinfo->irq != UIO_IRQ_NONE)
+		irq_dispose_mapping(uioinfo->irq);
+
+	kfree(uioinfo);
+	return ret;
+}
+
+static __devexit int uio_of_genirq_remove(struct of_device *op)
+{
+	struct uio_pdrv_genirq_platdata *priv = dev_get_drvdata(&op->dev);
+
+	uio_unregister_device(priv->uioinfo);
+
+	if (priv->uioinfo->irq != UIO_IRQ_NONE)
+		irq_dispose_mapping(priv->uioinfo->irq);
+
+	kfree(priv->uioinfo);
+	kfree(priv);
+	return 0;
+}
+
+/* Match table for of_platform binding */
+static const struct of_device_id __devinitconst uio_of_genirq_match[] = {
+	{ .compatible = "generic-uio", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, uio_of_genirq_match);
+
+static struct of_platform_driver uio_of_genirq_driver = {
+	.owner = THIS_MODULE,
+	.name = "uio-of-genirq",
+	.match_table = uio_of_genirq_match,
+	.probe = uio_of_genirq_probe,
+	.remove = __devexit_p(uio_of_genirq_remove),
+};
+
+static inline int __init uio_of_genirq_init(void)
+{
+	return of_register_platform_driver(&uio_of_genirq_driver);
+}
+module_init(uio_of_genirq_init);
+
+static inline void __exit uio_of_genirq_exit(void)
+{
+	of_unregister_platform_driver(&uio_of_genirq_driver);
+}
+module_exit(uio_of_genirq_exit);
+
+MODULE_AUTHOR("Wolfram Sang");
+MODULE_DESCRIPTION("Userspace I/O OF driver with generic IRQ handling");
+MODULE_LICENSE("GPL v2");
diff -purN --exclude=.git linux-2.6.31.12/drivers/uio/uio_pdrv_genirq.c linux-2.6.31.12-petalinux/drivers/uio/uio_pdrv_genirq.c
--- linux-2.6.31.12/drivers/uio/uio_pdrv_genirq.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/uio/uio_pdrv_genirq.c	2010-08-08 17:40:16.592837709 +0200
@@ -20,15 +20,10 @@
 #include <linux/bitops.h>
 #include <linux/interrupt.h>
 #include <linux/stringify.h>
+#include <linux/uio_pdrv_genirq.h>
 
 #define DRIVER_NAME "uio_pdrv_genirq"
 
-struct uio_pdrv_genirq_platdata {
-	struct uio_info *uioinfo;
-	spinlock_t lock;
-	unsigned long flags;
-};
-
 static irqreturn_t uio_pdrv_genirq_handler(int irq, struct uio_info *dev_info)
 {
 	struct uio_pdrv_genirq_platdata *priv = dev_info->priv;
@@ -68,29 +63,18 @@ static int uio_pdrv_genirq_irqcontrol(st
 	return 0;
 }
 
-static int uio_pdrv_genirq_probe(struct platform_device *pdev)
+int __uio_pdrv_genirq_probe(struct device *dev, struct uio_info *uioinfo,
+		struct resource *resources, unsigned int num_resources)
 {
-	struct uio_info *uioinfo = pdev->dev.platform_data;
 	struct uio_pdrv_genirq_platdata *priv;
 	struct uio_mem *uiomem;
-	int ret = -EINVAL;
-	int i;
-
-	if (!uioinfo || !uioinfo->name || !uioinfo->version) {
-		dev_err(&pdev->dev, "missing platform_data\n");
-		goto bad0;
-	}
-
-	if (uioinfo->handler || uioinfo->irqcontrol ||
-	    uioinfo->irq_flags & IRQF_SHARED) {
-		dev_err(&pdev->dev, "interrupt configuration error\n");
-		goto bad0;
-	}
+	unsigned int i;
+	int ret;
 
 	priv = kzalloc(sizeof(*priv), GFP_KERNEL);
 	if (!priv) {
 		ret = -ENOMEM;
-		dev_err(&pdev->dev, "unable to kmalloc\n");
+		dev_err(dev, "unable to kmalloc\n");
 		goto bad0;
 	}
 
@@ -100,14 +84,14 @@ static int uio_pdrv_genirq_probe(struct 
 
 	uiomem = &uioinfo->mem[0];
 
-	for (i = 0; i < pdev->num_resources; ++i) {
-		struct resource *r = &pdev->resource[i];
+	for (i = 0; i < num_resources; ++i) {
+		struct resource *r = resources + i;
 
 		if (r->flags != IORESOURCE_MEM)
 			continue;
 
 		if (uiomem >= &uioinfo->mem[MAX_UIO_MAPS]) {
-			dev_warn(&pdev->dev, "device has more than "
+			dev_warn(dev, "device has more than "
 					__stringify(MAX_UIO_MAPS)
 					" I/O memory resources.\n");
 			break;
@@ -138,19 +122,39 @@ static int uio_pdrv_genirq_probe(struct 
 	uioinfo->irqcontrol = uio_pdrv_genirq_irqcontrol;
 	uioinfo->priv = priv;
 
-	ret = uio_register_device(&pdev->dev, priv->uioinfo);
+	ret = uio_register_device(dev, priv->uioinfo);
 	if (ret) {
-		dev_err(&pdev->dev, "unable to register uio device\n");
+		dev_err(dev, "unable to register uio device\n");
 		goto bad1;
 	}
 
-	platform_set_drvdata(pdev, priv);
+	dev_set_drvdata(dev, priv);
 	return 0;
  bad1:
 	kfree(priv);
  bad0:
 	return ret;
 }
+EXPORT_SYMBOL_GPL(__uio_pdrv_genirq_probe);
+
+static int uio_pdrv_genirq_probe(struct platform_device *pdev)
+{
+	struct uio_info *uioinfo = pdev->dev.platform_data;
+
+	if (!uioinfo || !uioinfo->name || !uioinfo->version) {
+		dev_err(&pdev->dev, "missing platform_data\n");
+		return -EINVAL;
+	}
+
+	if (uioinfo->handler || uioinfo->irqcontrol ||
+	    uioinfo->irq_flags & IRQF_SHARED) {
+		dev_err(&pdev->dev, "interrupt configuration error\n");
+		return -EINVAL;
+	}
+
+	return __uio_pdrv_genirq_probe(&pdev->dev, uioinfo, pdev->resource,
+			pdev->num_resources);
+}
 
 static int uio_pdrv_genirq_remove(struct platform_device *pdev)
 {
diff -purN --exclude=.git linux-2.6.31.12/drivers/usb/host/ehci-hcd.c linux-2.6.31.12-petalinux/drivers/usb/host/ehci-hcd.c
--- linux-2.6.31.12/drivers/usb/host/ehci-hcd.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/usb/host/ehci-hcd.c	2010-08-08 17:40:16.600281044 +0200
@@ -1109,6 +1109,11 @@ MODULE_LICENSE ("GPL");
 #define OF_PLATFORM_DRIVER	ehci_hcd_ppc_of_driver
 #endif
 
+#ifdef CONFIG_XPS_USB_HCD_XILINX
+#include "ehci-xilinx-of.c"
+#define OF_PLATFORM_DRIVER	ehci_hcd_xilinx_of_driver
+#endif
+
 #ifdef CONFIG_PLAT_ORION
 #include "ehci-orion.c"
 #define	PLATFORM_DRIVER		ehci_orion_driver
diff -purN --exclude=.git linux-2.6.31.12/drivers/usb/host/ehci-xilinx-of.c linux-2.6.31.12-petalinux/drivers/usb/host/ehci-xilinx-of.c
--- linux-2.6.31.12/drivers/usb/host/ehci-xilinx-of.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/usb/host/ehci-xilinx-of.c	2010-08-08 17:26:27.612511510 +0200
@@ -0,0 +1,301 @@
+/*
+ * EHCI HCD (Host Controller Driver) for USB.
+ *
+ * Bus Glue for Xilinx EHCI core on the of_platform bus
+ *
+ * Copyright (c) 2009 Xilinx, Inc.
+ *
+ * Based on "ehci-ppc-of.c" by Valentine Barshak <vbarshak@ru.mvista.com>
+ * and "ehci-ppc-soc.c" by Stefan Roese <sr@denx.de>
+ * and "ohci-ppc-of.c" by Sylvain Munaut <tnt@246tNt.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2 of the License, or (at your
+ * option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+ * or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software Foundation,
+ * Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ */
+
+#include <linux/signal.h>
+
+#include <linux/of.h>
+#include <linux/of_platform.h>
+
+/**
+ * ehci_xilinx_of_setup - Initialize the device for ehci_reset()
+ * @hcd:	Pointer to the usb_hcd device to which the host controller bound
+ *
+ * called during probe() after chip reset completes.
+ */
+static int ehci_xilinx_of_setup(struct usb_hcd *hcd)
+{
+	struct ehci_hcd	*ehci = hcd_to_ehci(hcd);
+	int		retval;
+
+	retval = ehci_halt(ehci);
+	if (retval)
+		return retval;
+
+	retval = ehci_init(hcd);
+	if (retval)
+		return retval;
+
+	ehci->sbrn = 0x20;
+
+	return ehci_reset(ehci);
+}
+
+/**
+ * ehci_xilinx_port_handed_over - hand the port out if failed to enable it
+ * @hcd:	Pointer to the usb_hcd device to which the host controller bound
+ * @portnum:Port number to which the device is attached.
+ *
+ * This function is used as a place to tell the user that the Xilinx USB host
+ * controller does support LS devices. And in an HS only configuration, it
+ * does not support FS devices either. It is hoped that this can help a
+ * confused user.
+ *
+ * There are cases when the host controller fails to enable the port due to,
+ * for example, insufficient power that can be supplied to the device from
+ * the USB bus. In those cases, the messages printed here are not helpful.
+ */
+static int ehci_xilinx_port_handed_over(struct usb_hcd *hcd, int portnum)
+{
+	dev_warn(hcd->self.controller, "port %d cannot be enabled\n", portnum);
+	if (hcd->has_tt) {
+		dev_warn(hcd->self.controller,
+			"Maybe you have connected an LS device?\n");
+
+		dev_warn(hcd->self.controller,
+			"We do not support LS devices\n");
+	} else {
+		dev_warn(hcd->self.controller,
+			"Maybe your device is not an HS device?\n");
+		dev_warn(hcd->self.controller,
+			"The USB host controller does not support FS or "
+			"LS devices\n");
+		dev_warn(hcd->self.controller,
+			"You can reconfigure the host controller to have "
+			"FS support\n");
+	}
+
+	return 0;
+}
+
+
+static const struct hc_driver ehci_xilinx_of_hc_driver = {
+	.description		= hcd_name,
+	.product_desc		= "OF EHCI",
+	.hcd_priv_size		= sizeof(struct ehci_hcd),
+
+	/*
+	 * generic hardware linkage
+	 */
+	.irq			= ehci_irq,
+	.flags			= HCD_MEMORY | HCD_USB2,
+
+	/*
+	 * basic lifecycle operations
+	 */
+	.reset			= ehci_xilinx_of_setup,
+	.start			= ehci_run,
+	.stop			= ehci_stop,
+	.shutdown		= ehci_shutdown,
+
+	/*
+	 * managing i/o requests and associated device resources
+	 */
+	.urb_enqueue		= ehci_urb_enqueue,
+	.urb_dequeue		= ehci_urb_dequeue,
+	.endpoint_disable	= ehci_endpoint_disable,
+
+	/*
+	 * scheduling support
+	 */
+	.get_frame_number	= ehci_get_frame,
+
+	/*
+	 * root hub support
+	 */
+	.hub_status_data	= ehci_hub_status_data,
+	.hub_control		= ehci_hub_control,
+#ifdef	CONFIG_PM
+	.bus_suspend		= ehci_bus_suspend,
+	.bus_resume		= ehci_bus_resume,
+#endif
+	.relinquish_port	= NULL,
+	.port_handed_over	= ehci_xilinx_port_handed_over,
+};
+
+/**
+ * ehci_hcd_xilinx_of_probe - Probe method for the USB host controller
+ * @op:		pointer to the of_device to which the host controller bound
+ * @match:	pointer to of_device_id structure, not used
+ *
+ * This function requests resources and sets up appropriate properties for the
+ * host controller. Because the Xilinx USB host controller can be configured
+ * as HS only or HS/FS only, it checks the configuration in the device tree
+ * entry, and sets an appropriate value for hcd->has_tt.
+ */
+static int __devinit
+ehci_hcd_xilinx_of_probe(struct of_device *op, const struct of_device_id *match)
+{
+	struct device_node *dn = op->node;
+	struct usb_hcd *hcd;
+	struct ehci_hcd	*ehci;
+	struct resource res;
+	int irq;
+	int rv;
+	int *value;
+
+	if (usb_disabled())
+		return -ENODEV;
+
+	dev_dbg(&op->dev, "initializing XILINX-OF USB Controller\n");
+
+	rv = of_address_to_resource(dn, 0, &res);
+	if (rv)
+		return rv;
+
+	hcd = usb_create_hcd(&ehci_xilinx_of_hc_driver, &op->dev,
+				"XILINX-OF USB");
+	if (!hcd)
+		return -ENOMEM;
+
+	hcd->rsrc_start = res.start;
+	hcd->rsrc_len = res.end - res.start + 1;
+
+	if (!request_mem_region(hcd->rsrc_start, hcd->rsrc_len, hcd_name)) {
+		printk(KERN_ERR __FILE__ ": request_mem_region failed\n");
+		rv = -EBUSY;
+		goto err_rmr;
+	}
+
+	irq = irq_of_parse_and_map(dn, 0);
+	if (irq == NO_IRQ) {
+		printk(KERN_ERR __FILE__ ": irq_of_parse_and_map failed\n");
+		rv = -EBUSY;
+		goto err_irq;
+	}
+
+	hcd->regs = ioremap(hcd->rsrc_start, hcd->rsrc_len);
+	if (!hcd->regs) {
+		printk(KERN_ERR __FILE__ ": ioremap failed\n");
+		rv = -ENOMEM;
+		goto err_ioremap;
+	}
+
+	ehci = hcd_to_ehci(hcd);
+
+	/* This core always has big-endian register interface and uses
+	 * big-endian memory descriptors.
+	 */
+	ehci->big_endian_mmio = 1;
+	ehci->big_endian_desc = 1;
+
+	/* Check whether the FS support option is selected in the hardware.
+	 */
+	value = (int *)of_get_property(dn, "xlnx,support-usb-fs", NULL);
+	if (value && (*value == 1)) {
+		ehci_dbg(ehci, "USB host controller supports FS devices\n");
+		hcd->has_tt = 1;
+	} else {
+		ehci_dbg(ehci,
+			"USB host controller is HS only\n");
+		hcd->has_tt = 0;
+	}
+
+	/* Debug registers are at the first 0x100 region
+	 */
+	ehci->caps = hcd->regs + 0x100;
+	ehci->regs = hcd->regs + 0x100 +
+			HC_LENGTH(ehci_readl(ehci, &ehci->caps->hc_capbase));
+
+	/* cache this readonly data; minimize chip reads */
+	ehci->hcs_params = ehci_readl(ehci, &ehci->caps->hcs_params);
+
+	rv = usb_add_hcd(hcd, irq, 0);
+	if (rv == 0)
+		return 0;
+
+	iounmap(hcd->regs);
+err_ioremap:
+	irq_dispose_mapping(irq);
+err_irq:
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+err_rmr:
+	usb_put_hcd(hcd);
+
+	return rv;
+}
+
+/**
+ * ehci_hcd_xilinx_of_remove - shutdown hcd and release resources
+ * @op:		pointer to of_device structure that is to be removed
+ *
+ * Remove the hcd structure, and release resources that has been requested
+ * during probe.
+ */
+static int ehci_hcd_xilinx_of_remove(struct of_device *op)
+{
+	struct usb_hcd *hcd = dev_get_drvdata(&op->dev);
+	dev_set_drvdata(&op->dev, NULL);
+
+	dev_dbg(&op->dev, "stopping XILINX-OF USB Controller\n");
+
+	usb_remove_hcd(hcd);
+
+	iounmap(hcd->regs);
+	irq_dispose_mapping(hcd->irq);
+	release_mem_region(hcd->rsrc_start, hcd->rsrc_len);
+
+	usb_put_hcd(hcd);
+
+	return 0;
+}
+
+/**
+ * ehci_hcd_xilinx_of_shutdown - shutdown the hcd
+ * @op:		pointer to of_device structure that is to be removed
+ *
+ * Properly shutdown the hcd, call driver's shutdown routine.
+ */
+static int ehci_hcd_xilinx_of_shutdown(struct of_device *op)
+{
+	struct usb_hcd *hcd = dev_get_drvdata(&op->dev);
+
+	if (hcd->driver->shutdown)
+		hcd->driver->shutdown(hcd);
+
+	return 0;
+}
+
+
+static struct of_device_id ehci_hcd_xilinx_of_match[] = {
+	{
+		.compatible = "usb-ehci",
+	},
+	{},
+};
+MODULE_DEVICE_TABLE(of, ehci_hcd_xilinx_of_match);
+
+static struct of_platform_driver ehci_hcd_xilinx_of_driver = {
+	.name		= "xilinx-of-ehci",
+	.match_table	= ehci_hcd_xilinx_of_match,
+	.probe		= ehci_hcd_xilinx_of_probe,
+	.remove		= ehci_hcd_xilinx_of_remove,
+	.shutdown	= ehci_hcd_xilinx_of_shutdown,
+	.driver		= {
+		.name	= "xilinx-of-ehci",
+		.owner	= THIS_MODULE,
+	},
+};
diff -purN --exclude=.git linux-2.6.31.12/drivers/usb/host/Kconfig linux-2.6.31.12-petalinux/drivers/usb/host/Kconfig
--- linux-2.6.31.12/drivers/usb/host/Kconfig	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/usb/host/Kconfig	2010-08-08 17:26:27.596526166 +0200
@@ -90,14 +90,26 @@ config USB_EHCI_TT_NEWSCHED
 
 config USB_EHCI_BIG_ENDIAN_MMIO
 	bool
-	depends on USB_EHCI_HCD && (PPC_CELLEB || PPC_PS3 || 440EPX || ARCH_IXP4XX)
+	depends on USB_EHCI_HCD && (PPC_CELLEB || PPC_PS3 || 440EPX || ARCH_IXP4XX || XPS_USB_HCD_XILINX)
 	default y
 
 config USB_EHCI_BIG_ENDIAN_DESC
 	bool
-	depends on USB_EHCI_HCD && (440EPX || ARCH_IXP4XX)
+	depends on USB_EHCI_HCD && (440EPX || ARCH_IXP4XX || XPS_USB_HCD_XILINX)
 	default y
 
+config XPS_USB_HCD_XILINX
+	bool "Use Xilinx usb host EHCI controller core"
+	depends on USB_EHCI_HCD
+	select PPC_OF
+	select USB_EHCI_BIG_ENDIAN_DESC
+	select USB_EHCI_BIG_ENDIAN_MMIO
+	---help---
+		Xilinx xps USB host controller core that is EHCI compilant and
+		has transaction translator built-in. It can be configured either 
+		to support both high speed and full speed devices, or high speed
+		devices only.
+
 config USB_EHCI_FSL
 	bool "Support for Freescale on-chip EHCI USB controller"
 	depends on USB_EHCI_HCD && FSL_SOC
diff -purN --exclude=.git linux-2.6.31.12/drivers/usb/Kconfig linux-2.6.31.12-petalinux/drivers/usb/Kconfig
--- linux-2.6.31.12/drivers/usb/Kconfig	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/usb/Kconfig	2010-08-08 17:26:27.544526401 +0200
@@ -22,7 +22,6 @@ config USB_ARCH_HAS_HCD
 	default y if PCMCIA && !M32R			# sl811_cs
 	default y if ARM				# SL-811
 	default y if SUPERH				# r8a66597-hcd
-	default y if MICROBLAZE
 	default PCI
 
 # many non-PCI SOC chips embed OHCI
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/Kconfig linux-2.6.31.12-petalinux/drivers/xilinx_common/Kconfig
--- linux-2.6.31.12/drivers/xilinx_common/Kconfig	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/Kconfig	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,33 @@
+config XILINX_EDK
+	bool
+	depends on XILINX_VIRTEX || MICROBLAZE
+	default y
+
+config XILINX_LLDMA_USE_DCR
+	bool
+	depends on NEED_XILINX_LLDMA
+	default XILINX_VIRTEX_5_FXT
+
+
+#
+# Xilinx devices and common device driver infrastructure
+#
+
+config XILINX_DRIVERS
+	bool
+	depends on PPC32 || MICROBLAZE
+	default y
+	---help---
+	  This option is used to enable all of the Xilinx drivers on
+	  supported architectures.  This is often useful if you have a
+	  Xilinx FPGA in a system, either using embedded processors
+	  internal to the FPGA or external processors.
+
+config NEED_XILINX_DMAV3
+	bool
+
+config NEED_XILINX_LLDMA
+	bool
+
+config NEED_XILINX_IPIF
+	bool
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/Makefile linux-2.6.31.12-petalinux/drivers/xilinx_common/Makefile
--- linux-2.6.31.12/drivers/xilinx_common/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/Makefile	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,19 @@
+# The Xilinx OS common code 
+
+obj-$(CONFIG_XILINX_EDK) += xbasic_types.o xilinx_syms.o					\
+				xversion.o	xpacket_fifo_v2_00_a.o xpacket_fifo_l_v2_00_a.o	\
+				xdma_channel.o xdma_channel_sg.o xio.o
+
+obj-$(CONFIG_NEED_XILINX_DMAV3) += \
+			    xdmav3.o xdmav3_intr.o xdmav3_sg.o			\
+			    xdmav3_selftest.o xdmav3_simple.o
+
+obj-$(CONFIG_NEED_XILINX_LLDMA) += \
+			    xlldma_bdring.o xlldma.o				\
+			    xllfifo.o xstreamer.o
+
+obj-$(CONFIG_XILINX_LLDMA_USE_DCR) += \
+					xio_dcr.o
+
+obj-$(CONFIG_NEED_XILINX_IPIF) += \
+			    xipif_v1_23_b.o
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xbasic_types.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xbasic_types.c
--- linux-2.6.31.12/drivers/xilinx_common/xbasic_types.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xbasic_types.c	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,135 @@
+/* $Id $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002-2003 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xbasic_types.c
+*
+* This file contains basic functions for Xilinx software IP.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who    Date   Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a rpm  11/07/03 Added XNullHandler function as a stub interrupt handler
+* 1.00a xd   11/03/04 Improved support for doxygen.
+* </pre>
+*
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+
+/************************** Constant Definitions *****************************/
+
+/**************************** Type Definitions *******************************/
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/************************** Variable Definitions *****************************/
+
+/**
+ * This variable allows testing to be done easier with asserts. An assert
+ * sets this variable such that a driver can evaluate this variable
+ * to determine if an assert occurred.
+ */
+unsigned int XAssertStatus;
+
+/**
+ * This variable allows the assert functionality to be changed for testing
+ * such that it does not wait infinitely. Use the debugger to disable the
+ * waiting during testing of asserts.
+ */
+u32 XWaitInAssert = TRUE;
+
+/* The callback function to be invoked when an assert is taken */
+static XAssertCallback XAssertCallbackRoutine = (XAssertCallback) NULL;
+
+/************************** Function Prototypes ******************************/
+
+/*****************************************************************************/
+/**
+*
+* Implements assert. Currently, it calls a user-defined callback function
+* if one has been set.  Then, it potentially enters an infinite loop depending
+* on the value of the XWaitInAssert variable.
+*
+* @param    File is the name of the filename of the source
+* @param    Line is the linenumber within File
+*
+* @return   None.
+*
+* @note     None.
+*
+******************************************************************************/
+void XAssert(char *File, int Line)
+{
+	/* if the callback has been set then invoke it */
+	if (XAssertCallbackRoutine != NULL) {
+		(*XAssertCallbackRoutine) (File, Line);
+	}
+
+	/* if specified, wait indefinitely such that the assert will show up
+	 * in testing
+	 */
+	while (XWaitInAssert) {
+	}
+}
+
+/*****************************************************************************/
+/**
+*
+* Sets up a callback function to be invoked when an assert occurs. If there
+* was already a callback installed, then it is replaced.
+*
+* @param    Routine is the callback to be invoked when an assert is taken
+*
+* @return   None.
+*
+* @note     This function has no effect if NDEBUG is set
+*
+******************************************************************************/
+void XAssertSetCallback(XAssertCallback Routine)
+{
+	XAssertCallbackRoutine = Routine;
+}
+
+
+/*****************************************************************************/
+/**
+*
+* Null handler function. This follows the XInterruptHandler signature for
+* interrupt handlers. It can be used to assign a null handler (a stub) to an
+* interrupt controller vector table.
+*
+* @param    NullParameter is an arbitrary void pointer and not used.
+*
+* @return   None.
+*
+* @note     None.
+*
+******************************************************************************/
+void XNullHandler(void *NullParameter)
+{
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xbasic_types.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xbasic_types.h
--- linux-2.6.31.12/drivers/xilinx_common/xbasic_types.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xbasic_types.h	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,223 @@
+/* $Id: xbasic_types.h,v 1.1 2006/12/13 14:21:22 imanuilov Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002-2004 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xbasic_types.h
+*
+* This file contains basic types for Xilinx software IP.  These types do not
+* follow the standard naming convention with respect to using the component
+* name in front of each name because they are considered to be primitives.
+*
+* @note
+*
+* This file contains items which are architecture dependent.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who    Date   Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a rmm  12/14/01 First release
+*       rmm  05/09/03 Added "xassert always" macros to rid ourselves of diab
+*                     compiler warnings
+* 1.00a rpm  11/07/03 Added XNullHandler function as a stub interrupt handler
+* 1.00a rpm  07/21/04 Added XExceptionHandler typedef for processor exceptions
+* 1.00a xd   11/03/04 Improved support for doxygen.
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XBASIC_TYPES_H		/* prevent circular inclusions */
+#define XBASIC_TYPES_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+
+/***************************** Include Files *********************************/
+
+#include <linux/types.h>
+
+/************************** Constant Definitions *****************************/
+
+#ifndef TRUE
+#define TRUE 1
+#endif
+
+#ifndef FALSE
+#define FALSE !(TRUE)
+#endif
+
+#define XCOMPONENT_IS_READY     0x11111111  /**< component has been initialized */
+#define XCOMPONENT_IS_STARTED   0x22222222  /**< component has been started */
+
+/* the following constants and declarations are for unit test purposes and are
+ * designed to be used in test applications.
+ */
+#define XTEST_PASSED    0
+#define XTEST_FAILED    1
+
+#define XASSERT_NONE     0
+#define XASSERT_OCCURRED 1
+
+extern unsigned int XAssertStatus;
+extern void XAssert(char *, int);
+
+/**************************** Type Definitions *******************************/
+/**
+ * This data type defines an interrupt handler for a device.
+ * The argument points to the instance of the component
+ */
+typedef void (*XInterruptHandler) (void *InstancePtr);
+
+/**
+ * This data type defines an exception handler for a processor.
+ * The argument points to the instance of the component
+ */
+typedef void (*XExceptionHandler) (void *InstancePtr);
+
+/**
+ * This data type defines a callback to be invoked when an
+ * assert occurs. The callback is invoked only when asserts are enabled
+ */
+typedef void (*XAssertCallback) (char *FilenamePtr, int LineNumber);
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+#ifndef NDEBUG
+
+/*****************************************************************************/
+/**
+* This assert macro is to be used for functions that do not return anything
+* (void). This in conjunction with the XWaitInAssert boolean can be used to
+* accomodate tests so that asserts which fail allow execution to continue.
+*
+* @param    expression is the expression to evaluate. If it evaluates to
+*           false, the assert occurs.
+*
+* @return   Returns void unless the XWaitInAssert variable is true, in which
+*           case no return is made and an infinite loop is entered.
+*
+* @note     None.
+*
+******************************************************************************/
+#define XASSERT_VOID(expression)                   \
+{                                                  \
+    if (expression)                                \
+    {                                              \
+        XAssertStatus = XASSERT_NONE;              \
+    }                                              \
+    else                                           \
+    {                                              \
+        XAssert(__FILE__, __LINE__);               \
+                XAssertStatus = XASSERT_OCCURRED;  \
+        return;                                    \
+    }                                              \
+}
+
+/*****************************************************************************/
+/**
+* This assert macro is to be used for functions that do return a value. This in
+* conjunction with the XWaitInAssert boolean can be used to accomodate tests so
+* that asserts which fail allow execution to continue.
+*
+* @param    expression is the expression to evaluate. If it evaluates to false,
+*           the assert occurs.
+*
+* @return   Returns 0 unless the XWaitInAssert variable is true, in which case
+*           no return is made and an infinite loop is entered.
+*
+* @note     None.
+*
+******************************************************************************/
+#define XASSERT_NONVOID(expression)                \
+{                                                  \
+    if (expression)                                \
+    {                                              \
+        XAssertStatus = XASSERT_NONE;              \
+    }                                              \
+    else                                           \
+    {                                              \
+        XAssert(__FILE__, __LINE__);               \
+                XAssertStatus = XASSERT_OCCURRED;  \
+        return 0;                                  \
+    }                                              \
+}
+
+/*****************************************************************************/
+/**
+* Always assert. This assert macro is to be used for functions that do not
+* return anything (void). Use for instances where an assert should always
+* occur.
+*
+* @return Returns void unless the XWaitInAssert variable is true, in which case
+*         no return is made and an infinite loop is entered.
+*
+* @note   None.
+*
+******************************************************************************/
+#define XASSERT_VOID_ALWAYS()                      \
+{                                                  \
+   XAssert(__FILE__, __LINE__);                    \
+           XAssertStatus = XASSERT_OCCURRED;       \
+   return;                                         \
+}
+
+/*****************************************************************************/
+/**
+* Always assert. This assert macro is to be used for functions that do return
+* a value. Use for instances where an assert should always occur.
+*
+* @return Returns void unless the XWaitInAssert variable is true, in which case
+*         no return is made and an infinite loop is entered.
+*
+* @note   None.
+*
+******************************************************************************/
+#define XASSERT_NONVOID_ALWAYS()                   \
+{                                                  \
+   XAssert(__FILE__, __LINE__);                    \
+           XAssertStatus = XASSERT_OCCURRED;       \
+   return 0;                                       \
+}
+
+
+#else
+
+#define XASSERT_VOID(expression)
+#define XASSERT_VOID_ALWAYS()
+#define XASSERT_NONVOID(expression)
+#define XASSERT_NONVOID_ALWAYS()
+#endif
+
+/************************** Function Prototypes ******************************/
+
+void XAssertSetCallback(XAssertCallback Routine);
+void XNullHandler(void *NullParameter);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xbuf_descriptor.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xbuf_descriptor.h
--- linux-2.6.31.12/drivers/xilinx_common/xbuf_descriptor.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xbuf_descriptor.h	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,1095 @@
+/* $Id: xbuf_descriptor.h,v 1.1 2006/12/13 14:21:30 imanuilov Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2001-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xbuf_descriptor.h
+*
+* <b>Description</b>
+*
+* This file contains the interface for the XBufDescriptor component.
+* The XBufDescriptor component is a passive component that only maps over
+* a buffer descriptor data structure shared by the scatter gather DMA hardware
+* and software. The component's primary purpose is to provide encapsulation of
+* the buffer descriptor processing.  See the source file xbuf_descriptor.c for
+* details.
+*
+* @note
+*
+* Most of the functions of this component are implemented as macros in order
+* to optimize the processing.  The names are not all uppercase such that they
+* can be switched between macros and functions easily.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 1.00a xd   10/27/04 Doxygenated for inclusion in API documentation
+* 1.00b ecm  10/31/05 Updated for the check sum offload changes.
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XBUF_DESCRIPTOR_H	/* prevent circular inclusions */
+#define XBUF_DESCRIPTOR_H	/* by using protection macros */
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xdma_channel_i.h"
+
+/************************** Constant Definitions *****************************/
+
+/** @name Buffer Descriptor fields
+ *
+ * @{
+ */
+/** This constant allows access to fields of a buffer descriptor
+ * and is necessary at this level of visibility to allow macros to access
+ * and modify the fields of a buffer descriptor.  It is not expected that the
+ * user of a buffer descriptor would need to use this constant.
+ */
+#define XBD_DEVICE_STATUS_OFFSET    0
+#define XBD_CONTROL_OFFSET          1
+#define XBD_SOURCE_OFFSET           2
+#define XBD_DESTINATION_OFFSET      3
+#define XBD_LENGTH_OFFSET           4
+#define XBD_STATUS_OFFSET           5
+#define XBD_NEXT_PTR_OFFSET         6
+#define XBD_ID_OFFSET               7
+#define XBD_FLAGS_OFFSET            8
+#define XBD_RQSTED_LENGTH_OFFSET    9
+#define XBD_SIZE_IN_WORDS           10
+/* @} */
+
+/**
+ * The following constants define the bits of the flags field of a buffer
+ * descriptor
+ */
+#define XBD_FLAGS_LOCKED_MASK       1UL
+
+/**************************** Type Definitions *******************************/
+
+typedef u32 XBufDescriptor[XBD_SIZE_IN_WORDS];
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/**
+ * each of the following macros are named the same as functions rather than all
+ * upper case in order to allow either the macros or the functions to be
+ * used, see the source file xbuf_descriptor.c for documentation
+ */
+
+
+/*****************************************************************************/
+/**
+*
+* This function initializes a buffer descriptor component by zeroing all of the
+* fields of the buffer descriptor.  This function should be called prior to
+* using a buffer descriptor.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_Initialize(InstancePtr)                  \
+{                                                               \
+    (*((u32 *)InstancePtr + XBD_CONTROL_OFFSET) = 0);       \
+    (*((u32 *)InstancePtr + XBD_SOURCE_OFFSET) = 0);        \
+    (*((u32 *)InstancePtr + XBD_DESTINATION_OFFSET) = 0);   \
+    (*((u32 *)InstancePtr + XBD_LENGTH_OFFSET) = 0);        \
+    (*((u32 *)InstancePtr + XBD_STATUS_OFFSET) = 0);        \
+    (*((u32 *)InstancePtr + XBD_DEVICE_STATUS_OFFSET) = 0); \
+    (*((u32 *)InstancePtr + XBD_NEXT_PTR_OFFSET) = 0);      \
+    (*((u32 *)InstancePtr + XBD_ID_OFFSET) = 0);            \
+    (*((u32 *)InstancePtr + XBD_FLAGS_OFFSET) = 0);         \
+    (*((u32 *)InstancePtr + XBD_RQSTED_LENGTH_OFFSET) = 0); \
+}
+
+/*****************************************************************************/
+/**
+*
+* This function gets the control field of a buffer descriptor component.  The
+* DMA channel hardware transfers the control field from the buffer descriptor
+* into the DMA control register when a buffer descriptor is processed.  It
+* controls the details of the DMA transfer.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* The control field contents of the buffer descriptor. One or more of the
+* following values may be contained the field.  Each of the values are
+* unique bit masks.
+*                               <br><br>
+* - XDC_DMACR_SOURCE_INCR_MASK  Increment the source address
+*                               <br><br>
+* - XDC_DMACR_DEST_INCR_MASK    Increment the destination address
+*                               <br><br>
+* - XDC_DMACR_SOURCE_LOCAL_MASK Local source address
+*                               <br><br>
+* - XDC_DMACR_DEST_LOCAL_MASK   Local destination address
+*                               <br><br>
+* - XDC_DMACR_SG_ENABLE_MASK    Scatter gather enable
+*                               <br><br>
+* - XDC_DMACR_GEN_BD_INTR_MASK  Individual buffer descriptor interrupt
+*                               <br><br>
+* - XDC_DMACR_LAST_BD_MASK      Last buffer descriptor in a packet
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetControl(InstancePtr)   \
+    (u32)(*((u32 *)InstancePtr + XBD_CONTROL_OFFSET))
+
+/*****************************************************************************/
+/**
+*
+* This function sets the control field of a buffer descriptor component.  The
+* DMA channel hardware transfers the control field from the buffer descriptor
+* into the DMA control register when a buffer descriptor is processed.  It
+* controls the details of the DMA transfer such as
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @param
+*
+* Control contains the value to be written to the control field of the buffer
+* descriptor. One or more of the following values may be contained the field.
+* Each of the values are unique bit masks such that they may be ORed together
+* to enable multiple bits or inverted and ANDed to disable multiple bits.
+* - XDC_DMACR_SOURCE_INCR_MASK  Increment the source address
+* - XDC_DMACR_DEST_INCR_MASK    Increment the destination address
+* - XDC_DMACR_SOURCE_LOCAL_MASK Local source address
+* - XDC_DMACR_DEST_LOCAL_MASK   Local destination address
+* - XDC_DMACR_SG_ENABLE_MASK    Scatter gather enable
+* - XDC_DMACR_GEN_BD_INTR_MASK  Individual buffer descriptor interrupt
+* - XDC_DMACR_LAST_BD_MASK      Last buffer descriptor in a packet
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetControl(InstancePtr, Control)  \
+    (*((u32 *)InstancePtr + XBD_CONTROL_OFFSET) = (u32)Control)
+
+/*****************************************************************************/
+/**
+*
+* This function determines if this buffer descriptor is marked as being the
+* last in the control field.  A packet may be broken up across multiple
+* buffer descriptors such that the last buffer descriptor is the end of the
+* packet.  The DMA channel hardware copies the control field from the buffer
+* descriptor to the control register of the DMA channel when the buffer
+* descriptor is processed.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* TRUE if the buffer descriptor is marked as last in the control field,
+* otherwise, FALSE.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_IsLastControl(InstancePtr) \
+    (u32)((*((u32 *)InstancePtr + XBD_CONTROL_OFFSET) & \
+               XDC_CONTROL_LAST_BD_MASK) == XDC_CONTROL_LAST_BD_MASK)
+
+/*****************************************************************************/
+/**
+*
+* This function marks the buffer descriptor as being last in the control
+* field of the buffer descriptor.  A packet may be broken up across multiple
+* buffer descriptors such that the last buffer descriptor is the end of the
+* packet.  The DMA channel hardware copies the control field from the buffer
+* descriptor to the control register of the DMA channel when the buffer
+* descriptor is processed.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetLast(InstancePtr) \
+    (*((u32 *)InstancePtr + XBD_CONTROL_OFFSET) |= XDC_CONTROL_LAST_BD_MASK)
+
+/*****************************************************************************/
+/**
+*
+* This function gets the source address field of the buffer descriptor.
+* The source address indicates the address of memory which is the
+* source of a DMA scatter gather operation.  The DMA channel hardware
+* copies the source address from the buffer descriptor to the source
+* address register of the DMA channel when the buffer descriptor is processed.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* The source address field of the buffer descriptor.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetSrcAddress(InstancePtr) \
+    ((u32 *)(*((u32 *)InstancePtr + XBD_SOURCE_OFFSET)))
+
+/*****************************************************************************/
+/**
+*
+* This function sets the source address field of the buffer descriptor.
+* The source address indicates the address of memory which is the
+* source of a DMA scatter gather operation.  The DMA channel hardware
+* copies the source address from the buffer descriptor to the source
+* address register of the DMA channel when the buffer descriptor is processed.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @param
+*
+* SourceAddress contains the source address field for the buffer descriptor.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetSrcAddress(InstancePtr, Source) \
+    (*((u32 *)InstancePtr + XBD_SOURCE_OFFSET) = (u32)Source)
+
+/*****************************************************************************/
+/**
+*
+* This function gets the destination address field of the buffer descriptor.
+* The destination address indicates the address of memory which is the
+* destination of a DMA scatter gather operation.  The DMA channel hardware
+* copies the destination address from the buffer descriptor to the destination
+* address register of the DMA channel when the buffer descriptor is processed.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* The destination address field of the buffer descriptor.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetDestAddress(InstancePtr) \
+    ((u32 *)(*((u32 *)InstancePtr + XBD_DESTINATION_OFFSET)))
+
+/*****************************************************************************/
+/**
+*
+* This function sets the destination address field of the buffer descriptor.
+* The destination address indicates the address of memory which is the
+* destination of a DMA scatter gather operation.  The DMA channel hardware
+* copies the destination address from the buffer descriptor to the destination
+* address register of the DMA channel when the buffer descriptor is processed.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @param
+*
+* DestinationAddress contains the destination address field for the buffer
+* descriptor.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetDestAddress(InstancePtr, Destination) \
+    (*((u32 *)InstancePtr + XBD_DESTINATION_OFFSET) = (u32)Destination)
+
+/*****************************************************************************/
+/**
+*
+* This function gets the length of the data transfer if the buffer descriptor
+* has been processed by the DMA channel hardware.  If the buffer descriptor
+* has not been processed, the return value will be zero indicating that no data
+* has been transferred yet.  This function uses both the length and requested
+* length fields of the buffer descriptor to determine the number of bytes
+* transferred by the DMA operation. The length field of the buffer descriptor
+* contains the number of bytes remaining from the requested length.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* The number of bytes which have been transferred by a DMA operation on the
+* buffer descriptor.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetLength(InstancePtr)                           \
+    (u32)(*((u32 *)InstancePtr + XBD_RQSTED_LENGTH_OFFSET) -    \
+              *((u32 *)InstancePtr + XBD_LENGTH_OFFSET))
+
+/*****************************************************************************/
+/**
+*
+* This function sets the length and the requested length fields of the buffer
+* descriptor.  The length field indicates the number of bytes to transfer for
+* the DMA operation and the requested length is written with the same value.
+* The requested length is not modified by the DMA hardware while the length
+* field is modified by the hardware to indicate the number of bytes remaining
+* in the transfer after the transfer is complete.  The requested length allows
+* the software to calculate the actual number of bytes transferred for the DMA
+* operation.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @param
+*
+* Length contains the length to put in the length and requested length fields
+* of the buffer descriptor.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetLength(InstancePtr, Length)                       \
+{                                                                           \
+    (*((u32 *)InstancePtr + XBD_LENGTH_OFFSET) = (u32)(Length));    \
+    (*((u32 *)InstancePtr + XBD_RQSTED_LENGTH_OFFSET) = (u32)(Length));\
+}
+
+/*****************************************************************************/
+/**
+*
+* This function gets the status field of a buffer descriptor component. The
+* status field is written to the buffer descriptor by the DMA channel hardware
+* after processing of a buffer descriptor is complete.  The status field
+* indicates the status of the DMA operation.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* The status field contents of the buffer descriptor. One or more of the
+* following values may be contained the field. Each of the values are
+* unique bit masks.
+*                               <br><br>
+* - XDC_DMASR_BUSY_MASK         The DMA channel is busy
+*                               <br><br>
+* - XDC_DMASR_BUS_ERROR_MASK    A bus error occurred
+*                               <br><br>
+* - XDC_DMASR_BUS_TIMEOUT_MASK  A bus timeout occurred
+*                               <br><br>
+* - XDC_DMASR_LAST_BD_MASK      The last buffer descriptor of a packet
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetStatus(InstancePtr)    \
+    (u32)(*((u32 *)InstancePtr + XBD_STATUS_OFFSET))
+
+/*****************************************************************************/
+/**
+*
+* This function sets the status field of a buffer descriptor component.  The
+* status field is written to the buffer descriptor by the DMA channel hardware
+* after processing of a buffer descriptor is complete.  This function would
+* typically be used during debugging of buffer descriptor processing.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @param
+*
+* Status contains the status field for the buffer descriptor.
+* The status register contents of the DMA channel. One or more of the
+* following values may be contained the register. Each of the values are
+* unique bit masks.
+* - XDC_DMASR_BUSY_MASK         The DMA channel is busy
+* - XDC_DMASR_BUS_ERROR_MASK    A bus error occurred
+* - XDC_DMASR_BUS_TIMEOUT_MASK  A bus timeout occurred
+* - XDC_DMASR_LAST_BD_MASK      The last buffer descriptor of a packet
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetStatus(InstancePtr, Status)    \
+    (*((u32 *)InstancePtr + XBD_STATUS_OFFSET) = (u32)Status)
+
+/*****************************************************************************/
+/**
+*
+* This function determines if this buffer descriptor is marked as being the
+* last in the status field.  A packet may be broken up across multiple
+* buffer descriptors such that the last buffer descriptor is the end of the
+* packet.  The DMA channel hardware copies the status register contents to
+* the buffer descriptor of the DMA channel after processing of the buffer
+* descriptor is complete.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* TRUE if the buffer descriptor is marked as last in the status field,
+* otherwise, FALSE.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_IsLastStatus(InstancePtr) \
+    (u32)((*((u32 *)InstancePtr + XBD_STATUS_OFFSET) & \
+               XDC_STATUS_LAST_BD_MASK) == XDC_STATUS_LAST_BD_MASK)
+
+/*****************************************************************************/
+/**
+*
+* This function gets the device status field of the buffer descriptor.  The
+* device status is device specific such that the definition of the contents
+* of this field are not defined in this function. The device is defined as the
+* device which is using the DMA channel, such as an ethernet controller.  The
+* DMA channel hardware copies the contents of the device status register into
+* the buffer descriptor when processing of the buffer descriptor is complete.
+* This value is typically used by the device driver for the device to determine
+* the status of the DMA operation with respect to the device.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* The device status field of the buffer descriptor.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetDeviceStatus(InstancePtr) \
+    ((u32)(*((u32 *)InstancePtr + XBD_DEVICE_STATUS_OFFSET)))
+
+/*****************************************************************************/
+/**
+*
+* This function sets the device status field of the buffer descriptor.  The
+* device status is device specific such that the definition of the contents
+* of this field are not defined in this function. The device is defined as the
+* device which is using the DMA channel, such as an ethernet controller.  This
+* function is typically only used for debugging/testing.
+*
+* The DMA channel hardware copies the contents of the device status register
+* into the buffer descriptor when processing of the buffer descriptor is
+* complete.  This value is typically used by the device driver for the device
+* to determine the status of the DMA operation with respect to the device.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @param
+*
+* Status contains the device status field for the buffer descriptor.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetDeviceStatus(InstancePtr, Status) \
+{                                                                   \
+    u32 Register;                                               \
+    Register = (*((u32 *)InstancePtr + XBD_DEVICE_STATUS_OFFSET));     \
+    Register &= XDC_DMASR_RX_CS_RAW_MASK;                         \
+    (*((u32 *)InstancePtr + XBD_DEVICE_STATUS_OFFSET)) =               \
+              Register | ((u32) (Status));               \
+}
+
+/*****************************************************************************/
+/**
+*
+* This function gets the next pointer field of the buffer descriptor.  This
+* field is used to link the buffer descriptors together such that multiple DMA
+* operations can be automated for scatter gather.  It also allows a single
+* packet to be broken across multiple buffer descriptors.  The DMA channel
+* hardware traverses the list of buffer descriptors using the next pointer
+* of each buffer descriptor.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* The next pointer field of the buffer descriptor.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetNextPtr(InstancePtr) \
+    (XBufDescriptor *)(*((u32 *)InstancePtr + XBD_NEXT_PTR_OFFSET))
+
+/*****************************************************************************/
+/**
+*
+* This function sets the next pointer field of the buffer descriptor.  This
+* field is used to link the buffer descriptors together such that many DMA
+* operations can be automated for scatter gather.  It also allows a single
+* packet to be broken across multiple buffer descriptors.  The DMA channel
+* hardware traverses the list of buffer descriptors using the next pointer
+* of each buffer descriptor.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @param
+*
+* NextPtr contains the next pointer field for the buffer descriptor.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetNextPtr(InstancePtr, NextPtr) \
+    (*((u32 *)InstancePtr + XBD_NEXT_PTR_OFFSET) = (u32)NextPtr)
+
+/*****************************************************************************/
+/**
+*
+* This function gets the ID field of the buffer descriptor.  The ID field is
+* provided to allow a device driver to correlate the buffer descriptor to other
+* data structures which may be operating system specific, such as a pointer to
+* a higher level memory block. The ID field is not used by the DMA channel
+* hardware and is application specific.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* The ID field of the buffer descriptor.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetId(InstancePtr) \
+    (u32)(*((u32 *)InstancePtr + XBD_ID_OFFSET))
+
+/*****************************************************************************/
+/**
+*
+* This function sets the ID field of the buffer descriptor.  The ID field is
+* provided to allow a device driver to correlate the buffer descriptor to other
+* data structures which may be operating system specific, such as a pointer to
+* a higher level memory block. The ID field is not used by the DMA channel
+* hardware and is application specific.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @param
+*
+* Id contains the ID field for the buffer descriptor.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetId(InstancePtr, Id) \
+    (*((u32 *)InstancePtr + XBD_ID_OFFSET) = (u32)Id)
+
+/*****************************************************************************/
+/**
+*
+* This function gets the flags field of the buffer descriptor.  The flags
+* field is not used by the DMA channel hardware and is used for software
+* processing of buffer descriptors.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* The flags field of the buffer descriptor.  The field may contain one or more
+* of the following values which are bit masks.
+*                               <br><br>
+* - XBD_FLAGS_LOCKED_MASK       Indicates the buffer descriptor is locked
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetFlags(InstancePtr) \
+    (u32)(*((u32 *)InstancePtr + XBD_FLAGS_OFFSET))
+
+/*****************************************************************************/
+/**
+*
+* This function sets the flags field of the buffer descriptor.  The flags
+* field is not used by the DMA channel hardware and is used for software
+* processing of buffer descriptors.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @param
+*
+* Flags contains the flags field for the buffer descriptor.  The field may
+* contain one or more of the following values which are bit masks.
+* - XBD_FLAGS_LOCKED_MASK       Indicates the buffer descriptor is locked
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetFlags(InstancePtr, Flags) \
+    (*((u32 *)InstancePtr + XBD_FLAGS_OFFSET) = (u32)Flags)
+
+/*****************************************************************************/
+/**
+*
+* This function locks the buffer descriptor. A lock is specific to the
+* scatter gather processing and prevents a buffer descriptor from being
+* overwritten in the scatter gather list.  This field is not used by the DMA
+* channel hardware such that the hardware could still write to the buffer
+* descriptor.  Locking a buffer descriptor is application specific and not
+* necessary to allow the DMA channel to use the buffer descriptor, but is
+* provided for flexibility in designing device drivers.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_Lock(InstancePtr) \
+    (*((u32 *)InstancePtr + XBD_FLAGS_OFFSET) |= XBD_FLAGS_LOCKED_MASK)
+
+/*****************************************************************************/
+/**
+*
+* This function unlocks the buffer descriptor.  A lock is specific to the
+* scatter gather processing and prevents a buffer descriptor from being
+* overwritten in the scatter gather list.  This field is not used by the DMA
+* channel hardware such that the hardware could still write to the buffer
+* descriptor.  Locking a buffer descriptor is application specific and not
+* necessary to allow the DMA channel to use the buffer descriptor, but is
+* provided for flex ability in designing device drivers.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_Unlock(InstancePtr) \
+    (*((u32 *)InstancePtr + XBD_FLAGS_OFFSET) &= ~XBD_FLAGS_LOCKED_MASK)
+
+/*****************************************************************************/
+/**
+*
+* This function determines if the buffer descriptor is locked.  The lock
+* is not used by the DMA channel hardware and is used for software processing
+* of buffer descriptors.
+*
+* @param
+*
+* InstancePtr points to the buffer descriptor to operate on.
+*
+* @return
+*
+* TRUE if the buffer descriptor is locked, otherwise FALSE.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_IsLocked(InstancePtr) \
+    (u32) ((*((u32 *)InstancePtr + XBD_FLAGS_OFFSET) & \
+        XBD_FLAGS_LOCKED_MASK) == XBD_FLAGS_LOCKED_MASK)
+
+/*****************************************************************************/
+/**
+*
+* This function gets the Initial value for the CS offload function.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* The initial value that will be used for checksum offload operation as DMA
+* moves the data.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetCSInit(InstancePtr)\
+(*((u32 *)InstancePtr + XBD_CONTROL_OFFSET) &= XDC_DMACR_TX_CS_INIT_MASK)
+
+/*****************************************************************************/
+/**
+*
+* This function Sets the Initial value for the CS offload function.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* None
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetCSInit(InstancePtr, InitialValue)            \
+{                                                                   \
+    u32 Register;                                               \
+    Register = (*((u32 *)InstancePtr + XBD_CONTROL_OFFSET));     \
+    Register &= ~XDC_DMACR_TX_CS_INIT_MASK;                         \
+    (*((u32 *)InstancePtr + XBD_CONTROL_OFFSET)) =               \
+              Register | ((u32) (InitialValue));               \
+}
+/*****************************************************************************/
+/**
+*
+* This function gets the byte position where the CS offload function
+* inserts the calculated checksum.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* The insert byte location value that will be used to place the results of
+* the checksum offload.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetCSInsertLoc(InstancePtr)                     \
+(*((u32 *)InstancePtr + XBD_DESTINATION_OFFSET) &= XDC_DAREG_CS_INSERT_MASK)
+
+/*****************************************************************************/
+/**
+*
+* This function sets the byte position where the CS offload function
+* inserts the calculated checksum.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* None
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetCSInsertLoc(InstancePtr, InsertLocation)            \
+{                                                                   \
+    u32 Register;                                               \
+    Register = (*((u32 *)InstancePtr + XBD_DESTINATION_OFFSET));      \
+    Register &= ~XDC_DAREG_CS_INSERT_MASK;                         \
+    (*((u32 *)InstancePtr + XBD_DESTINATION_OFFSET)) =                \
+              Register | ((u32) (InsertLocation));             \
+}
+
+/*****************************************************************************/
+/**
+*
+* This function gets the byte position where the CS offload function
+* begins the calculation of the checksum.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* The insert byte location value that will be used to place the results of
+* the checksum offload.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetCSBegin(InstancePtr)                      \
+(u16)((*((u32 *)InstancePtr + XBD_DESTINATION_OFFSET)) >> 16)
+/*****************************************************************************/
+/**
+*
+* This function sets the byte position where the CS offload function
+* begins the calculation of the checksum.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* None
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_SetCSBegin(InstancePtr, BeginLocation)               \
+{                                                                           \
+    u32 Register;                                                       \
+    Register = (*((u32 *)InstancePtr + XBD_DESTINATION_OFFSET));             \
+    Register &= ~XDC_DAREG_CS_BEGIN_MASK;                                 \
+    (*((u32 *)InstancePtr + XBD_DESTINATION_OFFSET)) =                       \
+              Register | (((u32) (BeginLocation)) << 16);               \
+}
+/*****************************************************************************/
+/**
+*
+* This function gets the resulting checksum from the rx channel.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* The raw checksum calculation from the receive operation. It needs to
+* be adjusted to remove the header and packet FCS to be correct.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XBufDescriptor_GetCSRaw(InstancePtr)                     \
+(u16)((*((u32 *)InstancePtr + XBD_DEVICE_STATUS_OFFSET)) >> 16)
+
+/************************** Function Prototypes ******************************/
+
+/* The following prototypes are provided to allow each of the functions to
+ * be implemented as a function rather than a macro, and to provide the
+ * syntax to allow users to understand how to call the macros, they are
+ * commented out to prevent linker errors
+ *
+
+u32 XBufDescriptor_Initialize(XBufDescriptor* InstancePtr);
+
+u32 XBufDescriptor_GetControl(XBufDescriptor* InstancePtr);
+void XBufDescriptor_SetControl(XBufDescriptor* InstancePtr, u32 Control);
+
+u32 XBufDescriptor_IsLastControl(XBufDescriptor* InstancePtr);
+void XBufDescriptor_SetLast(XBufDescriptor* InstancePtr);
+
+u32 XBufDescriptor_GetLength(XBufDescriptor* InstancePtr);
+void XBufDescriptor_SetLength(XBufDescriptor* InstancePtr, u32 Length);
+
+u32 XBufDescriptor_GetStatus(XBufDescriptor* InstancePtr);
+void XBufDescriptor_SetStatus(XBufDescriptor* InstancePtr, u32 Status);
+u32 XBufDescriptor_IsLastStatus(XBufDescriptor* InstancePtr);
+
+u32 XBufDescriptor_GetDeviceStatus(XBufDescriptor* InstancePtr);
+void XBufDescriptor_SetDeviceStatus(XBufDescriptor* InstancePtr,
+                                    u32 Status);
+
+u32 XBufDescriptor_GetSrcAddress(XBufDescriptor* InstancePtr);
+void XBufDescriptor_SetSrcAddress(XBufDescriptor* InstancePtr,
+                                  u32 SourceAddress);
+
+u32 XBufDescriptor_GetDestAddress(XBufDescriptor* InstancePtr);
+void XBufDescriptor_SetDestAddress(XBufDescriptor* InstancePtr,
+                                   u32 DestinationAddress);
+
+XBufDescriptor* XBufDescriptor_GetNextPtr(XBufDescriptor* InstancePtr);
+void XBufDescriptor_SetNextPtr(XBufDescriptor* InstancePtr,
+                               XBufDescriptor* NextPtr);
+
+u32 XBufDescriptor_GetId(XBufDescriptor* InstancePtr);
+void XBufDescriptor_SetId(XBufDescriptor* InstancePtr, u32 Id);
+
+u32 XBufDescriptor_GetFlags(XBufDescriptor* InstancePtr);
+void XBufDescriptor_SetFlags(XBufDescriptor* InstancePtr, u32 Flags);
+
+void XBufDescriptor_Lock(XBufDescriptor* InstancePtr);
+void XBufDescriptor_Unlock(XBufDescriptor* InstancePtr);
+u32 XBufDescriptor_IsLocked(XBufDescriptor* InstancePtr);
+
+u16 XBufDescriptor_GetCSInit(XBufDescriptor* InstancePtr)
+void XBufDescriptor_SetCSInit(XBufDescriptor* InstancePtr, u16 InitialValue)
+
+u16 XBufDescriptor_GetCSInsertLoc(XBufDescriptor* InstancePtr)
+void XBufDescriptor_SetCSInsertLoc(XBufDescriptor* InstancePtr, u16 InsertLocation)
+
+u16 XBufDescriptor_GetCSBegin(XBufDescriptor* InstancePtr)
+void XBufDescriptor_SetCSBegin(XBufDescriptor* InstancePtr, u16 BeginLocation)
+
+u16 XBufDescriptor_GetCSRaw(XBufDescriptor* InstancePtr)
+
+void XBufDescriptor_Copy(XBufDescriptor* InstancePtr,
+                         XBufDescriptor* DestinationPtr);
+
+*/
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdebug.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xdebug.h
--- linux-2.6.31.12/drivers/xilinx_common/xdebug.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdebug.h	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,48 @@
+#ifndef XDEBUG
+#define XDEBUG
+
+#undef DEBUG
+
+#if defined(DEBUG) && !defined(NDEBUG)
+
+#ifndef XDEBUG_WARNING
+#define XDEBUG_WARNING
+#warning DEBUG is enabled
+#endif
+
+int printf(const char *format, ...);
+
+#define XDBG_DEBUG_ERROR             0x00000001    /* error condition messages */
+#define XDBG_DEBUG_GENERAL           0x00000002    /* general debug  messages */
+#define XDBG_DEBUG_ALL               0xFFFFFFFF    /* all debugging data */
+
+#define XDBG_DEBUG_FIFO_REG          0x00000100    /* display register reads/writes */
+#define XDBG_DEBUG_FIFO_RX           0x00000101    /* receive debug messages */
+#define XDBG_DEBUG_FIFO_TX           0x00000102    /* transmit debug messages */
+#define XDBG_DEBUG_FIFO_ALL          0x0000010F    /* all fifo debug messages */
+
+#define XDBG_DEBUG_TEMAC_REG         0x00000400    /* display register reads/writes */
+#define XDBG_DEBUG_TEMAC_RX          0x00000401    /* receive debug messages */
+#define XDBG_DEBUG_TEMAC_TX          0x00000402    /* transmit debug messages */
+#define XDBG_DEBUG_TEMAC_ALL         0x0000040F    /* all temac  debug messages */
+
+#define XDBG_DEBUG_TEMAC_ADPT_RX     0x00000800    /* receive debug messages */
+#define XDBG_DEBUG_TEMAC_ADPT_TX     0x00000801    /* transmit debug messages */
+#define XDBG_DEBUG_TEMAC_ADPT_IOCTL  0x00000802    /* ioctl debug messages */
+#define XDBG_DEBUG_TEMAC_ADPT_MISC   0x00000803    /* debug msg for other routines */
+#define XDBG_DEBUG_TEMAC_ADPT_ALL    0x0000080F    /* all temac adapter debug messages */
+
+#define xdbg_current_types (XDBG_DEBUG_ERROR | XDBG_DEBUG_GENERAL | XDBG_DEBUG_FIFO_REG | XDBG_DEBUG_TEMAC_REG)
+
+#define xdbg_stmnt(x)  x
+#define xdbg_printf(type, ...) (if ((type) & xdbg_current_types) printf (__VA_ARGS__) : 0)
+
+#else
+#define xdbg_stmnt(x)
+#define xdbg_printf(...)
+#endif
+
+
+
+
+#endif /* XDEBUG */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdmabdv3.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmabdv3.h
--- linux-2.6.31.12/drivers/xilinx_common/xdmabdv3.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmabdv3.h	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,531 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2006 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+ *
+ * @file xdmabdv3.h
+ *
+ * This header provides operations to manage buffer descriptors in support
+ * of simple and scatter-gather DMA (see xdmav3.h).
+ *
+ * The API exported by this header defines abstracted macros that allow the
+ * user to read/write specific BD fields.
+ *
+ * <b>Buffer Descriptors</b>
+ *
+ * A buffer descriptor (BD) defines a DMA transaction (see "Transaction"
+ * section in xdmav3.h). The macros defined by this header file allow access
+ * to most fields within a BD to tailor a DMA transaction according to user
+ * and HW requirements.  See the HW IP DMA spec for more information on BD
+ * fields and how they affect transfers.
+ *
+ * The XDmaBdV3 structure defines a BD. The organization of this structure is
+ * driven mainly by the hardware for use in scatter-gather DMA transfers.
+ *
+ * <b>Accessor Macros</b>
+ *
+ * Most of the BD attributes can be accessed through macro functions defined
+ * here in this API. Words such as XDMAV3_BD_USR0_OFFSET (see xdmav3_l.h)
+ * should be accessed using XDmaV3_mReadBd() and XDmaV3_mWriteBd() as defined in
+ * xdmav3_l.h. The USR words are implementation dependent. For example, they may
+ * implement checksum offloading fields for Ethernet devices. Accessor macros
+ * may be defined in the device specific API to get at this data.
+ *
+ * <b>Performance</b>
+ *
+ * BDs are typically in a non-cached memory space. Limiting I/O to BDs can
+ * improve overall performance of the DMA channel.
+ *
+ * <pre>
+ * MODIFICATION HISTORY:
+ *
+ * Ver   Who  Date     Changes
+ * ----- ---- -------- -------------------------------------------------------
+ * 3.00a rmm  03/11/06 First release
+ *       rmm  06/22/06 Added extern "C"
+ * </pre>
+ *
+ * ***************************************************************************
+ */
+
+#ifndef XDMABD_H		/* prevent circular inclusions */
+#define XDMABD_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include <asm/delay.h>
+#include "xdmav3_l.h"
+
+/************************** Constant Definitions *****************************/
+
+/**************************** Type Definitions *******************************/
+
+/**
+ * The XDmaBdV3 is the type for buffer descriptors (BDs).
+ */
+typedef u32 XDmaBdV3[XDMAV3_BD_NUM_WORDS];
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/*****************************************************************************/
+/**
+ * Zero out BD fields
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @return Nothing
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mClear(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mClear(BdPtr)                    \
+    memset((BdPtr), 0, sizeof(XDmaBdV3))
+
+
+/*****************************************************************************/
+/**
+ * Retrieve the BD's Packet DMA transfer status word.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @return Word at offset XDMAV3_BD_DMASR_OFFSET
+ *
+ * @note
+ * C-style signature:
+ *    u32 XDmaBdV3_mGetStatus(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mGetStatus(BdPtr)              \
+    XDmaV3_mReadBd((BdPtr), XDMAV3_BD_DMASR_OFFSET)
+
+
+/*****************************************************************************/
+/**
+ * Retrieve the BD's Packet status word. This is the first word of local link
+ * footer information for receive channels.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @return Word at offset XDMAV3_BD_SR_OFFSET
+ *
+ * @note
+ * C-style signature:
+ *    u32 XDmaBdV3_mGetPacketStatus(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mGetPacketStatus(BdPtr)                \
+    XDmaV3_mReadBd((BdPtr), XDMAV3_BD_SR_OFFSET)
+
+
+/*****************************************************************************/
+/**
+ * Retrieve the BD length field.
+ *
+ * For Tx channels, the returned value is the same as that written with
+ * XDmaBdV3_mSetLength().
+ *
+ * For Rx channels, the returned value is the size of the received packet.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @return Bytes processed by HW or set by XDmaBdV3_mSetLength().
+ *
+ * @note
+ * C-style signature:
+ *    u32 XDmaBdV3_mGetLength(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mGetLength(BdPtr)                      \
+    XDmaV3_mReadBd((BdPtr), XDMAV3_BD_LENGTH_OFFSET)
+
+
+/*****************************************************************************/
+/**
+ * Retrieve the BD length copy field. See XDmaBdV3_mSetLengthCopy() for
+ * more information.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @return Value as set by XDmaBdV3_mSetLengthCopy().
+ *
+ * @note
+ * C-style signature:
+ *    u32 XDmaBdV3_mGetLengthCopy(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mGetLengthCopy(BdPtr)                  \
+    XDmaV3_mReadBd((BdPtr), XDMAV3_BD_LENCPY_OFFSET)
+
+
+/*****************************************************************************/
+/**
+ * Test whether the given BD has been marked as the last BD of a packet.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @return TRUE if BD represents the "Last" BD of a packet, FALSE otherwise
+ *
+ * @note
+ * C-style signature:
+ *    u32 XDmaBdV3_mIsLast(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mIsLast(BdPtr)                                         \
+    ((XDmaV3_mReadBd((BdPtr), XDMAV3_BD_DMACR_OFFSET) & XDMAV3_DMACR_LAST_MASK) ? \
+     TRUE : FALSE)
+
+/*****************************************************************************/
+/**
+ * Set the ID field of the given BD. The ID is an arbitrary piece of data the
+ * user can associate with a specific BD.
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  Id is a 32 bit quantity to set in the BD
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mSetId(XDmaBdV3* BdPtr, void Id)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mSetId(BdPtr, Id)                                      \
+    (XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_ID_OFFSET, (u32)Id))
+
+
+/*****************************************************************************/
+/**
+ * Retrieve the ID field of the given BD previously set with XDmaBdV3_mSetId.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @note
+ * C-style signature:
+ *    u32 XDmaBdV3_mGetId(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mGetId(BdPtr) (XDmaV3_mReadBd((BdPtr), XDMAV3_BD_ID_OFFSET))
+
+
+/*****************************************************************************/
+/**
+ * Causes the DMA engine to increment the buffer address during the DMA
+ * transfer for this BD. This is the desirable setting when the buffer data
+ * occupies a memory range.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mSetBufIncrement(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mSetBufIncrement(BdPtr)                                \
+    (XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_DMACR_OFFSET,                   \
+     XDmaV3_mReadBd((BdPtr), XDMAV3_BD_DMACR_OFFSET) | XDMAV3_DMACR_AINC_MASK))
+
+
+/*****************************************************************************/
+/**
+ * Cause the DMA engine to use the same memory buffer address during the DMA
+ * transfer for this BD. This is the desirable setting when the buffer data
+ * occupies a single address as may be the case if transferring to/from a FIFO.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mSetBufNoIncrement(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mSetBufNoIncrement(BdPtr)                              \
+    (XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_DMACR_OFFSET,                   \
+        XDmaV3_mReadBd((BdPtr), XDMAV3_BD_DMACR_OFFSET) & ~XDMAV3_DMACR_AINC_MASK))
+
+
+/*****************************************************************************/
+/**
+ * Bypass data realignment engine (DRE) if DMA channel has DRE capability.
+ * Has no effect if channel does not have DRE.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mIgnoreDre(XDmaBdV3* BdPtr)
+ *
+ ******************************************************************************/
+#define XDmaBdV3_mIgnoreDre(BdPtr)                                      \
+    (XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_DMACR_OFFSET,                   \
+        XDmaV3_mReadBd((BdPtr), XDMAV3_BD_DMACR_OFFSET) | XDMAV3_DMACR_BPDRE_MASK))
+
+
+/*****************************************************************************/
+/**
+ * Use data realignment engine (DRE) if DMA channel has DRE capability.
+ * Has no effect if channel does not have DRE.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mUseDre(XDmaBdV3* BdPtr)
+ *
+ ******************************************************************************/
+#define XDmaBdV3_mUseDre(BdPtr)                                         \
+    (XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_DMACR_OFFSET,                   \
+        XDmaV3_mReadBd((BdPtr), XDMAV3_BD_DMACR_OFFSET) & ~XDMAV3_DMACR_BPDRE_MASK))
+
+
+/*****************************************************************************/
+/**
+ * Tell the SG DMA engine that the given BD marks the end of the current packet
+ * to be processed.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mSetLast(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mSetLast(BdPtr)                                        \
+    (XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_DMACR_OFFSET,                   \
+        XDmaV3_mReadBd((BdPtr), XDMAV3_BD_DMACR_OFFSET) | XDMAV3_DMACR_LAST_MASK))
+
+
+/*****************************************************************************/
+/**
+ * Tell the SG DMA engine that the current packet does not end with the given
+ * BD.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mClearLast(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mClearLast(BdPtr)                                      \
+    (XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_DMACR_OFFSET,                   \
+        XDmaV3_mReadBd((BdPtr), XDMAV3_BD_DMACR_OFFSET) & ~XDMAV3_DMACR_LAST_MASK))
+
+
+/*****************************************************************************/
+/**
+ * Set the Device Select field of the given BD.
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  DevSel is the IP device select to use with LSB of 1. This value
+ *         selects which IP block the transaction will address. Normally this
+ *         is set to 0, but complex IP may require a specific DEVSEL.
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mSetDevSel(XDmaBdV3* BdPtr, unsigned DevSel)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mSetDevSel(BdPtr, DevSel)                              \
+    {                                                                   \
+        u32 Dmacr;                                                  \
+        Dmacr = XDmaV3_mReadBd((BdPtr), XDMAV3_BD_DMACR_OFFSET);        \
+        Dmacr = Dmacr | (((DevSel) << XDMAV3_DMACR_DEVSEL_SHIFT) &      \
+                  XDMAV3_DMACR_DEVSEL_MASK);                            \
+        XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_DMACR_OFFSET, Dmacr);        \
+    }
+
+
+/*****************************************************************************/
+/**
+ * Set the Page field of the given BD. The Page must be in terms of a physical
+ * address. Use this macro if using 36 bit bus addressing.
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  Page is the page to set. LSB=1
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mSetBdPage(XDmaBdV3* BdPtr, unsigned Page)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mSetBdPage(BdPtr, Page)                                \
+    {                                                                   \
+        u32 Dmacr;                                                  \
+        Dmacr = XDmaV3_mReadBd((BdPtr), XDMAV3_BD_DMACR_OFFSET);        \
+        Dmacr = Dmacr | (((Page) << XDMAV3_DMACR_BDPAGE_SHIFT) &        \
+                  XDMAV3_DMACR_BDPAGE_MASK);                            \
+        XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_DMACR_OFFSET, Dmacr);        \
+    }
+
+
+/*****************************************************************************/
+/**
+ * Set transfer attributes for the given BD.
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  Type defines whether the transfer occurs with single beat or burst
+ *         transfers on the target bus. This parameter must be one of the
+ *         XDMAV3_DMACR_TYPE_*_MASK constants defined in xdma_l.h.
+ * @param  Width defines the width of the transfer as it occurs on the target
+ *         bus. This parameter must be one of the XDMAV3_DMACR_DSIZE_*_MASK
+ *         constants defined in xdma_l.h
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mSetTransferType(XDmaBdV3* BdPtr, unsigned Type,
+ *                                   unsigned Width)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mSetTransferType(BdPtr, Type, Width)                   \
+    (XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_DMACR_OFFSET,                   \
+         XDmaV3_mReadBd((BdPtr), XDMAV3_BD_DMACR_OFFSET) |              \
+         ((Type) & XDMAV3_DMACR_TYPE_MASK) | ((Width) & XDMAV3_DMACR_DSIZE_MASK)))
+
+
+/*****************************************************************************/
+/**
+ * Set transfer length in bytes for the given BD. The length must be set each
+ * time a BD is submitted to HW.
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  LenBytes is the number of bytes to transfer.
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mSetLength(XDmaBdV3* BdPtr, u32 LenBytes)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mSetLength(BdPtr, LenBytes)                            \
+    XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_LENGTH_OFFSET, (LenBytes))
+
+
+/*****************************************************************************/
+/**
+ * Write the given length to the length copy offset of the BD. This function
+ * is useful only if an application needs to recover the number of bytes
+ * originally set by XDmaBdV3_mSetLength() for Rx channels.
+ *
+ * To effectively use this function, an application would call
+ * XDmaBdV3_mSetLength() to set the length on a Rx descriptor, followed by a
+ * call to this macro to set the same length. When HW has processed the Rx
+ * descriptor it will overwrite the BD length field with the actual length of
+ * the packet. When the application performs post processing of the Rx
+ * descriptor, it can call XDmaBdV3_mGetLengthCopy() to find out how many bytes
+ * were originally allocated to the descriptor.
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  LenBytes is the number of bytes to transfer.
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mSetLengthCopy(XDmaBdV3* BdPtr, u32 LenBytes)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mSetLengthCopy(BdPtr, LenBytes)                            \
+    XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_LENCPY_OFFSET, (LenBytes))
+
+
+/*****************************************************************************/
+/**
+ * Set the high order address of the BD's buffer address. Use this macro when
+ * the address bus width is greater than 32 bits.
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  HighAddr is the high order address bits to set, LSB = 2^32.
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mSetBufAddrHigh(XDmaBdV3* BdPtr, u32 HighAddr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mSetBufAddrHigh(BdPtr, HighAddr)               \
+    (XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_MSBA_OFFSET, (u32)(HighAddr)))
+
+
+/*****************************************************************************/
+/**
+ * Set the low order address (bits 0..31) of the BD's buffer address.
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  LowAddr is the low order address bits to set, LSB = 1.
+ *
+ * @note
+ * C-style signature:
+ *    void XDmaBdV3_mSetBufAddrLow(XDmaBdV3* BdPtr, u32 LowAddr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mSetBufAddrLow(BdPtr, LowAddr)                 \
+    (XDmaV3_mWriteBd((BdPtr), XDMAV3_BD_LSBA_OFFSET, (u32)(LowAddr)))
+
+
+/*****************************************************************************/
+/**
+ * Get the high order address of the BD's buffer address. Use this macro when
+ * the address bus width is greater than 32 bits.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @note
+ * C-style signature:
+ *    u32 XDmaBdV3_mGetBufAddrHigh(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mGetBufAddrHigh(BdPtr)                 \
+    (XDmaV3_mReadBd((BdPtr), XDMAV3_BD_MSBA_OFFSET))
+
+
+/*****************************************************************************/
+/**
+ * Get the low order address (bits 0..31) of the BD's buffer address.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @note
+ * C-style signature:
+ *    u32 XDmaBdV3_mGetBufAddrLow(XDmaBdV3* BdPtr)
+ *
+ *****************************************************************************/
+#define XDmaBdV3_mGetBufAddrLow(BdPtr)                  \
+    (XDmaV3_mReadBd((BdPtr), XDMAV3_BD_LSBA_OFFSET))
+
+
+/************************** Function Prototypes ******************************/
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdma_channel.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xdma_channel.c
--- linux-2.6.31.12/drivers/xilinx_common/xdma_channel.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdma_channel.c	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,714 @@
+/* $Id: xdma_channel.c,v 1.1 2006/12/13 14:21:45 imanuilov Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2001-2004 Xilinx Inc.
+*       All rights reserved. 
+* This program is free software; you can redistribute it and/or modify it 
+* under the terms of the GNU General Public License as published by the 
+* Free Software Foundation; either version 2 of the License, or (at your 
+* option) any later version. 
+*
+* You should have received a copy of the GNU General Public License 
+* along with this program; if not, write to the Free Software 
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xdma_channel.c
+*
+* <b>Description</b>
+*
+* This file contains the DMA channel component. This component supports
+* a distributed DMA design in which each device can have it's own dedicated
+* DMA channel, as opposed to a centralized DMA design. This component
+* performs processing for DMA on all devices.
+*
+* See xdma_channel.h for more information about this component.
+*
+* @note
+*
+* None.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 1.00a xd  10/27/04  Doxygenated for inclusion in API documentation
+* 1.00b ecm 10/31/05  Updated for the check sum offload changes.
+* 1.00b xd  03/22/06  Fixed a multi-descriptor packet related bug that sgdma
+*                     engine is restarted in case no scatter gather disabled
+*                     bit is set yet
+* </pre>
+*
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include "xdma_channel.h"
+#include "xbasic_types.h"
+#include "xio.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+
+/*****************************************************************************/
+/**
+*
+* This function initializes a DMA channel.  This function must be called
+* prior to using a DMA channel.  Initialization of a channel includes setting
+* up the registers base address, and resetting the channel such that it's in a
+* known state.  Interrupts for the channel are disabled when the channel is
+* reset.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @param
+*
+* BaseAddress contains the base address of the registers for the DMA channel.
+*
+* @return
+*
+* XST_SUCCESS indicating initialization was successful.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+int XDmaChannel_Initialize(XDmaChannel * InstancePtr, u32 BaseAddress)
+{
+	/* assert to verify input arguments, don't assert base address */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+
+	/* setup the base address of the registers for the DMA channel such
+	 * that register accesses can be done
+	 */
+	InstancePtr->RegBaseAddress = BaseAddress;
+
+	/* initialize the scatter gather list such that it indicates it has not
+	 * been created yet and the DMA channel is ready to use (initialized)
+	 */
+	InstancePtr->GetPtr = NULL;
+	InstancePtr->PutPtr = NULL;
+	InstancePtr->CommitPtr = NULL;
+	InstancePtr->LastPtr = NULL;
+
+	InstancePtr->TotalDescriptorCount = 0;
+	InstancePtr->ActiveDescriptorCount = 0;
+
+	InstancePtr->ActivePacketCount = 0;
+	InstancePtr->Committed = FALSE;
+
+	InstancePtr->IsReady = XCOMPONENT_IS_READY;
+
+	/* initialize the version of the component
+	 */
+	XVersion_FromString(&InstancePtr->Version, "1.00a");
+
+	/* reset the DMA channel such that it's in a known state and ready
+	 * and indicate the initialization occurred with no errors, note that
+	 * the is ready variable must be set before this call or reset will assert
+	 */
+	XDmaChannel_Reset(InstancePtr);
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************/
+/**
+*
+* This function determines if a DMA channel component has been successfully
+* initialized such that it's ready to use.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* TRUE if the DMA channel component is ready, FALSE otherwise.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+u32 XDmaChannel_IsReady(XDmaChannel * InstancePtr)
+{
+	/* assert to verify input arguments used by the base component */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+
+	return InstancePtr->IsReady == XCOMPONENT_IS_READY;
+}
+
+/*****************************************************************************/
+/**
+*
+* This function gets the software version for the specified DMA channel
+* component.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* A pointer to the software version of the specified DMA channel.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+XVersion *XDmaChannel_GetVersion(XDmaChannel * InstancePtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* return a pointer to the version of the DMA channel */
+
+	return &InstancePtr->Version;
+}
+
+/*****************************************************************************/
+/**
+*
+* This function performs a self test on the specified DMA channel.  This self
+* test is destructive as the DMA channel is reset and a register default is
+* verified.
+*
+* @param
+*
+* InstancePtr is a pointer to the DMA channel to be operated on.
+*
+* @return
+*
+* XST_SUCCESS is returned if the self test is successful, or one of the
+* following errors.
+*                                       <br><br>
+* - XST_DMA_RESET_REGISTER_ERROR        Indicates the control register value
+*                                       after a reset was not correct
+*
+* @note
+*
+* This test does not performs a DMA transfer to test the channel because the
+* DMA hardware will not currently allow a non-local memory transfer to non-local
+* memory (memory copy), but only allows a non-local memory to or from the device
+* memory (typically a FIFO).
+*
+******************************************************************************/
+
+#define XDC_CONTROL_REG_RESET_MASK  0x98000000UL	/* control reg reset value */
+
+int XDmaChannel_SelfTest(XDmaChannel * InstancePtr)
+{
+	u32 ControlReg;
+
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* reset the DMA channel such that it's in a known state before the test
+	 * it resets to no interrupts enabled, the desired state for the test
+	 */
+	XDmaChannel_Reset(InstancePtr);
+
+	/* this should be the first test to help prevent a lock up with the polling
+	 * loop that occurs later in the test, check the reset value of the DMA
+	 * control register to make sure it's correct, return with an error if not
+	 */
+	ControlReg = XDmaChannel_GetControl(InstancePtr);
+	if (ControlReg != XDC_CONTROL_REG_RESET_MASK) {
+		return XST_DMA_RESET_REGISTER_ERROR;
+	}
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************/
+/**
+*
+* This function resets the DMA channel. This is a destructive operation such
+* that it should not be done while a channel is being used.  If the DMA channel
+* is transferring data into other blocks, such as a FIFO, it may be necessary
+* to reset other blocks.  This function does not modify the contents of a
+* scatter gather list for a DMA channel such that the user is responsible for
+* getting buffer descriptors from the list if necessary.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void XDmaChannel_Reset(XDmaChannel * InstancePtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* reset the DMA channel such that it's in a known state, the reset
+	 * register is self clearing such that it only has to be set
+	 */
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_RST_REG_OFFSET,
+		  XDC_RESET_MASK);
+}
+
+/*****************************************************************************/
+/**
+*
+* This function gets the control register contents of the DMA channel.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* The control register contents of the DMA channel. One or more of the
+* following values may be contained the register.  Each of the values are
+* unique bit masks.
+*                               <br><br>
+* - XDC_DMACR_SOURCE_INCR_MASK  Increment the source address
+*                               <br><br>
+* - XDC_DMACR_DEST_INCR_MASK    Increment the destination address
+*                               <br><br>
+* - XDC_DMACR_SOURCE_LOCAL_MASK Local source address
+*                               <br><br>
+* - XDC_DMACR_DEST_LOCAL_MASK   Local destination address
+*                               <br><br>
+* - XDC_DMACR_SG_ENABLE_MASK    Scatter gather enable
+*                               <br><br>
+* - XDC_DMACR_GEN_BD_INTR_MASK  Individual buffer descriptor interrupt
+*                               <br><br>
+* - XDC_DMACR_LAST_BD_MASK      Last buffer descriptor in a packet
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+u32 XDmaChannel_GetControl(XDmaChannel * InstancePtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* return the contents of the DMA control register */
+
+	return XIo_In32(InstancePtr->RegBaseAddress + XDC_DMAC_REG_OFFSET);
+}
+
+/*****************************************************************************/
+/**
+*
+* This function sets the control register of the specified DMA channel.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @param
+*
+* Control contains the value to be written to the control register of the DMA
+* channel. One or more of the following values may be contained the register.
+* Each of the values are unique bit masks such that they may be ORed together
+* to enable multiple bits or inverted and ANDed to disable multiple bits.
+* - XDC_DMACR_SOURCE_INCR_MASK  Increment the source address
+* - XDC_DMACR_DEST_INCR_MASK    Increment the destination address
+* - XDC_DMACR_SOURCE_LOCAL_MASK Local source address
+* - XDC_DMACR_DEST_LOCAL_MASK   Local destination address
+* - XDC_DMACR_SG_ENABLE_MASK    Scatter gather enable
+* - XDC_DMACR_GEN_BD_INTR_MASK  Individual buffer descriptor interrupt
+* - XDC_DMACR_LAST_BD_MASK      Last buffer descriptor in a packet
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void XDmaChannel_SetControl(XDmaChannel * InstancePtr, u32 Control)
+{
+	u32 Register;
+
+	/* assert to verify input arguments except the control which can't be
+	 * asserted since all values are valid
+	 */
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/*
+	 * set the DMA control register to the specified value, not altering the
+	 * other fields in the register
+	 */
+
+	Register = XIo_In32(InstancePtr->RegBaseAddress + XDC_DMAC_REG_OFFSET);
+	Register &= XDC_DMACR_TX_CS_INIT_MASK;
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_DMAC_REG_OFFSET,
+		  Register | Control);
+}
+
+/*****************************************************************************/
+/**
+*
+* This function gets the status register contents of the DMA channel.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* The status register contents of the DMA channel. One or more of the
+* following values may be contained the register. Each of the values are
+* unique bit masks.
+*                               <br><br>
+* - XDC_DMASR_BUSY_MASK         The DMA channel is busy
+*                               <br><br>
+* - XDC_DMASR_BUS_ERROR_MASK    A bus error occurred
+*                               <br><br>
+* - XDC_DMASR_BUS_TIMEOUT_MASK  A bus timeout occurred
+*                               <br><br>
+* - XDC_DMASR_LAST_BD_MASK      The last buffer descriptor of a packet
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+u32 XDmaChannel_GetStatus(XDmaChannel * InstancePtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* return the contents of the DMA status register */
+
+	return XIo_In32(InstancePtr->RegBaseAddress + XDC_DMAS_REG_OFFSET);
+}
+
+/*****************************************************************************/
+/**
+*
+* This function sets the interrupt status register of the specified DMA channel.
+* Setting any bit of the interrupt status register will clear the bit to
+* indicate the interrupt processing has been completed. The definitions of each
+* bit in the register match the definition of the bits in the interrupt enable
+* register.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @param
+*
+* Status contains the value to be written to the status register of the DMA
+* channel.  One or more of the following values may be contained the register.
+* Each of the values are unique bit masks such that they may be ORed together
+* to enable multiple bits or inverted and ANDed to disable multiple bits.
+* - XDC_IXR_DMA_DONE_MASK       The dma operation is done
+* - XDC_IXR_DMA_ERROR_MASK      The dma operation had an error
+* - XDC_IXR_PKT_DONE_MASK       A packet is complete
+* - XDC_IXR_PKT_THRESHOLD_MASK  The packet count threshold reached
+* - XDC_IXR_PKT_WAIT_BOUND_MASK The packet wait bound reached
+* - XDC_IXR_SG_DISABLE_ACK_MASK The scatter gather disable completed
+* - XDC_IXR_BD_MASK             A buffer descriptor is done
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void XDmaChannel_SetIntrStatus(XDmaChannel * InstancePtr, u32 Status)
+{
+	/* assert to verify input arguments except the status which can't be
+	 * asserted since all values are valid
+	 */
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* set the interrupt status register with the specified value such that
+	 * all bits which are set in the register are cleared effectively clearing
+	 * any active interrupts
+	 */
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_IS_REG_OFFSET, Status);
+}
+
+/*****************************************************************************/
+/**
+*
+* This function gets the interrupt status register of the specified DMA channel.
+* The interrupt status register indicates which interrupts are active
+* for the DMA channel.  If an interrupt is active, the status register must be
+* set (written) with the bit set for each interrupt which has been processed
+* in order to clear the interrupts.  The definitions of each bit in the register
+* match the definition of the bits in the interrupt enable register.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* The interrupt status register contents of the specified DMA channel.
+* One or more of the following values may be contained the register.
+* Each of the values are unique bit masks.
+*                               <br><br>
+* - XDC_IXR_DMA_DONE_MASK       The dma operation is done
+*                               <br><br>
+* - XDC_IXR_DMA_ERROR_MASK      The dma operation had an error
+*                               <br><br>
+* - XDC_IXR_PKT_DONE_MASK       A packet is complete
+*                               <br><br>
+* - XDC_IXR_PKT_THRESHOLD_MASK  The packet count threshold reached
+*                               <br><br>
+* - XDC_IXR_PKT_WAIT_BOUND_MASK The packet wait bound reached
+*                               <br><br>
+* - XDC_IXR_SG_DISABLE_ACK_MASK The scatter gather disable completed
+*                               <br><br>
+* - XDC_IXR_SG_END_MASK         Current descriptor was the end of the list
+*                               <br><br>
+* - XDC_IXR_BD_MASK             A buffer descriptor is done
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+u32 XDmaChannel_GetIntrStatus(XDmaChannel * InstancePtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* return the contents of the interrupt status register */
+
+	return XIo_In32(InstancePtr->RegBaseAddress + XDC_IS_REG_OFFSET);
+}
+
+/*****************************************************************************/
+/**
+*
+* This function sets the interrupt enable register of the specified DMA
+* channel.  The interrupt enable register contains bits which enable
+* individual interrupts for the DMA channel.  The definitions of each bit
+* in the register match the definition of the bits in the interrupt status
+* register.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @param
+*
+* Enable contains the interrupt enable register contents to be written
+* in the DMA channel. One or more of the following values may be contained
+* the register. Each of the values are unique bit masks such that they may be
+* ORed together to enable multiple bits or inverted and ANDed to disable
+* multiple bits.
+* - XDC_IXR_DMA_DONE_MASK       The dma operation is done
+* - XDC_IXR_DMA_ERROR_MASK      The dma operation had an error
+* - XDC_IXR_PKT_DONE_MASK       A packet is complete
+* - XDC_IXR_PKT_THRESHOLD_MASK  The packet count threshold reached
+* - XDC_IXR_PKT_WAIT_BOUND_MASK The packet wait bound reached
+* - XDC_IXR_SG_DISABLE_ACK_MASK The scatter gather disable completed
+* - XDC_IXR_SG_END_MASK         Current descriptor was the end of the list
+* - XDC_IXR_BD_MASK             A buffer descriptor is done
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void XDmaChannel_SetIntrEnable(XDmaChannel * InstancePtr, u32 Enable)
+{
+	/* assert to verify input arguments except the enable which can't be
+	 * asserted since all values are valid
+	 */
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* set the interrupt enable register to the specified value */
+
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_IE_REG_OFFSET, Enable);
+}
+
+/*****************************************************************************/
+/**
+*
+* This function gets the interrupt enable of the DMA channel.  The
+* interrupt enable contains flags which enable individual interrupts for the
+* DMA channel. The definitions of each bit in the register match the definition
+* of the bits in the interrupt status register.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @return
+*
+* The interrupt enable of the DMA channel.  One or more of the following values
+* may be contained the register. Each of the values are unique bit masks.
+*                               <br><br>
+* - XDC_IXR_DMA_DONE_MASK       The dma operation is done
+*                               <br><br>
+* - XDC_IXR_DMA_ERROR_MASK      The dma operation had an error
+*                               <br><br>
+* - XDC_IXR_PKT_DONE_MASK       A packet is complete
+*                               <br><br>
+* - XDC_IXR_PKT_THRESHOLD_MASK  The packet count threshold reached
+*                               <br><br>
+* - XDC_IXR_PKT_WAIT_BOUND_MASK The packet wait bound reached
+*                               <br><br>
+* - XDC_IXR_SG_DISABLE_ACK_MASK The scatter gather disable completed
+*                               <br><br>
+* - XDC_IXR_BD_MASK             A buffer descriptor is done
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+u32 XDmaChannel_GetIntrEnable(XDmaChannel * InstancePtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* return the contents of the interrupt enable register */
+
+	return XIo_In32(InstancePtr->RegBaseAddress + XDC_IE_REG_OFFSET);
+}
+
+/*****************************************************************************/
+/**
+*
+* This function starts the DMA channel transferring data from a memory source
+* to a memory destination. This function only starts the operation and returns
+* before the operation may be complete.  If the interrupt is enabled, an
+* interrupt will be generated when the operation is complete, otherwise it is
+* necessary to poll the channel status to determine when it's complete.  It is
+* the responsibility of the caller to determine when the operation is complete
+* by handling the generated interrupt or polling the status.  It is also the
+* responsibility of the caller to ensure that the DMA channel is not busy with
+* another transfer before calling this function.
+*
+* @param
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.
+*
+* @param
+*
+* SourcePtr contains a pointer to the source memory where the data is to
+* be transferred from and must be 32 bit aligned.
+*
+* @param
+*
+* DestinationPtr contains a pointer to the destination memory where the data
+* is to be transferred and must be 32 bit aligned.
+*
+* @param
+*
+* ByteCount contains the number of bytes to transfer during the DMA operation.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* The DMA hw will not currently allow a non-local memory transfer to non-local
+* memory (memory copy), but only allows a non-local memory to or from the device
+* memory (typically a FIFO).
+* <br><br>
+* It is the responsibility of the caller to ensure that the cache is
+* flushed and invalidated both before and after the DMA operation completes
+* if the memory pointed to is cached. The caller must also ensure that the
+* pointers contain a physical address rather than a virtual address
+* if address translation is being used.
+*
+******************************************************************************/
+void XDmaChannel_Transfer(XDmaChannel * InstancePtr,
+			  u32 *SourcePtr, u32 *DestinationPtr, u32 ByteCount)
+{
+	/* assert to verify input arguments and the alignment of any arguments
+	 * which have expected alignments
+	 */
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(SourcePtr != NULL);
+	XASSERT_VOID(((u32) SourcePtr & 3) == 0);
+	XASSERT_VOID(DestinationPtr != NULL);
+	XASSERT_VOID(((u32) DestinationPtr & 3) == 0);
+	XASSERT_VOID(ByteCount != 0);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* setup the source and destination address registers for the transfer */
+
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_SA_REG_OFFSET,
+		  (u32) SourcePtr);
+
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_DA_REG_OFFSET,
+		  (u32) DestinationPtr);
+
+	/* start the DMA transfer to copy from the source buffer to the
+	 * destination buffer by writing the length to the length register
+	 */
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_LEN_REG_OFFSET, ByteCount);
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdma_channel.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xdma_channel.h
--- linux-2.6.31.12/drivers/xilinx_common/xdma_channel.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdma_channel.h	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,314 @@
+/******************************************************************************
+*
+*     Author: Xilinx, Inc.
+*
+*
+*     This program is free software; you can redistribute it and/or modify it
+*     under the terms of the GNU General Public License as published by the
+*     Free Software Foundation; either version 2 of the License, or (at your
+*     option) any later version.
+*
+*
+*     XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS" AS A
+*     COURTESY TO YOU. BY PROVIDING THIS DESIGN, CODE, OR INFORMATION AS
+*     ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE, APPLICATION OR STANDARD,
+*     XILINX IS MAKING NO REPRESENTATION THAT THIS IMPLEMENTATION IS FREE
+*     FROM ANY CLAIMS OF INFRINGEMENT, AND YOU ARE RESPONSIBLE FOR OBTAINING
+*     ANY THIRD PARTY RIGHTS YOU MAY REQUIRE FOR YOUR IMPLEMENTATION.
+*     XILINX EXPRESSLY DISCLAIMS ANY WARRANTY WHATSOEVER WITH RESPECT TO
+*     THE ADEQUACY OF THE IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY
+*     WARRANTIES OR REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM
+*     CLAIMS OF INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND
+*     FITNESS FOR A PARTICULAR PURPOSE.
+*
+*
+*     Xilinx hardware products are not intended for use in life support
+*     appliances, devices, or systems. Use in such applications is
+*     expressly prohibited.
+*
+*
+*     (c) Copyright 2002-2004 Xilinx Inc.
+*     All rights reserved.
+*
+*
+*     You should have received a copy of the GNU General Public License along
+*     with this program; if not, write to the Free Software Foundation, Inc.,
+*     675 Mass Ave, Cambridge, MA 02139, USA.
+*
+* FILENAME:
+*
+* xdma_channel.h
+*
+* DESCRIPTION:
+*
+* This file contains the DMA channel component implementation. This component
+* supports a distributed DMA design in which each device can have it's own
+* dedicated DMA channel, as opposed to a centralized DMA design.
+* A device which uses DMA typically contains two DMA channels, one for
+* sending data and the other for receiving data.
+*
+* This component is designed to be used as a basic building block for
+* designing a device driver. It provides registers accesses such that all
+* DMA processing can be maintained easier, but the device driver designer
+* must still understand all the details of the DMA channel.
+*
+* The DMA channel allows a CPU to minimize the CPU interaction required to move
+* data between a memory and a device.  The CPU requests the DMA channel to
+* perform a DMA operation and typically continues performing other processing
+* until the DMA operation completes.  DMA could be considered a primitive form
+* of multiprocessing such that caching and address translation can be an issue.
+*
+* Scatter Gather Operations
+*
+* The DMA channel may support scatter gather operations. A scatter gather
+* operation automates the DMA channel such that multiple buffers can be
+* sent or received with minimal software interaction with the hardware.  Buffer
+* descriptors, contained in the XBufDescriptor component, are used by the
+* scatter gather operations of the DMA channel to describe the buffers to be
+* processed.
+*
+* Scatter Gather List Operations
+*
+* A scatter gather list may be supported by each DMA channel.  The scatter
+* gather list allows buffer descriptors to be put into the list by a device
+* driver which requires scatter gather.  The hardware processes the buffer
+* descriptors which are contained in the list and modifies the buffer
+* descriptors to reflect the status of the DMA operations.  The device driver
+* is notified by interrupt that specific DMA events occur including scatter
+* gather events.  The device driver removes the completed buffer descriptors
+* from the scatter gather list to evaluate the status of each DMA operation.
+*
+* The scatter gather list is created and buffer descriptors are inserted into
+* the list.  Buffer descriptors are never removed from the list after it's
+* creation such that a put operation copies from a temporary buffer descriptor
+* to a buffer descriptor in the list.  Get operations don't copy from the list
+* to a temporary, but return a pointer to the buffer descriptor in the list.
+* A buffer descriptor in the list may be locked to prevent it from being
+* overwritten by a put operation.  This allows the device driver to get a
+* descriptor from a scatter gather list and prevent it from being overwritten
+* until the buffer associated with the buffer descriptor has been processed.
+*
+* Typical Scatter Gather Processing
+*
+* The following steps illustrate the typical processing to use the
+* scatter gather features of a DMA channel.
+*
+* 1. Create a scatter gather list for the DMA channel which puts empty buffer
+*    descriptors into the list.
+* 2. Create buffer descriptors which describe the buffers to be filled with
+*    receive data or the buffers which contain data to be sent.
+* 3. Put buffer descriptors into the DMA channel scatter list such that scatter
+*    gather operations are requested.
+* 4. Commit the buffer descriptors in the list such that they are ready to be
+*    used by the DMA channel hardware.
+* 5. Start the scatter gather operations of the DMA channel.
+* 6. Process any interrupts which occur as a result of the scatter gather
+*    operations or poll the DMA channel to determine the status.
+*
+* Interrupts
+*
+* Each DMA channel has the ability to generate an interrupt.  This component
+* does not perform processing for the interrupt as this processing is typically
+* tightly coupled with the device which is using the DMA channel.  It is the
+* responsibility of the caller of DMA functions to manage the interrupt
+* including connecting to the interrupt and enabling/disabling the interrupt.
+*
+* Critical Sections
+*
+* It is the responsibility of the device driver designer to use critical
+* sections as necessary when calling functions of the DMA channel.  This
+* component does not use critical sections and it does access registers using
+* read-modify-write operations.  Calls to DMA functions from a main thread
+* and from an interrupt context could produce unpredictable behavior such that
+* the caller must provide the appropriate critical sections.
+*
+* Address Translation
+*
+* All addresses of data structures which are passed to DMA functions must
+* be physical (real) addresses as opposed to logical (virtual) addresses.
+*
+* Caching
+*
+* The memory which is passed to the function which creates the scatter gather
+* list must not be cached such that buffer descriptors are non-cached.  This
+* is necessary because the buffer descriptors are kept in a ring buffer and
+* not directly accessible to the caller of DMA functions.
+*
+* The caller of DMA functions is responsible for ensuring that any data
+* buffers which are passed to the DMA channel are cache-line aligned if
+* necessary.
+*
+* The caller of DMA functions is responsible for ensuring that any data
+* buffers which are passed to the DMA channel have been flushed from the cache.
+*
+* The caller of DMA functions is responsible for ensuring that the cache is
+* invalidated prior to using any data buffers which are the result of a DMA
+* operation.
+*
+* Memory Alignment
+*
+* The addresses of data buffers which are passed to DMA functions must be
+* 32 bit word aligned since the DMA hardware performs 32 bit word transfers.
+*
+* Mutual Exclusion
+*
+* The functions of the DMA channel are not thread safe such that the caller
+* of all DMA functions is responsible for ensuring mutual exclusion for a
+* DMA channel.  Mutual exclusion across multiple DMA channels is not
+* necessary.
+*
+* NOTES:
+*
+* Many of the provided functions which are register accessors don't provide
+* a lot of error detection. The caller is expected to understand the impact
+* of a function call based upon the current state of the DMA channel.  This
+* is done to minimize the overhead in this component.
+*
+******************************************************************************/
+
+#ifndef XDMA_CHANNEL_H		/* prevent circular inclusions */
+#define XDMA_CHANNEL_H		/* by using protection macros */
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xstatus.h"
+#include "xversion.h"
+#include "xbuf_descriptor.h"
+#include "xdma_channel_i.h"	/* constants shared with buffer descriptor */
+
+/************************** Constant Definitions *****************************/
+
+/* the following constants provide access to the bit fields of the DMA control
+ * register (DMACR)
+ */
+#define XDC_DMACR_SOURCE_INCR_MASK  0x80000000UL	/* increment source address */
+#define XDC_DMACR_DEST_INCR_MASK    0x40000000UL	/* increment dest address */
+#define XDC_DMACR_SOURCE_LOCAL_MASK 0x20000000UL	/* local source address */
+#define XDC_DMACR_DEST_LOCAL_MASK   0x10000000UL	/* local dest address */
+#define XDC_DMACR_SG_DISABLE_MASK   0x08000000UL	/* scatter gather disable */
+#define XDC_DMACR_GEN_BD_INTR_MASK  0x04000000UL	/* descriptor interrupt */
+#define XDC_DMACR_LAST_BD_MASK      XDC_CONTROL_LAST_BD_MASK	/* last buffer */
+				    /*     descriptor  */
+#define XDC_DMACR_DRE_MODE_MASK     0x01000000UL	/* DRE/normal mode */
+
+#define XDC_DMACR_TX_CS_INIT_MASK    0x0000FFFFUL	/* Initial value for TX
+							   CS offload */
+#define XDC_DMACR_CS_OFFLOAD_MASK    0x00800000UL	/* Enable CS offload */
+
+/* the following constants provide access to the bit fields of the DMA status
+ * register (DMASR)
+ */
+#define XDC_DMASR_BUSY_MASK         0x80000000UL	/* channel is busy */
+#define XDC_DMASR_BUS_ERROR_MASK    0x40000000UL	/* bus error occurred */
+#define XDC_DMASR_BUS_TIMEOUT_MASK  0x20000000UL	/* bus timeout occurred */
+#define XDC_DMASR_LAST_BD_MASK      XDC_STATUS_LAST_BD_MASK	/* last buffer */
+				/* descriptor  */
+#define XDC_DMASR_SG_BUSY_MASK      0x08000000UL	/* scatter gather is busy */
+/* @} */
+
+/** @name DMA destination address register bit fields when checksum offload is
+ * used
+ *
+ * the following constants provide access to the bit fields of the
+ * Destination Address Register (DAREG)
+ * @{
+ */
+#define XDC_DAREG_CS_BEGIN_MASK      0xFFFF0000UL	/* byte position to begin
+							   checksum calculation */
+#define XDC_DAREG_CS_INSERT_MASK     0x0000FFFFUL	/* byte position to place
+							   calculated checksum */
+/* the following constants provide access to the bit fields of the interrupt
+ * status register (ISR) and the interrupt enable register (IER), bit masks
+ * match for both registers such that they are named IXR
+ */
+#define XDC_IXR_DMA_DONE_MASK       0x1UL	/* dma operation done */
+#define XDC_IXR_DMA_ERROR_MASK      0x2UL	/* dma operation error */
+#define XDC_IXR_PKT_DONE_MASK       0x4UL	/* packet done */
+#define XDC_IXR_PKT_THRESHOLD_MASK  0x8UL	/* packet count threshold */
+#define XDC_IXR_PKT_WAIT_BOUND_MASK 0x10UL	/* packet wait bound reached */
+#define XDC_IXR_SG_DISABLE_ACK_MASK 0x20UL	/* scatter gather disable
+						   acknowledge occurred */
+#define XDC_IXR_SG_END_MASK         0x40UL	/* last buffer descriptor
+						   disabled scatter gather */
+#define XDC_IXR_BD_MASK             0x80UL	/* buffer descriptor done */
+
+/**************************** Type Definitions *******************************/
+
+/*
+ * the following structure contains data which is on a per instance basis
+ * for the XDmaChannel component
+ */
+typedef struct XDmaChannelTag {
+	XVersion Version;	/* version of the driver */
+	u32 RegBaseAddress;	/* base address of registers */
+	u32 IsReady;		/* device is initialized and ready */
+
+	XBufDescriptor *PutPtr;	/* keep track of where to put into list */
+	XBufDescriptor *GetPtr;	/* keep track of where to get from list */
+	XBufDescriptor *CommitPtr;	/* keep track of where to commit in list */
+	XBufDescriptor *LastPtr;	/* keep track of the last put in the list */
+	void *VirtPtr;		/* virtual base of memory */
+	void *PhyPtr;		/* physical base of memory */
+	u32 TotalDescriptorCount;	/* total # of descriptors in the list */
+	u32 ActiveDescriptorCount;	/* # of descriptors pointing to buffers
+					 * in the buffer descriptor list */
+	u32 ActivePacketCount;	/* # of packets that have been put into
+				   the list and transmission confirmation
+				   have not been received by the driver */
+	u32 Committed;		/* CommitPuts is called? */
+} XDmaChannel;
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/************************** Function Prototypes ******************************/
+
+int XDmaChannel_Initialize(XDmaChannel * InstancePtr, u32 BaseAddress);
+u32 XDmaChannel_IsReady(XDmaChannel * InstancePtr);
+XVersion *XDmaChannel_GetVersion(XDmaChannel * InstancePtr);
+int XDmaChannel_SelfTest(XDmaChannel * InstancePtr);
+void XDmaChannel_Reset(XDmaChannel * InstancePtr);
+
+/* Control functions */
+
+u32 XDmaChannel_GetControl(XDmaChannel * InstancePtr);
+void XDmaChannel_SetControl(XDmaChannel * InstancePtr, u32 Control);
+
+/* Status functions */
+
+u32 XDmaChannel_GetStatus(XDmaChannel * InstancePtr);
+void XDmaChannel_SetIntrStatus(XDmaChannel * InstancePtr, u32 Status);
+u32 XDmaChannel_GetIntrStatus(XDmaChannel * InstancePtr);
+void XDmaChannel_SetIntrEnable(XDmaChannel * InstancePtr, u32 Enable);
+u32 XDmaChannel_GetIntrEnable(XDmaChannel * InstancePtr);
+
+/* DMA without scatter gather functions */
+
+void XDmaChannel_Transfer(XDmaChannel * InstancePtr,
+			  u32 *SourcePtr, u32 *DestinationPtr, u32 ByteCount);
+
+/* Scatter gather functions */
+
+int XDmaChannel_SgStart(XDmaChannel * InstancePtr);
+int XDmaChannel_SgStop(XDmaChannel * InstancePtr,
+		       XBufDescriptor ** BufDescriptorPtr);
+int XDmaChannel_CreateSgList(XDmaChannel * InstancePtr,
+			     u32 *MemoryPtr, u32 ByteCount, void *PhyPtr);
+u32 XDmaChannel_IsSgListEmpty(XDmaChannel * InstancePtr);
+
+int XDmaChannel_PutDescriptor(XDmaChannel * InstancePtr,
+			      XBufDescriptor * BufDescriptorPtr);
+int XDmaChannel_CommitPuts(XDmaChannel * InstancePtr);
+int XDmaChannel_GetDescriptor(XDmaChannel * InstancePtr,
+			      XBufDescriptor ** BufDescriptorPtr);
+
+/* Packet functions for interrupt collescing */
+
+u32 XDmaChannel_GetPktCount(XDmaChannel * InstancePtr);
+void XDmaChannel_DecrementPktCount(XDmaChannel * InstancePtr);
+int XDmaChannel_SetPktThreshold(XDmaChannel * InstancePtr, u8 Threshold);
+u8 XDmaChannel_GetPktThreshold(XDmaChannel * InstancePtr);
+void XDmaChannel_SetPktWaitBound(XDmaChannel * InstancePtr, u32 WaitBound);
+u32 XDmaChannel_GetPktWaitBound(XDmaChannel * InstancePtr);
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdma_channel_i.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xdma_channel_i.h
--- linux-2.6.31.12/drivers/xilinx_common/xdma_channel_i.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdma_channel_i.h	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,131 @@
+/* $Id: xdma_channel_i.h,v 1.1 2006/12/13 14:22:04 imanuilov Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2001-2004 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xdma_channel_i.h
+*
+* <b>Description</b>
+*
+* This file contains data which is shared internal data for the DMA channel
+* component. It is also shared with the buffer descriptor component which is
+* very tightly coupled with the DMA channel component.
+*
+* @note
+*
+* The last buffer descriptor constants must be located here to prevent a
+* circular dependency between the DMA channel component and the buffer
+* descriptor component.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 1.00a xd   10/27/04 Doxygenated for inclusion in API documentation
+* 1.00b ecm  10/31/05 Updated for the check sum offload changes.
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XDMA_CHANNEL_I_H	/* prevent circular inclusions */
+#define XDMA_CHANNEL_I_H	/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xstatus.h"
+#include "xversion.h"
+
+/************************** Constant Definitions *****************************/
+
+#define XDC_DMA_CHANNEL_V1_00_B     "1.00b"
+
+/** @name DMA control register bit fields
+ *
+ * the following constant provides access to the bit fields of the DMA control
+ * register (DMACR) which must be shared between the DMA channel component
+ * and the buffer descriptor component
+ * @{
+ */
+#define XDC_CONTROL_LAST_BD_MASK    0x02000000UL /**< last buffer descriptor */
+/* @} */
+
+/** @name DMA status register bit fields
+ *
+ * the following constant provides access to the bit fields of the DMA status
+ * register (DMASR) which must be shared between the DMA channel component
+ * and the buffer descriptor component
+ * @{
+ */
+#define XDC_STATUS_LAST_BD_MASK     0x10000000UL /**< last buffer descriptor */
+
+#define XDC_DMASR_RX_CS_RAW_MASK    0xFFFF0000UL /**< RAW CS value for RX data */
+/* @} */
+
+/** @name DMA Channel register offsets
+ *
+ * the following constants provide access to each of the registers of a DMA
+ * channel
+ * @{
+ */
+#define XDC_RST_REG_OFFSET  0	/**< reset register */
+#define XDC_MI_REG_OFFSET   0	/**< module information register */
+#define XDC_DMAC_REG_OFFSET 4	/**< DMA control register */
+#define XDC_SA_REG_OFFSET   8	/**< source address register */
+#define XDC_DA_REG_OFFSET   12	/**< destination address register */
+#define XDC_LEN_REG_OFFSET  16	/**< length register */
+#define XDC_DMAS_REG_OFFSET 20	/**< DMA status register */
+#define XDC_BDA_REG_OFFSET  24	/**< buffer descriptor address register */
+#define XDC_SWCR_REG_OFFSET 28	/**< software control register */
+#define XDC_UPC_REG_OFFSET  32	/**< unserviced packet count register */
+#define XDC_PCT_REG_OFFSET  36	/**< packet count threshold register */
+#define XDC_PWB_REG_OFFSET  40	/**< packet wait bound register */
+#define XDC_IS_REG_OFFSET   44	/**< interrupt status register */
+#define XDC_IE_REG_OFFSET   48	/**< interrupt enable register */
+/* @} */
+
+/**
+ * the following constant is written to the reset register to reset the
+ * DMA channel
+ */
+#define XDC_RESET_MASK              0x0000000AUL
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdma_channel_sg.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xdma_channel_sg.c
--- linux-2.6.31.12/drivers/xilinx_common/xdma_channel_sg.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdma_channel_sg.c	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,1327 @@
+/******************************************************************************
+*
+*     Author: Xilinx, Inc.
+*
+*
+*     This program is free software; you can redistribute it and/or modify it
+*     under the terms of the GNU General Public License as published by the
+*     Free Software Foundation; either version 2 of the License, or (at your
+*     option) any later version.
+*
+*
+*     XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS" AS A
+*     COURTESY TO YOU. BY PROVIDING THIS DESIGN, CODE, OR INFORMATION AS
+*     ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE, APPLICATION OR STANDARD,
+*     XILINX IS MAKING NO REPRESENTATION THAT THIS IMPLEMENTATION IS FREE
+*     FROM ANY CLAIMS OF INFRINGEMENT, AND YOU ARE RESPONSIBLE FOR OBTAINING
+*     ANY THIRD PARTY RIGHTS YOU MAY REQUIRE FOR YOUR IMPLEMENTATION.
+*     XILINX EXPRESSLY DISCLAIMS ANY WARRANTY WHATSOEVER WITH RESPECT TO
+*     THE ADEQUACY OF THE IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY
+*     WARRANTIES OR REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM
+*     CLAIMS OF INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND
+*     FITNESS FOR A PARTICULAR PURPOSE.
+*
+*
+*     Xilinx hardware products are not intended for use in life support
+*     appliances, devices, or systems. Use in such applications is
+*     expressly prohibited.
+*
+*
+*     (c) Copyright 2002-2004 Xilinx Inc.
+*     All rights reserved.
+*
+*
+*     You should have received a copy of the GNU General Public License along
+*     with this program; if not, write to the Free Software Foundation, Inc.,
+*     675 Mass Ave, Cambridge, MA 02139, USA.
+*
+* FILENAME:
+*
+* xdma_channel_sg.c
+*
+* DESCRIPTION:
+*
+* This file contains the implementation of the XDmaChannel component which is
+* related to scatter gather operations.
+*
+* Scatter Gather Operations
+*
+* The DMA channel may support scatter gather operations. A scatter gather
+* operation automates the DMA channel such that multiple buffers can be
+* sent or received with minimal software interaction with the hardware.  Buffer
+* descriptors, contained in the XBufDescriptor component, are used by the
+* scatter gather operations of the DMA channel to describe the buffers to be
+* processed.
+*
+* Scatter Gather List Operations
+*
+* A scatter gather list may be supported by each DMA channel.  The scatter
+* gather list allows buffer descriptors to be put into the list by a device
+* driver which requires scatter gather.  The hardware processes the buffer
+* descriptors which are contained in the list and modifies the buffer
+* descriptors to reflect the status of the DMA operations.  The device driver
+* is notified by interrupt that specific DMA events occur including scatter
+* gather events.  The device driver removes the completed buffer descriptors
+* from the scatter gather list to evaluate the status of each DMA operation.
+*
+* The scatter gather list is created and buffer descriptors are inserted into
+* the list.  Buffer descriptors are never removed from the list after it's
+* creation such that a put operation copies from a temporary buffer descriptor
+* to a buffer descriptor in the list.  Get operations don't copy from the list
+* to a temporary, but return a pointer to the buffer descriptor in the list.
+* A buffer descriptor in the list may be locked to prevent it from being
+* overwritten by a put operation.  This allows the device driver to get a
+* descriptor from a scatter gather list and prevent it from being overwritten
+* until the buffer associated with the buffer descriptor has been processed.
+*
+* The get and put functions only operate on the list and are asynchronous from
+* the hardware which may be using the list of descriptors.  This is important
+* because there are no checks in the get and put functions to ensure that the
+* hardware has processed the descriptors.  This must be handled by the driver
+* using the DMA scatter gather channel through the use of the other functions.
+* When a scatter gather operation is started, the start function does ensure
+* that the descriptor to start has not already been processed by the hardware
+* and is not the first of a series of descriptors that have not been committed
+* yet.
+*
+* Descriptors are put into the list but not marked as ready to use by the
+* hardware until a commit operation is done.  This allows multiple descriptors
+* which may contain a single packet of information for a protocol to be
+* guaranteed not to cause any underflow conditions during transmission. The
+* hardware design only allows descriptors to cause it to stop after a descriptor
+* has been processed rather than before it is processed.  A series of
+* descriptors are put into the list followed by a commit operation, or each
+* descriptor may be commited.  A commit operation is performed by changing a
+* single descriptor, the first of the series of puts, to indicate that the
+* hardware may now use all descriptors after it.  The last descriptor in the
+* list is always set to cause the hardware to stop after it is processed.
+*
+* Typical Scatter Gather Processing
+*
+* The following steps illustrate the typical processing to use the
+* scatter gather features of a DMA channel.
+*
+* 1. Create a scatter gather list for the DMA channel which puts empty buffer
+*    descriptors into the list.
+* 2. Create buffer descriptors which describe the buffers to be filled with
+*    receive data or the buffers which contain data to be sent.
+* 3. Put buffer descriptors into the DMA channel scatter list such that scatter
+*    gather operations are requested.
+* 4. Commit the buffer descriptors in the list such that they are ready to be
+*    used by the DMA channel hardware.
+* 5. Start the scatter gather operations of the DMA channel.
+* 6. Process any interrupts which occur as a result of the scatter gather
+*    operations or poll the DMA channel to determine the status.  This may
+*    be accomplished by getting the packet count for the channel and then
+*    getting the appropriate number of descriptors from the list for that
+*    number of packets.
+*
+* Minimizing Interrupts
+*
+* The Scatter Gather operating mode is designed to reduce the amount of CPU
+* throughput necessary to manage the hardware for devices. A key to the CPU
+* throughput is the number and rate of interrupts that the CPU must service.
+* Devices with higher data rates can cause larger numbers of interrupts and
+* higher frequency interrupts. Ideally the number of interrupts can be reduced
+* by only generating an interrupt when a specific amount of data has been
+* received from the interface. This design suffers from a lack of interrupts
+* when the amount of data received is less than the specified amount of data
+* to generate an interrupt. In order to help minimize the number of interrupts
+* which the CPU must service, an algorithm referred to as "interrupt coalescing"
+* is utilized.
+*
+* Interrupt Coalescing
+*
+* The principle of interrupt coalescing is to wait before generating an
+* interrupt until a certain number of packets have been received or sent. An
+* interrupt is also generated if a smaller number of packets have been received
+* followed by a certain period of time with no packet reception. This is a
+* trade-off of latency for bandwidth and is accomplished using several
+* mechanisms of the hardware including a counter for packets received or
+* transmitted and a packet timer. These two hardware mechanisms work in
+* combination to allow a reduction in the number of interrupts processed by the
+* CPU for packet reception.
+*
+* Unserviced Packet Count
+*
+* The purpose of the packet counter is to count the number of packets received
+* or transmitted and provide an interrupt when a specific number of packets
+* have been processed by the hardware. An interrupt is generated whenever the
+* counter is greater than or equal to the Packet Count Threshold. This counter
+* contains an accurate count of the number of packets that the hardware has
+* processed, either received or transmitted, and the software has not serviced.
+*
+* The packet counter allows the number of interrupts to be reduced by waiting
+* to generate an interrupt until enough packets are received. For packet
+* reception, packet counts of less than the number to generate an interrupt
+* would not be serviced without the addition of a packet timer. This counter is
+* continuously updated by the hardware, not latched to the value at the time
+* the interrupt occurred.
+*
+* The packet counter can be used within the interrupt service routine for the
+* device to reduce the number of interrupts. The interrupt service routine
+* loops while performing processing for each packet which has been received or
+* transmitted and decrements the counter by a specified value. At the same time,
+* the hardware is possibly continuing to receive or transmit more packets such
+* that the software may choose, based upon the value in the packet counter, to
+* remain in the interrupt service routine rather than exiting and immediately
+* returning. This feature should be used with caution as reducing the number of
+* interrupts is beneficial, but unbounded interrupt processing is not desirable.
+*
+* Since the hardware may be incrementing the packet counter simultaneously
+* with the software decrementing the counter, there is a need for atomic
+* operations. The hardware ensures that the operation is atomic such that
+* simultaneous accesses are properly handled.
+*
+* Packet Wait Bound
+*
+* The purpose of the packet wait bound is to augment the unserviced packet
+* count. Whenever there is no pending interrupt for the channel and the
+* unserviced packet count is non-zero, a timer starts counting timeout at the
+* value contained the the packet wait bound register.  If the timeout is
+* reached, an interrupt is generated such that the software may service the
+* data which was buffered.
+*
+* NOTES:
+*
+* Special Test Conditions:
+*
+* The scatter gather list processing must be thoroughly tested if changes are
+* made.  Testing should include putting and committing single descriptors and
+* putting multiple descriptors followed by a single commit.  There are some
+* conditions in the code which handle the exception conditions.
+*
+* The Put Pointer points to the next location in the descriptor list to copy
+* in a new descriptor. The Get Pointer points to the next location in the
+* list to get a descriptor from.  The Get Pointer only allows software to
+* have a traverse the list after the hardware has finished processing some
+* number of descriptors.  The Commit Pointer points to the descriptor in the
+* list which is to be committed.  It is also used to determine that no
+* descriptor is waiting to be commited (NULL).  The Last Pointer points to
+* the last descriptor that was put into the list.  It typically points
+* to the previous descriptor to the one pointed to by the Put Pointer.
+* Comparisons are done between these pointers to determine when the following
+* special conditions exist.
+
+* Single Put And Commit
+*
+* The buffer descriptor is ready to be used by the hardware so it is important
+* for the descriptor to not appear to be waiting to be committed.  The commit
+* pointer is reset when a commit is done indicating there are no descriptors
+* waiting to be committed.  In all cases but this one, the descriptor is
+* changed to cause the hardware to go to the next descriptor after processing
+* this one.  But in this case, this is the last descriptor in the list such
+* that it must not be changed.
+*
+* 3 Or More Puts And Commit
+*
+* A series of 3 or more puts followed by a single commit is different in that
+* only the 1st descriptor put into the list is changed when the commit is done.
+* This requires each put starting on the 3rd to change the previous descriptor
+* so that it allows the hardware to continue to the next descriptor in the list.
+*
+* The 1st Put Following A Commit
+*
+* The commit caused the commit pointer to be NULL indicating that there are no
+* descriptors waiting to be committed.  It is necessary for the next put to set
+* the commit pointer so that a commit must follow the put for the hardware to
+* use the descriptor.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- ------------------------------------------------------
+* 1.00a rpm  02/03/03 Removed the XST_DMA_SG_COUNT_EXCEEDED return code
+*                     from SetPktThreshold.
+* </pre>
+*
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include "xdma_channel.h"
+#include "xbasic_types.h"
+#include "xio.h"
+#include "xbuf_descriptor.h"
+#include "xstatus.h"
+
+/* simple virt<-->phy pointer conversions for a single dma channel */
+#define P_TO_V(p) \
+    ((p) ? \
+     (InstancePtr->VirtPtr + ((u32)(p) - (u32)InstancePtr->PhyPtr)) : \
+     0)
+
+#define V_TO_P(v) \
+    ((v) ? \
+     (InstancePtr->PhyPtr + ((u32)(v) - (u32)InstancePtr->VirtPtr)) : \
+     0)
+
+/************************** Constant Definitions *****************************/
+
+#define XDC_SWCR_SG_ENABLE_MASK 0x80000000UL	/* scatter gather enable */
+
+/**************************** Type Definitions *******************************/
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/* the following macro copies selected fields of a buffer descriptor to another
+ * buffer descriptor, this was provided by the buffer descriptor component but
+ * was moved here since it is only used internally to this component and since
+ * it does not copy all fields
+ */
+#define CopyBufferDescriptor(InstancePtr, DestinationPtr)          \
+{                                                                  \
+    *((u32 *)DestinationPtr + XBD_CONTROL_OFFSET) =            \
+        *((u32 *)InstancePtr + XBD_CONTROL_OFFSET);            \
+    *((u32 *)DestinationPtr + XBD_SOURCE_OFFSET) =             \
+        *((u32 *)InstancePtr + XBD_SOURCE_OFFSET);             \
+    *((u32 *)DestinationPtr + XBD_DESTINATION_OFFSET) =        \
+        *((u32 *)InstancePtr + XBD_DESTINATION_OFFSET);        \
+    *((u32 *)DestinationPtr + XBD_LENGTH_OFFSET) =             \
+        *((u32 *)InstancePtr + XBD_LENGTH_OFFSET);             \
+    *((u32 *)DestinationPtr + XBD_STATUS_OFFSET) =             \
+        *((u32 *)InstancePtr + XBD_STATUS_OFFSET);             \
+    *((u32 *)DestinationPtr + XBD_DEVICE_STATUS_OFFSET) =      \
+        *((u32 *)InstancePtr + XBD_DEVICE_STATUS_OFFSET);      \
+    *((u32 *)DestinationPtr + XBD_ID_OFFSET) =                 \
+        *((u32 *)InstancePtr + XBD_ID_OFFSET);                 \
+    *((u32 *)DestinationPtr + XBD_FLAGS_OFFSET) =              \
+        *((u32 *)InstancePtr + XBD_FLAGS_OFFSET);              \
+    *((u32 *)DestinationPtr + XBD_RQSTED_LENGTH_OFFSET) =      \
+        *((u32 *)InstancePtr + XBD_RQSTED_LENGTH_OFFSET);      \
+}
+
+/************************** Variable Definitions *****************************/
+
+/************************** Function Prototypes ******************************/
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_SgStart
+*
+* DESCRIPTION:
+*
+* This function starts a scatter gather operation for a scatter gather
+* DMA channel.  The first buffer descriptor in the buffer descriptor list
+* will be started with the scatter gather operation.  A scatter gather list
+* should have previously been created for the DMA channel and buffer
+* descriptors put into the scatter gather list such that there are scatter
+* operations ready to be performed.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* RETURN VALUE:
+*
+* A status containing XST_SUCCESS if scatter gather was started successfully
+* for the DMA channel.
+*
+* A value of XST_DMA_SG_NO_LIST indicates the scatter gather list has not
+* been created.
+*
+* A value of XST_DMA_SG_LIST_EMPTY indicates scatter gather was not started
+* because the scatter gather list of the DMA channel does not contain any
+* buffer descriptors that are ready to be processed by the hardware.
+*
+* A value of XST_DMA_SG_IS_STARTED indicates scatter gather was not started
+* because the scatter gather was not stopped, but was already started.
+*
+* A value of XST_DMA_SG_BD_NOT_COMMITTED indicates the buffer descriptor of
+* scatter gather list which was to be started is not committed to the list.
+* This status is more likely if this function is being called from an ISR
+* and non-ISR processing is putting descriptors into the list.
+*
+* A value of XST_DMA_SG_NO_DATA indicates that the buffer descriptor of the
+* scatter gather list which was to be started had already been used by the
+* hardware for a DMA transfer that has been completed.
+*
+* NOTES:
+*
+* It is the responsibility of the caller to get all the buffer descriptors
+* after performing a stop operation and before performing a start operation.
+* If buffer descriptors are not retrieved between stop and start operations,
+* buffer descriptors may be processed by the hardware more than once.
+*
+******************************************************************************/
+int XDmaChannel_SgStart(XDmaChannel * InstancePtr)
+{
+	u32 Register;
+	XBufDescriptor *LastDescriptorPtr;
+
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* if a scatter gather list has not been created yet, return a status */
+
+	if (InstancePtr->TotalDescriptorCount == 0) {
+		return XST_DMA_SG_NO_LIST;
+	}
+
+	/* if the scatter gather list exists but is empty then return a status */
+
+	if (XDmaChannel_IsSgListEmpty(InstancePtr)) {
+		return XST_DMA_SG_LIST_EMPTY;
+	}
+
+	/* if scatter gather is busy for the DMA channel, return a status because
+	 * restarting it could lose data
+	 */
+
+	Register = XIo_In32(InstancePtr->RegBaseAddress + XDC_DMAS_REG_OFFSET);
+	if (Register & XDC_DMASR_SG_BUSY_MASK) {
+		return XST_DMA_SG_IS_STARTED;
+	}
+
+	/* get the address of the last buffer descriptor which the DMA hardware
+	 * finished processing
+	 */
+	LastDescriptorPtr = (XBufDescriptor *)
+		P_TO_V(XIo_In32
+		       (InstancePtr->RegBaseAddress + XDC_BDA_REG_OFFSET));
+
+	/* setup the first buffer descriptor that will be sent when the scatter
+	 * gather channel is enabled, this is only necessary one time since
+	 * the BDA register of the channel maintains the last buffer descriptor
+	 * processed
+	 */
+	if (LastDescriptorPtr == NULL) {
+		XIo_Out32(InstancePtr->RegBaseAddress + XDC_BDA_REG_OFFSET,
+			  (u32) V_TO_P(InstancePtr->GetPtr));
+	}
+	else {
+		XBufDescriptor *NextDescriptorPtr;
+
+		/* get the next descriptor to be started, if the status indicates it
+		 * hasn't already been used by the h/w, then it's OK to start it,
+		 * s/w sets the status of each descriptor to busy and then h/w clears
+		 * the busy when it is complete
+		 */
+		NextDescriptorPtr =
+			P_TO_V(XBufDescriptor_GetNextPtr(LastDescriptorPtr));
+
+		if ((XBufDescriptor_GetStatus(NextDescriptorPtr) &
+		     XDC_DMASR_BUSY_MASK) == 0) {
+			return XST_DMA_SG_NO_DATA;
+		}
+		/* don't start the DMA SG channel if the descriptor to be processed
+		 * by h/w is to be committed by the s/w, this function can be called
+		 * such that it interrupts a thread that was putting into the list
+		 */
+		if (NextDescriptorPtr == InstancePtr->CommitPtr) {
+			return XST_DMA_SG_BD_NOT_COMMITTED;
+		}
+	}
+
+	/* start the scatter gather operation by clearing the stop bit in the
+	 * control register and setting the enable bit in the s/w control register,
+	 * both of these are necessary to cause it to start, right now the order of
+	 * these statements is important, the software control register should be
+	 * set 1st.  The other order can cause the CPU to have a loss of sync
+	 * because it cannot read/write the register while the DMA operation is
+	 * running
+	 */
+
+	Register = XIo_In32(InstancePtr->RegBaseAddress + XDC_SWCR_REG_OFFSET);
+
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_SWCR_REG_OFFSET,
+		  Register | XDC_SWCR_SG_ENABLE_MASK);
+
+	Register = XIo_In32(InstancePtr->RegBaseAddress + XDC_DMAC_REG_OFFSET);
+
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_DMAC_REG_OFFSET,
+		  Register & ~XDC_DMACR_SG_DISABLE_MASK);
+
+	/* indicate the DMA channel scatter gather operation was started
+	 * successfully
+	 */
+	return XST_SUCCESS;
+}
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_SgStop
+*
+* DESCRIPTION:
+*
+* This function stops a scatter gather operation for a scatter gather
+* DMA channel. This function starts the process of stopping a scatter
+* gather operation that is in progress and waits for the stop to be completed.
+* Since it waits for the operation to stopped before returning, this function
+* could take an amount of time relative to the size of the DMA scatter gather
+* operation which is in progress.  The scatter gather list of the DMA channel
+* is not modified by this function such that starting the scatter gather
+* channel after stopping it will cause it to resume.  This operation is
+* considered to be a graceful stop in that the scatter gather operation
+* completes the current buffer descriptor before stopping.
+*
+* If the interrupt is enabled, an interrupt will be generated when the
+* operation is stopped and the caller is responsible for handling the
+* interrupt.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* BufDescriptorPtr is also a return value which contains a pointer to the
+* buffer descriptor which the scatter gather operation completed when it
+* was stopped.
+*
+* RETURN VALUE:
+*
+* A status containing XST_SUCCESS if scatter gather was stopped successfully
+* for the DMA channel.
+*
+* A value of XST_DMA_SG_IS_STOPPED indicates scatter gather was not stoppped
+* because the scatter gather is not started, but was already stopped.
+*
+* BufDescriptorPtr contains a pointer to the buffer descriptor which was
+* completed when the operation was stopped.
+*
+* NOTES:
+*
+* This function implements a loop which polls the hardware for an infinite
+* amount of time. If the hardware is not operating correctly, this function
+* may never return.
+*
+******************************************************************************/
+int
+XDmaChannel_SgStop(XDmaChannel * InstancePtr,
+		   XBufDescriptor ** BufDescriptorPtr)
+{
+	u32 Register;
+
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(BufDescriptorPtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* get the contents of the software control register, if scatter gather is not
+	 * enabled (started), then return a status because the disable acknowledge
+	 * would not be generated
+	 */
+	Register = XIo_In32(InstancePtr->RegBaseAddress + XDC_SWCR_REG_OFFSET);
+
+	if ((Register & XDC_SWCR_SG_ENABLE_MASK) == 0) {
+		return XST_DMA_SG_IS_STOPPED;
+	}
+
+	/* disable scatter gather by writing to the software control register
+	 * without modifying any other bits of the register
+	 */
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_SWCR_REG_OFFSET,
+		  Register & ~XDC_SWCR_SG_ENABLE_MASK);
+
+	/* scatter gather does not disable immediately, but after the current
+	 * buffer descriptor is complete, so wait for the DMA channel to indicate
+	 * the disable is complete
+	 */
+	do {
+		Register =
+			XIo_In32(InstancePtr->RegBaseAddress +
+				 XDC_DMAS_REG_OFFSET);
+	}
+	while (Register & XDC_DMASR_SG_BUSY_MASK);
+
+	/* set the specified buffer descriptor pointer to point to the buffer
+	 * descriptor that the scatter gather DMA channel was processing
+	 */
+	*BufDescriptorPtr = (XBufDescriptor *)
+		P_TO_V(XIo_In32
+		       (InstancePtr->RegBaseAddress + XDC_BDA_REG_OFFSET));
+
+	return XST_SUCCESS;
+}
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_CreateSgList
+*
+* DESCRIPTION:
+*
+* This function creates a scatter gather list in the DMA channel.  A scatter
+* gather list consists of a list of buffer descriptors that are available to
+* be used for scatter gather operations.  Buffer descriptors are put into the
+* list to request a scatter gather operation to be performed.
+*
+* A number of buffer descriptors are created from the specified memory and put
+* into a buffer descriptor list as empty buffer descriptors. This function must
+* be called before non-empty buffer descriptors may be put into the DMA channel
+* to request scatter gather operations.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* MemoryPtr contains a pointer to the memory which is to be used for buffer
+* descriptors and must not be cached (virtual).
+*
+* ByteCount contains the number of bytes for the specified memory to be used
+* for buffer descriptors.
+*
+* PhyPtr contains a pointer to the physical memory use for buffer descriptors.
+*
+* RETURN VALUE:
+*
+* A status contains XST_SUCCESS if the scatter gather list was successfully
+* created.
+*
+* A value of XST_DMA_SG_LIST_EXISTS indicates that the scatter gather list
+* was not created because the list has already been created.
+*
+* NOTES:
+*
+* None.
+*
+******************************************************************************/
+int
+XDmaChannel_CreateSgList(XDmaChannel * InstancePtr,
+			 u32 *MemoryPtr, u32 ByteCount, void *PhyPtr)
+{
+	XBufDescriptor *BufferDescriptorPtr = (XBufDescriptor *) MemoryPtr;
+	XBufDescriptor *PreviousDescriptorPtr = NULL;
+	XBufDescriptor *StartOfListPtr = BufferDescriptorPtr;
+	u32 UsedByteCount;
+
+	/* assert to verify valid input arguments, alignment for those
+	 * arguments that have alignment restrictions, and at least enough
+	 * memory for one buffer descriptor
+	 */
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(MemoryPtr != NULL);
+	XASSERT_NONVOID(((u32) MemoryPtr & 3) == 0);
+	XASSERT_NONVOID(ByteCount != 0);
+	XASSERT_NONVOID(ByteCount >= sizeof(XBufDescriptor));
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* if the scatter gather list has already been created, then return
+	 * with a status
+	 */
+	if (InstancePtr->TotalDescriptorCount != 0) {
+		return XST_DMA_SG_LIST_EXISTS;
+	}
+
+	/* save this up front so V_TO_P() works correctly */
+	InstancePtr->VirtPtr = MemoryPtr;
+	InstancePtr->PhyPtr = PhyPtr;
+
+	/* loop thru the specified memory block and create as many buffer
+	 * descriptors as possible putting each into the list which is
+	 * implemented as a ring buffer, make sure not to use any memory which
+	 * is not large enough for a complete buffer descriptor
+	 */
+	UsedByteCount = 0;
+	while ((UsedByteCount + sizeof(XBufDescriptor)) <= ByteCount) {
+		/* setup a pointer to the next buffer descriptor in the memory and
+		 * update # of used bytes to know when all of memory is used
+		 */
+		BufferDescriptorPtr = (XBufDescriptor *) ((u32) MemoryPtr +
+							  UsedByteCount);
+
+		/* initialize the new buffer descriptor such that it doesn't contain
+		 * garbage which could be used by the DMA hardware
+		 */
+		XBufDescriptor_Initialize(BufferDescriptorPtr);
+
+		/* if this is not the first buffer descriptor to be created,
+		 * then link it to the last created buffer descriptor
+		 */
+		if (PreviousDescriptorPtr != NULL) {
+			XBufDescriptor_SetNextPtr(PreviousDescriptorPtr,
+						  V_TO_P(BufferDescriptorPtr));
+		}
+
+		/* always keep a pointer to the last created buffer descriptor such
+		 * that they can be linked together in the ring buffer
+		 */
+		PreviousDescriptorPtr = BufferDescriptorPtr;
+
+		/* keep a count of the number of descriptors in the list to allow
+		 * error processing to be performed
+		 */
+		InstancePtr->TotalDescriptorCount++;
+
+		UsedByteCount += sizeof(XBufDescriptor);
+	}
+
+	/* connect the last buffer descriptor created and inserted in the list
+	 * to the first such that a ring buffer is created
+	 */
+	XBufDescriptor_SetNextPtr(BufferDescriptorPtr, V_TO_P(StartOfListPtr));
+
+	/* initialize the ring buffer to indicate that there are no
+	 * buffer descriptors in the list which point to valid data buffers
+	 */
+	InstancePtr->PutPtr = BufferDescriptorPtr;
+	InstancePtr->GetPtr = BufferDescriptorPtr;
+	InstancePtr->CommitPtr = NULL;
+	InstancePtr->LastPtr = BufferDescriptorPtr;
+	InstancePtr->ActiveDescriptorCount = 0;
+	InstancePtr->ActivePacketCount = 0;
+	InstancePtr->Committed = FALSE;
+
+	/* indicate the scatter gather list was successfully created */
+
+	return XST_SUCCESS;
+}
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_IsSgListEmpty
+*
+* DESCRIPTION:
+*
+* This function determines if the scatter gather list of a DMA channel is
+* empty with regard to buffer descriptors which are pointing to buffers to be
+* used for scatter gather operations.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* RETURN VALUE:
+*
+* A value of TRUE if the scatter gather list is empty, otherwise a value of
+* FALSE.
+*
+* NOTES:
+*
+* None.
+*
+******************************************************************************/
+u32 XDmaChannel_IsSgListEmpty(XDmaChannel * InstancePtr)
+{
+	/* assert to verify valid input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* if the number of descriptors which are being used in the list is zero
+	 * then the list is empty
+	 */
+	return (InstancePtr->ActiveDescriptorCount == 0);
+}
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_PutDescriptor
+*
+* DESCRIPTION:
+*
+* This function puts a buffer descriptor into the DMA channel scatter
+* gather list. A DMA channel maintains a list of buffer descriptors which are
+* to be processed.  This function puts the specified buffer descriptor
+* at the next location in the list.  Note that since the list is already intact,
+* the information in the parameter is copied into the list (rather than modify
+* list pointers on the fly).
+*
+* After buffer descriptors are put into the list, they must also be committed
+* by calling another function.  This allows multiple buffer descriptors which
+* span a single packet to be put into the list while preventing the hardware
+* from starting the first buffer descriptor of the packet.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* BufferDescriptorPtr is a pointer to the buffer descriptor to be put into
+* the next available location of the scatter gather list.
+*
+* RETURN VALUE:
+*
+* A status which indicates XST_SUCCESS if the buffer descriptor was
+* successfully put into the scatter gather list.
+*
+* A value of XST_DMA_SG_NO_LIST indicates the scatter gather list has not
+* been created.
+*
+* A value of XST_DMA_SG_LIST_FULL indicates the buffer descriptor was not
+* put into the list because the list was full.
+*
+* A value of XST_DMA_SG_BD_LOCKED indicates the buffer descriptor was not
+* put into the list because the buffer descriptor in the list which is to
+* be overwritten was locked.  A locked buffer descriptor indicates the higher
+* layered software is still using the buffer descriptor.
+*
+* NOTES:
+*
+* It is necessary to create a scatter gather list for a DMA channel before
+* putting buffer descriptors into it.
+*
+******************************************************************************/
+int
+XDmaChannel_PutDescriptor(XDmaChannel * InstancePtr,
+			  XBufDescriptor * BufferDescriptorPtr)
+{
+	u32 Control;
+
+	/* assert to verify valid input arguments and alignment for those
+	 * arguments that have alignment restrictions
+	 */
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(BufferDescriptorPtr != NULL);
+	XASSERT_NONVOID(((u32) BufferDescriptorPtr & 3) == 0);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* if a scatter gather list has not been created yet, return a status */
+
+	if (InstancePtr->TotalDescriptorCount == 0) {
+		return XST_DMA_SG_NO_LIST;
+	}
+
+	/* if the list is full because all descriptors are pointing to valid
+	 * buffers, then indicate an error, this code assumes no list or an
+	 * empty list is detected above
+	 */
+	if (InstancePtr->ActiveDescriptorCount ==
+	    InstancePtr->TotalDescriptorCount) {
+		return XST_DMA_SG_LIST_FULL;
+	}
+
+	/* if the buffer descriptor in the list which is to be overwritten is
+	 * locked, then don't overwrite it and return a status
+	 */
+	if (XBufDescriptor_IsLocked(InstancePtr->PutPtr)) {
+		return XST_DMA_SG_BD_LOCKED;
+	}
+
+	/* set the scatter gather stop bit in the control word of the descriptor
+	 * to cause the h/w to stop after it processes this descriptor since it
+	 * will be the last in the list
+	 */
+	Control = XBufDescriptor_GetControl(BufferDescriptorPtr);
+	XBufDescriptor_SetControl(BufferDescriptorPtr,
+				  Control | XDC_DMACR_SG_DISABLE_MASK);
+
+	/* set both statuses in the descriptor so we tell if they are updated with
+	 * the status of the transfer, the hardware should change the busy in the
+	 * DMA status to be false when it completes
+	 */
+	XBufDescriptor_SetStatus(BufferDescriptorPtr, XDC_DMASR_BUSY_MASK);
+	XBufDescriptor_SetDeviceStatus(BufferDescriptorPtr, 0);
+
+	/* copy the descriptor into the next position in the list so it's ready to
+	 * be used by the h/w, this assumes the descriptor in the list prior to this
+	 * one still has the stop bit in the control word set such that the h/w
+	 * use this one yet
+	 */
+	CopyBufferDescriptor(BufferDescriptorPtr, InstancePtr->PutPtr);
+
+	/* End of a packet is reached. Bump the packet counter */
+	if (XBufDescriptor_IsLastControl(InstancePtr->PutPtr)) {
+		InstancePtr->ActivePacketCount++;
+	}
+
+	/* only the last in the list and the one to be committed have scatter gather
+	 * disabled in the control word, a commit requires only one descriptor
+	 * to be changed, when # of descriptors to commit > 2 all others except the
+	 * 1st and last have scatter gather enabled
+	 */
+	if ((InstancePtr->CommitPtr != InstancePtr->LastPtr) &&
+	    (InstancePtr->CommitPtr != NULL)) {
+		Control = XBufDescriptor_GetControl(InstancePtr->LastPtr);
+		XBufDescriptor_SetControl(InstancePtr->LastPtr,
+					  Control & ~XDC_DMACR_SG_DISABLE_MASK);
+	}
+
+	/* update the list data based upon putting a descriptor into the list,
+	 * these operations must be last
+	 */
+	InstancePtr->ActiveDescriptorCount++;
+
+	/* only update the commit pointer if it is not already active, this allows
+	 * it to be deactivated after every commit such that a single descriptor
+	 * which is committed does not appear to be waiting to be committed
+	 */
+	if (InstancePtr->CommitPtr == NULL) {
+		InstancePtr->CommitPtr = InstancePtr->LastPtr;
+	}
+
+	/* these updates MUST BE LAST after the commit pointer update in order for
+	 * the commit pointer to track the correct descriptor to be committed
+	 */
+	InstancePtr->LastPtr = InstancePtr->PutPtr;
+	InstancePtr->PutPtr =
+		P_TO_V(XBufDescriptor_GetNextPtr(InstancePtr->PutPtr));
+
+	return XST_SUCCESS;
+}
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_CommitPuts
+*
+* DESCRIPTION:
+*
+* This function commits the buffer descriptors which have been put into the
+* scatter list for the DMA channel since the last commit operation was
+* performed.  This enables the calling functions to put several buffer
+* descriptors into the list (e.g.,a packet's worth) before allowing the scatter
+* gather operations to start.  This prevents the DMA channel hardware from
+* starting to use the buffer descriptors in the list before they are ready
+* to be used (multiple buffer descriptors for a single packet).
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* RETURN VALUE:
+*
+* A status indicating XST_SUCCESS if the buffer descriptors of the list were
+* successfully committed.
+*
+* A value of XST_DMA_SG_NOTHING_TO_COMMIT indicates that the buffer descriptors
+* were not committed because there was nothing to commit in the list.  All the
+* buffer descriptors which are in the list are commited.
+*
+* NOTES:
+*
+* None.
+*
+******************************************************************************/
+int XDmaChannel_CommitPuts(XDmaChannel * InstancePtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* if the buffer descriptor to be committed is already committed or
+	 * the list is empty (none have been put in), then indicate an error
+	 */
+	if ((InstancePtr->CommitPtr == NULL) ||
+	    XDmaChannel_IsSgListEmpty(InstancePtr)) {
+		return XST_DMA_SG_NOTHING_TO_COMMIT;
+	}
+
+	/* last descriptor in the list must have scatter gather disabled so the end
+	 * of the list is hit by h/w, if descriptor to commit is not last in list,
+	 * commit descriptors by enabling scatter gather in the descriptor
+	 */
+	if (InstancePtr->CommitPtr != InstancePtr->LastPtr) {
+		u32 Control;
+
+		Control = XBufDescriptor_GetControl(InstancePtr->CommitPtr);
+		XBufDescriptor_SetControl(InstancePtr->CommitPtr, Control &
+					  ~XDC_DMACR_SG_DISABLE_MASK);
+	}
+
+	/* Buffer Descriptors are committed. DMA is ready to be enabled */
+	InstancePtr->Committed = TRUE;
+
+	/* Update the commit pointer to indicate that there is nothing to be
+	 * committed, this state is used by start processing to know that the
+	 * buffer descriptor to start is not waiting to be committed
+	 */
+	InstancePtr->CommitPtr = NULL;
+
+	return XST_SUCCESS;
+}
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_GetDescriptor
+*
+* DESCRIPTION:
+*
+* This function gets a buffer descriptor from the scatter gather list of the
+* DMA channel. The buffer descriptor is retrieved from the scatter gather list
+* and the scatter gather list is updated to not include the retrieved buffer
+* descriptor.  This is typically done after a scatter gather operation
+* completes indicating that a data buffer has been successfully sent or data
+* has been received into the data buffer. The purpose of this function is to
+* allow the device using the scatter gather operation to get the results of the
+* operation.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* BufDescriptorPtr is a pointer to a pointer to the buffer descriptor which
+* was retrieved from the list.  The buffer descriptor is not really removed
+* from the list, but it is changed to a state such that the hardware will not
+* use it again until it is put into the scatter gather list of the DMA channel.
+*
+* RETURN VALUE:
+*
+* A status indicating XST_SUCCESS if a buffer descriptor was retrieved from
+* the scatter gather list of the DMA channel.
+*
+* A value of XST_DMA_SG_NO_LIST indicates the scatter gather list has not
+* been created.
+*
+* A value of XST_DMA_SG_LIST_EMPTY indicates no buffer descriptor was
+* retrieved from the list because there are no buffer descriptors to be
+* processed in the list.
+*
+* BufDescriptorPtr is updated to point to the buffer descriptor which was
+* retrieved from the list if the status indicates success.
+*
+* NOTES:
+*
+* None.
+*
+******************************************************************************/
+int
+XDmaChannel_GetDescriptor(XDmaChannel * InstancePtr,
+			  XBufDescriptor ** BufDescriptorPtr)
+{
+	u32 Control;
+
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(BufDescriptorPtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* if a scatter gather list has not been created yet, return a status */
+
+	if (InstancePtr->TotalDescriptorCount == 0) {
+		return XST_DMA_SG_NO_LIST;
+	}
+
+	/* if the buffer descriptor list is empty, then indicate an error */
+
+	if (XDmaChannel_IsSgListEmpty(InstancePtr)) {
+		return XST_DMA_SG_LIST_EMPTY;
+	}
+
+	/* retrieve the next buffer descriptor which is ready to be processed from
+	 * the buffer descriptor list for the DMA channel, set the control word
+	 * such that hardware will stop after the descriptor has been processed
+	 */
+	Control = XBufDescriptor_GetControl(InstancePtr->GetPtr);
+	XBufDescriptor_SetControl(InstancePtr->GetPtr,
+				  Control | XDC_DMACR_SG_DISABLE_MASK);
+
+	/* set the input argument, which is also an output, to point to the
+	 * buffer descriptor which is to be retrieved from the list
+	 */
+	*BufDescriptorPtr = InstancePtr->GetPtr;
+
+	/* update the pointer of the DMA channel to reflect the buffer descriptor
+	 * was retrieved from the list by setting it to the next buffer descriptor
+	 * in the list and indicate one less descriptor in the list now
+	 */
+	InstancePtr->GetPtr =
+		P_TO_V(XBufDescriptor_GetNextPtr(InstancePtr->GetPtr));
+	InstancePtr->ActiveDescriptorCount--;
+
+	return XST_SUCCESS;
+}
+
+/*********************** Interrupt Collescing Functions **********************/
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_GetPktCount
+*
+* DESCRIPTION:
+*
+* This function returns the value of the unserviced packet count register of
+* the DMA channel.  This count represents the number of packets that have been
+* sent or received by the hardware, but not processed by software.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* RETURN VALUE:
+*
+* The unserviced packet counter register contents for the DMA channel.
+*
+* NOTES:
+*
+* None.
+*
+******************************************************************************/
+u32 XDmaChannel_GetPktCount(XDmaChannel * InstancePtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* get the unserviced packet count from the register and return it */
+
+	return XIo_In32(InstancePtr->RegBaseAddress + XDC_UPC_REG_OFFSET);
+}
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_DecrementPktCount
+*
+* DESCRIPTION:
+*
+* This function decrements the value of the unserviced packet count register.
+* This informs the hardware that the software has processed a packet.  The
+* unserviced packet count register may only be decremented by one in the
+* hardware.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* RETURN VALUE:
+*
+* None.
+*
+* NOTES:
+*
+* None.
+*
+******************************************************************************/
+void XDmaChannel_DecrementPktCount(XDmaChannel * InstancePtr)
+{
+	u32 Register;
+
+	/* assert to verify input arguments */
+
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* if the unserviced packet count register can be decremented (rather
+	 * than rolling over) decrement it by writing a 1 to the register,
+	 * this is the only valid write to the register as it serves as an
+	 * acknowledge that a packet was handled by the software
+	 */
+	Register = XIo_In32(InstancePtr->RegBaseAddress + XDC_UPC_REG_OFFSET);
+	if (Register > 0) {
+		XIo_Out32(InstancePtr->RegBaseAddress + XDC_UPC_REG_OFFSET,
+			  1UL);
+	}
+}
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_SetPktThreshold
+*
+* DESCRIPTION:
+*
+* This function sets the value of the packet count threshold register of the
+* DMA channel.  It reflects the number of packets that must be sent or
+* received before generating an interrupt.  This value helps implement
+* a concept called "interrupt coalescing", which is used to reduce the number
+* of interrupts from devices with high data rates.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* Threshold is the value that is written to the threshold register of the
+* DMA channel.
+*
+* RETURN VALUE:
+*
+* A status containing XST_SUCCESS if the packet count threshold was
+* successfully set.
+*
+* NOTES:
+*
+* The packet threshold could be set to larger than the number of descriptors
+* allocated to the DMA channel. In this case, the wait bound will take over
+* and always indicate data arrival. There was a check in this function that
+* returned an error if the treshold was larger than the number of descriptors,
+* but that was removed because users would then have to set the threshold
+* only after they set descriptor space, which is an order dependency that
+* caused confustion.
+*
+******************************************************************************/
+int XDmaChannel_SetPktThreshold(XDmaChannel * InstancePtr, u8 Threshold)
+{
+	/* assert to verify input arguments, don't assert the threshold since
+	 * it's range is unknown
+	 */
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* set the packet count threshold in the register such that an interrupt
+	 * may be generated, if enabled, when the packet count threshold is
+	 * reached or exceeded
+	 */
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_PCT_REG_OFFSET,
+		  (u32) Threshold);
+
+	/* indicate the packet count threshold was successfully set */
+
+	return XST_SUCCESS;
+}
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_GetPktThreshold
+*
+* DESCRIPTION:
+*
+* This function gets the value of the packet count threshold register of the
+* DMA channel.  This value reflects the number of packets that must be sent or
+* received before generating an interrupt.  This value helps implement a concept
+* called "interrupt coalescing", which is used to reduce the number of
+* interrupts from devices with high data rates.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* RETURN VALUE:
+*
+* The packet threshold register contents for the DMA channel and is a value in
+* the range 0 - 1023.  A value of 0 indicates the packet wait bound timer is
+* disabled.
+*
+* NOTES:
+*
+* None.
+*
+******************************************************************************/
+u8 XDmaChannel_GetPktThreshold(XDmaChannel * InstancePtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* get the packet count threshold from the register and return it,
+	 * since only 8 bits are used, cast it to return only those bits */
+
+	return (u8) XIo_In32(InstancePtr->RegBaseAddress + XDC_PCT_REG_OFFSET);
+}
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_SetPktWaitBound
+*
+* DESCRIPTION:
+*
+* This function sets the value of the packet wait bound register of the
+* DMA channel.  This value reflects the timer value used to trigger an
+* interrupt when not enough packets have been received to reach the packet
+* count threshold.
+*
+* The timer is in millisecond units with +/- 33% accuracy.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* WaitBound is the value, in milliseconds, to be stored in the wait bound
+* register of the DMA channel and is a value in the range 0  - 1023.  A value
+* of 0 disables the packet wait bound timer.
+*
+* RETURN VALUE:
+*
+* None.
+*
+* NOTES:
+*
+* None.
+*
+******************************************************************************/
+void XDmaChannel_SetPktWaitBound(XDmaChannel * InstancePtr, u32 WaitBound)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(WaitBound < 1024);
+	XASSERT_VOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* set the packet wait bound in the register such that interrupt may be
+	 * generated, if enabled, when packets have not been handled for a specific
+	 * amount of time
+	 */
+	XIo_Out32(InstancePtr->RegBaseAddress + XDC_PWB_REG_OFFSET, WaitBound);
+}
+
+/******************************************************************************
+*
+* FUNCTION:
+*
+* XDmaChannel_GetPktWaitBound
+*
+* DESCRIPTION:
+*
+* This function gets the value of the packet wait bound register of the
+* DMA channel.  This value contains the timer value used to trigger an
+* interrupt when not enough packets have been received to reach the packet
+* count threshold.
+*
+* The timer is in millisecond units with +/- 33% accuracy.
+*
+* ARGUMENTS:
+*
+* InstancePtr contains a pointer to the DMA channel to operate on.  The DMA
+* channel should be configured to use scatter gather in order for this function
+* to be called.
+*
+* RETURN VALUE:
+*
+* The packet wait bound register contents for the DMA channel.
+*
+* NOTES:
+*
+* None.
+*
+******************************************************************************/
+u32 XDmaChannel_GetPktWaitBound(XDmaChannel * InstancePtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* get the packet wait bound from the register and return it */
+
+	return XIo_In32(InstancePtr->RegBaseAddress + XDC_PWB_REG_OFFSET);
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdmav3.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3.c
--- linux-2.6.31.12/drivers/xilinx_common/xdmav3.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3.c	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,104 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2006 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xdmav3.c
+*
+* This file implements initialization and control related functions. For more
+* information on this driver, see xdmav3.h.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 3.00a rmm  03/11/05 First release
+* </pre>
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include <linux/string.h>
+#include <asm/delay.h>
+
+#include "xdmav3.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+
+/************************** Variable Definitions *****************************/
+
+
+/*****************************************************************************/
+/**
+* This function initializes a DMA channel.  This function must be called
+* prior to using a DMA channel. Initialization of a channel includes setting
+* up the register base address, setting up the instance data, and ensuring the
+* HW is in a quiescent state.
+*
+* @param InstancePtr is a pointer to the instance to be worked on.
+* @param BaseAddress is where the registers for this channel can be found.
+*        If address translation is being used, then this parameter must
+*        reflect the virtual base address.
+*
+* @return
+* - XST_SUCCESS if initialization was successful
+*
+******************************************************************************/
+int XDmaV3_Initialize(XDmaV3 * InstancePtr, u32 BaseAddress)
+{
+	u32 Dmasr;
+
+	/* Setup the instance */
+	memset(InstancePtr, 0, sizeof(XDmaV3));
+	InstancePtr->RegBase = BaseAddress;
+	InstancePtr->IsReady = XCOMPONENT_IS_READY;
+	InstancePtr->BdRing.RunState = XST_DMA_SG_IS_STOPPED;
+
+	/* If this is SGDMA channel, then make sure it is stopped */
+	Dmasr = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_DMASR_OFFSET);
+	if (Dmasr & (XDMAV3_DMASR_DMACNFG_SGDMARX_MASK |
+		     XDMAV3_DMASR_DMACNFG_SGDMATX_MASK |
+		     XDMAV3_DMASR_DMACNFG_SSGDMA_MASK)) {
+		XDmaV3_SgStop(InstancePtr);
+	}
+
+	return (XST_SUCCESS);
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdmav3.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3.h
--- linux-2.6.31.12/drivers/xilinx_common/xdmav3.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3.h	2010-08-08 17:22:50.616446438 +0200
@@ -0,0 +1,515 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2006 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xdmav3.h
+*
+* The Xilinx Simple and Scatter Gather DMA driver.  This component supports a
+* distributed DMA design in which each device can have it's own dedicated DMA
+* channel, as opposed to a centralized DMA design. A device which uses DMA
+* typically contains two DMA channels, one for sending data and the other for
+* receiving data.
+*
+* This component is designed to be used as a basic building block for
+* designing a device driver. It provides registers accesses such that all
+* DMA processing can be maintained easier, but the device driver designer
+* must still understand all the details of the DMA channel.
+*
+* For a full description of DMA features, please see the HW spec. This driver
+* supports the following features:
+*   - Simple DMA
+*   - Scatter-Gather DMA (SGDMA)
+*   - Interrupts
+*   - Programmable interrupt coalescing for SGDMA
+*   - 36 Bit bus addressing
+*   - Programmable transaction types
+*   - APIs to manage Buffer Descriptors (BD) movement to and from the SGDMA
+*     engine
+*   - Virtual memory support
+*
+* <b>Transactions</b>
+*
+* To describe a DMA transaction in its simplest form, you need a source address,
+* destination address, and the number of bytes to transfer. When using a DMA
+* receive channel, the source address is within some piece of IP HW and doesn't
+* require the user explicitly set it. Likewise with a transmit channel and the
+* destination address. So this leaves a user buffer address and the number
+* bytes to transfer as the primary transaction attributes. There are more
+* obscure attributes such as:
+*
+*   - Is the user buffer a fixed address FIFO or a range of memory
+*   - The size of the data bus over which the transaction occurs.
+*   - Does the transfer use single beat or bursting capabilities of the
+*     bus over which the transaction occurs.
+*   - If the transaction occurs on a bus wider than 32 bits, what are the
+*     highest order address bits.
+*   - If SGDMA, does this transaction represent the end of a packet.
+*
+* The object used to describe a transaction is referred to as a Buffer
+* Descriptor (BD). The format of a BD closely matches that of the DMA HW.
+* Many fields within the BD correspond directly with the same fields within the
+* HW registers. See xdmabdv3.h for a detailed description of and the API for
+* manipulation of these objects.
+*
+* <b>Simple DMA</b>
+*
+* Simple DMA is a single transaction type of operation. The user uses this
+* driver to setup a transaction, initiate the transaction, then either wait for
+* an interrupt or poll the HW for completion of the transaction. A new
+* transaction may not be initiated until the current one completes.
+*
+* <b>Scatter-Gather DMA</b>
+*
+* SGDMA is more sophisticated in that it allows the user to define a list of
+* transactions in memory which the HW will process without further user
+* intervention. During this time, the user is free to continue adding more work
+* to keep the HW busy.
+*
+* Notification of completed transactions can be done either by polling the HW,
+* or using interrupts that signal a transaction has completed or a series of
+* transactions have been processed.
+*
+* SGDMA processes in units of packets. A packet is defined as a series of
+* data bytes that represent a message. SGDMA allows a packet of data to be
+* broken up into one or more transactions. For example, take an Ethernet IP
+* packet which consists of a 14 byte header followed by a 1 or more byte
+* payload. With SGDMA, the user may point a BD to the header and another BD to
+* the payload, then transfer them as a single message. This strategy can make a
+* TCP/IP stack more efficient by allowing it to keep packet headers and data in
+* different memory regions instead of assembling packets into contiguous blocks
+* of memory.
+*
+* <b>Interrupt Coalescing</b>
+*
+* SGDMA provides control over the frequency of interrupts. On a high speed link
+* significant processor overhead may be used servicing interrupts. Interrupt
+* coalescing provides two mechanisms that help control interrupt frequency.
+*
+* The packet threshold will hold off interrupting the CPU until a programmable
+* number of packets have been processed by the engine. The packet waitbound
+* timer is used to interrupt the CPU if after a programmable amount of time
+* after processing the last packet, no new packets were processed.
+*
+* <b>Interrupts</b>
+*
+* This driver does not service interrupts. This is done typically within
+* a higher level driver that uses DMA. This driver does provide an API to
+* enable or disable specific interrupts.
+*
+* <b>SGDMA List Management</b>
+*
+* The HW expectes BDs to be setup as a singly linked list. As BDs are completed,
+* the DMA engine will dereference BD.Next and load the next BD to process.
+* This driver uses a fixed buffer ring where all BDs are linked to the next
+* adjacent BD in memory. The last BD in the ring is linked to the first.
+*
+* Within the BD ring, the driver maintains four groups of BDs. Each group
+* consists of 0 or more adjacent BDs:
+*
+*   - Free group: Those BDs that can be allocated by the user with
+*     XDmaV3_SgBdAlloc(). These BDs are under driver control.
+*
+*   - Pre-work group: Those BDs that have been allocated with
+*     XDmaV3_SgBdAlloc(). These BDs are under user control. The user modifies
+*     these BDs in preparation for future DMA transactions.
+*
+*   - Work group: Those BDs that have been enqueued to HW with
+*     XDmaV3_SgBdToHw(). These BDs are under HW control and may be in a
+*     state of awaiting HW processing, in process, or processed by HW.
+*
+*   - Post-work group: Those BDs that have been processed by HW and have been
+*     extracted from the work group with XDmaV3_SgBdFromHw(). These BDs are under
+*     user control. The user may access these BDs to determine the result
+*     of DMA transactions. When the user is finished, XDmaV3_SgBdFree() should
+*     be called to place them back into the Free group.
+*
+* It is considered an error for the user to change BDs while they are in the
+* Work group. Doing so can cause data corruption and lead to system instability.
+*
+* The API provides macros that allow BD list traversal. These macros should be
+* used with care as they do not understand where one group ends and another
+* begins.
+*
+* The driver does not cache or keep copies of any BD. When the user modifies
+* BDs returned by XDmaV3_SgBdAlloc() or XDmaV3_SgBdFromHw(), they are modifying
+* the same BD list that HW accesses.
+*
+* Certain pairs of list modification functions have usage restrictions. See
+* the function headers for XDmaV3_SgBdAlloc() and XDmaV3_SgBdFromHw() for
+* more information.
+*
+* <b>SGDMA List Creation</b>
+*
+* During initialization, the function XDmaV3_SgListCreate() is used to setup
+* a user supplied memory block to contain all BDs for the DMA channel. This
+* function takes as an argument the number of BDs to place in the list. To
+* arrive at this number, the user is given two methods of calculating it.
+*
+* The first method assumes the user has a block of memory and they just
+* want to fit as many BDs as possible into it. The user must calculate the
+* number of BDs that will fit with XDmaV3_mSgListCntCalc(), then supply that
+* number into the list creation function.
+*
+* The second method allows the user to just supply the number directly. The
+* driver assumes the memory block is large enough to contain them all. To
+* double-check, the user should invoke XDmaV3_mSgListMemCalc() to verify the
+* memory block is adequate.
+*
+* Once the list has been created, it can be used right away to perform DMA
+* transactions. However, there are optional steps that can be done to increase
+* throughput and decrease user code complexity by the use of XDmaV3_SgListClone().
+*
+* BDs have many user accessible attributes that affect how DMA transactions are
+* carried out. Many of these attributes (such as the bus width) will probably
+* be constant at run-time. The cloning function can be used to copy a template
+* BD to every BD in the list relieving the user of having to setup transactions
+* from scratch every time a BD is submitted to HW.
+*
+* Ideally, the only transaction parameters that need to be set at run-time
+* should be: buffer address, bytes to transfer, and whether the BD is the
+* "Last" BD of a packet.
+*
+* <b>Adding / Removing BDs from the SGDMA Engine</b>
+*
+* BDs may be enqueued (see XDmaV3_SgBdToHw()) to the engine any time after
+* the SGDMA list is created. If the channel is running (see XDmaV3_SgStart()),
+* then newly added BDs will be processed as soon as the engine reaches them.
+* If the channel is stopped (see XDmaV3_SgStop()), the newly added BDs will
+* be accepted but not processed by the engine until it is restarted.
+*
+* Processed BDs may be removed (see XDmaV3_SgBdFromHw()) at any time
+* after the SGDMA list is created provided the engine has processed any.
+*
+* <b>Address Translation</b>
+*
+* When the BD list is setup with XDmaV3_SgListCreate(), a physical and
+* virtual address is supplied for the segment of memory containing the
+* descriptors. The driver will handle any translations internally. Subsequent
+* access of descriptors by the user is done in terms of the virtual address.
+*
+* <b>Alignment</b>
+*
+* Except for 4 byte alignment of BDs there are no other alignment restrictions
+* imposed by this driver. Individual DMA channels may, based on their
+* capabilities or which bus they are a master of, have more stringent alignment
+* requirements. It is up to the user to match the requirements of the DMA
+* channel being used.
+*
+* Aside from the initial creation of BD list (see XDmaV3_SgListCreate()),
+* there are no other run-time checks for proper alignment. Misaligned user
+* buffers or BDs may result in corrupted data.
+*
+* <b>Cache Coherency</b>
+*
+* This driver expects all user buffers attached to BDs to be in cache coherent
+* memory. Buffers for transmit should be flushed from the cache before passing
+* the associated BD to this driver. Buffers for receive should be invalidated
+* before being accessed.
+*
+* If the user wishes that the BD space itself be in cached memory, then
+* modification of this driver is required. The driver helps the user in
+* this area by: 1) Allowing the user to specify what alignment BDs should
+* use (ie. aligned along cache lines); 2) Provide unimplemented invalidate/flush
+* macro placeholders in the driver source code where needed.
+*
+* <b>Reset After Stopping</b>
+*
+* This driver is designed to allow for stop-reset-start cycles of the DMA
+* HW while keeping the BD list intact. When restarted after a reset, this
+* driver will point the DMA engine to where it left off after stopping it.
+*
+* <b>Limitations</b>
+*
+* This driver requires exclusive use of the hardware DMACR.SGS bit. This
+* applies to the actual HW register and BDs submitted through this driver to
+* be processed. If a BD is encountered with this bit set, then it will be
+* cleared within the driver.
+*
+* This driver does not have any mechanism for mutual exclusion. It is up to the
+* user to provide this protection.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 3.00a rmm  03/11/06 First release
+*       rmm  06/22/06 Added extern "C"
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XDMAV3_H		/* prevent circular inclusions */
+#define XDMAV3_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xdmabdv3.h"
+#include "xstatus.h"
+
+/************************** Constant Definitions *****************************/
+
+/* Minimum alignment */
+#define XDMABDV3_MINIMUM_ALIGNMENT  4
+
+
+/**************************** Type Definitions *******************************/
+
+/** This is an internal structure used to maintain the SGDMA list */
+typedef struct {
+	u32 PhysBaseAddr;
+		       /**< Physical address of 1st BD in list */
+	u32 BaseAddr;  /**< Virtual address of 1st BD in list */
+	u32 HighAddr;  /**< Virtual address of last BD in the list */
+	u32 Length;    /**< Total size of ring in bytes */
+	u32 RunState;  /**< Flag to indicate SGDMA is started */
+	u32 Separation;/**< Number of bytes between the starting address
+                                of adjacent BDs */
+	XDmaBdV3 *FreeHead;/**< First BD in the free group */
+	XDmaBdV3 *PreHead; /**< First BD in the pre-work group */
+	XDmaBdV3 *HwHead;  /**< First BD in the work group */
+	XDmaBdV3 *HwTail;  /**< Last BD in the work group */
+	XDmaBdV3 *PostHead;/**< First BD in the post-work group */
+	XDmaBdV3 *BdaRestart;
+			   /**< BDA to load when channel is started */
+	unsigned HwCnt;	   /**< Number of BDs in work group */
+	unsigned PreCnt;   /**< Number of BDs in pre-work group */
+	unsigned FreeCnt;  /**< Number of allocatable BDs in the free group */
+	unsigned PostCnt;  /**< Number of BDs in post-work group */
+	unsigned AllCnt;   /**< Total Number of BDs for channel */
+} XDmaV3_BdRing;
+
+/**
+ * The XDmaV3 driver instance data. An instance must be allocated for each DMA
+ * channel in use. If address translation is enabled, then all addresses and
+ * pointers excluding PhysBase are expressed in terms of the virtual address.
+ */
+typedef struct XDmaV3 {
+	u32 RegBase;	   /**< Base address of channel registers */
+	u32 IsReady;	   /**< Flag to indicate device is ready to use */
+	XDmaV3_BdRing BdRing;  /**< BD storage for SGDMA */
+} XDmaV3;
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/*****************************************************************************/
+/**
+* Use this macro at initialization time to determine how many BDs will fit
+* in a BD list within the given memory constraints.
+*
+* The results of this macro can be provided to XDmaV3_SgListCreate().
+*
+* @param Alignment specifies what byte alignment the BDs must fall on and
+*        must be a power of 2 to get an accurate calculation (32, 64, 126,...)
+* @param Bytes is the number of bytes to be used to store BDs.
+*
+* @return Number of BDs that can fit in the given memory area
+*
+* @note
+* C-style signature:
+*    u32 XDmaV3_mSgListCntCalc(u32 Alignment, u32 Bytes)
+*
+******************************************************************************/
+#define XDmaV3_mSgListCntCalc(Alignment, Bytes)                           \
+    (u32)((Bytes) / ((sizeof(XDmaBdV3) + ((Alignment)-1)) & ~((Alignment)-1)))
+
+/*****************************************************************************/
+/**
+* Use this macro at initialization time to determine how many bytes of memory
+* is required to contain a given number of BDs at a given alignment.
+*
+* @param Alignment specifies what byte alignment the BDs must fall on. This
+*        parameter must be a power of 2 to get an accurate calculation (32, 64,
+*        128,...)
+* @param NumBd is the number of BDs to calculate memory size requirements for
+*
+* @return The number of bytes of memory required to create a BD list with the
+*         given memory constraints.
+*
+* @note
+* C-style signature:
+*    u32 XDmaV3_mSgListMemCalc(u32 Alignment, u32 NumBd)
+*
+******************************************************************************/
+#define XDmaV3_mSgListMemCalc(Alignment, NumBd)                           \
+    (u32)((sizeof(XDmaBdV3) + ((Alignment)-1)) & ~((Alignment)-1)) * (NumBd)
+
+
+/****************************************************************************/
+/**
+* Return the total number of BDs allocated by this channel with
+* XDmaV3_SgListCreate().
+*
+* @param  InstancePtr is the DMA channel to operate on.
+*
+* @return The total number of BDs allocated for this channel.
+*
+* @note
+* C-style signature:
+*    u32 XDmaBdV3_mSgGetCnt(XDmaV3* InstancePtr)
+*
+*****************************************************************************/
+#define XDmaV3_mSgGetCnt(InstancePtr)       ((InstancePtr)->BdRing.AllCnt)
+
+
+/****************************************************************************/
+/**
+* Return the number of BDs allocatable with XDmaV3_SgBdAlloc() for pre-
+* processing.
+*
+* @param  InstancePtr is the DMA channel to operate on.
+*
+* @return The number of BDs currently allocatable.
+*
+* @note
+* C-style signature:
+*    u32 XDmaBdV3_mSgGetFreeCnt(XDmaV3* InstancePtr)
+*
+*****************************************************************************/
+#define XDmaV3_mSgGetFreeCnt(InstancePtr)   ((InstancePtr)->BdRing.FreeCnt)
+
+
+/****************************************************************************/
+/**
+* Return the next BD in a list.
+*
+* @param  InstancePtr is the DMA channel to operate on.
+* @param  BdPtr is the BD to operate on.
+*
+* @return The next BD in the list relative to the BdPtr parameter.
+*
+* @note
+* C-style signature:
+*    XDmaBdV3 *XDmaV3_mSgBdNext(XDmaV3* InstancePtr, XDmaBdV3 *BdPtr)
+*
+*****************************************************************************/
+#define XDmaV3_mSgBdNext(InstancePtr, BdPtr)                            \
+    (((u32)(BdPtr) >= (InstancePtr)->BdRing.HighAddr) ?             \
+     (XDmaBdV3*)(InstancePtr)->BdRing.BaseAddr :                        \
+     (XDmaBdV3*)((u32)(BdPtr) + (InstancePtr)->BdRing.Separation))
+
+
+/****************************************************************************/
+/**
+* Return the previous BD in the list.
+*
+* @param  InstancePtr is the DMA channel to operate on.
+* @param  BdPtr is the BD to operate on
+*
+* @return The previous BD in the list relative to the BdPtr parameter.
+*
+* @note
+* C-style signature:
+*    XDmaBdV3 *XDmaV3_mSgBdPrev(XDmaV3* InstancePtr, XDmaBdV3 *BdPtr)
+*
+*****************************************************************************/
+#define XDmaV3_mSgBdPrev(InstancePtr, BdPtr)                            \
+    (((u32)(BdPtr) <= (InstancePtr)->BdRing.BaseAddr) ?             \
+     (XDmaBdV3*)(InstancePtr)->BdRing.HighAddr :                        \
+     (XDmaBdV3*)((u32)(BdPtr) - (InstancePtr)->BdRing.Separation))
+
+
+/****************************************************************************/
+/**
+* Retrieve the current contents of the DMASR register. This macro can be
+* used to poll the DMA HW for completion of a transaction.
+*
+* @param  InstancePtr is the DMA channel to operate on.
+*
+* @return The current contents of the DMASR register.
+*
+* @note
+* C-style signature:
+*    u32 XDmaV3_mGetStatus(XDmaV3* InstancePtr)
+*
+*****************************************************************************/
+#define XDmaV3_mGetStatus(InstancePtr)                                  \
+    XDmaV3_mReadReg((InstancePtr)->RegBase, XDMAV3_DMASR_OFFSET)
+
+
+/************************** Function Prototypes ******************************/
+
+/*
+ * Initialization and control functions in xdmav3.c
+ */
+int XDmaV3_Initialize(XDmaV3 * InstancePtr, u32 BaseAddress);
+
+/*
+ * Interrupt related functions in xdmav3_intr.c
+ */
+void XDmaV3_SetInterruptStatus(XDmaV3 * InstancePtr, u32 Mask);
+u32 XDmaV3_GetInterruptStatus(XDmaV3 * InstancePtr);
+void XDmaV3_SetInterruptEnable(XDmaV3 * InstancePtr, u32 Mask);
+u32 XDmaV3_GetInterruptEnable(XDmaV3 * InstancePtr);
+
+/*
+ * Simple DMA related functions in xdmav3_simple.c
+ */
+int XDmaV3_SimpleTransfer(XDmaV3 * InstancePtr, XDmaBdV3 * Bdptr);
+
+/*
+ * Scatter gather DMA related functions in xdmav3_sg.c
+ */
+int XDmaV3_SgStart(XDmaV3 * InstancePtr);
+void XDmaV3_SgStop(XDmaV3 * InstancePtr);
+int XDmaV3_SgSetPktThreshold(XDmaV3 * InstancePtr, u16 Threshold);
+int XDmaV3_SgSetPktWaitbound(XDmaV3 * InstancePtr, u16 TimerVal);
+u16 XDmaV3_SgGetPktThreshold(XDmaV3 * InstancePtr);
+u16 XDmaV3_SgGetPktWaitbound(XDmaV3 * InstancePtr);
+
+int XDmaV3_SgListCreate(XDmaV3 * InstancePtr, u32 PhysAddr,
+			u32 VirtAddr, u32 Alignment, unsigned BdCount);
+int XDmaV3_SgListClone(XDmaV3 * InstancePtr, XDmaBdV3 * SrcBdPtr);
+int XDmaV3_SgCheck(XDmaV3 * InstancePtr);
+int XDmaV3_SgBdAlloc(XDmaV3 * InstancePtr, unsigned NumBd,
+		     XDmaBdV3 ** BdSetPtr);
+int XDmaV3_SgBdUnAlloc(XDmaV3 * InstancePtr, unsigned NumBd,
+		       XDmaBdV3 * BdSetPtr);
+int XDmaV3_SgBdToHw(XDmaV3 * InstancePtr, unsigned NumBd, XDmaBdV3 * BdSetPtr);
+int XDmaV3_SgBdFree(XDmaV3 * InstancePtr, unsigned NumBd, XDmaBdV3 * BdSetPtr);
+unsigned XDmaV3_SgBdFromHw(XDmaV3 * InstancePtr, unsigned BdLimit,
+			   XDmaBdV3 ** BdSetPtr);
+
+/*
+ * Selftest functions in xdmav3_selftest.c
+ */
+int XDmaV3_SelfTest(XDmaV3 * InstancePtr);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdmav3_intr.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3_intr.c
--- linux-2.6.31.12/drivers/xilinx_common/xdmav3_intr.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3_intr.c	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,129 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2006 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xdmav3_intr.c
+*
+* This file implements interrupt control related functions. For more
+* information on this driver, see xdmav3.h.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 3.00a rmm  03/11/06 First release
+* </pre>
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include "xdmav3.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+
+/************************** Variable Definitions *****************************/
+
+
+/*****************************************************************************/
+/**
+* Set the interrupt status register for this channel. Use this function
+* to ack pending interrupts.
+*
+* @param InstancePtr is a pointer to the instance to be worked on.
+* @param Mask is a logical OR of XDMAV3_IPXR_*_MASK constants found in
+*        xdmav3_l.h.
+*
+******************************************************************************/
+void XDmaV3_SetInterruptStatus(XDmaV3 * InstancePtr, u32 Mask)
+{
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_ISR_OFFSET, Mask);
+}
+
+
+/*****************************************************************************/
+/**
+* Retrieve the interrupt status for this channel. OR the results of this
+* function with results from XDmaV3_GetInterruptEnable() to determine which
+* interrupts are currently pending to the processor.
+*
+* @param InstancePtr is a pointer to the instance to be worked on.
+*
+* @return Mask of interrupt bits made up of XDMAV3_IPXR_*_MASK constants found
+*         in xdmav3_l.h.
+*
+******************************************************************************/
+u32 XDmaV3_GetInterruptStatus(XDmaV3 * InstancePtr)
+{
+	return (XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_ISR_OFFSET));
+}
+
+
+/*****************************************************************************/
+/**
+* Enable specific DMA interrupts.
+*
+* @param InstancePtr is a pointer to the instance to be worked on.
+* @param Mask is a logical OR of of XDMAV3_IPXR_*_MASK constants found in
+*        xdmav3_l.h.
+*
+******************************************************************************/
+void XDmaV3_SetInterruptEnable(XDmaV3 * InstancePtr, u32 Mask)
+{
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_IER_OFFSET, Mask);
+}
+
+
+/*****************************************************************************/
+/**
+* Retrieve the interrupt enable register for this channel. Use this function to
+* determine which interrupts are currently enabled to the processor.
+*
+* @param InstancePtr is a pointer to the instance to be worked on.
+*
+* @return Mask of interrupt bits made up of XDMAV3_IPXR_*_MASK constants found in
+*         xdmav3_l.h.
+*
+******************************************************************************/
+u32 XDmaV3_GetInterruptEnable(XDmaV3 * InstancePtr)
+{
+	return (XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_IER_OFFSET));
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdmav3_l.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3_l.h
--- linux-2.6.31.12/drivers/xilinx_common/xdmav3_l.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3_l.h	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,295 @@
+/* $Id: */
+
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2006 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+
+/*****************************************************************************/
+/**
+*
+* @file xdmav3_l.h
+*
+* This header file contains identifiers and low-level driver functions (or
+* macros) that can be used to access the Direct Memory Access and Scatter
+* Gather (SG DMA) device.
+*
+* For more information about the operation of this device, see the hardware
+* specification and documentation in the higher level driver xdma.h source
+* code file.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 3.00a rmm  03/11/06 First release
+*       rmm  06/22/06 Added extern "C"
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XDMAV3_L_H		/* prevent circular inclusions */
+#define XDMAV3_L_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xio.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/* Register offset definitions. Unless otherwise noted, register access is
+ * 32 bit.
+ */
+
+/** @name DMA channel registers
+ *  @{
+ */
+#define XDMAV3_DMASR_OFFSET  0x00000000	 /**< DMA Status Register */
+#define XDMAV3_DMACR_OFFSET  0x00000004	 /**< DMA Control Register */
+#define XDMAV3_MSBA_OFFSET   0x00000008	 /**< Most Significant Bus Address */
+#define XDMAV3_LSBA_OFFSET   0x0000000C	 /**< Least Significant Bus Address */
+#define XDMAV3_BDA_OFFSET    0x00000010	 /**< Buffer Descriptor Address */
+#define XDMAV3_LENGTH_OFFSET 0x00000014	 /**< DMA Length */
+#define XDMAV3_ISR_OFFSET    0x00000018	 /**< Interrupt Status Register */
+#define XDMAV3_IER_OFFSET    0x0000001C	 /**< Interrupt Enable Register */
+#define XDMAV3_SWCR_OFFSET   0x00000020	 /**< Software Control Register */
+/*@}*/
+
+/** @name Buffer Descriptor register offsets
+ *  @{
+ */
+#define XDMAV3_BD_DMASR_OFFSET     0x00	 /**< Channel DMASR register contents */
+#define XDMAV3_BD_DMACR_OFFSET     0x04	 /**< Channel DMACR register contents */
+#define XDMAV3_BD_MSBA_OFFSET      0x08	 /**< Channel MSBA register contents */
+#define XDMAV3_BD_LSBA_OFFSET      0x0C	 /**< Channel LSBA register contents */
+#define XDMAV3_BD_BDA_OFFSET       0x10	 /**< Next buffer descriptor pointer */
+#define XDMAV3_BD_LENGTH_OFFSET    0x14	 /**< Channel LENGTH register contents */
+#define XDMAV3_BD_SR_OFFSET        0x18	 /**< Packet Status */
+#define XDMAV3_BD_RSVD_OFFSET      0x1C	 /**< Reserved */
+#define XDMAV3_BD_USR0_OFFSET      0x20	 /**< HW User defined */
+#define XDMAV3_BD_USR1_OFFSET      0x24	 /**< HW User defined */
+#define XDMAV3_BD_USR2_OFFSET      0x28	 /**< HW User defined */
+#define XDMAV3_BD_USR3_OFFSET      0x2C	 /**< HW User defined */
+#define XDMAV3_BD_USR4_OFFSET      0x30	 /**< HW User defined */
+#define XDMAV3_BD_USR5_OFFSET      0x34	 /**< HW User defined */
+#define XDMAV3_BD_LENCPY_OFFSET    0x38	 /**< SW Driver usage */
+#define XDMAV3_BD_ID_OFFSET        0x3C	 /**< SW Driver usage */
+
+#define XDMAV3_BD_NUM_WORDS        16	 /**< Number of 32-bit words that make
+                                              up a BD */
+/*@}*/
+
+/* Register masks. The following constants define bit locations of various
+ * control bits in the registers. Constants are not defined for those registers
+ * that have a single bit field representing all 32 bits. For further
+ * information on the meaning of the various bit masks, refer to the HW spec.
+ */
+
+
+/** @name DMA Status Register (DMASR) bitmasks
+ *  @note These bitmasks are identical between XDMAV3_DMASR_OFFSET and
+ *  XDMAV3_BD_DMASR_OFFSET
+ * @{
+ */
+#define XDMAV3_DMASR_DMABSY_MASK  0x80000000  /**< DMA busy */
+#define XDMAV3_DMASR_DBE_MASK     0x40000000  /**< Bus error */
+#define XDMAV3_DMASR_DBT_MASK     0x20000000  /**< Bus timeout */
+#define XDMAV3_DMASR_DMADONE_MASK 0x10000000  /**< DMA done */
+#define XDMAV3_DMASR_SGBSY_MASK   0x08000000  /**< SG channel busy */
+#define XDMAV3_DMASR_LAST_MASK    0x04000000  /**< Last BD of packet */
+#define XDMAV3_DMASR_SGDONE_MASK  0x01000000  /**< SGDMA done */
+#define XDMAV3_DMASR_DMACNFG_MASK 0x00300000  /**< DMA configuration */
+
+#define XDMAV3_DMASR_DMACNFG_SIMPLE_MASK  0x00000000  /**< Simple DMA config */
+#define XDMAV3_DMASR_DMACNFG_SSGDMA_MASK  0x00100000  /**< Simple SGDMA config */
+#define XDMAV3_DMASR_DMACNFG_SGDMATX_MASK 0x00200000  /**< SGDMA xmit config */
+#define XDMAV3_DMASR_DMACNFG_SGDMARX_MASK 0x00300000  /**< SGDMA recv config */
+#define XDMAV3_DMASR_DMACNFG_MASK         0x00300000  /**< Mask for all */
+
+/*@}*/
+
+/** @name DMA Control Register (DMACR) bitmasks
+ *  @note These bitmasks are identical between XDMAV3_DMACR_OFFSET and
+ *  XDMAV3_BD_DMACR_OFFSET
+ * @{
+ */
+#define XDMAV3_DMACR_AINC_MASK    0x80000000  /**< Address increment */
+#define XDMAV3_DMACR_BPDRE_MASK   0x20000000  /**< Bypass DRE */
+#define XDMAV3_DMACR_SGS_MASK     0x08000000  /**< Scatter gather stop */
+#define XDMAV3_DMACR_LAST_MASK    0x04000000  /**< Last BD of packet */
+#define XDMAV3_DMACR_DEVSEL_MASK  0x00FF0000  /**< Device select */
+#define XDMAV3_DMACR_BDPAGE_MASK  0x00000F00  /**< BD page address */
+#define XDMAV3_DMACR_TYPE_MASK    0x00000070  /**< DMA transfer type */
+#define XDMAV3_DMACR_DSIZE_MASK   0x00000007  /**< DMA transfer width */
+
+/* Sub-fields within XDMAV3_DMACR_DIR_MASK */
+#define XDMAV3_DMACR_DIR_RX_MASK       0x40000000  /**< Xfer in Rx direction */
+#define XDMAV3_DMACR_DIR_TX_MASK       0x00000000  /**< Xfer in Tx direction */
+
+/* Sub-fields within XDMAV3_DMACR_TYPE_MASK */
+#define XDMAV3_DMACR_TYPE_BFBURST_MASK 0x00000010  /**< Bounded fixed length
+                                                        burst */
+#define XDMAV3_DMACR_TYPE_BIBURST_MASK 0x00000020  /**< Bounded indeterminate
+                                                        burst */
+
+/* Sub-fields within XDMAV3_DMACR_DSIZE_MASK */
+#define XDMAV3_DMACR_DSIZE_8_MASK      0x00000000  /**< Xfer width = 8 bits */
+#define XDMAV3_DMACR_DSIZE_16_MASK     0x00000001  /**< Xfer width = 16 bits */
+#define XDMAV3_DMACR_DSIZE_32_MASK     0x00000002  /**< Xfer width = 32 bits */
+#define XDMAV3_DMACR_DSIZE_64_MASK     0x00000003  /**< Xfer width = 64 bits */
+#define XDMAV3_DMACR_DSIZE_128_MASK    0x00000004  /**< Xfer width = 128 bits */
+
+/* Left shift values for selected masks */
+#define XDMAV3_DMACR_DEVSEL_SHIFT      16
+#define XDMAV3_DMACR_BDPAGE_SHIFT      8
+/*@}*/
+
+/** @name Interrupt status bits for MAC interrupts
+ *  These bits are associated with XDMAV3_ISR_OFFSET and
+ *  XDMAV3_IER_OFFSET registers.
+ *  @{
+ */
+#define XDMAV3_IPXR_DD_MASK      0x00000040  /**< DMA complete */
+#define XDMAV3_IPXR_DE_MASK      0x00000020  /**< DMA error */
+#define XDMAV3_IPXR_PD_MASK      0x00000010  /**< Pkt done */
+#define XDMAV3_IPXR_PCTR_MASK    0x00000008  /**< Pkt count threshold reached */
+#define XDMAV3_IPXR_PWBR_MASK    0x00000004  /**< Pkt waitbound reached */
+#define XDMAV3_IPXR_SGDA_MASK    0x00000002  /**< SG Disable ack */
+#define XDMAV3_IPXR_SGEND_MASK   0x00000001  /**< SG End */
+/*@}*/
+
+/** @name Software control register (SWCR) bitmasks
+ *  @{
+ */
+#define XDMAV3_SWCR_SGE_MASK     0x80000000  /**< SG Enable */
+#define XDMAV3_SWCR_SGD_MASK     0x40000000  /**< SG Disable */
+#define XDMAV3_SWCR_DSGAR_MASK   0x20000000  /**< SG Disable auto-restart */
+#define XDMAV3_SWCR_PWB_MASK     0x00FFF000  /**< Pkt waitbound */
+#define XDMAV3_SWCR_PCT_MASK     0x00000FFF  /**< Pkt threshold count */
+
+/* Left shift values for selected masks */
+#define XDMAV3_SWCR_PCT_SHIFT    0
+#define XDMAV3_SWCR_PWB_SHIFT    12
+/*@}*/
+
+/**************************** Type Definitions *******************************/
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/****************************************************************************/
+/**
+*
+* Read the given IPIF register.
+*
+* @param    BaseAddress is the IPIF base address of the device
+* @param    RegOffset is the register offset to be read
+*
+* @return   The 32-bit value of the register
+*
+* @note
+* C-style signature:
+*    u32 XDmaV3_mReadReg(u32 BaseAddress, u32 RegOffset)
+*
+*****************************************************************************/
+#define XDmaV3_mReadReg(BaseAddress, RegOffset) \
+    XIo_In32((u32)(BaseAddress) + (u32)(RegOffset))
+
+
+/****************************************************************************/
+/**
+*
+* Write the given IPIF register.
+*
+* @param    BaseAddress is the IPIF base address of the device
+* @param    RegOffset is the register offset to be written
+* @param    Data is the 32-bit value to write to the register
+*
+* @return   None.
+*
+* @note
+* C-style signature:
+*    void XDmaV3_mWriteReg(u32 BaseAddress, u32 RegOffset, u32 Data)
+*
+*****************************************************************************/
+#define XDmaV3_mWriteReg(BaseAddress, RegOffset, Data)  \
+    XIo_Out32((u32)(BaseAddress) + (u32)(RegOffset), (u32)(Data))
+
+
+/****************************************************************************/
+/**
+*
+* Read the given Buffer Descriptor word.
+*
+* @param    BaseAddress is the base address of the BD to read
+* @param    Offset is the word offset to be read
+*
+* @return   The 32-bit value of the field
+*
+* @note
+* C-style signature:
+*    u32 XDmaV3_mReadBd(u32 BaseAddress, u32 Offset)
+*
+*****************************************************************************/
+#define XDmaV3_mReadBd(BaseAddress, Offset)             \
+    (*(u32*)((u32)(BaseAddress) + (u32)(Offset)))
+
+
+/****************************************************************************/
+/**
+*
+* Write the given Buffer Descriptor word.
+*
+* @param    BaseAddress is the base address of the BD to write
+* @param    Offset is the word offset to be written
+* @param    Data is the 32-bit value to write to the field
+*
+* @return   None.
+*
+* @note
+* C-style signature:
+*    void XDmaV3_mWriteReg(u32 BaseAddress, u32 Offset, u32 Data)
+*
+*****************************************************************************/
+#define XDmaV3_mWriteBd(BaseAddress, Offset, Data)              \
+    (*(u32*)((u32)(BaseAddress) + (u32)(Offset)) = (Data))
+
+
+/************************** Function Prototypes ******************************/
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdmav3_selftest.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3_selftest.c
--- linux-2.6.31.12/drivers/xilinx_common/xdmav3_selftest.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3_selftest.c	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,79 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2006 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xdmav3_selftest.c
+*
+* This file implements DMA selftest related functions. For more
+* information on this driver, see xdmav3.h.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 3.00a rmm  03/11/06 First release
+* </pre>
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include "xdmav3.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+
+/************************** Variable Definitions *****************************/
+
+
+/*****************************************************************************/
+/**
+* Selftest is not implemented.
+*
+* @param InstancePtr is a pointer to the instance to be worked on.
+*
+* @return
+* - XST_SUCCESS if the self test passes
+*
+******************************************************************************/
+int XDmaV3_SelfTest(XDmaV3 * InstancePtr)
+{
+	return (XST_SUCCESS);
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdmav3_sg.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3_sg.c
--- linux-2.6.31.12/drivers/xilinx_common/xdmav3_sg.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3_sg.c	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,1261 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2006 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xdmav3_sg.c
+*
+* This file implements Scatter-Gather DMA (SGDMA) related functions. For more
+* information on this driver, see xdmav3.h.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 3.00a rmm  03/11/06 First release
+*       rmm  06/22/06 Fixed C++ compiler warnings
+* </pre>
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include <linux/string.h>
+#include <asm/delay.h>
+
+#include "xdmav3.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/****************************************************************************
+ * These cache macros are used throughout this source code file to show
+ * users where cache operations should occur if BDs were to be placed in
+ * a cached memory region. Cacheing BD regions, however, is not common.
+ *
+ * The macros are implemented as NULL operations, but may be hooked into
+ * XENV macros in future revisions of this driver.
+ ****************************************************************************/
+#define XDMAV3_CACHE_FLUSH(BdPtr)
+#define XDMAV3_CACHE_INVALIDATE(BdPtr)
+
+/****************************************************************************
+ * Compute the virtual address of a descriptor from its physical address
+ *
+ * @param Ring is the ring BdPtr appears in
+ * @param BdPtr is the physical address of the BD
+ *
+ * @returns Virtual address of BdPtr
+ *
+ * @note Assume BdPtr is always a valid BD in the ring
+ ****************************************************************************/
+#define XDMAV3_PHYS_TO_VIRT(Ring, BdPtr) \
+    ((u32)BdPtr + (Ring->BaseAddr - Ring->PhysBaseAddr))
+
+/****************************************************************************
+ * Compute the physical address of a descriptor from its virtual address
+ *
+ * @param Ring is the ring BdPtr appears in
+ * @param BdPtr is the physical address of the BD
+ *
+ * @returns Physical address of BdPtr
+ *
+ * @note Assume BdPtr is always a valid BD in the ring
+ ****************************************************************************/
+#define XDMAV3_VIRT_TO_PHYS(Ring, BdPtr) \
+    ((u32)BdPtr - (Ring->BaseAddr - Ring->PhysBaseAddr))
+
+/****************************************************************************
+ * Clear or set the SGS bit of the DMACR register
+ ****************************************************************************/
+#define XDMAV3_HW_SGS_CLEAR                                             \
+    XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_DMACR_OFFSET,         \
+                     XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_DMACR_OFFSET) \
+                     & ~XDMAV3_DMACR_SGS_MASK)
+
+#define XDMAV3_HW_SGS_SET                                               \
+    XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_DMACR_OFFSET,         \
+                     XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_DMACR_OFFSET) \
+                     | XDMAV3_DMACR_SGS_MASK)
+
+/****************************************************************************
+ * Move the BdPtr argument ahead an arbitrary number of BDs wrapping around
+ * to the beginning of the ring if needed.
+ *
+ * We know if a wrapaound should occur if the new BdPtr is greater than
+ * the high address in the ring OR if the new BdPtr crosses over the
+ * 0xFFFFFFFF to 0 boundary. The latter test is a valid one since we do not
+ * allow a BD space to span this boundary.
+ *
+ * @param Ring is the ring BdPtr appears in
+ * @param BdPtr on input is the starting BD position and on output is the
+ *        final BD position
+ * @param NumBd is the number of BD spaces to increment
+ *
+ ****************************************************************************/
+#define XDMAV3_RING_SEEKAHEAD(Ring, BdPtr, NumBd)                       \
+    {                                                                   \
+        u32 Addr = (u32)BdPtr;                                  \
+                                                                        \
+        Addr += (Ring->Separation * NumBd);                             \
+        if ((Addr > Ring->HighAddr) || ((u32)BdPtr > Addr))         \
+        {                                                               \
+            Addr -= Ring->Length;                                       \
+        }                                                               \
+                                                                        \
+        BdPtr = (XDmaBdV3*)Addr;                                        \
+    }
+
+/****************************************************************************
+ * Move the BdPtr argument backwards an arbitrary number of BDs wrapping
+ * around to the end of the ring if needed.
+ *
+ * We know if a wrapaound should occur if the new BdPtr is less than
+ * the base address in the ring OR if the new BdPtr crosses over the
+ * 0xFFFFFFFF to 0 boundary. The latter test is a valid one since we do not
+ * allow a BD space to span this boundary.
+ *
+ * @param Ring is the ring BdPtr appears in
+ * @param BdPtr on input is the starting BD position and on output is the
+ *        final BD position
+ * @param NumBd is the number of BD spaces to increment
+ *
+ ****************************************************************************/
+#define XDMAV3_RING_SEEKBACK(Ring, BdPtr, NumBd)                        \
+    {                                                                   \
+        u32 Addr = (u32)BdPtr;                                  \
+                                                                        \
+        Addr -= (Ring->Separation * NumBd);                             \
+        if ((Addr < Ring->BaseAddr) || ((u32)BdPtr < Addr))         \
+        {                                                               \
+            Addr += Ring->Length;                                       \
+        }                                                               \
+                                                                        \
+        BdPtr = (XDmaBdV3*)Addr;                                        \
+    }
+
+
+/************************** Function Prototypes ******************************/
+
+static int IsSgDmaChannel(XDmaV3 * InstancePtr);
+
+
+/************************** Variable Definitions *****************************/
+
+/******************************************************************************/
+/**
+ * Start the SGDMA channel.
+ *
+ * @param InstancePtr is a pointer to the instance to be started.
+ *
+ * @return
+ * - XST_SUCCESS if channel was started.
+ * - XST_DMA_SG_NO_LIST if the channel has no initialized BD ring.
+ *
+ ******************************************************************************/
+int XDmaV3_SgStart(XDmaV3 * InstancePtr)
+{
+	XDmaV3_BdRing *Ring = &InstancePtr->BdRing;
+	u32 Swcr;
+
+	/* BD list has yet to be created for this channel */
+	if (Ring->AllCnt == 0) {
+		return (XST_DMA_SG_NO_LIST);
+	}
+
+	/* Do nothing if already started */
+	if (Ring->RunState == XST_DMA_SG_IS_STARTED) {
+		return (XST_SUCCESS);
+	}
+
+	/* Note as started */
+	Ring->RunState = XST_DMA_SG_IS_STARTED;
+
+	/* Restore BDA */
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_BDA_OFFSET,
+			 Ring->BdaRestart);
+
+	/* If there are unprocessed BDs then we want to channel to begin processing
+	 * right away
+	 */
+	if ((XDmaV3_mReadBd(XDMAV3_PHYS_TO_VIRT(Ring, Ring->BdaRestart),
+			    XDMAV3_BD_DMASR_OFFSET) & XDMAV3_DMASR_DMADONE_MASK)
+	    == 0) {
+		/* DMACR.SGS = 0 */
+		XDMAV3_HW_SGS_CLEAR;
+	}
+
+	/* To start, clear SWCR.DSGAR, and set SWCR.SGE */
+	Swcr = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET);
+	Swcr &= ~XDMAV3_SWCR_DSGAR_MASK;
+	Swcr |= XDMAV3_SWCR_SGE_MASK;
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET, Swcr);
+
+	return (XST_SUCCESS);
+}
+
+
+/******************************************************************************/
+/**
+ * Stop the SGDMA or Simple SGDMA channel gracefully. Any DMA operation
+ * currently in progress is allowed to finish.
+ *
+ * An interrupt may be generated as the DMA engine finishes the packet in
+ * process. To prevent this (if desired) then disabled DMA interrupts prior to
+ * invoking this function.
+ *
+ * If after stopping the channel, new BDs are enqueued with XDmaV3_SgBdToHw(),
+ * then those BDs will not be processed until after XDmaV3_SgStart() is called.
+ *
+ * @param InstancePtr is a pointer to the instance to be stopped.
+ *
+ * @note This function will block until the HW indicates that DMA has stopped.
+ *
+ ******************************************************************************/
+void XDmaV3_SgStop(XDmaV3 * InstancePtr)
+{
+	volatile u32 Swcr;
+	u32 Dmasr;
+	XDmaV3_BdRing *Ring = &InstancePtr->BdRing;
+	u32 Ier;
+
+	/* Save the contents of the interrupt enable register then disable
+	 * interrupts. This register will be restored at the end of the function
+	 */
+	Ier = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_IER_OFFSET);
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_IER_OFFSET, 0);
+
+	/* Stopping the HW is a three step process:
+	 *   1. Set SWCR.SGD=1
+	 *   2. Wait for SWCR.SGE=0
+	 *   3. Set SWCR.DSGAR=0 and SWCR.SGE=1
+	 *
+	 * Once we've successfully gone through this process, the HW is fully
+	 * stopped. To restart we must give the HW a new BDA.
+	 */
+	Swcr = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET);
+
+	/* If the channel is currently active, stop it by setting SWCR.SGD=1
+	 * and waiting for SWCR.SGE to toggle to 0
+	 */
+	if (Swcr & XDMAV3_SWCR_SGE_MASK) {
+		Swcr |= XDMAV3_SWCR_SGD_MASK;
+		XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET,
+				 Swcr);
+
+		while (Swcr & XDMAV3_SWCR_SGE_MASK) {
+			Swcr = XDmaV3_mReadReg(InstancePtr->RegBase,
+					       XDMAV3_SWCR_OFFSET);
+		}
+	}
+
+	/* Note as stopped */
+	Ring->RunState = XST_DMA_SG_IS_STOPPED;
+
+	/* Save the BDA to restore when channel is restarted */
+	Ring->BdaRestart =
+		(XDmaBdV3 *) XDmaV3_mReadReg(InstancePtr->RegBase,
+					     XDMAV3_BDA_OFFSET);
+
+	/* If this is a receive channel, then the BDA restore may require a more
+	 * complex treatment. If the channel stopped without processing a packet,
+	 * then DMASR.SGDONE will be clear. The BDA we've already read in this case
+	 * is really BDA->BDA so we need to backup one BDA to get the correct
+	 * restart point.
+	 */
+	Dmasr = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_DMASR_OFFSET);
+	if ((Dmasr & XDMAV3_DMASR_DMACNFG_MASK) ==
+	    XDMAV3_DMASR_DMACNFG_SGDMARX_MASK) {
+		if (!(Dmasr & XDMAV3_DMASR_SGDONE_MASK)) {
+			Ring->BdaRestart =
+				(XDmaBdV3 *) XDMAV3_PHYS_TO_VIRT(Ring,
+								 Ring->
+								 BdaRestart);
+			Ring->BdaRestart =
+				XDmaV3_mSgBdPrev(InstancePtr, Ring->BdaRestart);
+			Ring->BdaRestart =
+				(XDmaBdV3 *) XDMAV3_VIRT_TO_PHYS(Ring,
+								 Ring->
+								 BdaRestart);
+		}
+	}
+
+	Swcr |= XDMAV3_SWCR_DSGAR_MASK;
+	Swcr &= ~XDMAV3_SWCR_SGD_MASK;
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET, Swcr);
+
+	/* Restore interrupt enables. If an interrupt occurs due to this function
+	 * stopping the channel then it will happen right here
+	 */
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_IER_OFFSET, Ier);
+}
+
+
+/******************************************************************************/
+/**
+ * Set the packet threshold for this SGDMA channel. This has the effect of
+ * delaying processor interrupts until the given number of packets (not BDs)
+ * have been processed.
+ *
+ * @param InstancePtr is a pointer to the instance to be worked on.
+ * @param Threshold is the packet threshold to set. If 0 is specified, then
+ *        this feature is disabled. Maximum threshold is 2^12 - 1.
+ *
+ * @return
+ * - XST_SUCCESS if threshold set properly.
+ * - XST_NO_FEATURE if this function was called on a DMA channel that does not
+ *   have interrupt coalescing capabilities.
+ *
+ * @note This function should not be prempted by another XDmaV3 function.
+ *
+ ******************************************************************************/
+int XDmaV3_SgSetPktThreshold(XDmaV3 * InstancePtr, u16 Threshold)
+{
+	u32 Reg;
+
+	/* Is this a SGDMA channel */
+	Reg = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_DMASR_OFFSET);
+	if (!IsSgDmaChannel(InstancePtr)) {
+		return (XST_NO_FEATURE);
+	}
+
+	/* Replace the pkt threshold field in the SWCR */
+	Reg = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET);
+	Reg &= ~XDMAV3_SWCR_PCT_MASK;
+	Reg |= ((Threshold << XDMAV3_SWCR_PCT_SHIFT) & XDMAV3_SWCR_PCT_MASK);
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET, Reg);
+
+	/* Finished */
+	return (XST_SUCCESS);
+}
+
+
+/******************************************************************************/
+/**
+ * Set the packet waitbound timer for this SGDMA channel. See xdmav3.h for more
+ * information on interrupt coalescing and the effects of the waitbound timer.
+ *
+ * @param InstancePtr is a pointer to the instance to be worked on.
+ * @param TimerVal is the waitbound period to set. If 0 is specified, then
+ *        this feature is disabled. Maximum waitbound is 2^12 - 1. LSB is
+ *        1 millisecond (approx).
+ *
+ * @return
+ * - XST_SUCCESS if waitbound set properly.
+ * - XST_NO_FEATURE if this function was called on a DMA channel that does not
+ *   have interrupt coalescing capabilities.
+ *
+ * @note This function should not be prempted by another XDmaV3 function.
+ *
+ ******************************************************************************/
+int XDmaV3_SgSetPktWaitbound(XDmaV3 * InstancePtr, u16 TimerVal)
+{
+	u32 Reg;
+
+	/* Is this a SGDMA channel */
+	Reg = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_DMASR_OFFSET);
+	if (!IsSgDmaChannel(InstancePtr)) {
+		return (XST_NO_FEATURE);
+	}
+
+	/* Replace the waitbound field in the SWCR */
+	Reg = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET);
+	Reg &= ~XDMAV3_SWCR_PWB_MASK;
+	Reg |= ((TimerVal << XDMAV3_SWCR_PWB_SHIFT) & XDMAV3_SWCR_PWB_MASK);
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET, Reg);
+
+	/* Finished */
+	return (XST_SUCCESS);
+}
+
+
+/******************************************************************************/
+/**
+ * Get the packet threshold for this channel that was set with
+ * XDmaV3_SgSetPktThreshold().
+ *
+ * @param InstancePtr is a pointer to the instance to be worked on.
+ *
+ * @return Current packet threshold as reported by HW. If the channel does not
+ *         include interrupt coalescing, then the return value will always be 0.
+ ******************************************************************************/
+u16 XDmaV3_SgGetPktThreshold(XDmaV3 * InstancePtr)
+{
+	u32 Reg;
+
+	/* Is this a SGDMA channel */
+	Reg = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_DMASR_OFFSET);
+	if (!IsSgDmaChannel(InstancePtr)) {
+		return (0);
+	}
+
+	/* Get the threshold */
+	Reg = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET);
+	Reg &= XDMAV3_SWCR_PCT_MASK;
+	Reg >>= XDMAV3_SWCR_PCT_SHIFT;
+	return ((u16) Reg);
+}
+
+
+/******************************************************************************/
+/**
+ * Get the waitbound timer for this channel that was set with
+ * XDmaV3_SgSetPktWaitbound().
+ *
+ * @param InstancePtr is a pointer to the instance to be worked on.
+ *
+ * @return Current waitbound timer as reported by HW. If the channel does not
+ *         include interrupt coalescing, then the return value will always be 0.
+ ******************************************************************************/
+u16 XDmaV3_SgGetPktWaitbound(XDmaV3 * InstancePtr)
+{
+	u32 Reg;
+
+	/* Is this a SGDMA channel */
+	Reg = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_DMASR_OFFSET);
+	if (!IsSgDmaChannel(InstancePtr)) {
+		return (0);
+	}
+
+	/* Get the threshold */
+	Reg = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET);
+	Reg &= XDMAV3_SWCR_PWB_MASK;
+	Reg >>= XDMAV3_SWCR_PWB_SHIFT;
+	return ((u16) Reg);
+}
+
+
+/******************************************************************************/
+/**
+ * Using a memory segment allocated by the caller, create and setup the BD list
+ * for the given SGDMA channel.
+ *
+ * @param InstancePtr is the instance to be worked on.
+ * @param PhysAddr is the physical base address of user memory region.
+ * @param VirtAddr is the virtual base address of the user memory region. If
+ *        address translation is not being utilized, then VirtAddr should be
+ *        equivalent to PhysAddr.
+ * @param Alignment governs the byte alignment of individual BDs. This function
+ *        will enforce a minimum alignment of 4 bytes with no maximum as long as
+ *        it is specified as a power of 2.
+ * @param BdCount is the number of BDs to setup in the user memory region. It is
+ *        assumed the region is large enough to contain the BDs. Refer to the
+ *        "SGDMA List Creation" section  in xdmav3.h for more information on
+ *        list creation.
+ *
+ * @return
+ *
+ * - XST_SUCCESS if initialization was successful
+ * - XST_NO_FEATURE if the provided instance is a non SGDMA type of DMA
+ *   channel.
+ * - XST_INVALID_PARAM under any of the following conditions: 1) PhysAddr and/or
+ *   VirtAddr are not aligned to the given Alignment parameter; 2) Alignment
+ *   parameter does not meet minimum requirements or is not a power of 2 value;
+ *   3) BdCount is 0.
+ * - XST_DMA_SG_LIST_ERROR if the memory segment containing the list spans
+ *   over address 0x00000000 in virtual address space.
+ *
+ * @note
+ *
+ * Some DMA HW requires 8 or more byte alignments of BDs. Make sure the correct
+ * value is passed into the Alignment parameter to meet individual DMA HW
+ * requirements.
+ *
+ ******************************************************************************/
+int XDmaV3_SgListCreate(XDmaV3 * InstancePtr, u32 PhysAddr, u32 VirtAddr,
+			u32 Alignment, unsigned BdCount)
+{
+	unsigned i;
+	u32 BdV;
+	u32 BdP;
+	XDmaV3_BdRing *Ring = &InstancePtr->BdRing;
+
+	/* In case there is a failure prior to creating list, make sure the following
+	 * attributes are 0 to prevent calls to other SG functions from doing anything
+	 */
+	Ring->AllCnt = 0;
+	Ring->FreeCnt = 0;
+	Ring->HwCnt = 0;
+	Ring->PreCnt = 0;
+	Ring->PostCnt = 0;
+
+	/* Is this a SGDMA channel */
+	if (!IsSgDmaChannel(InstancePtr)) {
+		return (XST_NO_FEATURE);
+	}
+
+	/* Make sure Alignment parameter meets minimum requirements */
+	if (Alignment < XDMABDV3_MINIMUM_ALIGNMENT) {
+		return (XST_INVALID_PARAM);
+	}
+
+	/* Make sure Alignment is a power of 2 */
+	if ((Alignment - 1) & Alignment) {
+		return (XST_INVALID_PARAM);
+	}
+
+	/* Make sure PhysAddr and VirtAddr are on same Alignment */
+	if ((PhysAddr % Alignment) || (VirtAddr % Alignment)) {
+		return (XST_INVALID_PARAM);
+	}
+
+	/* Is BdCount reasonable? */
+	if (BdCount == 0) {
+		return (XST_INVALID_PARAM);
+	}
+
+	/* Parameters are sane. Stop the HW just to be safe */
+	XDmaV3_SgStop(InstancePtr);
+
+	/* Figure out how many bytes will be between the start of adjacent BDs */
+	Ring->Separation =
+		(sizeof(XDmaBdV3) + (Alignment - 1)) & ~(Alignment - 1);
+
+	/* Must make sure the ring doesn't span address 0x00000000. If it does,
+	 * then the next/prev BD traversal macros will fail.
+	 */
+	if (VirtAddr > (VirtAddr + (Ring->Separation * BdCount) - 1)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* Initial ring setup:
+	 *  - Clear the entire space
+	 *  - Setup each BD's BDA field with the physical address of the next BD
+	 *  - Set each BD's DMASR.DMADONE bit
+	 */
+	memset((void *) VirtAddr, 0, (Ring->Separation * BdCount));
+
+	BdV = VirtAddr;
+	BdP = PhysAddr + Ring->Separation;
+	for (i = 1; i < BdCount; i++) {
+		XDmaV3_mWriteBd(BdV, XDMAV3_BD_BDA_OFFSET, BdP);
+		XDmaV3_mWriteBd(BdV, XDMAV3_BD_DMASR_OFFSET,
+				XDMAV3_DMASR_DMADONE_MASK);
+		XDMAV3_CACHE_FLUSH(BdV);
+		BdV += Ring->Separation;
+		BdP += Ring->Separation;
+	}
+
+	/* At the end of the ring, link the last BD back to the top */
+	XDmaV3_mWriteBd(BdV, XDMAV3_BD_BDA_OFFSET, PhysAddr);
+
+	/* Setup and initialize pointers and counters */
+	InstancePtr->BdRing.RunState = XST_DMA_SG_IS_STOPPED;
+	Ring->BaseAddr = VirtAddr;
+	Ring->PhysBaseAddr = PhysAddr;
+	Ring->HighAddr = BdV;
+	Ring->Length = Ring->HighAddr - Ring->BaseAddr + Ring->Separation;
+	Ring->AllCnt = BdCount;
+	Ring->FreeCnt = BdCount;
+	Ring->FreeHead = (XDmaBdV3 *) VirtAddr;
+	Ring->PreHead = (XDmaBdV3 *) VirtAddr;
+	Ring->HwHead = (XDmaBdV3 *) VirtAddr;
+	Ring->HwTail = (XDmaBdV3 *) VirtAddr;
+	Ring->PostHead = (XDmaBdV3 *) VirtAddr;
+	Ring->BdaRestart = (XDmaBdV3 *) PhysAddr;
+
+	/* Make sure the DMACR.SGS is 1 so that no DMA operations proceed until
+	 * the start function is called.
+	 */
+	XDMAV3_HW_SGS_SET;
+
+	return (XST_SUCCESS);
+}
+
+
+/******************************************************************************/
+/**
+ * Clone the given BD into every BD in the list. Except for XDMAV3_BD_BDA_OFFSET,
+ * every field of the source BD is replicated in every BD of the list.
+ *
+ * This function can be called only when all BDs are in the free group such as
+ * they are immediately after initialization with XDmaV3_SgListCreate(). This
+ * prevents modification of BDs while they are in use by HW or the user.
+ *
+ * @param InstancePtr is the instance to be worked on.
+ * @param SrcBdPtr is the source BD template to be cloned into the list. This BD
+ *        will be modified.
+ *
+ * @return
+ *   - XST_SUCCESS if the list was modified.
+ *   - XST_DMA_SG_NO_LIST if a list has not been created.
+ *   - XST_DMA_SG_LIST_ERROR if some of the BDs in this channel are under HW
+ *     or user control.
+ *   - XST_DEVICE_IS_STARTED if the DMA channel has not been stopped.
+ *
+ ******************************************************************************/
+int XDmaV3_SgListClone(XDmaV3 * InstancePtr, XDmaBdV3 * SrcBdPtr)
+{
+	unsigned i;
+	u32 CurBd;
+	u32 Save;
+	XDmaV3_BdRing *Ring = &InstancePtr->BdRing;
+
+	/* Can't do this function if there isn't a ring */
+	if (Ring->AllCnt == 0) {
+		return (XST_DMA_SG_NO_LIST);
+	}
+
+	/* Can't do this function with the channel running */
+	if (Ring->RunState == XST_DMA_SG_IS_STARTED) {
+		return (XST_DEVICE_IS_STARTED);
+	}
+
+	/* Can't do this function with some of the BDs in use */
+	if (Ring->FreeCnt != Ring->AllCnt) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* Modify the template by setting DMASR.DMADONE */
+	Save = XDmaV3_mReadBd(SrcBdPtr, XDMAV3_BD_DMASR_OFFSET);
+	Save |= XDMAV3_DMASR_DMADONE_MASK;
+	XDmaV3_mWriteBd(SrcBdPtr, XDMAV3_BD_DMASR_OFFSET, Save);
+
+	/* Starting from the top of the ring, save BD.Next, overwrite the entire BD
+	 * with the template, then restore BD.Next
+	 */
+	for (i = 0, CurBd = Ring->BaseAddr;
+	     i < Ring->AllCnt; i++, CurBd += Ring->Separation) {
+		Save = XDmaV3_mReadBd(CurBd, XDMAV3_BD_BDA_OFFSET);
+		memcpy((void *) CurBd, SrcBdPtr, sizeof(XDmaBdV3));
+		XDmaV3_mWriteBd(CurBd, XDMAV3_BD_BDA_OFFSET, Save);
+		XDMAV3_CACHE_FLUSH(CurBd);
+	}
+
+	return (XST_SUCCESS);
+}
+
+
+/******************************************************************************/
+/**
+ * Reserve locations in the BD list. The set of returned BDs may be modified in
+ * preparation for future DMA transaction(s). Once the BDs are ready to be
+ * submitted to HW, the user must call XDmaV3_SgBdToHw() in the same order which
+ * they were allocated here. Example:
+ *
+ * <pre>
+ *        NumBd = 2;
+ *        Status = XDmaV3_SgBdAlloc(MyDmaInstPtr, NumBd, &MyBdSet);
+ *
+ *        if (Status != XST_SUCCESS)
+ *        {
+ *            // Not enough BDs available for the request
+ *        }
+ *
+ *        CurBd = MyBdSet;
+ *        for (i=0; i<NumBd; i++)
+ *        {
+ *            // Prepare CurBd.....
+ *
+ *            // Onto next BD
+ *            CurBd = XDmaV3_mSgBdNext(MyDmaInstPtr, CurBd);
+ *        }
+ *
+ *        // Give list to HW
+ *        Status = XDmaV3_SgBdToHw(MyDmaInstPtr, NumBd, MyBdSet);
+ * </pre>
+ *
+ * A more advanced use of this function may allocate multiple sets of BDs.
+ * They must be allocated and given to HW in the correct sequence:
+ * <pre>
+ *        // Legal
+ *        XDmaV3_SgBdAlloc(MyDmaInstPtr, NumBd1, &MySet1);
+ *        XDmaV3_SgBdToHw(MyDmaInstPtr, NumBd1, MySet1);
+ *
+ *        // Legal
+ *        XDmaV3_SgBdAlloc(MyDmaInstPtr, NumBd1, &MySet1);
+ *        XDmaV3_SgBdAlloc(MyDmaInstPtr, NumBd2, &MySet2);
+ *        XDmaV3_SgBdToHw(MyDmaInstPtr, NumBd1, MySet1);
+ *        XDmaV3_SgBdToHw(MyDmaInstPtr, NumBd2, MySet2);
+ *
+ *        // Not legal
+ *        XDmaV3_SgBdAlloc(MyDmaInstPtr, NumBd1, &MySet1);
+ *        XDmaV3_SgBdAlloc(MyDmaInstPtr, NumBd2, &MySet2);
+ *        XDmaV3_SgBdToHw(MyDmaInstPtr, NumBd2, MySet2);
+ *        XDmaV3_SgBdToHw(MyDmaInstPtr, NumBd1, MySet1);
+ * </pre>
+ *
+ * Use the API defined in xdmabdv3.h to modify individual BDs. Traversal of the
+ * BD set can be done using XDmaV3_mSgBdNext() and XDmaV3_mSgBdPrev().
+ *
+ * @param InstancePtr is a pointer to the instance to be worked on.
+ * @param NumBd is the number of BDs to allocate
+ * @param BdSetPtr is an output parameter, it points to the first BD available
+ *        for modification.
+ *
+ * @return
+ *   - XST_SUCCESS if the requested number of BDs was returned in the BdSetPtr
+ *     parameter.
+ *   - XST_FAILURE if there were not enough free BDs to satisfy the request.
+ *
+ * @note This function should not be preempted by another XDmaV3 function call
+ *       that modifies the BD space. It is the caller's responsibility to
+ *       provide a mutual exclusion mechanism.
+ *
+ * @note Do not modify more BDs than the number requested with the NumBd
+ *       parameter. Doing so will lead to data corruption and system
+ *       instability.
+ *
+ ******************************************************************************/
+int XDmaV3_SgBdAlloc(XDmaV3 * InstancePtr, unsigned NumBd, XDmaBdV3 ** BdSetPtr)
+{
+	XDmaV3_BdRing *Ring = &InstancePtr->BdRing;
+
+	/* Enough free BDs available for the request? */
+	if (Ring->FreeCnt < NumBd) {
+		return (XST_FAILURE);
+	}
+
+	/* Set the return argument and move FreeHead forward */
+	*BdSetPtr = Ring->FreeHead;
+	XDMAV3_RING_SEEKAHEAD(Ring, Ring->FreeHead, NumBd);
+	Ring->FreeCnt -= NumBd;
+	Ring->PreCnt += NumBd;
+	return (XST_SUCCESS);
+}
+
+/******************************************************************************/
+/**
+ * Fully or partially undo an XDmaV3_SgBdAlloc() operation. Use this function
+ * if all the BDs allocated by XDmaV3_SgBdAlloc() could not be transferred to
+ * HW with XDmaV3_SgBdToHw().
+ *
+ * This function helps out in situations when an unrelated error occurs after
+ * BDs have been allocated but before they have been given to HW. An example of
+ * this type of error would be an OS running out of resources.
+ *
+ * This function is not the same as XDmaV3_SgBdFree(). The Free function returns
+ * BDs to the free list after they have been processed by HW, while UnAlloc
+ * returns them before being processed by HW.
+ *
+ * There are two scenarios where this function can be used. Full UnAlloc or
+ * Partial UnAlloc. A Full UnAlloc means all the BDs Alloc'd will be returned:
+ *
+ * <pre>
+ *    Status = XDmaV3_SgBdAlloc(Inst, 10, &BdPtr);
+ *        .
+ *        .
+ *    if (Error)
+ *    {
+ *        Status = XDmaV3_SgBdUnAlloc(Inst, 10, &BdPtr);
+ *    }
+ * </pre>
+ *
+ * A partial UnAlloc means some of the BDs Alloc'd will be returned:
+ *
+ * <pre>
+ *    Status = XDmaV3_SgBdAlloc(Inst, 10, &BdPtr);
+ *    BdsLeft = 10;
+ *    CurBdPtr = BdPtr;
+ *
+ *    while (BdsLeft)
+ *    {
+ *       if (Error)
+ *       {
+ *          Status = XDmaV3_SgBdUnAlloc(Inst, BdsLeft, CurBdPtr);
+ *       }
+ *
+ *       CurBdPtr = XDmaV3_SgBdNext(Inst, CurBdPtr);
+ *       BdsLeft--;
+ *    }
+ * </pre>
+ *
+ * A partial UnAlloc must include the last BD in the list that was Alloc'd.
+ *
+ * @param InstancePtr is a pointer to the instance to be worked on.
+ * @param NumBd is the number of BDs to allocate
+ * @param BdSetPtr is an output parameter, it points to the first BD available
+ *        for modification.
+ *
+ * @return
+ *   - XST_SUCCESS if the BDs were unallocated.
+ *   - XST_FAILURE if NumBd parameter was greater that the number of BDs in the
+ *     preprocessing state.
+ *
+ * @note This function should not be preempted by another XDmaV3 function call
+ *       that modifies the BD space. It is the caller's responsibility to
+ *       provide a mutual exclusion mechanism.
+ *
+ ******************************************************************************/
+int XDmaV3_SgBdUnAlloc(XDmaV3 * InstancePtr, unsigned NumBd,
+		       XDmaBdV3 * BdSetPtr)
+{
+	XDmaV3_BdRing *Ring = &InstancePtr->BdRing;
+
+	/* Enough BDs in the free state for the request? */
+	if (Ring->PreCnt < NumBd) {
+		return (XST_FAILURE);
+	}
+
+	/* Set the return argument and move FreeHead backward */
+	XDMAV3_RING_SEEKBACK(Ring, Ring->FreeHead, NumBd);
+	Ring->FreeCnt += NumBd;
+	Ring->PreCnt -= NumBd;
+	return (XST_SUCCESS);
+}
+
+
+/******************************************************************************/
+/**
+ * Enqueue a set of BDs to HW that were previously allocated by
+ * XDmaV3_SgBdAlloc(). Once this function returns, the argument BD set goes
+ * under HW control. Any changes made to these BDs after this point will corrupt
+ * the BD list leading to data corruption and system instability.
+ *
+ * The set will be rejected if the last BD of the set does not mark the end of
+ * a packet (see XDmaBdV3_mSetLast()).
+ *
+ * @param InstancePtr is a pointer to the instance to be worked on.
+ * @param NumBd is the number of BDs in the set.
+ * @param BdSetPtr is the first BD of the set to commit to HW.
+ *
+ * @return
+ *   - XST_SUCCESS if the set of BDs was accepted and enqueued to HW.
+ *   - XST_FAILURE if the set of BDs was rejected because the last BD of the set
+ *     did not have its "last" bit set.
+ *   - XST_DMA_SG_LIST_ERROR if this function was called out of sequence with
+ *     XDmaV3_SgBdAlloc().
+ *
+ * @note This function should not be preempted by another XDmaV3 function call
+ *       that modifies the BD space. It is the caller's responsibility to
+ *       provide a mutual exclusion mechanism.
+ *
+ ******************************************************************************/
+int XDmaV3_SgBdToHw(XDmaV3 * InstancePtr, unsigned NumBd, XDmaBdV3 * BdSetPtr)
+{
+	XDmaV3_BdRing *Ring = &InstancePtr->BdRing;
+	XDmaBdV3 *LastBdPtr;
+	unsigned i;
+	u32 Dmacr;
+	u32 Swcr;
+
+	/* Make sure we are in sync with XDmaV3_SgBdAlloc() */
+	if ((Ring->PreCnt < NumBd) || (Ring->PreHead != BdSetPtr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* For all BDs in this set (except the last one)
+	 *   - Clear DMASR except for DMASR.DMABSY
+	 *   - Clear DMACR.SGS
+	 *
+	 * For the last BD in this set
+	 *   - Clear DMASR except for DMASR.DMABSY
+	 *   - Set DMACR.SGS (marks the end of the new active list)
+	 */
+	LastBdPtr = BdSetPtr;
+	for (i = 1; i < NumBd; i++) {
+		XDmaV3_mWriteBd(LastBdPtr, XDMAV3_BD_DMASR_OFFSET,
+				XDMAV3_DMASR_DMABSY_MASK);
+
+		Dmacr = XDmaV3_mReadBd(LastBdPtr, XDMAV3_BD_DMACR_OFFSET);
+		XDmaV3_mWriteBd(LastBdPtr, XDMAV3_BD_DMACR_OFFSET,	/* DMACR.SGS = 0 */
+				Dmacr & ~XDMAV3_DMACR_SGS_MASK);
+		XDMAV3_CACHE_FLUSH(LastBdPtr);
+
+		LastBdPtr = XDmaV3_mSgBdNext(InstancePtr, LastBdPtr);
+	}
+
+	/* Last BD */
+	XDmaV3_mWriteBd(LastBdPtr, XDMAV3_BD_DMASR_OFFSET,
+			XDMAV3_DMASR_DMABSY_MASK);
+
+	Dmacr = XDmaV3_mReadBd(LastBdPtr, XDMAV3_BD_DMACR_OFFSET);
+	XDmaV3_mWriteBd(LastBdPtr, XDMAV3_BD_DMACR_OFFSET,	/* DMACR.SGS = 1 */
+			Dmacr | XDMAV3_DMACR_SGS_MASK);
+	XDMAV3_CACHE_FLUSH(LastBdPtr);
+
+	/* The last BD should have DMACR.LAST set */
+	if (!(Dmacr & XDMAV3_DMACR_LAST_MASK)) {
+		return (XST_FAILURE);
+	}
+
+	/* This set has completed pre-processing, adjust ring pointers & counters */
+	XDMAV3_RING_SEEKAHEAD(Ring, Ring->PreHead, NumBd);
+	Ring->PreCnt -= NumBd;
+
+	/* If it is running, tell the DMA engine to pause */
+	Swcr = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET);
+	if (Ring->RunState == XST_DMA_SG_IS_STARTED) {
+		Swcr |= XDMAV3_SWCR_SGD_MASK;
+		XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET,
+				 Swcr);
+	}
+
+	/* Transfer control of the BDs to the DMA engine. There are two cases to
+	 * consider:
+	 *
+	 * 1) No currently active list.
+	 *    In this case, just resume the engine.
+	 *
+	 * 2) Active list.
+	 *    In this case, the last BD in the current list should have DMACR.SGS
+	 *    cleared so the engine will never stop there. The new stopping
+	 *    point is at the end of the extended list. Once the SGS bits are
+	 *    changed, resume the engine.
+	 */
+	if (Ring->HwCnt != 0) {
+		/* Handle case 2 */
+		Dmacr = XDmaV3_mReadBd(Ring->HwTail, XDMAV3_BD_DMACR_OFFSET);
+		Dmacr &= ~XDMAV3_DMACR_SGS_MASK;
+		XDmaV3_mWriteBd(Ring->HwTail, XDMAV3_BD_DMACR_OFFSET, Dmacr);
+		XDMAV3_CACHE_FLUSH(Ring->HwTail);
+	}
+
+	/* Adjust Hw pointers and counters. XDMAV3_RING_SEEKAHEAD could be used to
+	 * advance HwTail, but it will always evaluate to LastBdPtr
+	 */
+	Ring->HwTail = LastBdPtr;
+	Ring->HwCnt += NumBd;
+
+	/* If it was enabled, tell the engine to resume */
+	if (Ring->RunState == XST_DMA_SG_IS_STARTED) {
+		Swcr &= ~XDMAV3_SWCR_SGD_MASK;
+		Swcr |= XDMAV3_SWCR_SGE_MASK;
+		XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_SWCR_OFFSET,
+				 Swcr);
+	}
+
+	return (XST_SUCCESS);
+}
+
+
+/******************************************************************************/
+/**
+ * Returns a set of BD(s) that have been processed by HW. The returned BDs may
+ * be examined to determine the outcome of the DMA transaction(s). Once the BDs
+ * have been examined, the user must call XDmaV3_SgBdFree() in the same order
+ * which they were retrieved here. Example:
+ *
+ * <pre>
+ *        MaxBd = 0xFFFFFFFF;   // Ensure we get all that are ready
+ *
+ *        NumBd = XDmaV3_SgBdFromHw(MyDmaInstPtr, MaxBd, &MyBdSet);
+ *
+ *        if (NumBd == 0)
+ *        {
+ *           // HW has nothing ready for us yet
+ *        }
+ *
+ *        CurBd = MyBdSet;
+ *        for (i=0; i<NumBd; i++)
+ *        {
+ *           // Examine CurBd for post processing.....
+ *
+ *           // Onto next BD
+ *           CurBd = XDmaV3_mSgBdNext(MyDmaInstPtr, CurBd);
+ *           }
+ *
+ *           XDmaV3_SgBdFree(MyDmaInstPtr, NumBd, MyBdSet); // Return the list
+ *        }
+ * </pre>
+ *
+ * A more advanced use of this function may allocate multiple sets of BDs.
+ * They must be retrieved from HW and freed in the correct sequence:
+ * <pre>
+ *        // Legal
+ *        XDmaV3_SgBdFromHw(MyDmaInstPtr, NumBd1, &MySet1);
+ *        XDmaV3_SgBdFree(MyDmaInstPtr, NumBd1, MySet1);
+ *
+ *        // Legal
+ *        XDmaV3_SgBdFromHw(MyDmaInstPtr, NumBd1, &MySet1);
+ *        XDmaV3_SgBdFromHw(MyDmaInstPtr, NumBd2, &MySet2);
+ *        XDmaV3_SgBdFree(MyDmaInstPtr, NumBd1, MySet1);
+ *        XDmaV3_SgBdFree(MyDmaInstPtr, NumBd2, MySet2);
+ *
+ *        // Not legal
+ *        XDmaV3_SgBdFromHw(MyDmaInstPtr, NumBd1, &MySet1);
+ *        XDmaV3_SgBdFromHw(MyDmaInstPtr, NumBd2, &MySet2);
+ *        XDmaV3_SgBdFree(MyDmaInstPtr, NumBd2, MySet2);
+ *        XDmaV3_SgBdFree(MyDmaInstPtr, NumBd1, MySet1);
+ * </pre>
+ *
+ * If HW has only partially completed a packet spanning multiple BDs, then none
+ * of the BDs for that packet will be included in the results.
+ *
+ * @param InstancePtr is a pointer to the instance to be worked on.
+ * @param BdLimit is the maximum number of BDs to return in the set.
+ * @param BdSetPtr is an output parameter, it points to the first BD available
+ *        for examination.
+ *
+ * @return
+ *   The number of BDs processed by HW. A value of 0 indicates that no data
+ *   is available. No more than BdLimit BDs will be returned.
+ *
+ * @note Treat BDs returned by this function as read-only.
+ *
+ * @note This function should not be preempted by another XDmaV3 function call
+ *       that modifies the BD space. It is the caller's responsibility to
+ *       provide a mutual exclusion mechanism.
+ *
+ ******************************************************************************/
+unsigned XDmaV3_SgBdFromHw(XDmaV3 * InstancePtr, unsigned BdLimit,
+			   XDmaBdV3 ** BdSetPtr)
+{
+	XDmaV3_BdRing *Ring = &InstancePtr->BdRing;
+	XDmaBdV3 *CurBd;
+	unsigned BdCount;
+	unsigned BdPartialCount;
+	u32 Dmasr;
+
+	CurBd = Ring->HwHead;
+	BdCount = 0;
+	BdPartialCount = 0;
+
+	/* If no BDs in work group, then there's nothing to search */
+	if (Ring->HwCnt == 0) {
+		*BdSetPtr = NULL;
+		return (0);
+	}
+
+	/* Starting at HwHead, keep moving forward in the list until:
+	 *  - A BD is encountered with its DMASR.DMABSY bit set which means HW has
+	 *    not completed processing of that BD.
+	 *  - Ring->HwTail is reached
+	 *  - The number of requested BDs has been processed
+	 */
+	while (BdCount < BdLimit) {
+		/* Read the status */
+		XDMAV3_CACHE_INVALIDATE(CurBd);
+		Dmasr = XDmaV3_mReadBd(CurBd, XDMAV3_BD_DMASR_OFFSET);
+
+		/* If the HW still hasn't processed this BD then we are done */
+		if (Dmasr & XDMAV3_DMASR_DMABSY_MASK) {
+			break;
+		}
+
+		BdCount++;
+
+		/* HW has processed this BD so check the "last" bit. If it is clear,
+		 * then there are more BDs for the current packet. Keep a count of
+		 * these partial packet BDs.
+		 */
+		if (Dmasr & XDMAV3_DMASR_LAST_MASK) {
+			BdPartialCount = 0;
+		}
+		else {
+			BdPartialCount++;
+		}
+
+		/* Reached the end of the work group */
+		if (CurBd == Ring->HwTail) {
+			break;
+		}
+
+		/* Move on to next BD in work group */
+		CurBd = XDmaV3_mSgBdNext(InstancePtr, CurBd);
+	}
+
+	/* Subtract off any partial packet BDs found */
+	BdCount -= BdPartialCount;
+
+	/* If BdCount is non-zero then BDs were found to return. Set return
+	 * parameters, update pointers and counters, return success
+	 */
+	if (BdCount) {
+		*BdSetPtr = Ring->HwHead;
+		Ring->HwCnt -= BdCount;
+		Ring->PostCnt += BdCount;
+		XDMAV3_RING_SEEKAHEAD(Ring, Ring->HwHead, BdCount);
+		return (BdCount);
+	}
+	else {
+		*BdSetPtr = NULL;
+		return (0);
+	}
+}
+
+
+/******************************************************************************/
+/**
+ * Frees a set of BDs that had been previously retrieved with XDmaV3_SgBdFromHw().
+ *
+ * @param InstancePtr is a pointer to the instance to be worked on.
+ * @param NumBd is the number of BDs to free.
+ * @param BdSetPtr is the head of a list of BDs returned by XDmaV3_SgBdFromHw().
+ *
+ * @return
+ *   - XST_SUCCESS if the set of BDs was freed.
+ *   - XST_DMA_SG_LIST_ERROR if this function was called out of sequence with
+ *     XDmaV3_SgBdFromHw().
+ *
+ * @note This function should not be preempted by another XDmaV3 function call
+ *       that modifies the BD space. It is the caller's responsibility to
+ *       provide a mutual exclusion mechanism.
+ *
+ ******************************************************************************/
+int XDmaV3_SgBdFree(XDmaV3 * InstancePtr, unsigned NumBd, XDmaBdV3 * BdSetPtr)
+{
+	XDmaV3_BdRing *Ring = &InstancePtr->BdRing;
+
+	/* Make sure we are in sync with XDmaV3_SgBdFromHw() */
+	if ((Ring->PostCnt < NumBd) || (Ring->PostHead != BdSetPtr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* Update pointers and counters */
+	Ring->FreeCnt += NumBd;
+	Ring->PostCnt -= NumBd;
+	XDMAV3_RING_SEEKAHEAD(Ring, Ring->PostHead, NumBd);
+	return (XST_SUCCESS);
+}
+
+
+/******************************************************************************/
+/**
+ * Check the internal data structures of the BD ring for the provided channel.
+ * The following checks are made:
+ *
+ *   - Is the BD ring linked correctly in physical address space.
+ *   - Do the internal pointers point to BDs in the ring.
+ *   - Do the internal counters add up.
+ *
+ * The channel should be stopped prior to calling this function.
+ *
+ * @param InstancePtr is a pointer to the instance to be worked on.
+ *
+ * @return
+ *   - XST_SUCCESS if the set of BDs was freed.
+ *   - XST_DMA_SG_NO_LIST if the list has not been created.
+ *   - XST_IS_STARTED if the channel is not stopped.
+ *   - XST_DMA_SG_LIST_ERROR if a problem is found with the internal data
+ *     structures. If this value is returned, the channel should be reset to
+ *     avoid data corruption or system instability.
+ *
+ * @note This function should not be preempted by another XDmaV3 function call
+ *       that modifies the BD space. It is the caller's responsibility to
+ *       provide a mutual exclusion mechanism.
+ *
+ ******************************************************************************/
+int XDmaV3_SgCheck(XDmaV3 * InstancePtr)
+{
+	XDmaV3_BdRing *RingPtr = &InstancePtr->BdRing;
+	u32 AddrV, AddrP;
+	unsigned i;
+
+	/* Is the list created */
+	if (RingPtr->AllCnt == 0) {
+		return (XST_DMA_SG_NO_LIST);
+	}
+
+	/* Can't check if channel is running */
+	if (RingPtr->RunState == XST_DMA_SG_IS_STARTED) {
+		return (XST_IS_STARTED);
+	}
+
+	/* RunState doesn't make sense */
+	else if (RingPtr->RunState != XST_DMA_SG_IS_STOPPED) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* Verify internal pointers point to correct memory space */
+	AddrV = (u32) RingPtr->FreeHead;
+	if ((AddrV < RingPtr->BaseAddr) || (AddrV > RingPtr->HighAddr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	AddrV = (u32) RingPtr->PreHead;
+	if ((AddrV < RingPtr->BaseAddr) || (AddrV > RingPtr->HighAddr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	AddrV = (u32) RingPtr->HwHead;
+	if ((AddrV < RingPtr->BaseAddr) || (AddrV > RingPtr->HighAddr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	AddrV = (u32) RingPtr->HwTail;
+	if ((AddrV < RingPtr->BaseAddr) || (AddrV > RingPtr->HighAddr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	AddrV = (u32) RingPtr->PostHead;
+	if ((AddrV < RingPtr->BaseAddr) || (AddrV > RingPtr->HighAddr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* Verify internal counters add up */
+	if ((RingPtr->HwCnt + RingPtr->PreCnt + RingPtr->FreeCnt +
+	     RingPtr->PostCnt) != RingPtr->AllCnt) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* Verify BDs are linked correctly */
+	AddrV = RingPtr->BaseAddr;
+	AddrP = RingPtr->PhysBaseAddr + RingPtr->Separation;
+	for (i = 1; i < RingPtr->AllCnt; i++) {
+		/* Check BDA for this BD. It should point to next physical addr */
+		if (XDmaV3_mReadBd(AddrV, XDMAV3_BD_BDA_OFFSET) != AddrP) {
+			return (XST_DMA_SG_LIST_ERROR);
+		}
+
+		/* Move on to next BD */
+		AddrV += RingPtr->Separation;
+		AddrP += RingPtr->Separation;
+	}
+
+	/* Last BD should point back to the beginning of ring */
+	if (XDmaV3_mReadBd(AddrV, XDMAV3_BD_BDA_OFFSET) !=
+	    RingPtr->PhysBaseAddr) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* No problems found */
+	return (XST_SUCCESS);
+}
+
+
+/******************************************************************************
+ * Verify given channel is of the SGDMA variety.
+ *
+ * @param InstancePtr is a pointer to the instance to be worked on.
+ *
+ * @return
+ *   - 1 if channel is of type SGDMA
+ *   - 0 if channel is not of type SGDMA
+ ******************************************************************************/
+static int IsSgDmaChannel(XDmaV3 * InstancePtr)
+{
+	u32 Dmasr;
+
+	Dmasr = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_DMASR_OFFSET);
+	if (Dmasr & (XDMAV3_DMASR_DMACNFG_SGDMARX_MASK |
+		     XDMAV3_DMASR_DMACNFG_SGDMATX_MASK |
+		     XDMAV3_DMASR_DMACNFG_SSGDMA_MASK)) {
+		return (1);
+	}
+	else {
+		return (0);
+	}
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xdmav3_simple.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3_simple.c
--- linux-2.6.31.12/drivers/xilinx_common/xdmav3_simple.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xdmav3_simple.c	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,124 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2006 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xdmav3_simple.c
+*
+* This file implements Simple DMA related functions. For more
+* information on this driver, see xdmav3.h.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 3.00a rmm  03/11/06 First release
+* </pre>
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include "xdmav3.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+
+/************************** Variable Definitions *****************************/
+
+
+/*****************************************************************************/
+/**
+* Initiate a simple DMA transfer. The BD argument sets the parameters of the
+* transfer. Since the BD is also used for SG DMA transfers, some fields of the
+* BD will be ignored. The following BD macros will have no effect on the
+* transfer:
+*
+* - XDmaBdV3_mSetLast()
+* - XDmaBdV3_mClearLast()
+* - XDmaBdV3_mSetBdPage()
+*
+* To determine when the transfer has completed, the user can poll the device
+* with XDmaV3_mGetStatus() and test the XDMAV3_DMASR_DMABSY_MASK bit, or wait for
+* an interrupt. When the DMA operation has completed, the outcome of the
+* transfer can be retrieved by calling XDmaV3_mGetStatus() and testing for DMA
+* bus errors bits.
+*
+* @param InstancePtr is a pointer to the instance to be worked on.
+* @param BdPtr sets the parameters of the transfer.
+*
+* @return
+* - XST_SUCCESS if the transfer was initated
+* - XST_DEVICE_BUSY if a transfer is already in progress
+*
+******************************************************************************/
+int XDmaV3_SimpleTransfer(XDmaV3 * InstancePtr, XDmaBdV3 * BdPtr)
+{
+	u32 Dmasr;
+
+	/* Is the channel busy */
+	Dmasr = XDmaV3_mReadReg(InstancePtr->RegBase, XDMAV3_DMASR_OFFSET);
+	if (Dmasr & (XDMAV3_DMASR_DMABSY_MASK | XDMAV3_DMASR_SGBSY_MASK)) {
+		return (XST_DEVICE_BUSY);
+	}
+
+	/* Copy BdPtr fields into the appropriate HW registers */
+
+	/* DMACR: SGS bit is set always. This is done in case the transfer
+	 * occurs on a SGDMA channel and will prevent the HW from fetching the
+	 * next BD.
+	 */
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_DMACR_OFFSET,
+			 XDmaV3_mReadBd(BdPtr, XDMAV3_BD_DMACR_OFFSET)
+			 | XDMAV3_DMACR_SGS_MASK);
+
+	/* MSBA */
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_MSBA_OFFSET,
+			 XDmaV3_mReadBd(BdPtr, XDMAV3_BD_MSBA_OFFSET));
+
+	/* LSBA */
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_LSBA_OFFSET,
+			 XDmaV3_mReadBd(BdPtr, XDMAV3_BD_LSBA_OFFSET));
+
+	/* LENGTH: Writing this register starts HW */
+	XDmaV3_mWriteReg(InstancePtr->RegBase, XDMAV3_LENGTH_OFFSET,
+			 XDmaV3_mReadBd(BdPtr, XDMAV3_BD_LENGTH_OFFSET));
+
+	return (XST_SUCCESS);
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xenv.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xenv.h
--- linux-2.6.31.12/drivers/xilinx_common/xenv.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xenv.h	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,249 @@
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2005-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xenv_linux.h
+*
+* Defines common services specified by xenv.h.
+*
+* @note
+* 	This file is not intended to be included directly by driver code.
+* 	Instead, the generic xenv.h file is intended to be included by driver
+* 	code.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 1.00a wgr  02/28/07 Added cache handling macros.
+* 1.00a wgr  02/27/07 Simplified code. Deprecated old-style macro names.
+* 1.00a xd   11/03/04 Improved support for doxygen.
+* 1.00a ch   10/24/02 First release
+* 1.10a wgr  03/22/07 Converted to new coding style.
+* </pre>
+*
+*
+******************************************************************************/
+
+#ifndef XENV_LINUX_H
+#define XENV_LINUX_H
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+
+/***************************** Include Files *********************************/
+
+#include <asm/cache.h>
+#include <asm/cacheflush.h>
+#include <linux/string.h>
+#include <linux/delay.h>
+
+
+/******************************************************************************
+ *
+ * MEMCPY / MEMSET related macros.
+ *
+ * Those macros are defined to catch legacy code in Xilinx drivers. The
+ * XENV_MEM_COPY and XENV_MEM_FILL macros were used in early Xilinx driver
+ * code. They are being replaced by memcpy() and memset() function calls. These
+ * macros are defined to catch any remaining occurences of those macros.
+ *
+ ******************************************************************************/
+
+/*****************************************************************************/
+/**
+ *
+ * Copies a non-overlapping block of memory.
+ *
+ * @param	DestPtr
+ *		Destination address to copy data to.
+ *
+ * @param	SrcPtr
+ * 		Source address to copy data from.
+ *
+ * @param	Bytes
+ * 		Number of bytes to copy.
+ *
+ * @return	None.
+ *
+ *****************************************************************************/
+
+#define XENV_MEM_COPY(DestPtr, SrcPtr, Bytes) \
+		memcpy(DestPtr, SrcPtr, Bytes)
+/*		do_not_use_XENV_MEM_COPY_use_memcpy_instead */
+
+
+/*****************************************************************************/
+/**
+ *
+ * Fills an area of memory with constant data.
+ *
+ * @param	DestPtr
+ *		Destination address to copy data to.
+ *
+ * @param	Data
+ * 		Value to set.
+ *
+ * @param	Bytes
+ * 		Number of bytes to copy.
+ *
+ * @return	None.
+ *
+ *****************************************************************************/
+
+#define XENV_MEM_FILL(DestPtr, Data, Bytes) \
+		memset(DestPtr, Data, Bytes)
+/*		do_not_use_XENV_MEM_FILL_use_memset_instead */
+
+
+/******************************************************************************
+ *
+ * TIME related macros
+ *
+ ******************************************************************************/
+/**
+ * A structure that contains a time stamp used by other time stamp macros
+ * defined below. This structure is processor dependent.
+ */
+typedef int XENV_TIME_STAMP;
+
+/*****************************************************************************/
+/**
+ *
+ * Time is derived from the 64 bit PPC timebase register
+ *
+ * @param   StampPtr is the storage for the retrieved time stamp.
+ *
+ * @return  None.
+ *
+ * @note
+ *
+ * Signature: void XENV_TIME_STAMP_GET(XTIME_STAMP *StampPtr)
+ * <br><br>
+ * This macro must be implemented by the user.
+ *
+ *****************************************************************************/
+#define XENV_TIME_STAMP_GET(StampPtr)
+
+/*****************************************************************************/
+/**
+ *
+ * This macro is not yet implemented and always returns 0.
+ *
+ * @param   Stamp1Ptr is the first sampled time stamp.
+ * @param   Stamp2Ptr is the second sampled time stamp.
+ *
+ * @return  0
+ *
+ * @note
+ *
+ * This macro must be implemented by the user.
+ *
+ *****************************************************************************/
+#define XENV_TIME_STAMP_DELTA_US(Stamp1Ptr, Stamp2Ptr)     (0)
+
+/*****************************************************************************/
+/**
+ *
+ * This macro is not yet implemented and always returns 0.
+ *
+ * @param   Stamp1Ptr is the first sampled time stamp.
+ * @param   Stamp2Ptr is the second sampled time stamp.
+ *
+ * @return  0
+ *
+ * @note
+ *
+ * This macro must be implemented by the user
+ *
+ *****************************************************************************/
+#define XENV_TIME_STAMP_DELTA_MS(Stamp1Ptr, Stamp2Ptr)     (0)
+
+/*****************************************************************************/
+/**
+ *
+ * Delay the specified number of microseconds.
+ *
+ * @param	delay
+ * 		Number of microseconds to delay.
+ *
+ * @return	None.
+ *
+ * @note	XENV_USLEEP is deprecated. Use udelay() instead.
+ *
+ *****************************************************************************/
+
+#define XENV_USLEEP(delay)	udelay(delay)
+/*		do_not_use_XENV_MEM_COPY_use_memcpy_instead */
+
+
+/******************************************************************************
+ *
+ * CACHE handling macros / mappings
+ *
+ * The implementation of the cache handling functions can be found in
+ * arch/microblaze.
+ *
+ * These #defines are simple mappings to the Linux API.
+ *
+ * The underlying Linux implementation will take care of taking the right
+ * actions depending on the configuration of the MicroBlaze processor in the
+ * system.
+ *
+ ******************************************************************************/
+
+#define XCACHE_ENABLE_DCACHE()		__enable_dcache()
+#define XCACHE_DISABLE_DCACHE()		__disable_dcache()
+#define XCACHE_ENABLE_ICACHE()		__enable_icache()
+#define XCACHE_DISABLE_ICACHE()		__disable_icache()
+
+#define XCACHE_INVALIDATE_DCACHE_RANGE(Addr, Len) invalidate_dcache_range((u32)(Addr), (u32)((Addr)+(Len)))
+#define XCACHE_FLUSH_DCACHE_RANGE(Addr, Len)      flush_dcache_range((u32)(Addr), (u32)((Addr)+(Len)))
+
+#define XCACHE_INVALIDATE_ICACHE_RANGE(Addr, Len) "XCACHE_INVALIDATE_ICACHE_RANGE unsupported"
+#define XCACHE_FLUSH_ICACHE_RANGE(Addr, Len)      flush_icache_range(Addr, Len)
+
+#define XCACHE_ENABLE_CACHE()	\
+		{ XCACHE_ENABLE_DCACHE(); XCACHE_ENABLE_ICACHE(); }
+
+#define XCACHE_DISABLE_CACHE()	\
+		{ XCACHE_DISABLE_DCACHE(); XCACHE_DISABLE_ICACHE(); }
+
+
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif            /* end of protection macro */
+
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xilinx_syms.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xilinx_syms.c
--- linux-2.6.31.12/drivers/xilinx_common/xilinx_syms.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xilinx_syms.c	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,74 @@
+/*
+ * xilinx_syms.c
+ *
+ * This file EXPORT_SYMBOL_GPL's all of the Xilinx entry points.
+ *
+ * Author: MontaVista Software, Inc.
+ *         source@mvista.com
+ *
+ * 2002 (c) MontaVista, Software, Inc.  This file is licensed under the terms
+ * of the GNU General Public License version 2.  This program is licensed
+ * "as is" without any warranty of any kind, whether express or implied.
+ */
+
+#include <linux/module.h>
+
+#include "xbasic_types.h"
+EXPORT_SYMBOL_GPL(XAssert);
+EXPORT_SYMBOL_GPL(XAssertSetCallback);
+EXPORT_SYMBOL_GPL(XAssertStatus);
+extern u32 XWaitInAssert;
+EXPORT_SYMBOL_GPL(XWaitInAssert);
+
+#include "xdma_channel.h"
+EXPORT_SYMBOL_GPL(XDmaChannel_CommitPuts);
+EXPORT_SYMBOL_GPL(XDmaChannel_CreateSgList);
+EXPORT_SYMBOL_GPL(XDmaChannel_DecrementPktCount);
+EXPORT_SYMBOL_GPL(XDmaChannel_GetControl);
+EXPORT_SYMBOL_GPL(XDmaChannel_GetDescriptor);
+EXPORT_SYMBOL_GPL(XDmaChannel_GetIntrEnable);
+EXPORT_SYMBOL_GPL(XDmaChannel_GetIntrStatus);
+EXPORT_SYMBOL_GPL(XDmaChannel_GetPktCount);
+EXPORT_SYMBOL_GPL(XDmaChannel_GetPktThreshold);
+EXPORT_SYMBOL_GPL(XDmaChannel_GetPktWaitBound);
+EXPORT_SYMBOL_GPL(XDmaChannel_GetStatus);
+EXPORT_SYMBOL_GPL(XDmaChannel_GetVersion);
+EXPORT_SYMBOL_GPL(XDmaChannel_Initialize);
+EXPORT_SYMBOL_GPL(XDmaChannel_IsReady);
+EXPORT_SYMBOL_GPL(XDmaChannel_IsSgListEmpty);
+EXPORT_SYMBOL_GPL(XDmaChannel_PutDescriptor);
+EXPORT_SYMBOL_GPL(XDmaChannel_Reset);
+EXPORT_SYMBOL_GPL(XDmaChannel_SelfTest);
+EXPORT_SYMBOL_GPL(XDmaChannel_SetControl);
+EXPORT_SYMBOL_GPL(XDmaChannel_SetIntrEnable);
+EXPORT_SYMBOL_GPL(XDmaChannel_SetIntrStatus);
+EXPORT_SYMBOL_GPL(XDmaChannel_SetPktThreshold);
+EXPORT_SYMBOL_GPL(XDmaChannel_SetPktWaitBound);
+EXPORT_SYMBOL_GPL(XDmaChannel_SgStart);
+EXPORT_SYMBOL_GPL(XDmaChannel_SgStop);
+EXPORT_SYMBOL_GPL(XDmaChannel_Transfer);
+
+#include "xipif_v1_23_b.h"
+//EXPORT_SYMBOL_GPL(XIpIfV123b_SelfTest);
+
+#include "xpacket_fifo_v2_00_a.h"
+EXPORT_SYMBOL_GPL(XPacketFifoV200a_Initialize);
+EXPORT_SYMBOL_GPL(XPacketFifoV200a_Read);
+EXPORT_SYMBOL_GPL(XPacketFifoV200a_SelfTest);
+EXPORT_SYMBOL_GPL(XPacketFifoV200a_Write);
+
+#include "xio.h"
+EXPORT_SYMBOL_GPL(XIo_Out8);
+EXPORT_SYMBOL_GPL(XIo_In8);
+EXPORT_SYMBOL_GPL(XIo_Out16);
+EXPORT_SYMBOL_GPL(XIo_In16);
+EXPORT_SYMBOL_GPL(XIo_Out32);
+EXPORT_SYMBOL_GPL(XIo_In32);
+
+#include "xversion.h"
+EXPORT_SYMBOL_GPL(XVersion_Copy);
+EXPORT_SYMBOL_GPL(XVersion_FromString);
+EXPORT_SYMBOL_GPL(XVersion_IsEqual);
+EXPORT_SYMBOL_GPL(XVersion_Pack);
+EXPORT_SYMBOL_GPL(XVersion_ToString);
+EXPORT_SYMBOL_GPL(XVersion_UnPack);
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xio.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xio.c
--- linux-2.6.31.12/drivers/xilinx_common/xio.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xio.c	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,519 @@
+/* $Id: xio.c,v 1.5 2007/07/24 22:01:35 xduan Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2007-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xio.c
+*
+* Contains I/O functions for memory-mapped or non-memory-mapped I/O
+* architectures.  These functions encapsulate PowerPC architecture-specific
+* I/O requirements.
+*
+* @note
+*
+* This file contains architecture-dependent code.
+*
+* The order of the SYNCHRONIZE_IO and the read or write operation is
+* important. For the Read operation, all I/O needs to complete prior
+* to the desired read to insure valid data from the address. The PPC
+* is a weakly ordered I/O model and reads can and will occur prior
+* to writes and the SYNCHRONIZE_IO ensures that any writes occur prior
+* to the read. For the Write operation the SYNCHRONIZE_IO occurs
+* after the desired write to ensure that the address is updated with
+* the new value prior to any subsequent read.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- --------------------------------------------------------
+* 1.00a ecm  10/18/05 initial release
+*                     needs to be updated to replace eieio with mbar when
+*                     compilers support this mnemonic.
+*
+* 1.00a ecm  01/24/07 update for new coding standard.
+* 1.10a xd   07/24/07 Corrected the format in asm functions in __DCC__ mode.
+* </pre>
+******************************************************************************/
+
+
+/***************************** Include Files *********************************/
+#include "xio.h"
+#include "xbasic_types.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/************************** Function Prototypes ******************************/
+/*****************************************************************************/
+/**
+*
+* Performs a 16-bit endian converion.
+*
+* @param    Source contains the value to be converted.
+* @param    DestPtr contains a pointer to the location to put the
+*           converted value.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void OutSwap16(u16 Source, u16 *DestPtr)
+{
+    *DestPtr = (u16) (((Source & 0xFF00) >> 8) | ((Source & 0x00FF) << 8));
+}
+
+u16 InSwap16(u16 *DestPtr)
+{
+    u16 Source = *DestPtr;
+   return (u16) (((Source & 0xFF00) >> 8) | ((Source & 0x00FF) << 8));
+}
+/*****************************************************************************/
+/**
+*
+* Performs a 32-bit endian converion.
+*
+* @param    Source contains the value to be converted.
+* @param    DestPtr contains a pointer to the location to put the
+*           converted value.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void OutSwap32(u32 Source, u32 *DestPtr)
+{
+
+    /* get each of the half words from the 32 bit word */
+
+    u16 LoWord = (u16) (Source & 0x0000FFFF);
+    u16 HiWord = (u16) ((Source & 0xFFFF0000) >> 16);
+
+    /* byte swap each of the 16 bit half words */
+
+    LoWord = (((LoWord & 0xFF00) >> 8) | ((LoWord & 0x00FF) << 8));
+    HiWord = (((HiWord & 0xFF00) >> 8) | ((HiWord & 0x00FF) << 8));
+
+    /* swap the half words before returning the value */
+
+    *DestPtr = (u32) ((LoWord << 16) | HiWord);
+}
+
+u32 InSwap32(u32 *DestPtr)
+{
+   /* get each of the half words from the 32 bit word */
+    u32 Source = *DestPtr;
+
+    u16 LoWord = (u16) (Source & 0x0000FFFF);
+    u16 HiWord = (u16) ((Source & 0xFFFF0000) >> 16);
+
+    /* byte swap each of the 16 bit half words */
+
+    LoWord = (((LoWord & 0xFF00) >> 8) | ((LoWord & 0x00FF) << 8));
+    HiWord = (((HiWord & 0xFF00) >> 8) | ((HiWord & 0x00FF) << 8));
+
+    /* swap the half words before returning the value */
+
+    return (u32) ((LoWord << 16) | HiWord);
+}
+
+/*****************************************************************************/
+/**
+*
+* Performs an input operation for an 8-bit memory location by reading from the
+* specified address and returning the value read from that address.
+*
+* @param    InAddress contains the address to perform the input operation at.
+*
+* @return
+*
+* The value read from the specified input address.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+    u8 XIo_In8(XIo_Address InAddress)
+{
+    /* read the contents of the I/O location and then synchronize the I/O
+     * such that the I/O operation completes before proceeding on
+     */
+
+#if defined CONFIG_PPC
+
+    u8 IoContents;
+    __asm__ volatile ("eieio; lbz %0,0(%1)":"=r" (IoContents):"b"
+              (InAddress));
+    return IoContents;
+
+#else
+
+    SYNCHRONIZE_IO;
+    return *(u8 *) InAddress;
+
+#endif
+
+}
+
+/*****************************************************************************/
+/**
+*
+* Performs an input operation for a 16-bit memory location by reading from the
+* specified address and returning the value read from that address.
+*
+* @param    InAddress contains the address to perform the input operation at.
+*
+* @return
+*
+* The value read from the specified input address.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+u16 XIo_In16(XIo_Address InAddress)
+{
+    /* read the contents of the I/O location and then synchronize the I/O
+     * such that the I/O operation completes before proceeding on
+     */
+
+#if defined CONFIG_PPC
+
+    u16 IoContents;
+    __asm__ volatile ("eieio; lhz %0,0(%1)":"=r" (IoContents):"b"
+              (InAddress));
+    return IoContents;
+
+#else
+
+    SYNCHRONIZE_IO;
+    return *(u16 *) InAddress;
+
+#endif
+}
+
+/*****************************************************************************/
+/**
+*
+* Performs an input operation for a 32-bit memory location by reading from the
+* specified address and returning the value read from that address.
+*
+* @param    InAddress contains the address to perform the input operation at.
+*
+* @return
+*
+* The value read from the specified input address.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+u32 XIo_In32(XIo_Address InAddress)
+{
+    /* read the contents of the I/O location and then synchronize the I/O
+     * such that the I/O operation completes before proceeding on
+     */
+
+#ifdef CONFIG_PPC
+
+    u32 IoContents;
+    __asm__ volatile ("eieio; lwz %0,0(%1)":"=r" (IoContents):"b"
+              (InAddress));
+    return IoContents;
+
+#else
+
+    SYNCHRONIZE_IO;
+    return *(u32 *) InAddress;
+
+#endif
+
+}
+
+/*****************************************************************************/
+/**
+*
+* Performs an input operation for a 16-bit memory location by reading from the
+* specified address and returning the byte-swapped value read from that
+* address.
+*
+* @param    InAddress contains the address to perform the input operation at.
+*
+* @return
+*
+* The byte-swapped value read from the specified input address.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+u16 XIo_InSwap16(XIo_Address InAddress)
+{
+    /* read the contents of the I/O location and then synchronize the I/O
+     * such that the I/O operation completes before proceeding on
+     */
+#ifdef CONFIG_PPC
+    u16 IoContents;
+
+    __asm__ volatile ("eieio; lhbrx %0,0,%1":"=r" (IoContents):"b"
+              (InAddress));
+    return IoContents;
+#else
+    return InSwap16(InAddress);
+#endif
+}
+
+/*****************************************************************************/
+/**
+*
+* Performs an input operation for a 32-bit memory location by reading from the
+* specified address and returning the byte-swapped value read from that
+* address.
+*
+* @param    InAddress contains the address to perform the input operation at.
+*
+* @return
+*
+* The byte-swapped value read from the specified input address.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+u32 XIo_InSwap32(XIo_Address InAddress)
+{
+    /* read the contents of the I/O location and then synchronize the I/O
+     * such that the I/O operation completes before proceeding on
+     */
+#ifdef CONFIG_PPC
+    u32 IoContents;
+
+    __asm__ volatile ("eieio; lwbrx %0,0,%1":"=r" (IoContents):"b"
+              (InAddress));
+    return IoContents;
+#else
+    return InSwap32(InAddress);
+#endif
+
+}
+
+
+/*****************************************************************************/
+/**
+*
+* Performs an output operation for an 8-bit memory location by writing the
+* specified value to the the specified address.
+*
+* @param    OutAddress contains the address to perform the output operation at.
+* @param    Value contains the value to be output at the specified address.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void XIo_Out8(XIo_Address OutAddress, u8 Value)
+{
+    /* write the contents of the I/O location and then synchronize the I/O
+     * such that the I/O operation completes before proceeding on
+     */
+
+#ifdef CONFIG_PPC
+
+    __asm__ volatile ("stb %0,0(%1); eieio"::"r" (Value), "b"(OutAddress));
+
+#else
+
+    *(volatile u8 *) OutAddress = Value;
+    SYNCHRONIZE_IO;
+
+#endif
+
+}
+
+/*****************************************************************************/
+/**
+*
+* Performs an output operation for a 16-bit memory location by writing the
+* specified value to the the specified address.
+*
+* @param    OutAddress contains the address to perform the output operation at.
+* @param    Value contains the value to be output at the specified address.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void XIo_Out16(XIo_Address OutAddress, u16 Value)
+{
+    /* write the contents of the I/O location and then synchronize the I/O
+     * such that the I/O operation completes before proceeding on
+     */
+
+#ifdef CONFIG_PPC
+
+    __asm__ volatile ("sth %0,0(%1); eieio"::"r" (Value), "b"(OutAddress));
+
+#else
+
+    *(volatile u16 *) OutAddress = Value;
+    SYNCHRONIZE_IO;
+
+#endif
+}
+
+/*****************************************************************************/
+/**
+*
+* Performs an output operation for a 32-bit memory location by writing the
+* specified value to the the specified address.
+*
+* @param    OutAddress contains the address to perform the output operation at.
+* @param    Value contains the value to be output at the specified address.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void XIo_Out32(XIo_Address OutAddress, u32 Value)
+{
+    /* write the contents of the I/O location and then synchronize the I/O
+     * such that the I/O operation completes before proceeding on
+     */
+
+#ifdef CONFIG_PPC
+
+    __asm__ volatile ("stw %0,0(%1); eieio"::"r" (Value), "b"(OutAddress));
+
+#else
+
+    *(volatile u32 *) OutAddress = Value;
+    SYNCHRONIZE_IO;
+
+#endif
+}
+
+/*****************************************************************************/
+/**
+*
+* Performs an output operation for a 16-bit memory location by writing the
+* specified value to the the specified address. The value is byte-swapped
+* before being written.
+*
+* @param    OutAddress contains the address to perform the output operation at.
+* @param    Value contains the value to be output at the specified address.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void XIo_OutSwap16(XIo_Address OutAddress, u16 Value)
+{
+    /* write the contents of the I/O location and then synchronize the I/O
+     * such that the I/O operation completes before proceeding on
+     */
+#ifdef CONFIG_PPC
+    __asm__ volatile ("sthbrx %0,0,%1; eieio"::"r" (Value),
+              "b"(OutAddress));
+#else
+    OutSwap16(OutAddress, Value);
+#endif
+}
+
+/*****************************************************************************/
+/**
+*
+* Performs an output operation for a 32-bit memory location by writing the
+* specified value to the the specified address. The value is byte-swapped
+* before being written.
+*
+* @param    OutAddress contains the address to perform the output operation at.
+* @param    Value contains the value to be output at the specified address.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void XIo_OutSwap32(XIo_Address OutAddress, u32 Value)
+{
+    /* write the contents of the I/O location and then synchronize the I/O
+     * such that the I/O operation completes before proceeding on
+     */
+#ifdef CONFIG_PPC
+    __asm__ volatile ("stwbrx %0,0,%1; eieio"::"r" (Value),
+              "b"(OutAddress));
+#else
+    OutSwap32(OutAddress, Value);
+#endif
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xio_dcr.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xio_dcr.c
--- linux-2.6.31.12/drivers/xilinx_common/xio_dcr.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xio_dcr.c	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,520 @@
+/* $Id: xio_dcr.c,v 1.9 2007/01/24 17:00:16 meinelte Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2007-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xio_dcr.c
+*
+* The implementation of the XDcrIo interface. See xio_dcr.h for more
+* information about the component.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 1.00a ecm  11/09/06 Modified from the PPC405 version to use the indirect
+*                     addressing that is available in the PPC440 block in V5.
+*                     Removed the jump table structure in xio_dcr.c also.
+*                     Added functionality from the SEG driver to allow for
+*                     one file pair.
+* 1.00a ecm  01/02/07 Incorporated changes from testing with multiple DCR
+*                     masters, discovered and fixed several concurrency
+*                     issues.
+* 1.00a ecm  01/24/07 update for new coding standard.
+* </pre>
+*
+* @internal
+*
+* The C functions which subsequently call into either the assembly code or into
+* the provided table of functions are required since the registers assigned to
+* the calling and return from functions are strictly defined in the ABI and that
+* definition is used in the low-level functions directly. The use of macros is
+* not recommended since the temporary registers in the ABI are defined but there
+* is no way to force the compiler to use a specific register in a block of code.
+*
+*****************************************************************************/
+
+/***************************** Include Files ********************************/
+
+#include <asm/dcr.h>
+#include <asm/reg.h>
+
+#include "xstatus.h"
+#include "xbasic_types.h"
+#include "xio.h"
+#include "xio_dcr.h"
+
+/************************** Constant Definitions ****************************/
+
+/*
+ * base address defines for each of the four possible DCR base
+ * addresses a processor can have
+ */
+#define XDCR_0_BASEADDR 0x000
+#define XDCR_1_BASEADDR 0x100
+#define XDCR_2_BASEADDR 0x200
+#define XDCR_3_BASEADDR 0x300
+
+
+#define MAX_DCR_REGISTERS           4096
+#define MAX_DCR_REGISTER            MAX_DCR_REGISTERS - 1
+#define MIN_DCR_REGISTER            0
+
+/**************************** Type Definitions ******************************/
+
+
+/***************** Macros (Inline Functions) Definitions ********************/
+
+/************************** Variable Definitions ****************************/
+
+
+
+/************************** Function Prototypes *****************************/
+
+/*****************************************************************************/
+/**
+*
+* Outputs value provided to specified register defined in the header file.
+*
+* @param    DcrRegister is the intended destination DCR register
+* @param    Data is the value to be placed into the specified DCR register
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+****************************************************************************/
+void XIo_DcrOut(u32 DcrRegister, u32 Data)
+{
+    /*
+     * Assert validates the register number
+     */
+    XASSERT_VOID(DcrRegister < MAX_DCR_REGISTERS);
+
+    /*
+     * pass the call on to the proper function
+     */
+    XIo_mDcrIndirectAddrWriteReg(XDCR_0_BASEADDR, DcrRegister, Data);
+}
+
+/*****************************************************************************/
+/**
+*
+* Reads value from specified register.
+*
+* @param    DcrRegister is the intended source DCR register
+*
+* @return
+*
+* Contents of the specified DCR register.
+*
+* @note
+*
+* None.
+*
+****************************************************************************/
+u32 XIo_DcrIn(u32 DcrRegister)
+{
+    /*
+     * Assert validates the register number
+     */
+    XASSERT_NONVOID(DcrRegister < MAX_DCR_REGISTERS);
+
+    /*
+     * pass the call on to the proper function
+     */
+    return (XIo_mDcrIndirectAddrReadReg(XDCR_0_BASEADDR, DcrRegister));
+}
+
+/*****************************************************************************/
+/**
+*
+* Reads the value of the specified register using the indirect access method.
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    DcrRegister is the intended destination DCR register
+*
+* @return
+*
+* Contents of the specified DCR register.
+*
+* @note
+*
+* Uses the indirect addressing method available in V5 with PPC440.
+*
+****************************************************************************/
+u32 XIo_DcrReadReg(u32 DcrBase, u32 DcrRegister)
+{
+    switch (DcrBase) {
+    case 0x000:
+        return XIo_mDcrIndirectAddrReadReg(XDCR_0_BASEADDR,
+                           DcrRegister);
+    case 0x100:
+        return XIo_mDcrIndirectAddrReadReg(XDCR_1_BASEADDR,
+                           DcrRegister);
+    case 0x200:
+        return XIo_mDcrIndirectAddrReadReg(XDCR_2_BASEADDR,
+                           DcrRegister);
+    case 0x300:
+        return XIo_mDcrIndirectAddrReadReg(XDCR_3_BASEADDR,
+                           DcrRegister);
+    default:
+        return XIo_mDcrIndirectAddrReadReg(XDCR_0_BASEADDR,
+                           DcrRegister);
+    }
+}
+
+/*****************************************************************************/
+/**
+*
+* Writes the value to the specified register using the indirect access method.
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    DcrRegister is the intended destination DCR register
+* @param    Data is the value to be placed into the specified DCR register
+*
+* @return
+*
+* None
+*
+* @note
+*
+* Uses the indirect addressing method available in V5 with PPC440.
+*
+****************************************************************************/
+void XIo_DcrWriteReg(u32 DcrBase, u32 DcrRegister, u32 Data)
+{
+    switch (DcrBase) {
+    case 0x000:
+        XIo_mDcrIndirectAddrWriteReg(XDCR_0_BASEADDR, DcrRegister,
+                         Data);
+        return;
+    case 0x100:
+        XIo_mDcrIndirectAddrWriteReg(XDCR_1_BASEADDR, DcrRegister,
+                         Data);
+        return;
+    case 0x200:
+        XIo_mDcrIndirectAddrWriteReg(XDCR_2_BASEADDR, DcrRegister,
+                         Data);
+        return;
+    case 0x300:
+        XIo_mDcrIndirectAddrWriteReg(XDCR_3_BASEADDR, DcrRegister,
+                         Data);
+        return;
+    default:
+        XIo_mDcrIndirectAddrWriteReg(XDCR_0_BASEADDR, DcrRegister,
+                         Data);
+        return;
+    }
+}
+
+/*****************************************************************************/
+/**
+*
+* Explicitly acquires and release DCR lock--Auto-Lock is disabled.
+* Reads the value of the specified register using the indirect access method.
+* This function is provided because the most common usecase is to enable
+* Auto-Lock. Checking for Auto-Lock in every indirect access would defeat the
+* purpose of having Auto-Lock.
+* Auto-Lock can only be enable/disabled in hardware.
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    DcrRegister is the intended destination DCR register
+*
+* @return
+*
+* Contents of the specified DCR register.
+*
+* @note
+*
+* Uses the indirect addressing method available in V5 with PPC440.
+*
+****************************************************************************/
+u32 XIo_DcrLockAndReadReg(u32 DcrBase, u32 DcrRegister)
+{
+    unsigned int rVal;
+
+    switch (DcrBase) {
+    case 0x000:
+        XIo_mDcrLock(XDCR_0_BASEADDR);
+        rVal = XIo_mDcrIndirectAddrReadReg(XDCR_0_BASEADDR,
+                           DcrRegister);
+        XIo_mDcrUnlock(XDCR_0_BASEADDR);
+    case 0x100:
+        XIo_mDcrLock(XDCR_1_BASEADDR);
+        rVal = XIo_mDcrIndirectAddrReadReg(XDCR_1_BASEADDR,
+                           DcrRegister);
+        XIo_mDcrUnlock(XDCR_1_BASEADDR);
+    case 0x200:
+        XIo_mDcrLock(XDCR_2_BASEADDR);
+        rVal = XIo_mDcrIndirectAddrReadReg(XDCR_2_BASEADDR,
+                           DcrRegister);
+        XIo_mDcrUnlock(XDCR_2_BASEADDR);
+    case 0x300:
+        XIo_mDcrLock(XDCR_3_BASEADDR);
+        rVal = XIo_mDcrIndirectAddrReadReg(XDCR_3_BASEADDR,
+                           DcrRegister);
+        XIo_mDcrUnlock(XDCR_3_BASEADDR);
+    default:
+        XIo_mDcrLock(XDCR_0_BASEADDR);
+        rVal = XIo_mDcrIndirectAddrReadReg(XDCR_0_BASEADDR,
+                           DcrRegister);
+        XIo_mDcrUnlock(XDCR_0_BASEADDR);
+    }
+    return rVal;
+}
+
+/*****************************************************************************/
+/**
+*
+* Explicitly acquires and release DCR lock--Auto-Lock is disabled.
+* Writes the value to the specified register using the indirect access method.
+* This function is provided because the most common usecase is to enable
+* Auto-Lock. Checking for Auto-Lock in every indirect access would defeat the
+* purpose of having Auto-Lock.
+* Auto-Lock can only be enable/disabled in hardware.
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    DcrRegister is the intended destination DCR register
+* @param    Data is the value to be placed into the specified DCR register
+*
+* @return
+*
+* None
+*
+* @note
+*
+* Uses the indirect addressing method available in V5 with PPC440.
+*
+****************************************************************************/
+void XIo_DcrLockAndWriteReg(u32 DcrBase, u32 DcrRegister, u32 Data)
+{
+    switch (DcrBase) {
+    case 0x000:
+        XIo_mDcrLock(XDCR_0_BASEADDR);
+        XIo_mDcrIndirectAddrWriteReg(XDCR_0_BASEADDR, DcrRegister,
+                         Data);
+        XIo_mDcrUnlock(XDCR_0_BASEADDR);
+        return;
+    case 0x100:
+        XIo_mDcrLock(XDCR_1_BASEADDR);
+        XIo_mDcrIndirectAddrWriteReg(XDCR_1_BASEADDR, DcrRegister,
+                         Data);
+        XIo_mDcrUnlock(XDCR_1_BASEADDR);
+        return;
+    case 0x200:
+        XIo_mDcrLock(XDCR_2_BASEADDR);
+        XIo_mDcrIndirectAddrWriteReg(XDCR_2_BASEADDR, DcrRegister,
+                         Data);
+        XIo_mDcrUnlock(XDCR_2_BASEADDR);
+        return;
+    case 0x300:
+        XIo_mDcrLock(XDCR_3_BASEADDR);
+        XIo_mDcrIndirectAddrWriteReg(XDCR_3_BASEADDR, DcrRegister,
+                         Data);
+        XIo_mDcrUnlock(XDCR_3_BASEADDR);
+        return;
+    default:
+        XIo_mDcrLock(XDCR_0_BASEADDR);
+        XIo_mDcrIndirectAddrWriteReg(XDCR_0_BASEADDR, DcrRegister,
+                         Data);
+        XIo_mDcrUnlock(XDCR_0_BASEADDR);
+        return;
+    }
+}
+
+/*****************************************************************************/
+/**
+*
+* Read APU UDI DCR via indirect addressing.
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    UDInum is the desired APU UDI register
+*
+* @return
+*
+* Contents of the specified APU register.
+*
+* @note
+*
+* Uses the indirect addressing method available in V5 with PPC440.
+*
+****************************************************************************/
+u32 XIo_DcrReadAPUUDIReg(u32 DcrBase, short UDInum)
+{
+    switch (DcrBase) {
+    case 0x000:
+        return XIo_mDcrIndirectAddrReadAPUUDIReg(XDCR_0_BASEADDR,
+                             UDInum);
+    case 0x100:
+        return XIo_mDcrIndirectAddrReadAPUUDIReg(XDCR_1_BASEADDR,
+                             UDInum);
+    case 0x200:
+        return XIo_mDcrIndirectAddrReadAPUUDIReg(XDCR_2_BASEADDR,
+                             UDInum);
+    case 0x300:
+        return XIo_mDcrIndirectAddrReadAPUUDIReg(XDCR_3_BASEADDR,
+                             UDInum);
+    default:
+        return XIo_mDcrIndirectAddrReadAPUUDIReg(XDCR_0_BASEADDR,
+                             UDInum);
+    }
+}
+
+/*****************************************************************************/
+/**
+*
+* Writes the value to the APU UDI DCR using the indirect access method.
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    UDInum is the intended destination APU register
+* @param    Data is the value to be placed into the specified APU register
+*
+* @return
+*
+* None
+*
+* @note
+*
+* Uses the indirect addressing method available in V5 with PPC440.
+*
+****************************************************************************/
+void XIo_DcrWriteAPUUDIReg(u32 DcrBase, short UDInum, u32 Data)
+{
+    switch (DcrBase) {
+    case 0x000:
+        XIo_mDcrIndirectAddrWriteAPUUDIReg(XDCR_0_BASEADDR, UDInum,
+                           Data);
+        return;
+    case 0x100:
+        XIo_mDcrIndirectAddrWriteAPUUDIReg(XDCR_1_BASEADDR, UDInum,
+                           Data);
+        return;
+    case 0x200:
+        XIo_mDcrIndirectAddrWriteAPUUDIReg(XDCR_2_BASEADDR, UDInum,
+                           Data);
+        return;
+    case 0x300:
+        XIo_mDcrIndirectAddrWriteAPUUDIReg(XDCR_3_BASEADDR, UDInum,
+                           Data);
+        return;
+    default:
+        XIo_mDcrIndirectAddrWriteAPUUDIReg(XDCR_0_BASEADDR, UDInum,
+                           Data);
+        return;
+    }
+}
+
+/*****************************************************************************/
+/**
+*
+* Locks DCR bus via the Global Status/Control register.
+*
+* @param    DcrBase is the base of the block of DCR registers
+*
+* @return
+*
+* None
+*
+* @note
+*
+* Care must be taken to not write a '1' to either timeout bit because
+* it will be cleared. The internal PPC440 can clear both timeout bits but an
+* external DCR master can only clear the external DCR master's timeout bit.
+*
+* Only available in V5 with PPC440.
+*
+****************************************************************************/
+void XIo_DcrLock(u32 DcrBase)
+{
+    switch (DcrBase) {
+    case 0x000:
+        XIo_mDcrLock(XDCR_0_BASEADDR);
+        return;
+    case 0x100:
+        XIo_mDcrLock(XDCR_1_BASEADDR);
+        return;
+    case 0x200:
+        XIo_mDcrLock(XDCR_2_BASEADDR);
+        return;
+    case 0x300:
+        XIo_mDcrLock(XDCR_3_BASEADDR);
+        return;
+    default:
+        XIo_mDcrLock(XDCR_0_BASEADDR);
+        return;
+    }
+}
+
+/*****************************************************************************/
+/**
+*
+* Unlocks DCR bus via the Global Status/Control register.
+*
+* @param    DcrBase is the base of the block of DCR registers
+*
+* @return
+*
+* None
+*
+* @note
+*
+* Care must be taken to not write a '1' to either timeout bit because
+* it will be cleared. The internal PPC440 can clear both timeout bits but an
+* external DCR master can only clear the external DCR master's timeout bit.
+*
+* Only available in V5 with PPC440.
+*
+****************************************************************************/
+void XIo_DcrUnlock(u32 DcrBase)
+{
+    switch (DcrBase) {
+    case 0x000:
+        XIo_mDcrUnlock(XDCR_0_BASEADDR);
+        return;
+    case 0x100:
+        XIo_mDcrUnlock(XDCR_1_BASEADDR);
+        return;
+    case 0x200:
+        XIo_mDcrUnlock(XDCR_2_BASEADDR);
+        return;
+    case 0x300:
+        XIo_mDcrUnlock(XDCR_3_BASEADDR);
+        return;
+    default:
+        XIo_mDcrUnlock(XDCR_0_BASEADDR);
+        return;
+    }
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xio_dcr.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xio_dcr.h
--- linux-2.6.31.12/drivers/xilinx_common/xio_dcr.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xio_dcr.h	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,697 @@
+/* $Id: xio_dcr.h,v 1.8 2007/01/24 17:00:16 meinelte Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2007-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xio_dcr.h
+*
+* The DCR I/O access functions.
+*
+* @note
+*
+* These access functions are specific to the PPC440 CPU. Changes might be
+* necessary for other members of the IBM PPC Family.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 1.00a ecm  10/18/05 First release
+*                     Need to verify opcodes for mt/mfdcr remain the same.
+* 1.00a ecm  11/09/06 Modified from the PPC405 version to use the indirect
+*                     addressing that is available in the PPC440 block in V5.
+*                     Removed the jump table structure in xio_dcr.c also.
+*                     Added functionality from the SEG driver to allow for
+*                     one file pair.
+* 1.00a ecm  01/02/07 Incorporated changes from testing with multiple DCR
+*                     masters, discovered and fixed several concurrency
+*                     issues.
+* 1.00a ecm  01/24/07 update for new coding standard.
+* </pre>
+*
+* @internal
+*
+* This code WILL NOT FUNCTION on the PPC405 based architectures, V2P and V4.
+*
+******************************************************************************/
+
+#ifndef XDCRIO_H        /* prevent circular inclusions */
+#define XDCRIO_H        /* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+
+/***************************** Include Files *********************************/
+#include "xbasic_types.h"
+
+/************************** Constant Definitions *****************************/
+/*
+ *   256 internal DCR registers
+ *   Base address: 2 most signifcant bits of 10-bit addr taken from
+ *                 the C_DCRBASEADDR parameter of the processor block.
+ *   Offset: 8 least significant bits
+ */
+/* register base addresses */
+
+#define XDCR_APU_BASE   0x04
+#define XDCR_MIB_BASE   0x10
+#define XDCR_XB_BASE    0x20
+#define XDCR_PLBS0_BASE 0x34
+#define XDCR_PLBS1_BASE 0x44
+#define XDCR_PLBM_BASE  0x54
+#define XDCR_DMA0_BASE  0x80
+#define XDCR_DMA1_BASE  0x98
+#define XDCR_DMA2_BASE  0xB0
+#define XDCR_DMA3_BASE  0xC8
+
+/* register offsets */
+/* global registers 0x00-0x02 */
+
+#define XDCR_IDA_ADDR     0x00
+#define XDCR_IDA_ACC      0x01
+#define XDCR_CTRLCFGSTAT  0x02
+
+/* Auxiliary Processor Unit Controller (APU) 0x04-0x05 */
+
+#define XDCR_APU_UDI  (XDCR_APU_BASE+0x00)
+#define XDCR_APU_CTRL (XDCR_APU_BASE+0x01)
+
+/* Memory Interface Bridge (MIB) 0x10-0x13 */
+
+#define XDCR_MIB_CTRL (XDCR_MIB_BASE+0x00)
+#define XDCR_MIB_RCON (XDCR_MIB_BASE+0x01)
+#define XDCR_MIB_BCON (XDCR_MIB_BASE+0x02)
+
+/* Crossbar (XB) 0x20-0x33 */
+
+#define XDCR_XB_IST      (XDCR_XB_BASE+0x00)
+#define XDCR_XB_IMASK    (XDCR_XB_BASE+0x01)
+#define XDCR_XB_ARBCFGX  (XDCR_XB_BASE+0x03)
+#define XDCR_XB_FIFOSTX  (XDCR_XB_BASE+0x04)
+#define XDCR_XB_SMSTX    (XDCR_XB_BASE+0x05)
+#define XDCR_XB_MISCX    (XDCR_XB_BASE+0x06)
+#define XDCR_XB_ARBCFGM  (XDCR_XB_BASE+0x08)
+#define XDCR_XB_FIFOSTM  (XDCR_XB_BASE+0x09)
+#define XDCR_XB_SMSTM    (XDCR_XB_BASE+0x0A)
+#define XDCR_XB_MISCM    (XDCR_XB_BASE+0x0B)
+#define XDCR_XB_TMPL0MAP (XDCR_XB_BASE+0x0D)
+#define XDCR_XB_TMPL1MAP (XDCR_XB_BASE+0x0E)
+#define XDCR_XB_TMPL2MAP (XDCR_XB_BASE+0x0F)
+#define XDCR_XB_TMPL3MAP (XDCR_XB_BASE+0x10)
+#define XDCR_XB_TMPLSEL  (XDCR_XB_BASE+0x11)
+
+/* PLB Slave DCR offsets only */
+
+#define XDCR_PLBS_CFG        0x00
+#define XDCR_PLBS_SEARU      0x02
+#define XDCR_PLBS_SEARL      0x03
+#define XDCR_PLBS_SESR       0x04
+#define XDCR_PLBS_MISCST     0x05
+#define XDCR_PLBS_PLBERRST   0x06
+#define XDCR_PLBS_SMST       0x07
+#define XDCR_PLBS_MISC       0x08
+#define XDCR_PLBS_CMDSNIFF   0x09
+#define XDCR_PLBS_CMDSNIFFA  0x0A
+#define XDCR_PLBS_TMPL0MAP   0x0C
+#define XDCR_PLBS_TMPL1MAP   0x0D
+#define XDCR_PLBS_TMPL2MAP   0x0E
+#define XDCR_PLBS_TMPL3MAP   0x0F
+
+/* PLB Slave 0 (PLBS0) 0x34-0x43 */
+
+#define XDCR_PLBS0_CFG       (XDCR_PLBS0_BASE+0x00)
+#define XDCR_PLBS0_CNT       (XDCR_PLBS0_BASE+0x01)
+#define XDCR_PLBS0_SEARU     (XDCR_PLBS0_BASE+0x02)
+#define XDCR_PLBS0_SEARL     (XDCR_PLBS0_BASE+0x03)
+#define XDCR_PLBS0_SESR      (XDCR_PLBS0_BASE+0x04)
+#define XDCR_PLBS0_MISCST    (XDCR_PLBS0_BASE+0x05)
+#define XDCR_PLBS0_PLBERRST  (XDCR_PLBS0_BASE+0x06)
+#define XDCR_PLBS0_SMST      (XDCR_PLBS0_BASE+0x07)
+#define XDCR_PLBS0_MISC      (XDCR_PLBS0_BASE+0x08)
+#define XDCR_PLBS0_CMDSNIFF  (XDCR_PLBS0_BASE+0x09)
+#define XDCR_PLBS0_CMDSNIFFA (XDCR_PLBS0_BASE+0x0A)
+#define XDCR_PLBS0_TMPL0MAP  (XDCR_PLBS0_BASE+0x0C)
+#define XDCR_PLBS0_TMPL1MAP  (XDCR_PLBS0_BASE+0x0D)
+#define XDCR_PLBS0_TMPL2MAP  (XDCR_PLBS0_BASE+0x0E)
+#define XDCR_PLBS0_TMPL3MAP  (XDCR_PLBS0_BASE+0x0F)
+
+/* PLB Slave 1 (PLBS1) 0x44-0x53 */
+
+#define XDCR_PLBS1_CFG       (XDCR_PLBS1_BASE+0x00)
+#define XDCR_PLBS1_CNT       (XDCR_PLBS1_BASE+0x01)
+#define XDCR_PLBS1_SEARU     (XDCR_PLBS1_BASE+0x02)
+#define XDCR_PLBS1_SEARL     (XDCR_PLBS1_BASE+0x03)
+#define XDCR_PLBS1_SESR      (XDCR_PLBS1_BASE+0x04)
+#define XDCR_PLBS1_MISCST    (XDCR_PLBS1_BASE+0x05)
+#define XDCR_PLBS1_PLBERRST  (XDCR_PLBS1_BASE+0x06)
+#define XDCR_PLBS1_SMST      (XDCR_PLBS1_BASE+0x07)
+#define XDCR_PLBS1_MISC      (XDCR_PLBS1_BASE+0x08)
+#define XDCR_PLBS1_CMDSNIFF  (XDCR_PLBS1_BASE+0x09)
+#define XDCR_PLBS1_CMDSNIFFA (XDCR_PLBS1_BASE+0x0A)
+#define XDCR_PLBS1_TMPL0MAP  (XDCR_PLBS1_BASE+0x0C)
+#define XDCR_PLBS1_TMPL1MAP  (XDCR_PLBS1_BASE+0x0D)
+#define XDCR_PLBS1_TMPL2MAP  (XDCR_PLBS1_BASE+0x0E)
+#define XDCR_PLBS1_TMPL3MAP  (XDCR_PLBS1_BASE+0x0F)
+
+/* PLB Master (PLBM) 0x54-0x5F */
+
+#define XDCR_PLBM_CFG       (XDCR_PLBM_BASE+0x00)
+#define XDCR_PLBM_CNT       (XDCR_PLBM_BASE+0x01)
+#define XDCR_PLBM_FSEARU    (XDCR_PLBM_BASE+0x02)
+#define XDCR_PLBM_FSEARL    (XDCR_PLBM_BASE+0x03)
+#define XDCR_PLBM_FSESR     (XDCR_PLBM_BASE+0x04)
+#define XDCR_PLBM_MISCST    (XDCR_PLBM_BASE+0x05)
+#define XDCR_PLBM_PLBERRST  (XDCR_PLBM_BASE+0x06)
+#define XDCR_PLBM_SMST      (XDCR_PLBM_BASE+0x07)
+#define XDCR_PLBM_MISC      (XDCR_PLBM_BASE+0x08)
+#define XDCR_PLBM_CMDSNIFF  (XDCR_PLBM_BASE+0x09)
+#define XDCR_PLBM_CMDSNIFFA (XDCR_PLBM_BASE+0x0A)
+
+/* DMA Controller DCR offsets only */
+#define XDCR_DMA_TXNXTDESCPTR   0x00
+#define XDCR_DMA_TXCURBUFADDR   0x01
+#define XDCR_DMA_TXCURBUFLEN    0x02
+#define XDCR_DMA_TXCURDESCPTR   0x03
+#define XDCR_DMA_TXTAILDESCPTR  0x04
+#define XDCR_DMA_TXCHANNELCTRL  0x05
+#define XDCR_DMA_TXIRQ          0x06
+#define XDCR_DMA_TXSTATUS       0x07
+#define XDCR_DMA_RXNXTDESCPTR   0x08
+#define XDCR_DMA_RXCURBUFADDR   0x09
+#define XDCR_DMA_RXCURBUFLEN    0x0A
+#define XDCR_DMA_RXCURDESCPTR   0x0B
+#define XDCR_DMA_RXTAILDESCPTR  0x0C
+#define XDCR_DMA_RXCHANNELCTRL  0x0D
+#define XDCR_DMA_RXIRQ          0x0E
+#define XDCR_DMA_RXSTATUS       0x0F
+#define XDCR_DMA_CTRL           0x10
+
+/* DMA Controller 0 (DMA0) 0x80-0x90 */
+
+#define XDCR_DMA0_TXNXTDESCPTR  (XDCR_DMA0_BASE+0x00)
+#define XDCR_DMA0_TXCURBUFADDR  (XDCR_DMA0_BASE+0x01)
+#define XDCR_DMA0_TXCURBUFLEN   (XDCR_DMA0_BASE+0x02)
+#define XDCR_DMA0_TXCURDESCPTR  (XDCR_DMA0_BASE+0x03)
+#define XDCR_DMA0_TXTAILDESCPTR (XDCR_DMA0_BASE+0x04)
+#define XDCR_DMA0_TXCHANNELCTRL (XDCR_DMA0_BASE+0x05)
+#define XDCR_DMA0_TXIRQ         (XDCR_DMA0_BASE+0x06)
+#define XDCR_DMA0_TXSTATUS      (XDCR_DMA0_BASE+0x07)
+#define XDCR_DMA0_RXNXTDESCPTR  (XDCR_DMA0_BASE+0x08)
+#define XDCR_DMA0_RXCURBUFADDR  (XDCR_DMA0_BASE+0x09)
+#define XDCR_DMA0_RXCURBUFLEN   (XDCR_DMA0_BASE+0x0A)
+#define XDCR_DMA0_RXCURDESCPTR  (XDCR_DMA0_BASE+0x0B)
+#define XDCR_DMA0_RXTAILDESCPTR (XDCR_DMA0_BASE+0x0C)
+#define XDCR_DMA0_RXCHANNELCTRL (XDCR_DMA0_BASE+0x0D)
+#define XDCR_DMA0_RXIRQ         (XDCR_DMA0_BASE+0x0E)
+#define XDCR_DMA0_RXSTATUS      (XDCR_DMA0_BASE+0x0F)
+#define XDCR_DMA0_CTRL          (XDCR_DMA0_BASE+0x10)
+
+/* DMA Controller 1 (DMA1) 0x98-0xA8 */
+
+#define XDCR_DMA1_TXNXTDESCPTR  (XDCR_DMA1_BASE+0x00)
+#define XDCR_DMA1_TXCURBUFADDR  (XDCR_DMA1_BASE+0x01)
+#define XDCR_DMA1_TXCURBUFLEN   (XDCR_DMA1_BASE+0x02)
+#define XDCR_DMA1_TXCURDESCPTR  (XDCR_DMA1_BASE+0x03)
+#define XDCR_DMA1_TXTAILDESCPTR (XDCR_DMA1_BASE+0x04)
+#define XDCR_DMA1_TXCHANNELCTRL (XDCR_DMA1_BASE+0x05)
+#define XDCR_DMA1_TXIRQ         (XDCR_DMA1_BASE+0x06)
+#define XDCR_DMA1_TXSTATUS      (XDCR_DMA1_BASE+0x07)
+#define XDCR_DMA1_RXNXTDESCPTR  (XDCR_DMA1_BASE+0x08)
+#define XDCR_DMA1_RXCURBUFADDR  (XDCR_DMA1_BASE+0x09)
+#define XDCR_DMA1_RXCURBUFLEN   (XDCR_DMA1_BASE+0x0A)
+#define XDCR_DMA1_RXCURDESCPTR  (XDCR_DMA1_BASE+0x0B)
+#define XDCR_DMA1_RXTAILDESCPTR (XDCR_DMA1_BASE+0x0C)
+#define XDCR_DMA1_RXCHANNELCTRL (XDCR_DMA1_BASE+0x0D)
+#define XDCR_DMA1_RXIRQ         (XDCR_DMA1_BASE+0x0E)
+#define XDCR_DMA1_RXSTATUS      (XDCR_DMA1_BASE+0x0F)
+#define XDCR_DMA1_CTRL          (XDCR_DMA1_BASE+0x10)
+
+/* DMA Controller 2 (DMA2) 0xB0-0xC0 */
+
+#define XDCR_DMA2_TXNXTDESCPTR  (XDCR_DMA2_BASE+0x00)
+#define XDCR_DMA2_TXCURBUFADDR  (XDCR_DMA2_BASE+0x01)
+#define XDCR_DMA2_TXCURBUFLEN   (XDCR_DMA2_BASE+0x02)
+#define XDCR_DMA2_TXCURDESCPTR  (XDCR_DMA2_BASE+0x03)
+#define XDCR_DMA2_TXTAILDESCPTR (XDCR_DMA2_BASE+0x04)
+#define XDCR_DMA2_TXCHANNELCTRL (XDCR_DMA2_BASE+0x05)
+#define XDCR_DMA2_TXIRQ         (XDCR_DMA2_BASE+0x06)
+#define XDCR_DMA2_TXSTATUS      (XDCR_DMA2_BASE+0x07)
+#define XDCR_DMA2_RXNXTDESCPTR  (XDCR_DMA2_BASE+0x08)
+#define XDCR_DMA2_RXCURBUFADDR  (XDCR_DMA2_BASE+0x09)
+#define XDCR_DMA2_RXCURBUFLEN   (XDCR_DMA2_BASE+0x0A)
+#define XDCR_DMA2_RXCURDESCPTR  (XDCR_DMA2_BASE+0x0B)
+#define XDCR_DMA2_RXTAILDESCPTR (XDCR_DMA2_BASE+0x0C)
+#define XDCR_DMA2_RXCHANNELCTRL (XDCR_DMA2_BASE+0x0D)
+#define XDCR_DMA2_RXIRQ         (XDCR_DMA2_BASE+0x0E)
+#define XDCR_DMA2_RXSTATUS      (XDCR_DMA2_BASE+0x0F)
+#define XDCR_DMA2_CTRL          (XDCR_DMA2_BASE+0x10)
+
+/* DMA Controller 3 (DMA3) 0xC8-0xD8 */
+
+#define XDCR_DMA3_TXNXTDESCPTR  (XDCR_DMA3_BASE+0x00)
+#define XDCR_DMA3_TXCURBUFADDR  (XDCR_DMA3_BASE+0x01)
+#define XDCR_DMA3_TXCURBUFLEN   (XDCR_DMA3_BASE+0x02)
+#define XDCR_DMA3_TXCURDESCPTR  (XDCR_DMA3_BASE+0x03)
+#define XDCR_DMA3_TXTAILDESCPTR (XDCR_DMA3_BASE+0x04)
+#define XDCR_DMA3_TXCHANNELCTRL (XDCR_DMA3_BASE+0x05)
+#define XDCR_DMA3_TXIRQ         (XDCR_DMA3_BASE+0x06)
+#define XDCR_DMA3_TXSTATUS      (XDCR_DMA3_BASE+0x07)
+#define XDCR_DMA3_RXNXTDESCPTR  (XDCR_DMA3_BASE+0x08)
+#define XDCR_DMA3_RXCURBUFADDR  (XDCR_DMA3_BASE+0x09)
+#define XDCR_DMA3_RXCURBUFLEN   (XDCR_DMA3_BASE+0x0A)
+#define XDCR_DMA3_RXCURDESCPTR  (XDCR_DMA3_BASE+0x0B)
+#define XDCR_DMA3_RXTAILDESCPTR (XDCR_DMA3_BASE+0x0C)
+#define XDCR_DMA3_RXCHANNELCTRL (XDCR_DMA3_BASE+0x0D)
+#define XDCR_DMA3_RXIRQ         (XDCR_DMA3_BASE+0x0E)
+#define XDCR_DMA3_RXSTATUS      (XDCR_DMA3_BASE+0x0F)
+#define XDCR_DMA3_CTRL          (XDCR_DMA3_BASE+0x10)
+
+
+/**
+ * <pre
+ * These are the bit defines for the Control, Configuration, and Status
+ * register (XDCR_CTRLCFGSTAT)
+ * @{
+ */
+#define XDCR_INT_MSTR_LOCK_MASK        0x80000000   /* Internal Master Bus Lock */
+#define XDCR_INT_MSTR_AUTO_LOCK_MASK   0x40000000   /* Internal Master Bus Auto Lock, RO */
+#define XDCR_EXT_MSTR_LOCK_MASK        0x20000000   /* External Master Bus Master Lock */
+#define XDCR_EXT_MSTR_AUTO_LOCK_MASK   0x10000000   /* External Master Bus Auto Lock, RO */
+#define XDCR_ENB_DCR_AUTO_LOCK_MASK    0x08000000   /* Enable Auto Bus Lock */
+#define XDCR_ENB_MSTR_ASYNC_MASK       0x04000000   /* External Master in Async Mode */
+#define XDCR_ENB_SLV_ASYNC_MASK        0x02000000   /* External Slave in Async Mode */
+#define XDCR_ENB_DCR_TIMEOUT_SUPP_MASK 0x01000000   /* Enable Timeout Support */
+#define XDCR_INT_MSTR_TIMEOUT_BIT      0x00000002   /* Internal Master Bus Timeout Occurred */
+#define XDCR_EXT_MSTR_TIMEOUT_BIT      0x00000001   /* External Master Bus Timeout Occurred */
+
+/*
+ * Mask to disable exceptions in PPC440 MSR
+ * Bit 14: Critical Interrupt Enable            0x00020000
+ * Bit 16: External Interrupt Enable            0x00008000
+ * Bit 20: Floating-point Exceptions Mode 0     0x00000800
+ * Bit 23: Floating-point Exceptions Mode 1     0x00000100
+ */
+#define XDCR_DISABLE_EXCEPTIONS 0xFFFD76FF
+#define XDCR_ALL_LOCK           (XDCR_INT_MSTR_LOCK_MASK | XDCR_EXT_MSTR_LOCK_MASK)
+#define XDCR_ALL_TIMEOUT        (XDCR_INT_MSTR_TIMEOUT_BIT | XDCR_EXT_MSTR_TIMEOUT_BIT)
+
+/**************************** Type Definitions *******************************/
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/******************************************************************************/
+/**
+* Reads the register at the specified DCR address.
+*
+*
+* @param    DcrRegister is the intended source DCR register
+*
+* @return
+*
+* Contents of the specified DCR register.
+*
+* @note
+*
+* C-style signature:
+*    void XIo_mDcrReadReg(u32 DcrRegister)
+*
+*******************************************************************************/
+#define XIo_mDcrReadReg(DcrRegister) ({ mfdcr((DcrRegister)); })
+
+/******************************************************************************/
+/**
+* Writes the register at specified DCR address.
+*
+*
+* @param    DcrRegister is the intended destination DCR register
+* @param    Data is the value to be placed into the specified DRC register
+*
+* @return
+*
+* None
+*
+* @note
+*
+* C-style signature:
+*    void XIo_mDcrWriteReg(u32 DcrRegister, u32 Data)
+*
+*******************************************************************************/
+#define XIo_mDcrWriteReg(DcrRegister, Data) ({ mtdcr((DcrRegister), (Data)); })
+
+/******************************************************************************/
+/**
+* Explicitly locks the DCR bus
+*
+* @param    DcrBase is the base of the block of DCR registers
+*
+* @return
+*
+* None
+*
+* @note
+*
+* C-style signature:
+*   void XIo_mDcrLock(u32 DcrBase)
+*
+*   Sets either Lock bit. Since a master cannot edit another master's Lock bit,
+*   the macro can be simplified.
+*   Care must be taken to not write a '1' to either timeout bit because
+*   it will be cleared.
+*
+*******************************************************************************/
+#define XIo_mDcrLock(DcrBase) \
+({ \
+ mtdcr((DcrBase) | XDCR_CTRLCFGSTAT, \
+       (mfdcr((DcrBase) | XDCR_CTRLCFGSTAT) | XDCR_ALL_LOCK) & ~XDCR_ALL_TIMEOUT); \
+})
+
+/******************************************************************************/
+/**
+* Explicitly locks the DCR bus
+*
+* @param    DcrBase is the base of the block of DCR registers
+*
+* @return
+*
+* None
+*
+* @note
+*
+* C-style signature:
+*   void XIo_mDcrUnlock(u32 DcrBase)
+*
+*   Unsets either Lock bit. Since a master cannot edit another master's Lock bit,
+*   the macro can be simplified.
+*   Care must be taken to not write a '1' to either timeout bit because
+*   it will be cleared.
+*
+*******************************************************************************/
+#define XIo_mDcrUnlock(DcrBase) \
+({ \
+ mtdcr((DcrBase) | XDCR_CTRLCFGSTAT, \
+       (mfdcr((DcrBase) | XDCR_CTRLCFGSTAT) & ~(XDCR_ALL_LOCK | XDCR_ALL_TIMEOUT))); \
+})
+
+/******************************************************************************/
+/**
+* Reads the APU UDI register at the specified APU address.
+*
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    UDInum is the intended source APU register
+*
+* @return
+*
+* Contents of the specified APU register.
+*
+* @note
+*
+* C-style signature:
+*    u32 XIo_mDcrReadAPUUDIReg(u32 DcrRegister, u32 UDInum)
+*
+*   Since reading an APU UDI DCR requires a dummy write to the same DCR,
+*   the target UDI number is required. In order to make this operation atomic,
+*   interrupts are disabled before and enabled after the DCR accesses.
+*   Because an APU UDI access involves two DCR accesses, the DCR bus must be
+*   locked to ensure that another master doesn't access the APU UDI register
+*   at the same time.
+*   Care must be taken to not write a '1' to either timeout bit because
+*   it will be cleared.
+*   Steps:
+*   - save old MSR
+*   - disable interrupts by writing mask to MSR
+*   - acquire lock; since the PPC440 supports timeout wait, it will wait until
+*     it successfully acquires the DCR bus lock
+*   - shift and mask the UDI number to its bit position of [22:25]
+*   - add the DCR base address to the UDI number and perform the read
+*   - release DCR bus lock
+*   - restore MSR
+*   - return value read
+*
+*******************************************************************************/
+#define XIo_mDcrReadAPUUDIReg(DcrBase, UDInum) \
+({ \
+ unsigned int rVal; \
+ unsigned int oldMSR = mfmsr(); \
+ mtmsr(oldMSR & XDCR_DISABLE_EXCEPTIONS); \
+ XIo_DcrLock((DcrBase)); \
+ mtdcr((DcrBase) | XDCR_APU_UDI, (((UDInum) << 6) & 0x000003c0) | 0x00000030); \
+ rVal = mfdcr((DcrBase) | XDCR_APU_UDI); \
+ XIo_DcrUnlock((DcrBase)); \
+ mtmsr(oldMSR); \
+ rVal; \
+})
+
+/******************************************************************************/
+/**
+* Writes the data to the APU UDI register at the specified APU address.
+*
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    UDInum is the intended source APU register
+* @param    Data is the value to be placed into the specified APU register
+*
+* @return
+*
+* None
+*
+* @note
+*
+* C-style signature:
+*   void XIo_mDcrWriteAPUUDIReg(u32 DcrRegister, u32 UDInum, u32 Data)
+*
+*   Since writing an APU UDI DCR requires a dummy write to the same DCR,
+*   the target UDI number is required. In order to make this operation atomic,
+*   interrupts are disabled before and enabled after the DCR accesses.
+*   Because an APU UDI access involves two DCR accesses, the DCR bus must be
+*   locked to ensure that another master doesn't access the APU UDI register
+*   at the same time.
+*   Care must be taken to not write a '1' to either timeout bit because
+*   it will be cleared.
+*   Steps:
+*   - save old MSR
+*   - disable interrupts by writing mask to MSR
+*   - acquire lock, since the PPC440 supports timeout wait, it will wait until
+*     it successfully acquires the DCR bus lock
+*   - shift and mask the UDI number to its bit position of [22:25]
+*   - add DCR base address to UDI number offset and perform the write
+*   - release DCR bus lock
+*   - restore MSR
+*
+*******************************************************************************/
+#define XIo_mDcrWriteAPUUDIReg(DcrBase, UDInum, Data) \
+({ \
+ unsigned int oldMSR = mfmsr(); \
+ mtmsr(oldMSR & XDCR_DISABLE_EXCEPTIONS); \
+ XIo_DcrLock((DcrBase)); \
+ mtdcr((DcrBase) | XDCR_APU_UDI, (((UDInum) << 6) & 0x000003c0) | 0x00000030); \
+ mtdcr((DcrBase) | XDCR_APU_UDI, (Data)); \
+ XIo_DcrUnlock((DcrBase)); \
+ mtmsr(oldMSR); \
+})
+
+/******************************************************************************/
+/**
+* Reads the register at the specified DCR address using the indirect addressing
+* method.
+*
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    DcrRegister is the intended source DCR register
+*
+* @return
+*
+* Contents of the specified DCR register.
+*
+* @note
+*
+* C-style signature:
+*   void XIo_mDcrIndirectAddrReadReg(u32 DcrBase, u32 DcrRegister)
+*
+*   Assumes auto-buslocking feature is ON.
+*   In order to make this operation atomic, interrupts are disabled before
+*   and enabled after the DCR accesses.
+*
+*******************************************************************************/
+#define XIo_mDcrIndirectAddrReadReg(DcrBase, DcrRegister) \
+({ \
+ unsigned int rVal; \
+ unsigned int oldMSR = mfmsr(); \
+ mtmsr(oldMSR & XDCR_DISABLE_EXCEPTIONS); \
+ XIo_mDcrWriteReg((DcrBase) | XDCR_IDA_ADDR, (DcrBase) | DcrRegister); \
+ rVal = XIo_mDcrReadReg((DcrBase) | XDCR_IDA_ACC); \
+ mtmsr(oldMSR); \
+ rVal; \
+})
+
+/******************************************************************************/
+/**
+* Writes the register at specified DCR address using the indirect addressing
+* method.
+*
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    DcrRegister is the intended destination DCR register
+* @param    Data is the value to be placed into the specified DRC register
+*
+* @return
+*
+* None
+*
+* @note
+*
+* C-style signature:
+*   void XIo_mDcrIndirectAddrWriteReg(u32 DcrBase, u32 DcrRegister,
+*                                  u32 Data)
+*
+*   Assumes auto-buslocking feature is ON.
+*   In order to make this operation atomic, interrupts are disabled before
+*   and enabled after the DCR accesses.
+*
+*******************************************************************************/
+#define XIo_mDcrIndirectAddrWriteReg(DcrBase, DcrRegister, Data) \
+({ \
+ unsigned int oldMSR = mfmsr(); \
+ mtmsr(oldMSR & XDCR_DISABLE_EXCEPTIONS); \
+ XIo_mDcrWriteReg((DcrBase) | XDCR_IDA_ADDR, (DcrBase) | DcrRegister); \
+ XIo_mDcrWriteReg((DcrBase) | XDCR_IDA_ACC, Data); \
+ mtmsr(oldMSR); \
+})
+
+/******************************************************************************/
+/**
+* Reads the APU UDI register at the specified DCR address using the indirect
+* addressing method.
+*
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    UDInum is the intended source DCR register
+*
+* @return
+*
+* Contents of the specified APU register.
+*
+* @note
+*
+* C-style signature:
+*   void XIo_mDcrIndirectAddrReadAPUUDIReg(u32 DcrBase, u32 UDInum)
+*
+*   An indirect APU UDI read requires three DCR accesses:
+*     1) Indirect address reg write
+*     2) Indirect access reg write to specify the UDI number
+*     3) Indirect access reg read of the actual data
+*   Since (2) unlocks the DCR bus, the DCR bus must be explicitly locked
+*   instead of relying on the auto-lock feature.
+*   In order to make this operation atomic, interrupts are disabled before
+*   and enabled after the DCR accesses.
+*   Care must be taken to not write a '1' to either timeout bit because
+*   it will be cleared.
+*
+*******************************************************************************/
+#define XIo_mDcrIndirectAddrReadAPUUDIReg(DcrBase, UDInum) \
+({ \
+ unsigned int rVal; \
+ unsigned int oldMSR = mfmsr(); \
+ mtmsr(oldMSR & XDCR_DISABLE_EXCEPTIONS); \
+ XIo_DcrLock((DcrBase)); \
+ XIo_mDcrWriteReg((DcrBase) | XDCR_IDA_ADDR, (DcrBase) | XDCR_APU_UDI); \
+ XIo_mDcrWriteReg((DcrBase) | XDCR_IDA_ACC, ((UDInum << 6) & 0x000003c0) | 0x00000030); \
+ rVal = XIo_mDcrReadReg((DcrBase) | XDCR_IDA_ACC); \
+ XIo_DcrUnlock((DcrBase)); \
+ mtmsr(oldMSR); \
+ rVal; \
+})
+
+/******************************************************************************/
+/**
+* Writes the APU UDI register at specified DCR address using the indirect
+* addressing method.
+*
+*
+* @param    DcrBase is the base of the block of DCR registers
+* @param    UDInum is the intended source DCR register
+* @param    Data is the value to be placed into the specified DRC register
+*
+* @return
+*
+* None
+*
+* @note
+*
+* C-style signature:
+*   void XIo_mDcrIndirectAddrWriteReg(u32 DcrBase, u32 UDInum, u32 Data)
+*
+*   An indirect APU UDI write requires three DCR accesses:
+*     1) Indirect address reg write
+*     2) Indirect access reg write to specify the UDI number
+*     3) Indirect access reg write of the actual data
+*   Since (2) unlocks the DCR bus, the DCR bus must be explicitly locked
+*   instead of relying on the auto-lock feature.
+*   In order to make this operation atomic, interrupts are disabled before
+*   and enabled after the DCR accesses.
+*   Care must be taken to not write a '1' to either timeout bit because
+*   it will be cleared.
+*
+*******************************************************************************/
+#define XIo_mDcrIndirectAddrWriteAPUUDIReg(DcrBase, UDInum, Data) \
+({ \
+ unsigned int oldMSR = mfmsr(); \
+ mtmsr(oldMSR & XDCR_DISABLE_EXCEPTIONS); \
+ XIo_DcrLock((DcrBase)); \
+ XIo_mDcrWriteReg((DcrBase) | XDCR_IDA_ADDR, (DcrBase) | XDCR_APU_UDI); \
+ XIo_mDcrWriteReg((DcrBase) | XDCR_IDA_ACC, ((UDInum << 6) & 0x000003c0) | 0x00000030); \
+ XIo_mDcrWriteReg((DcrBase) | XDCR_IDA_ACC, Data);\
+ XIo_DcrUnlock((DcrBase)); \
+ mtmsr(oldMSR); \
+})
+
+/************************** Function Prototypes ******************************/
+void XIo_DcrOut(u32 DcrRegister, u32 Data);
+u32 XIo_DcrIn(u32 DcrRegister);
+
+u32 XIo_DcrReadReg(u32 DcrBase, u32 DcrRegister);
+void XIo_DcrWriteReg(u32 DcrBase, u32 DcrRegister, u32 Data);
+u32 XIo_DcrLockAndReadReg(u32 DcrBase, u32 DcrRegister);
+void XIo_DcrLockAndWriteReg(u32 DcrBase, u32 DcrRegister, u32 Data);
+
+void XIo_DcrWriteAPUUDIReg(u32 DcrBase, short UDInum, u32 Data);
+u32 XIo_DcrReadAPUUDIReg(u32 DcrBase, short UDInum);
+
+void XIo_DcrLock(u32 DcrBase);
+void XIo_DcrUnlock(u32 DcrBase);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xio.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xio.h
--- linux-2.6.31.12/drivers/xilinx_common/xio.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xio.h	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,209 @@
+/* $Id: xio.h,v 1.4 2007/07/24 22:01:35 xduan Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2007-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xio.h
+*
+* This file contains the interface for the XIo component, which encapsulates
+* the Input/Output functions for the PowerPC architecture.
+* This header file needs to be updated to replace eieio with mbar when
+* compilers support the mbar mnemonic.
+*
+* @note
+*
+* This file contains architecture-dependent items (memory mapped or non memory
+* mapped I/O).
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- --------------------------------------------------------
+* 1.00a ecm  10/18/05 initial release
+*                     needs to be updated to replace eieio with mbar when
+*                     compilers support this mnemonic.
+*
+* 1.00a ecm  01/24/07 update for new coding standard.
+* 1.10a xd   07/24/07 Corrected the format in asm functions in __DCC__ mode.
+* </pre>
+******************************************************************************/
+
+#ifndef XIO_H           /* prevent circular inclusions */
+#define XIO_H           /* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+/**
+ * Typedef for an I/O address.  Typically correlates to the width of the
+ * address bus.
+ */
+typedef u32 XIo_Address;
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/* The following macro is specific to the GNU compiler and PowerPC family. It
+ * performs an EIEIO instruction such that I/O operations are synced correctly.
+ * This macro is not necessarily portable across compilers since it uses
+ * inline assembly.
+ */
+#ifdef CONFIG_PPC
+#  define SYNCHRONIZE_IO __asm__ volatile ("eieio") /* should be 'mbar' ultimately */
+#else
+#  define SYNCHRONIZE_IO
+#endif
+
+/* The following macros allow the software to be transportable across
+ * processors which use big or little endian memory models.
+ *
+ * Defined first are processor-specific endian conversion macros specific to
+ * the GNU compiler and the PowerPC family, as well as a no-op endian conversion
+ * macro. These macros are not to be used directly by software. Instead, the
+ * XIo_To/FromLittleEndianXX and XIo_To/FromBigEndianXX macros below are to be
+ * used to allow the endian conversion to only be performed when necessary
+ */
+
+#define XIo_EndianNoop(Source, DestPtr)    (*DestPtr = Source)
+
+#ifdef CONFIG_PPC
+
+#define XIo_EndianSwap16(Source, DestPtr)  __asm__ __volatile__(\
+                                           "sthbrx %0,0,%1\n"\
+                                           : : "r" (Source), "r" (DestPtr)\
+                                           )
+
+#define XIo_EndianSwap32(Source, DestPtr)  __asm__ __volatile__(\
+                                           "stwbrx %0,0,%1\n"\
+                                           : : "r" (Source), "r" (DestPtr)\
+                                           )
+#else
+
+#define XIo_EndianSwap16(Source, DestPtr) \
+{\
+   u16 src = (Source); \
+   u16 *destptr = (DestPtr); \
+   *destptr = src >> 8; \
+   *destptr |= (src << 8); \
+}
+
+#define XIo_EndianSwap32(Source, DestPtr) \
+{\
+   u32 src = (Source); \
+   u32 *destptr = (DestPtr); \
+   *destptr = src >> 24; \
+   *destptr |= ((src >> 8)  & 0x0000FF00); \
+   *destptr |= ((src << 8)  & 0x00FF0000); \
+   *destptr |= ((src << 24) & 0xFF000000); \
+}
+
+#endif
+
+// #ifdef XLITTLE_ENDIAN
+// /* little-endian processor */
+
+// #define XIo_ToLittleEndian16                XIo_EndianNoop
+// #define XIo_ToLittleEndian32                XIo_EndianNoop
+// #define XIo_FromLittleEndian16              XIo_EndianNoop
+// #define XIo_FromLittleEndian32              XIo_EndianNoop
+
+// #define XIo_ToBigEndian16(Source, DestPtr)  XIo_EndianSwap16(Source, DestPtr)
+// #define XIo_ToBigEndian32(Source, DestPtr)  XIo_EndianSwap32(Source, DestPtr)
+// #define XIo_FromBigEndian16                 XIo_ToBigEndian16
+// #define XIo_FromBigEndian32                 XIo_ToBigEndian32
+
+// #else
+/* big-endian processor */ // ppc or microblaze
+
+#define XIo_ToLittleEndian16(Source, DestPtr) XIo_EndianSwap16(Source, DestPtr)
+#define XIo_ToLittleEndian32(Source, DestPtr) XIo_EndianSwap32(Source, DestPtr)
+#define XIo_FromLittleEndian16                XIo_ToLittleEndian16
+#define XIo_FromLittleEndian32                XIo_ToLittleEndian32
+
+#define XIo_ToBigEndian16                     XIo_EndianNoop
+#define XIo_ToBigEndian32                     XIo_EndianNoop
+#define XIo_FromBigEndian16                   XIo_EndianNoop
+#define XIo_FromBigEndian32                   XIo_EndianNoop
+
+// #endif
+
+
+/************************** Function Prototypes ******************************/
+
+/* The following macros allow optimized I/O operations for memory mapped I/O
+ * Note that the SYNCHRONIZE_IO may be moved by the compiler during
+ * optimization.
+ */
+
+u8 XIo_In8(XIo_Address InAddress);
+u16 XIo_In16(XIo_Address InAddress);
+u32 XIo_In32(XIo_Address InAddress);
+
+void XIo_Out8(XIo_Address OutAddress, u8 Value);
+void XIo_Out16(XIo_Address OutAddress, u16 Value);
+void XIo_Out32(XIo_Address OutAddress, u32 Value);
+
+
+/*
+#define XIo_In8(InputPtr)  (*(volatile u8  *)(InputPtr)); SYNCHRONIZE_IO;
+#define XIo_In16(InputPtr) (*(volatile u16 *)(InputPtr)); SYNCHRONIZE_IO;
+#define XIo_In32(InputPtr) (*(volatile u32 *)(InputPtr)); SYNCHRONIZE_IO;
+
+#define XIo_Out8(OutputPtr, Value)  \
+    { (*(volatile u8  *)(OutputPtr) = Value); SYNCHRONIZE_IO; }
+#define XIo_Out16(OutputPtr, Value) \
+    { (*(volatile u16 *)(OutputPtr) = Value); SYNCHRONIZE_IO; }
+#define XIo_Out32(OutputPtr, Value) \
+    { (*(volatile u32 *)(OutputPtr) = Value); SYNCHRONIZE_IO; }
+ */
+
+/* The following functions handle IO addresses where data must be swapped
+ * They cannot be implemented as macros
+ */
+u16 XIo_InSwap16(XIo_Address InAddress);
+u32 XIo_InSwap32(XIo_Address InAddress);
+void XIo_OutSwap16(XIo_Address OutAddress, u16 Value);
+void XIo_OutSwap32(XIo_Address OutAddress, u32 Value);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xipif_v1_23_b.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xipif_v1_23_b.c
--- linux-2.6.31.12/drivers/xilinx_common/xipif_v1_23_b.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xipif_v1_23_b.c	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,324 @@
+/* $Id: xipif_v1_23_b.c,v 1.3 2004/11/15 20:31:35 xduan Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002-2004 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xipif_v1_23_b.c
+*
+* This file contains the implementation of the XIpIf component. The
+* XIpIf component encapsulates the IPIF, which is the standard interface
+* that IP must adhere to when connecting to a bus.  The purpose of this
+* component is to encapsulate the IPIF processing such that maintainability
+* is increased.  This component does not provide a lot of abstraction from
+* from the details of the IPIF as it is considered a building block for
+* device drivers.  A device driver designer must be familiar with the
+* details of the IPIF hardware to use this component.
+*
+* The IPIF hardware provides a building block for all hardware devices such
+* that each device does not need to reimplement these building blocks. The
+* IPIF contains other building blocks, such as FIFOs and DMA channels, which
+* are also common to many devices.  These blocks are implemented as separate
+* hardware blocks and instantiated within the IPIF.  The primary hardware of
+* the IPIF which is implemented by this software component is the interrupt
+* architecture.  Since there are many blocks of a device which may generate
+* interrupts, all the interrupt processing is contained in the common part
+* of the device, the IPIF.  This interrupt processing is for the device level
+* only and does not include any processing for the interrupt controller.
+*
+* A device is a mechanism such as an Ethernet MAC.  The device is made
+* up of several parts which include an IPIF and the IP.  The IPIF contains most
+* of the device infrastructure which is common to all devices, such as
+* interrupt processing, DMA channels, and FIFOs.  The infrastructure may also
+* be referred to as IPIF internal blocks since they are part of the IPIF and
+* are separate blocks that can be selected based upon the needs of the device.
+* The IP of the device is the logic that is unique to the device and interfaces
+* to the IPIF of the device.
+*
+* In general, there are two levels of registers within the IPIF.  The first
+* level, referred to as the device level, contains registers which are for the
+* entire device.  The second level, referred to as the IP level, contains
+* registers which are specific to the IP of the device.  The two levels of
+* registers are designed to be hierarchical such that the device level is
+* is a more general register set above the more specific registers of the IP.
+* The IP level of registers provides functionality which is typically common
+* across all devices and allows IP designers to focus on the unique aspects
+* of the IP.
+*
+* The interrupt registers of the IPIF are parameterizable such that the only
+* the number of bits necessary for the device are implemented. The functions
+* of this component do not attempt to validate that the passed in arguments are
+* valid based upon the number of implemented bits.  This is necessary to
+* maintain the level of performance required for the common components.  Bits
+* of the registers are assigned starting at the least significant bit of the
+* registers.
+*
+* <b>Critical Sections</b>
+*
+* It is the responsibility of the device driver designer to use critical
+* sections as necessary when calling functions of the IPIF.  This component
+* does not use critical sections and it does access registers using
+* read-modify-write operations.  Calls to IPIF functions from a main thread
+* and from an interrupt context could produce unpredictable behavior such that
+* the caller must provide the appropriate critical sections.
+*
+* <b>Mutual Exclusion</b>
+*
+* The functions of the IPIF are not thread safe such that the caller of all
+* functions is responsible for ensuring mutual exclusion for an IPIF.  Mutual
+* exclusion across multiple IPIF components is not necessary.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 1.23b jhl  02/27/01 Repartioned to reduce size
+* 1.23b rpm  08/17/04 Doxygenated for inclusion in API documentation
+* 1.23b xd   10/27/04 Improve Doxygen format
+* </pre>
+*
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include "xipif_v1_23_b.h"
+#include "xio.h"
+
+/************************** Constant Definitions *****************************/
+
+/* the following constant is used to generate bit masks for register testing
+ * in the self test functions, it defines the starting bit mask that is to be
+ * shifted from the LSB to MSB in creating a register test mask
+ */
+#define XIIF_V123B_FIRST_BIT_MASK     1UL
+
+
+/* the following constant defines the maximum number of bits which may be
+ * used in the registers at the device and IP levels, this is based upon the
+ * number of bits available in the registers
+ */
+#define XIIF_V123B_MAX_REG_BIT_COUNT 32
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Variable Definitions *****************************/
+
+
+/************************** Function Prototypes ******************************/
+
+static int IpIntrSelfTest(u32 RegBaseAddress, u32 IpRegistersWidth);
+
+/*****************************************************************************/
+/**
+*
+* This function performs a self test on the specified IPIF component.  Many
+* of the registers in the IPIF are tested to ensure proper operation.  This
+* function is destructive because the IPIF is reset at the start of the test
+* and at the end of the test to ensure predictable results.  The IPIF reset
+* also resets the entire device that uses the IPIF.  This function exits with
+* all interrupts for the device disabled.
+*
+* @param RegBaseAddress is the base address of the device's IPIF registers
+*
+* @param IpRegistersWidth contains the number of bits in the IP interrupt
+*        registers of the device.  The hardware is parameterizable such that
+*        only the number of bits necessary to support a device are implemented.
+*        This value must be between 0 and 32 with 0 indicating there are no IP
+*        interrupt registers used.
+*
+* @return
+*
+* A value of XST_SUCCESS indicates the test was successful with no errors.
+* Any one of the following error values may also be returned.
+*                                       <br><br>
+*   - XST_IPIF_RESET_REGISTER_ERROR     The value of a register at reset was
+*                                       not valid
+*                                       <br><br>
+*   - XST_IPIF_IP_STATUS_ERROR          A write to the IP interrupt status
+*                                       register did not read back correctly
+*                                       <br><br>
+*   - XST_IPIF_IP_ACK_ERROR             One or more bits in the IP interrupt
+*                                       status register did not reset when acked
+*                                       <br><br>
+*   - XST_IPIF_IP_ENABLE_ERROR          The IP interrupt enable register
+*                                       did not read back correctly based upon
+*                                       what was written to it
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+int XIpIfV123b_SelfTest(u32 RegBaseAddress, u8 IpRegistersWidth)
+{
+	int Status;
+
+	/* assert to verify arguments are valid */
+
+	XASSERT_NONVOID(IpRegistersWidth <= XIIF_V123B_MAX_REG_BIT_COUNT);
+
+	/* reset the IPIF such that it's in a known state before the test
+	 * and interrupts are globally disabled
+	 */
+	XIIF_V123B_RESET(RegBaseAddress);
+
+	/* perform the self test on the IP interrupt registers, if
+	 * it is not successful exit with the status
+	 */
+	Status = IpIntrSelfTest(RegBaseAddress, IpRegistersWidth);
+	if (Status != XST_SUCCESS) {
+		return Status;
+	}
+
+	/* reset the IPIF such that it's in a known state before exiting test */
+
+	XIIF_V123B_RESET(RegBaseAddress);
+
+	/* reaching this point means there were no errors, return success */
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************
+*
+* Perform a self test on the IP interrupt registers of the IPIF. This
+* function modifies registers of the IPIF such that they are not guaranteed
+* to be in the same state when it returns.  Any bits in the IP interrupt
+* status register which are set are assumed to be set by default after a reset
+* and are not tested in the test.
+*
+* @param RegBaseAddress is the base address of the device's IPIF registers
+*
+* @param IpRegistersWidth contains the number of bits in the IP interrupt
+*        registers of the device.  The hardware is parameterizable such that
+*        only the number of bits necessary to support a device are implemented.
+*        This value must be between 0 and 32 with 0 indicating there are no IP
+*        interrupt registers used.
+*
+* @return
+*
+* A status indicating XST_SUCCESS if the test was successful.  Otherwise, one
+* of the following values is returned.
+*   - XST_IPIF_RESET_REGISTER_ERROR     The value of a register at reset was
+*                                       not valid
+*                                       <br><br>
+*   - XST_IPIF_IP_STATUS_ERROR          A write to the IP interrupt status
+*                                       register did not read back correctly
+*                                       <br><br>
+*   - XST_IPIF_IP_ACK_ERROR             One or more bits in the IP status
+*                                       register did not reset when acked
+*                                       <br><br>
+*   - XST_IPIF_IP_ENABLE_ERROR          The IP interrupt enable register
+*                                       did not read back correctly based upon
+*                                       what was written to it
+* @note
+*
+* None.
+*
+******************************************************************************/
+static int IpIntrSelfTest(u32 RegBaseAddress, u32 IpRegistersWidth)
+{
+	/* ensure that the IP interrupt enable register is  zero
+	 * as it should be at reset, the interrupt status is dependent upon the
+	 * IP such that it's reset value is not known
+	 */
+	if (XIIF_V123B_READ_IIER(RegBaseAddress) != 0) {
+		return XST_IPIF_RESET_REGISTER_ERROR;
+	}
+
+	/* if there are any used IP interrupts, then test all of the interrupt
+	 * bits in all testable registers
+	 */
+	if (IpRegistersWidth > 0) {
+		u32 BitCount;
+		u32 IpInterruptMask = XIIF_V123B_FIRST_BIT_MASK;
+		u32 Mask = XIIF_V123B_FIRST_BIT_MASK;	/* bits assigned MSB to LSB */
+		u32 InterruptStatus;
+
+		/* generate the register masks to be used for IP register tests, the
+		 * number of bits supported by the hardware is parameterizable such
+		 * that only that number of bits are implemented in the registers, the
+		 * bits are allocated starting at the MSB of the registers
+		 */
+		for (BitCount = 1; BitCount < IpRegistersWidth; BitCount++) {
+			Mask = Mask << 1;
+			IpInterruptMask |= Mask;
+		}
+
+		/* get the current IP interrupt status register contents, any bits
+		 * already set must default to 1 at reset in the device and these
+		 * bits can't be tested in the following test, remove these bits from
+		 * the mask that was generated for the test
+		 */
+		InterruptStatus = XIIF_V123B_READ_IISR(RegBaseAddress);
+		IpInterruptMask &= ~InterruptStatus;
+
+		/* set the bits in the device status register and verify them by reading
+		 * the register again, all bits of the register are latched
+		 */
+		XIIF_V123B_WRITE_IISR(RegBaseAddress, IpInterruptMask);
+		InterruptStatus = XIIF_V123B_READ_IISR(RegBaseAddress);
+		if ((InterruptStatus & IpInterruptMask) != IpInterruptMask)
+		{
+			return XST_IPIF_IP_STATUS_ERROR;
+		}
+
+		/* test to ensure that the bits set in the IP interrupt status register
+		 * can be cleared by acknowledging them in the IP interrupt status
+		 * register then read it again and verify it was cleared
+		 */
+		XIIF_V123B_WRITE_IISR(RegBaseAddress, IpInterruptMask);
+		InterruptStatus = XIIF_V123B_READ_IISR(RegBaseAddress);
+		if ((InterruptStatus & IpInterruptMask) != 0) {
+			return XST_IPIF_IP_ACK_ERROR;
+		}
+
+		/* set the IP interrupt enable set register and then read the IP
+		 * interrupt enable register and verify the interrupts were enabled
+		 */
+		XIIF_V123B_WRITE_IIER(RegBaseAddress, IpInterruptMask);
+		if (XIIF_V123B_READ_IIER(RegBaseAddress) != IpInterruptMask) {
+			return XST_IPIF_IP_ENABLE_ERROR;
+		}
+
+		/* clear the IP interrupt enable register and then read the
+		 * IP interrupt enable register and verify the interrupts were disabled
+		 */
+		XIIF_V123B_WRITE_IIER(RegBaseAddress, 0);
+		if (XIIF_V123B_READ_IIER(RegBaseAddress) != 0) {
+			return XST_IPIF_IP_ENABLE_ERROR;
+		}
+	}
+	return XST_SUCCESS;
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xipif_v1_23_b.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xipif_v1_23_b.h
--- linux-2.6.31.12/drivers/xilinx_common/xipif_v1_23_b.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xipif_v1_23_b.h	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,665 @@
+/* $Id: xipif_v1_23_b.h,v 1.5 2005/09/26 16:04:52 trujillo Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002-2004 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xipif_v1_23_b.h
+*
+* The XIpIf component encapsulates the IPIF, which is the standard interface
+* that IP must adhere to when connecting to a bus.  The purpose of this
+* component is to encapsulate the IPIF processing such that maintainability
+* is increased.  This component does not provide a lot of abstraction from
+* from the details of the IPIF as it is considered a building block for
+* device drivers.  A device driver designer must be familiar with the
+* details of the IPIF hardware to use this component.
+*
+* The IPIF hardware provides a building block for all hardware devices such
+* that each device does not need to reimplement these building blocks. The
+* IPIF contains other building blocks, such as FIFOs and DMA channels, which
+* are also common to many devices.  These blocks are implemented as separate
+* hardware blocks and instantiated within the IPIF.  The primary hardware of
+* the IPIF which is implemented by this software component is the interrupt
+* architecture.  Since there are many blocks of a device which may generate
+* interrupts, all the interrupt processing is contained in the common part
+* of the device, the IPIF.  This interrupt processing is for the device level
+* only and does not include any processing for the interrupt controller.
+*
+* A device is a mechanism such as an Ethernet MAC.  The device is made
+* up of several parts which include an IPIF and the IP.  The IPIF contains most
+* of the device infrastructure which is common to all devices, such as
+* interrupt processing, DMA channels, and FIFOs.  The infrastructure may also
+* be referred to as IPIF internal blocks since they are part of the IPIF and
+* are separate blocks that can be selected based upon the needs of the device.
+* The IP of the device is the logic that is unique to the device and interfaces
+* to the IPIF of the device.
+*
+* In general, there are two levels of registers within the IPIF.  The first
+* level, referred to as the device level, contains registers which are for the
+* entire device.  The second level, referred to as the IP level, contains
+* registers which are specific to the IP of the device.  The two levels of
+* registers are designed to be hierarchical such that the device level is
+* is a more general register set above the more specific registers of the IP.
+* The IP level of registers provides functionality which is typically common
+* across all devices and allows IP designers to focus on the unique aspects
+* of the IP.
+*
+* <b>Critical Sections</b>
+*
+* It is the responsibility of the device driver designer to use critical
+* sections as necessary when calling functions of the IPIF.  This component
+* does not use critical sections and it does access registers using
+* read-modify-write operations.  Calls to IPIF functions from a main thread
+* and from an interrupt context could produce unpredictable behavior such that
+* the caller must provide the appropriate critical sections.
+*
+* <b>Mutual Exclusion</b>
+*
+* The functions of the IPIF are not thread safe such that the caller of all
+* functions is responsible for ensuring mutual exclusion for an IPIF.  Mutual
+* exclusion across multiple IPIF components is not necessary.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- ---------------------------------------------------------
+* 1.23b jhl  02/27/01 Repartioned to minimize size
+* 1.23b rpm  07/16/04 Changed ifdef for circular inclusion to be more qualified
+* 1.23b rpm  08/17/04 Doxygenated for inclusion of API documentation
+* 1.23b xd   10/27/04 Improve Doxygen format
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XIPIF_V123B_H		/* prevent circular inclusions */
+#define XIPIF_V123B_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+
+/***************************** Include Files *********************************/
+#include "xbasic_types.h"
+#include "xstatus.h"
+#include "xversion.h"
+
+/************************** Constant Definitions *****************************/
+
+/** @name Register Offsets
+ *
+ * The following constants define the register offsets for the registers of the
+ * IPIF, there are some holes in the memory map for reserved addresses to allow
+ * other registers to be added and still match the memory map of the interrupt
+ * controller registers
+ * @{
+ */
+#define XIIF_V123B_DISR_OFFSET     0UL	/**< device interrupt status register */
+#define XIIF_V123B_DIPR_OFFSET     4UL	/**< device interrupt pending register */
+#define XIIF_V123B_DIER_OFFSET     8UL	/**< device interrupt enable register */
+#define XIIF_V123B_DIIR_OFFSET     24UL	/**< device interrupt ID register */
+#define XIIF_V123B_DGIER_OFFSET    28UL	/**< device global interrupt enable register */
+#define XIIF_V123B_IISR_OFFSET     32UL	/**< IP interrupt status register */
+#define XIIF_V123B_IIER_OFFSET     40UL	/**< IP interrupt enable register */
+#define XIIF_V123B_RESETR_OFFSET   64UL	/**< reset register */
+/* @} */
+
+/**
+ * The value used for the reset register to reset the IPIF
+ */
+#define XIIF_V123B_RESET_MASK             0xAUL
+
+/**
+ * The following constant is used for the device global interrupt enable
+ * register, to enable all interrupts for the device, this is the only bit
+ * in the register
+ */
+#define XIIF_V123B_GINTR_ENABLE_MASK      0x80000000UL
+
+/**
+ * The mask to identify each internal IPIF error condition in the device
+ * registers of the IPIF. Interrupts are assigned in the register from LSB
+ * to the MSB
+ */
+#define XIIF_V123B_ERROR_MASK             1UL	  /**< LSB of the register */
+
+/** @name Interrupt IDs
+ *
+ * The interrupt IDs which identify each internal IPIF condition, this value
+ * must correlate with the mask constant for the error
+ * @{
+ */
+#define XIIF_V123B_ERROR_INTERRUPT_ID     0    /**< interrupt bit #, (LSB = 0) */
+#define XIIF_V123B_NO_INTERRUPT_ID        128  /**< no interrupts are pending */
+/* @} */
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/*****************************************************************************/
+/**
+*
+* Reset the IPIF component and hardware.  This is a destructive operation that
+* could cause the loss of data since resetting the IPIF of a device also
+* resets the device using the IPIF and any blocks, such as FIFOs or DMA
+* channels, within the IPIF.  All registers of the IPIF will contain their
+* reset value when this function returns.
+*
+* @param RegBaseAddress contains the base address of the IPIF registers.
+*
+* @return   None
+*
+* @note     None
+*
+******************************************************************************/
+#define XIIF_V123B_RESET(RegBaseAddress) \
+    XIo_Out32(RegBaseAddress + XIIF_V123B_RESETR_OFFSET, XIIF_V123B_RESET_MASK)
+
+/*****************************************************************************/
+/**
+*
+* This macro sets the device interrupt status register to the value.
+* This register indicates the status of interrupt sources for a device
+* which contains the IPIF.  The status is independent of whether interrupts
+* are enabled and could be used for polling a device at a higher level rather
+* than a more detailed level.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* device which contains the IPIF.  With the exception of some internal IPIF
+* conditions, the contents of this register are not latched but indicate
+* the live status of the interrupt sources within the device.  Writing any of
+* the non-latched bits of the register will have no effect on the register.
+*
+* For the latched bits of this register only, setting a bit which is zero
+* within this register causes an interrupt to generated.  The device global
+* interrupt enable register and the device interrupt enable register must be set
+* appropriately to allow an interrupt to be passed out of the device. The
+* interrupt is cleared by writing to this register with the bits to be
+* cleared set to a one and all others to zero.  This register implements a
+* toggle on write functionality meaning any bits which are set in the value
+* written cause the bits in the register to change to the opposite state.
+*
+* This function writes the specified value to the register such that
+* some bits may be set and others cleared.  It is the caller's responsibility
+* to get the value of the register prior to setting the value to prevent a
+* destructive behavior.
+*
+* @param RegBaseAddress contains the base address of the IPIF registers.
+*
+* @param Status contains the value to be written to the interrupt status
+*        register of the device.  The only bits which can be written are
+*        the latched bits which contain the internal IPIF conditions.  The
+*        following values may be used to set the status register or clear an
+*        interrupt condition.
+*        - XIIF_V123B_ERROR_MASK     Indicates a device error in the IPIF
+*
+* @return   None.
+*
+* @note     None.
+*
+******************************************************************************/
+#define XIIF_V123B_WRITE_DISR(RegBaseAddress, Status) \
+    XIo_Out32((RegBaseAddress) + XIIF_V123B_DISR_OFFSET, (Status))
+
+/*****************************************************************************/
+/**
+*
+* This macro gets the device interrupt status register contents.
+* This register indicates the status of interrupt sources for a device
+* which contains the IPIF.  The status is independent of whether interrupts
+* are enabled and could be used for polling a device at a higher level.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* device which contains the IPIF.  With the exception of some internal IPIF
+* conditions, the contents of this register are not latched but indicate
+* the live status of the interrupt sources within the device.
+*
+* For only the latched bits of this register, the interrupt may be cleared by
+* writing to these bits in the status register.
+*
+* @param    RegBaseAddress contains the base address of the IPIF registers.
+*
+* @return
+*
+* A status which contains the value read from the interrupt status register of
+* the device. The bit definitions are specific to the device with
+* the exception of the latched internal IPIF condition bits. The following
+* values may be used to detect internal IPIF conditions in the status.
+* <br><br>
+* - XIIF_V123B_ERROR_MASK     Indicates a device error in the IPIF
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XIIF_V123B_READ_DISR(RegBaseAddress) \
+    XIo_In32((RegBaseAddress) + XIIF_V123B_DISR_OFFSET)
+
+/*****************************************************************************/
+/**
+*
+* This function sets the device interrupt enable register contents.
+* This register controls which interrupt sources of the device are allowed to
+* generate an interrupt.  The device global interrupt enable register must also
+* be set appropriately for an interrupt to be passed out of the device.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* device which contains the IPIF.  Setting a bit in this register enables that
+* interrupt source to generate an interrupt.  Clearing a bit in this register
+* disables interrupt generation for that interrupt source.
+*
+* This function writes only the specified value to the register such that
+* some interrupts source may be enabled and others disabled.  It is the
+* caller's responsibility to get the value of the interrupt enable register
+* prior to setting the value to prevent an destructive behavior.
+*
+* An interrupt source may not be enabled to generate an interrupt, but can
+* still be polled in the interrupt status register.
+*
+* @param    RegBaseAddress contains the base address of the IPIF registers.
+*
+* @param
+*
+* Enable contains the value to be written to the interrupt enable register
+* of the device.  The bit definitions are specific to the device with
+* the exception of the internal IPIF conditions. The following
+* values may be used to enable the internal IPIF conditions interrupts.
+*   - XIIF_V123B_ERROR_MASK     Indicates a device error in the IPIF
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* Signature: u32 XIIF_V123B_WRITE_DIER(u32 RegBaseAddress,
+*                                          u32 Enable)
+*
+******************************************************************************/
+#define XIIF_V123B_WRITE_DIER(RegBaseAddress, Enable) \
+    XIo_Out32((RegBaseAddress) + XIIF_V123B_DIER_OFFSET, (Enable))
+
+/*****************************************************************************/
+/**
+*
+* This function gets the device interrupt enable register contents.
+* This register controls which interrupt sources of the device
+* are allowed to generate an interrupt.  The device global interrupt enable
+* register and the device interrupt enable register must also be set
+* appropriately for an interrupt to be passed out of the device.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* device which contains the IPIF.  Setting a bit in this register enables that
+* interrupt source to generate an interrupt if the global enable is set
+* appropriately.  Clearing a bit in this register disables interrupt generation
+* for that interrupt source regardless of the global interrupt enable.
+*
+* @param    RegBaseAddress contains the base address of the IPIF registers.
+*
+* @return
+*
+* The value read from the interrupt enable register of the device.  The bit
+* definitions are specific to the device with the exception of the internal
+* IPIF conditions. The following values may be used to determine from the
+* value if the internal IPIF conditions interrupts are enabled.
+* <br><br>
+* - XIIF_V123B_ERROR_MASK     Indicates a device error in the IPIF
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XIIF_V123B_READ_DIER(RegBaseAddress) \
+    XIo_In32((RegBaseAddress) + XIIF_V123B_DIER_OFFSET)
+
+/*****************************************************************************/
+/**
+*
+* This function gets the device interrupt pending register contents.
+* This register indicates the pending interrupt sources, those that are waiting
+* to be serviced by the software, for a device which contains the IPIF.
+* An interrupt must be enabled in the interrupt enable register of the IPIF to
+* be pending.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* the device which contains the IPIF.  With the exception of some internal IPIF
+* conditions, the contents of this register are not latched since the condition
+* is latched in the IP interrupt status register, by an internal block of the
+* IPIF such as a FIFO or DMA channel, or by the IP of the device.  This register
+* is read only and is not latched, but it is necessary to acknowledge (clear)
+* the interrupt condition by performing the appropriate processing for the IP
+* or block within the IPIF.
+*
+* This register can be thought of as the contents of the interrupt status
+* register ANDed with the contents of the interrupt enable register.
+*
+* @param RegBaseAddress contains the base address of the IPIF registers.
+*
+* @return
+*
+* The value read from the interrupt pending register of the device.  The bit
+* definitions are specific to the device with the exception of the latched
+* internal IPIF condition bits. The following values may be used to detect
+* internal IPIF conditions in the value.
+* <br><br>
+* - XIIF_V123B_ERROR_MASK     Indicates a device error in the IPIF
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XIIF_V123B_READ_DIPR(RegBaseAddress) \
+    XIo_In32((RegBaseAddress) + XIIF_V123B_DIPR_OFFSET)
+
+/*****************************************************************************/
+/**
+*
+* This macro gets the device interrupt ID for the highest priority interrupt
+* which is pending from the interrupt ID register. This function provides
+* priority resolution such that faster interrupt processing is possible.
+* Without priority resolution, it is necessary for the software to read the
+* interrupt pending register and then check each interrupt source to determine
+* if an interrupt is pending.  Priority resolution becomes more important as the
+* number of interrupt sources becomes larger.
+*
+* Interrupt priorities are based upon the bit position of the interrupt in the
+* interrupt pending register with bit 0 being the highest priority. The
+* interrupt ID is the priority of the interrupt, 0 - 31, with 0 being the
+* highest priority. The interrupt ID register is live rather than latched such
+* that multiple calls to this function may not yield the same results.  A
+* special value, outside of the interrupt priority range of 0 - 31, is
+* contained in the register which indicates that no interrupt is pending.  This
+* may be useful for allowing software to continue processing interrupts in a
+* loop until there are no longer any interrupts pending.
+*
+* The interrupt ID is designed to allow a function pointer table to be used
+* in the software such that the interrupt ID is used as an index into that
+* table.  The function pointer table could contain an instance pointer, such
+* as to DMA channel, and a function pointer to the function which handles
+* that interrupt.  This design requires the interrupt processing of the device
+* driver to be partitioned into smaller more granular pieces based upon
+* hardware used by the device, such as DMA channels and FIFOs.
+*
+* It is not mandatory that this function be used by the device driver software.
+* It may choose to read the pending register and resolve the pending interrupt
+* priorities on it's own.
+*
+* @param RegBaseAddress contains the base address of the IPIF registers.
+*
+* @return
+*
+* An interrupt ID, 0 - 31, which identifies the highest priority interrupt
+* which is pending.  A value of XIIF_NO_INTERRUPT_ID indicates that there is
+* no interrupt pending. The following values may be used to identify the
+* interrupt ID for the internal IPIF interrupts.
+* <br><br>
+* - XIIF_V123B_ERROR_INTERRUPT_ID     Indicates a device error in the IPIF
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XIIF_V123B_READ_DIIR(RegBaseAddress) \
+    XIo_In32((RegBaseAddress) + XIIF_V123B_DIIR_OFFSET)
+
+/*****************************************************************************/
+/**
+*
+* This function disables all interrupts for the device by writing to the global
+* interrupt enable register.  This register provides the ability to disable
+* interrupts without any modifications to the interrupt enable register such
+* that it is minimal effort to restore the interrupts to the previous enabled
+* state.  The corresponding function, XIpIf_GlobalIntrEnable, is provided to
+* restore the interrupts to the previous enabled state.  This function is
+* designed to be used in critical sections of device drivers such that it is
+* not necessary to disable other device interrupts.
+*
+* @param RegBaseAddress contains the base address of the IPIF registers.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XIIF_V123B_GINTR_DISABLE(RegBaseAddress) \
+    XIo_Out32((RegBaseAddress) + XIIF_V123B_DGIER_OFFSET, 0)
+
+/*****************************************************************************/
+/**
+*
+* This function writes to the global interrupt enable register to enable
+* interrupts from the device.  This register provides the ability to enable
+* interrupts without any modifications to the interrupt enable register such
+* that it is minimal effort to restore the interrupts to the previous enabled
+* state.  This function does not enable individual interrupts as the interrupt
+* enable register must be set appropriately.  This function is designed to be
+* used in critical sections of device drivers such that it is not necessary to
+* disable other device interrupts.
+*
+* @param RegBaseAddress contains the base address of the IPIF registers.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XIIF_V123B_GINTR_ENABLE(RegBaseAddress)           \
+    XIo_Out32((RegBaseAddress) + XIIF_V123B_DGIER_OFFSET, \
+               XIIF_V123B_GINTR_ENABLE_MASK)
+
+/*****************************************************************************/
+/**
+*
+* This function determines if interrupts are enabled at the global level by
+* reading the global interrupt register. This register provides the ability to
+* disable interrupts without any modifications to the interrupt enable register
+* such that it is minimal effort to restore the interrupts to the previous
+* enabled state.
+*
+* @param RegBaseAddress contains the base address of the IPIF registers.
+*
+* @return
+*
+* TRUE if interrupts are enabled for the IPIF, FALSE otherwise.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XIIF_V123B_IS_GINTR_ENABLED(RegBaseAddress)             \
+    (XIo_In32((RegBaseAddress) + XIIF_V123B_DGIER_OFFSET) ==    \
+              XIIF_V123B_GINTR_ENABLE_MASK)
+
+/*****************************************************************************/
+/**
+*
+* This function sets the IP interrupt status register to the specified value.
+* This register indicates the status of interrupt sources for the IP of the
+* device.  The IP is defined as the part of the device that connects to the
+* IPIF.  The status is independent of whether interrupts are enabled such that
+* the status register may also be polled when interrupts are not enabled.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* IP.  All bits of this register are latched. Setting a bit which is zero
+* within this register causes an interrupt to be generated.  The device global
+* interrupt enable register and the device interrupt enable register must be set
+* appropriately to allow an interrupt to be passed out of the device. The
+* interrupt is cleared by writing to this register with the bits to be
+* cleared set to a one and all others to zero.  This register implements a
+* toggle on write functionality meaning any bits which are set in the value
+* written cause the bits in the register to change to the opposite state.
+*
+* This function writes only the specified value to the register such that
+* some status bits may be set and others cleared.  It is the caller's
+* responsibility to get the value of the register prior to setting the value
+* to prevent an destructive behavior.
+*
+* @param RegBaseAddress contains the base address of the IPIF registers.
+*
+* @param Status contains the value to be written to the IP interrupt status
+*        register.  The bit definitions are specific to the device IP.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XIIF_V123B_WRITE_IISR(RegBaseAddress, Status) \
+    XIo_Out32((RegBaseAddress) + XIIF_V123B_IISR_OFFSET, (Status))
+
+/*****************************************************************************/
+/**
+*
+* This macro gets the contents of the IP interrupt status register.
+* This register indicates the status of interrupt sources for the IP of the
+* device.  The IP is defined as the part of the device that connects to the
+* IPIF. The status is independent of whether interrupts are enabled such
+* that the status register may also be polled when interrupts are not enabled.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* device.  All bits of this register are latched.  Writing a 1 to a bit within
+* this register causes an interrupt to be generated if enabled in the interrupt
+* enable register and the global interrupt enable is set.  Since the status is
+* latched, each status bit must be acknowledged in order for the bit in the
+* status register to be updated.  Each bit can be acknowledged by writing a
+* 0 to the bit in the status register.
+*
+* @param RegBaseAddress contains the base address of the IPIF registers.
+*
+* @return
+*
+* A status which contains the value read from the IP interrupt status register.
+* The bit definitions are specific to the device IP.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XIIF_V123B_READ_IISR(RegBaseAddress) \
+    XIo_In32((RegBaseAddress) + XIIF_V123B_IISR_OFFSET)
+
+/*****************************************************************************/
+/**
+*
+* This macro sets the IP interrupt enable register contents.  This register
+* controls which interrupt sources of the IP are allowed to generate an
+* interrupt.  The global interrupt enable register and the device interrupt
+* enable register must also be set appropriately for an interrupt to be
+* passed out of the device containing the IPIF and the IP.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* IP.  Setting a bit in this register enables the interrupt source to generate
+* an interrupt.  Clearing a bit in this register disables interrupt generation
+* for that interrupt source.
+*
+* This function writes only the specified value to the register such that
+* some interrupt sources may be enabled and others disabled.  It is the
+* caller's responsibility to get the value of the interrupt enable register
+* prior to setting the value to prevent an destructive behavior.
+*
+* @param RegBaseAddress contains the base address of the IPIF registers.
+*
+* @param Enable contains the value to be written to the IP interrupt enable
+*        register. The bit definitions are specific to the device IP.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+#define XIIF_V123B_WRITE_IIER(RegBaseAddress, Enable) \
+    XIo_Out32((RegBaseAddress) + XIIF_V123B_IIER_OFFSET, (Enable))
+
+/*****************************************************************************/
+/**
+*
+* This macro gets the IP interrupt enable register contents.  This register
+* controls which interrupt sources of the IP are allowed to generate an
+* interrupt.  The global interrupt enable register and the device interrupt
+* enable register must also be set appropriately for an interrupt to be
+* passed out of the device containing the IPIF and the IP.
+*
+* Each bit of the register correlates to a specific interrupt source within the
+* IP.  Setting a bit in this register enables the interrupt source to generate
+* an interrupt.  Clearing a bit in this register disables interrupt generation
+* for that interrupt source.
+*
+* @param RegBaseAddress contains the base address of the IPIF registers.
+*
+* @return
+*
+* The contents read from the IP interrupt enable register.  The bit definitions
+* are specific to the device IP.
+*
+* @note
+*
+* Signature: u32 XIIF_V123B_READ_IIER(u32 RegBaseAddress)
+*
+******************************************************************************/
+#define XIIF_V123B_READ_IIER(RegBaseAddress) \
+    XIo_In32((RegBaseAddress) + XIIF_V123B_IIER_OFFSET)
+
+/************************** Function Prototypes ******************************/
+
+/**
+ * Initialization Functions
+ */
+int XIpIfV123b_SelfTest(u32 RegBaseAddress, u8 IpRegistersWidth);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xlldma_bd.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma_bd.h
--- linux-2.6.31.12/drivers/xilinx_common/xlldma_bd.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma_bd.h	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,302 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2007 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+ *
+ * @file xlldma_bd.h
+ *
+ * This header provides operations to manage buffer descriptors (BD) in support
+ * of Local-Link scatter-gather DMA (see xlldma.h).
+ *
+ * The API exported by this header defines abstracted macros that allow the
+ * application to read/write specific BD fields.
+ *
+ * <b>Buffer Descriptors</b>
+ *
+ * A buffer descriptor defines a DMA transaction (see "Transaction"
+ * section in xlldma.h). The macros defined by this header file allow access
+ * to most fields within a BD to tailor a DMA transaction according to
+ * application and hardware requirements.  See the hardware IP DMA spec for
+ * more information on BD fields and how they affect transfers.
+ *
+ * The XLlDma_Bd structure defines a BD. The organization of this structure is
+ * driven mainly by the hardware for use in scatter-gather DMA transfers.
+ *
+ * <b>Accessor Macros</b>
+ *
+ * Most of the BD attributes can be accessed through macro functions defined
+ * here in this API. Words such as XLLDMA_BD_USR1_OFFSET (see xlldma_hw.h)
+ * should be accessed using XLlDma_mBdRead() and XLlDma_mBdWrite() as defined
+ * in xlldma_hw.h. The USR words are implementation dependent. For example,
+ * they may implement checksum offloading fields for Ethernet devices. Accessor
+ * macros may be defined in the device specific API to get at this data.
+ *
+ * <b>Performance</b>
+ *
+ * BDs are typically in a non-cached memory space. Limiting I/O to BDs can
+ * improve overall performance of the DMA channel.
+ *
+ * <pre>
+ * MODIFICATION HISTORY:
+ *
+ * Ver   Who  Date     Changes
+ * ----- ---- -------- -------------------------------------------------------
+ * 1.00a xd   12/21/06 First release
+ * </pre>
+ *
+ *****************************************************************************/
+
+#ifndef XLLDMA_BD_H		/* prevent circular inclusions */
+#define XLLDMA_BD_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xenv.h"
+#include "xlldma_hw.h"
+
+/************************** Constant Definitions *****************************/
+
+/**************************** Type Definitions *******************************/
+
+/**
+ * The XLlDma_Bd is the type for buffer descriptors (BDs).
+ */
+typedef u32 XLlDma_Bd[XLLDMA_BD_NUM_WORDS];
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/*****************************************************************************/
+/**
+*
+* Read the given Buffer Descriptor word.
+*
+* @param    BaseAddress is the base address of the BD to read
+* @param    Offset is the word offset to be read
+*
+* @return   The 32-bit value of the field
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mBdRead(u32 BaseAddress, u32 Offset)
+*
+******************************************************************************/
+#define XLlDma_mBdRead(BaseAddress, Offset)				\
+	(*(u32*)((u32)(BaseAddress) + (u32)(Offset)))
+
+
+/*****************************************************************************/
+/**
+*
+* Write the given Buffer Descriptor word.
+*
+* @param    BaseAddress is the base address of the BD to write
+* @param    Offset is the word offset to be written
+* @param    Data is the 32-bit value to write to the field
+*
+* @return   None.
+*
+* @note
+* C-style signature:
+*    void XLlDma_mBdWrite(u32 BaseAddress, u32 RegOffset, u32 Data)
+*
+******************************************************************************/
+#define XLlDma_mBdWrite(BaseAddress, Offset, Data)			\
+	(*(u32*)((u32)(BaseAddress) + (u32)(Offset)) = (Data))
+
+
+/*****************************************************************************/
+/**
+ * Zero out all BD fields
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @return Nothing
+ *
+ * @note
+ * C-style signature:
+ *    void XLlDma_mBdClear(XLlDma_Bd* BdPtr)
+ *
+ *****************************************************************************/
+#define XLlDma_mBdClear(BdPtr)                    \
+	memset((BdPtr), 0, sizeof(XLlDma_Bd))
+
+
+/*****************************************************************************/
+/**
+ * Set the BD's STS/CTRL field. The word containing STS/CTRL also contains the
+ * USR0 field. USR0 will not be modified. This operation requires a read-
+ * modify-write operation. If it is wished to set both STS/CTRL and USR0 with
+ * a single write operation, then use XLlDma_mBdWrite(BdPtr,
+ * XLLDMA_BD_STSCTRL_USR0_OFFSET, Data).
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  Data is the value to write to STS/CTRL. Or 0 or more
+ *         XLLDMA_BD_STSCTRL_*** values defined in xlldma_hw.h to create a
+ *         valid value for this parameter
+ *
+ * @note
+ * C-style signature:
+ *    u32 XLlDma_mBdSetStsCtrl(XLlDma_Bd* BdPtr, u32 Data)
+ *
+ *****************************************************************************/
+#define XLlDma_mBdSetStsCtrl(BdPtr, Data)                                   \
+	XLlDma_mBdWrite((BdPtr), XLLDMA_BD_STSCTRL_USR0_OFFSET,             \
+		(XLlDma_mBdRead((BdPtr), XLLDMA_BD_STSCTRL_USR0_OFFSET)     \
+		& XLLDMA_BD_STSCTRL_USR0_MASK) |			    \
+		((Data) & XLLDMA_BD_STSCTRL_MASK))
+
+
+/*****************************************************************************/
+/**
+ * Retrieve the word containing the BD's STS/CTRL field. This word also
+ * contains the USR0 field.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @return Word at offset XLLDMA_BD_DMASR_OFFSET. Use XLLDMA_BD_STSCTRL_***
+ *         values defined in xlldma_hw.h to interpret this returned value
+ *
+ * @note
+ * C-style signature:
+ *    u32 XLlDma_mBdGetStsCtrl(XLlDma_Bd* BdPtr)
+ *
+ *****************************************************************************/
+#define XLlDma_mBdGetStsCtrl(BdPtr)              \
+	XLlDma_mBdRead((BdPtr), XLLDMA_BD_STSCTRL_USR0_OFFSET)
+
+
+/*****************************************************************************/
+/**
+ * Set transfer length in bytes for the given BD. The length must be set each
+ * time a BD is submitted to hardware.
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  LenBytes is the number of bytes to transfer.
+ *
+ * @note
+ * C-style signature:
+ *    void XLlDma_mBdSetLength(XLlDma_Bd* BdPtr, u32 LenBytes)
+ *
+ *****************************************************************************/
+#define XLlDma_mBdSetLength(BdPtr, LenBytes)                            \
+	XLlDma_mBdWrite((BdPtr), XLLDMA_BD_BUFL_OFFSET, (LenBytes))
+
+
+/*****************************************************************************/
+/**
+ * Retrieve the BD length field.
+ *
+ * For TX channels, the returned value is the same as that written with
+ * XLlDma_mBdSetLength().
+ *
+ * For RX channels, the returned value is what was written by the DMA engine
+ * after processing the BD. This value represents the number of bytes
+ * processed.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @return Bytes processed by hardware or set by XLlDma_mBdSetLength().
+ *
+ * @note
+ * C-style signature:
+ *    u32 XLlDma_mBdGetLength(XLlDma_Bd* BdPtr)
+ *
+ *****************************************************************************/
+#define XLlDma_mBdGetLength(BdPtr)                      \
+	XLlDma_mBdRead((BdPtr), XLLDMA_BD_BUFL_OFFSET)
+
+
+/*****************************************************************************/
+/**
+ * Set the ID field of the given BD. The ID is an arbitrary piece of data the
+ * application can associate with a specific BD.
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  Id is a 32 bit quantity to set in the BD
+ *
+ * @note
+ * C-style signature:
+ *    void XLlDma_mBdSetId(XLlDma_Bd* BdPtr, void Id)
+ *
+ *****************************************************************************/
+#define XLlDma_mBdSetId(BdPtr, Id)                                      \
+	(XLlDma_mBdWrite((BdPtr), XLLDMA_BD_ID_OFFSET, (u32)(Id)))
+
+
+/*****************************************************************************/
+/**
+ * Retrieve the ID field of the given BD previously set with XLlDma_mBdSetId.
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @note
+ * C-style signature:
+ *    u32 XLlDma_mBdGetId(XLlDma_Bd* BdPtr)
+ *
+ *****************************************************************************/
+#define XLlDma_mBdGetId(BdPtr) (XLlDma_mBdRead((BdPtr), XLLDMA_BD_ID_OFFSET))
+
+
+/*****************************************************************************/
+/**
+ * Set the BD's buffer address.
+ *
+ * @param  BdPtr is the BD to operate on
+ * @param  Addr is the address to set
+ *
+ * @note
+ * C-style signature:
+ *    void XLlDma_mBdSetBufAddr(XLlDma_Bd* BdPtr, u32 Addr)
+ *
+ *****************************************************************************/
+#define XLlDma_mBdSetBufAddr(BdPtr, Addr)                               \
+	(XLlDma_mBdWrite((BdPtr), XLLDMA_BD_BUFA_OFFSET, (u32)(Addr)))
+
+
+/*****************************************************************************/
+/**
+ * Get the BD's buffer address
+ *
+ * @param  BdPtr is the BD to operate on
+ *
+ * @note
+ * C-style signature:
+ *    u32 XLlDma_mBdGetBufAddrLow(XLlDma_Bd* BdPtr)
+ *
+ *****************************************************************************/
+#define XLlDma_mBdGetBufAddr(BdPtr)                     \
+	(XLlDma_mBdRead((BdPtr), XLLDMA_BD_BUFA_OFFSET))
+
+
+/************************** Function Prototypes ******************************/
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xlldma_bdring.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma_bdring.c
--- linux-2.6.31.12/drivers/xilinx_common/xlldma_bdring.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma_bdring.c	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,1144 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2007-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xlldma_bdring.c
+*
+* This file implements buffer descriptor ring related functions. For more
+* information on this driver, see xlldma.h.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a xd   12/21/06 First release
+* </pre>
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include <linux/string.h>
+
+#include "xlldma.h"
+#include "xenv.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/******************************************************************************
+ * Compute the virtual address of a descriptor from its physical address
+ *
+ * @param BdPtr is the physical address of the BD
+ *
+ * @returns Virtual address of BdPtr
+ *
+ * @note Assume BdPtr is always a valid BD in the ring
+ * @note RingPtr is an implicit parameter
+ *****************************************************************************/
+#define XLLDMA_PHYS_TO_VIRT(BdPtr) \
+	((u32)(BdPtr) + (RingPtr->FirstBdAddr - RingPtr->FirstBdPhysAddr))
+
+/******************************************************************************
+ * Compute the physical address of a descriptor from its virtual address
+ *
+ * @param BdPtr is the virtual address of the BD
+ *
+ * @returns Physical address of BdPtr
+ *
+ * @note Assume BdPtr is always a valid BD in the ring
+ * @note RingPtr is an implicit parameter
+ *****************************************************************************/
+#define XLLDMA_VIRT_TO_PHYS(BdPtr) \
+	((u32)(BdPtr) - (RingPtr->FirstBdAddr - RingPtr->FirstBdPhysAddr))
+
+/******************************************************************************
+ * Move the BdPtr argument ahead an arbitrary number of BDs wrapping around
+ * to the beginning of the ring if needed.
+ *
+ * We know if a wraparound should occur if the new BdPtr is greater than
+ * the high address in the ring OR if the new BdPtr crosses the 0xFFFFFFFF
+ * to 0 boundary.
+ *
+ * @param RingPtr is the ring BdPtr appears in
+ * @param BdPtr on input is the starting BD position and on output is the
+ *        final BD position
+ * @param NumBd is the number of BD spaces to increment
+ *
+ *****************************************************************************/
+#define XLLDMA_RING_SEEKAHEAD(RingPtr, BdPtr, NumBd)			    \
+	{								    \
+		u32 Addr = (u32)(BdPtr);				    \
+									    \
+		Addr += ((RingPtr)->Separation * (NumBd));		    \
+		if ((Addr > (RingPtr)->LastBdAddr) || ((u32)(BdPtr) > Addr))\
+		{							    \
+			Addr -= (RingPtr)->Length;			    \
+		}							    \
+									    \
+		(BdPtr) = (XLlDma_Bd*)Addr;				    \
+	}
+
+/******************************************************************************
+ * Move the BdPtr argument backwards an arbitrary number of BDs wrapping
+ * around to the end of the ring if needed.
+ *
+ * We know if a wraparound should occur if the new BdPtr is less than
+ * the base address in the ring OR if the new BdPtr crosses the 0xFFFFFFFF
+ * to 0 boundary.
+ *
+ * @param RingPtr is the ring BdPtr appears in
+ * @param BdPtr on input is the starting BD position and on output is the
+ *        final BD position
+ * @param NumBd is the number of BD spaces to increment
+ *
+ *****************************************************************************/
+#define XLLDMA_RING_SEEKBACK(RingPtr, BdPtr, NumBd)			      \
+	{                                                                     \
+		u32 Addr = (u32)(BdPtr);				      \
+									      \
+		Addr -= ((RingPtr)->Separation * (NumBd));		      \
+		if ((Addr < (RingPtr)->FirstBdAddr) || ((u32)(BdPtr) < Addr)) \
+		{							      \
+			Addr += (RingPtr)->Length;			      \
+		}							      \
+									      \
+		(BdPtr) = (XLlDma_Bd*)Addr;				      \
+	}
+
+/******************************************************************************
+ * Define methods to flush and invalidate cache for BDs should they be
+ * located in cached memory. These macros may NOPs if the underlying
+ * XCACHE_FLUSH_DCACHE_RANGE and XCACHE_INVALIDATE_DCACHE_RANGE macros are not
+ * implemented or they do nothing.
+ *
+ * MicroBlaze requires a physical address while Powerpc needs a virtual address
+ * for the cache functions.
+ *****************************************************************************/
+
+#ifdef XCACHE_FLUSH_DCACHE_RANGE
+#ifdef CONFIG_MICROBLAZE
+#  define XLLDMA_CACHE_FLUSH(BdPtr)               \
+	XCACHE_FLUSH_DCACHE_RANGE(XLLDMA_VIRT_TO_PHYS(BdPtr), XLLDMA_BD_HW_NUM_BYTES)
+#else
+#  define XLLDMA_CACHE_FLUSH(BdPtr)               \
+	XCACHE_FLUSH_DCACHE_RANGE((BdPtr), XLLDMA_BD_HW_NUM_BYTES)
+#endif
+#else
+#  define XLLDMA_CACHE_FLUSH(BdPtr)
+#endif
+
+#ifdef XCACHE_INVALIDATE_DCACHE_RANGE
+#ifdef CONFIG_MICROBLAZE
+#  define XLLDMA_CACHE_INVALIDATE(BdPtr)          \
+	XCACHE_INVALIDATE_DCACHE_RANGE(XLLDMA_VIRT_TO_PHYS(BdPtr), XLLDMA_BD_HW_NUM_BYTES)
+#else
+#  define XLLDMA_CACHE_INVALIDATE(BdPtr)          		 \
+	XCACHE_INVALIDATE_DCACHE_RANGE((BdPtr), XLLDMA_BD_HW_NUM_BYTES)
+#endif
+#else
+#  define XLLDMA_CACHE_INVALIDATE(BdPtr)
+#endif
+
+
+
+/************************** Function Prototypes ******************************/
+
+
+/************************** Variable Definitions *****************************/
+
+
+/*****************************************************************************/
+/**
+ * Using a memory segment allocated by the caller, create and setup the BD list
+ * for the given SGDMA ring.
+ *
+ * @param InstancePtr is the instance to be worked on.
+ * @param PhysAddr is the physical base address of application memory region.
+ * @param VirtAddr is the virtual base address of the application memory
+ *        region.If address translation is not being utilized, then VirtAddr
+ *        should be equivalent to PhysAddr.
+ * @param Alignment governs the byte alignment of individual BDs. This function
+ *        will enforce a minimum alignment of XLLDMA_BD_MINIMUM_ALIGNMENT bytes
+ *        with no maximum as long as it is specified as a power of 2.
+ * @param BdCount is the number of BDs to setup in the application memory
+ *        region. It is assumed the region is large enough to contain the BDs.
+ *        Refer to the "SGDMA Ring Creation" section  in xlldma.h for more
+ *        information. The minimum valid value for this parameter is 1.
+ *
+ * @return
+ *
+ * - XST_SUCCESS if initialization was successful
+ * - XST_NO_FEATURE if the provided instance is a non SGDMA type of DMA
+ *   channel.
+ * - XST_INVALID_PARAM under any of the following conditions: 1) PhysAddr
+ *   and/or VirtAddr are not aligned to the given Alignment parameter;
+ *   2) Alignment parameter does not meet minimum requirements or is not a
+ *   power of 2 value; 3) BdCount is 0.
+ * - XST_DMA_SG_LIST_ERROR if the memory segment containing the list spans
+ *   over address 0x00000000 in virtual address space.
+ *
+ *****************************************************************************/
+int XLlDma_BdRingCreate(XLlDma_BdRing * RingPtr, u32 PhysAddr,
+			u32 VirtAddr, u32 Alignment, unsigned BdCount)
+{
+	unsigned i;
+	u32 BdVirtAddr;
+	u32 BdPhysAddr;
+
+	/* In case there is a failure prior to creating list, make sure the
+	 * following attributes are 0 to prevent calls to other SG functions
+	 * from doing anything
+	 */
+	RingPtr->AllCnt = 0;
+	RingPtr->FreeCnt = 0;
+	RingPtr->HwCnt = 0;
+	RingPtr->PreCnt = 0;
+	RingPtr->PostCnt = 0;
+
+	/* Make sure Alignment parameter meets minimum requirements */
+	if (Alignment < XLLDMA_BD_MINIMUM_ALIGNMENT) {
+		return (XST_INVALID_PARAM);
+	}
+
+	/* Make sure Alignment is a power of 2 */
+	if ((Alignment - 1) & Alignment) {
+		return (XST_INVALID_PARAM);
+	}
+
+	/* Make sure PhysAddr and VirtAddr are on same Alignment */
+	if ((PhysAddr % Alignment) || (VirtAddr % Alignment)) {
+		return (XST_INVALID_PARAM);
+	}
+
+	/* Is BdCount reasonable? */
+	if (BdCount == 0) {
+		return (XST_INVALID_PARAM);
+	}
+
+	/* Compute how many bytes will be between the start of adjacent BDs */
+	RingPtr->Separation =
+		(sizeof(XLlDma_Bd) + (Alignment - 1)) & ~(Alignment - 1);
+
+	/* Must make sure the ring doesn't span address 0x00000000. If it does,
+	 * then the next/prev BD traversal macros will fail.
+	 */
+	if (VirtAddr > (VirtAddr + (RingPtr->Separation * BdCount) - 1)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* Initial ring setup:
+	 *  - Clear the entire space
+	 *  - Setup each BD's next pointer with the physical address of the
+	 *    next BD
+	 *  - Set each BD's DMA complete status bit
+	 */
+	memset((void *) VirtAddr, 0, (RingPtr->Separation * BdCount));
+
+	/* the 1st bd addresses (virtual and physical) have to initilized
+	 * before the cache functions are called as MicroBlaze requires
+	 * physical addresses
+	 */
+	RingPtr->FirstBdAddr = VirtAddr;
+	RingPtr->FirstBdPhysAddr = PhysAddr;
+
+	BdVirtAddr = VirtAddr;
+	BdPhysAddr = PhysAddr + RingPtr->Separation;
+	for (i = 1; i < BdCount; i++) {
+		XLlDma_mBdWrite(BdVirtAddr, XLLDMA_BD_NDESC_OFFSET, BdPhysAddr);
+		XLlDma_mBdWrite(BdVirtAddr, XLLDMA_BD_STSCTRL_USR0_OFFSET,
+				XLLDMA_BD_STSCTRL_COMPLETED_MASK);
+		XLLDMA_CACHE_FLUSH(BdVirtAddr);
+		BdVirtAddr += RingPtr->Separation;
+		BdPhysAddr += RingPtr->Separation;
+	}
+
+	/* At the end of the ring, link the last BD back to the top */
+	XLlDma_mBdWrite(BdVirtAddr, XLLDMA_BD_NDESC_OFFSET, PhysAddr);
+	XLLDMA_CACHE_FLUSH(BdVirtAddr);
+
+	/* Setup and initialize pointers and counters */
+	RingPtr->RunState = XST_DMA_SG_IS_STOPPED;
+	RingPtr->LastBdAddr = BdVirtAddr;
+	RingPtr->Length = RingPtr->LastBdAddr - RingPtr->FirstBdAddr +
+		RingPtr->Separation;
+	RingPtr->AllCnt = BdCount;
+	RingPtr->FreeCnt = BdCount;
+	RingPtr->FreeHead = (XLlDma_Bd *) VirtAddr;
+	RingPtr->PreHead = (XLlDma_Bd *) VirtAddr;
+	RingPtr->HwHead = (XLlDma_Bd *) VirtAddr;
+	RingPtr->HwTail = (XLlDma_Bd *) VirtAddr;
+	RingPtr->PostHead = (XLlDma_Bd *) VirtAddr;
+	RingPtr->BdaRestart = (XLlDma_Bd *) PhysAddr;
+
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * Clone the given BD into every BD in the ring. Except for
+ * XLLDMA_BD_NDESC_OFFSET, every field of the source BD is replicated in every
+ * BD in the ring.
+ *
+ * This function can be called only when all BDs are in the free group such as
+ * they are immediately after creation of the ring. This prevents modification
+ * of BDs while they are in use by hardware or the application.
+ *
+ * @param InstancePtr is the instance to be worked on.
+ * @param SrcBdPtr is the source BD template to be cloned into the list.
+ *
+ * @return
+ *   - XST_SUCCESS if the list was modified.
+ *   - XST_DMA_SG_NO_LIST if a list has not been created.
+ *   - XST_DMA_SG_LIST_ERROR if some of the BDs in this channel are under
+ *     hardware or application control.
+ *   - XST_DEVICE_IS_STARTED if the DMA channel has not been stopped.
+ *
+ *****************************************************************************/
+int XLlDma_BdRingClone(XLlDma_BdRing * RingPtr, XLlDma_Bd * SrcBdPtr)
+{
+	unsigned i;
+	u32 CurBd;
+	u32 Save;
+	XLlDma_Bd TmpBd;
+
+	/* Can't do this function if there isn't a ring */
+	if (RingPtr->AllCnt == 0) {
+		return (XST_DMA_SG_NO_LIST);
+	}
+
+	/* Can't do this function with the channel running */
+	if (RingPtr->RunState == XST_DMA_SG_IS_STARTED) {
+		return (XST_DEVICE_IS_STARTED);
+	}
+
+	/* Can't do this function with some of the BDs in use */
+	if (RingPtr->FreeCnt != RingPtr->AllCnt) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+
+	/* Make a copy of the template then modify it by setting complete bit
+	 * in status/control field
+	 */
+	memcpy(&TmpBd, SrcBdPtr, sizeof(XLlDma_Bd));
+	Save = XLlDma_mBdRead(&TmpBd, XLLDMA_BD_STSCTRL_USR0_OFFSET);
+	Save |= XLLDMA_BD_STSCTRL_COMPLETED_MASK;
+	XLlDma_mBdWrite(&TmpBd, XLLDMA_BD_STSCTRL_USR0_OFFSET, Save);
+
+	/* Starting from the top of the ring, save BD.Next, overwrite the
+	 * entire BD with the template, then restore BD.Next
+	 */
+	for (i = 0, CurBd = RingPtr->FirstBdAddr;
+	     i < RingPtr->AllCnt; i++, CurBd += RingPtr->Separation) {
+		Save = XLlDma_mBdRead(CurBd, XLLDMA_BD_NDESC_OFFSET);
+		memcpy((void *) CurBd, (void *) &TmpBd, sizeof(XLlDma_Bd));
+		XLlDma_mBdWrite(CurBd, XLLDMA_BD_NDESC_OFFSET, Save);
+		XLLDMA_CACHE_FLUSH(CurBd);
+	}
+
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * Allow DMA transactions to commence on the given channels if descriptors are
+ * ready to be processed.
+ *
+ * @param RingPtr is a pointer to the descriptor ring instance to be worked on.
+ *
+ * @return
+ * - XST_SUCCESS if the channel) were started.
+ * - XST_DMA_SG_NO_LIST if the channel) have no initialized BD ring.
+ *
+ *****************************************************************************/
+int XLlDma_BdRingStart(XLlDma_BdRing * RingPtr)
+{
+	/* BD list has yet to be created for this channel */
+	if (RingPtr->AllCnt == 0) {
+		return (XST_DMA_SG_NO_LIST);
+	}
+
+	/* Do nothing if already started */
+	if (RingPtr->RunState == XST_DMA_SG_IS_STARTED) {
+		return (XST_SUCCESS);
+	}
+
+	/* Sync hardware and driver with the last unprocessed BD or the 1st BD
+	 * in the ring if this is the first time starting the channel
+	 */
+	XLlDma_mWriteReg(RingPtr->ChanBase, XLLDMA_CDESC_OFFSET,
+			 (u32) RingPtr->BdaRestart);
+
+	/* Note as started */
+	RingPtr->RunState = XST_DMA_SG_IS_STARTED;
+
+	/* If there are unprocessed BDs then we want to channel to begin
+	 * processing right away
+	 */
+	if (RingPtr->HwCnt > 0) {
+		XLLDMA_CACHE_INVALIDATE(RingPtr->HwTail);
+
+		if ((XLlDma_mBdRead(RingPtr->HwTail,
+				    XLLDMA_BD_STSCTRL_USR0_OFFSET) &
+		     XLLDMA_BD_STSCTRL_COMPLETED_MASK) == 0) {
+			XLlDma_mWriteReg(RingPtr->ChanBase,
+					 XLLDMA_TDESC_OFFSET,
+					 XLLDMA_VIRT_TO_PHYS(RingPtr->HwTail));
+		}
+	}
+
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * Set interrupt coalescing parameters for the given descriptor ring channel.
+ *
+ * @param RingPtr is a pointer to the descriptor ring instance to be worked on.
+ * @param Counter sets the packet counter on the channel. Valid range is
+ *        1..255, or XLLDMA_NO_CHANGE to leave this setting unchanged.
+ * @param Timer sets the waitbound timer on the channel. Valid range is
+ *        1..255, or XLLDMA_NO_CHANGE to leave this setting unchanged. LSB is
+ *        in units of 1 / (local link clock).
+ *
+ * @return
+ *        - XST_SUCCESS if interrupt coalescing settings updated
+ *        - XST_FAILURE if Counter or Timer parameters are out of range
+ *****************************************************************************/
+int XLlDma_BdRingSetCoalesce(XLlDma_BdRing * RingPtr, u32 Counter, u32 Timer)
+{
+	u32 Cr = XLlDma_mReadReg(RingPtr->ChanBase, XLLDMA_CR_OFFSET);
+
+	if (Counter != XLLDMA_NO_CHANGE) {
+		if ((Counter == 0) || (Counter > 0xFF)) {
+			return (XST_FAILURE);
+		}
+
+		Cr = (Cr & ~XLLDMA_CR_IRQ_COUNT_MASK) |
+			(Counter << XLLDMA_CR_IRQ_COUNT_SHIFT);
+		Cr |= XLLDMA_CR_LD_IRQ_CNT_MASK;
+	}
+
+	if (Timer != XLLDMA_NO_CHANGE) {
+		if ((Timer == 0) || (Timer > 0xFF)) {
+			return (XST_FAILURE);
+		}
+
+		Cr = (Cr & ~XLLDMA_CR_IRQ_TIMEOUT_MASK) |
+			(Timer << XLLDMA_CR_IRQ_TIMEOUT_SHIFT);
+		Cr |= XLLDMA_CR_LD_IRQ_CNT_MASK;
+	}
+
+	XLlDma_mWriteReg(RingPtr->ChanBase, XLLDMA_CR_OFFSET, Cr);
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * Retrieve current interrupt coalescing parameters from the given descriptor
+ * ring channel.
+ *
+ * @param RingPtr is a pointer to the descriptor ring instance to be worked on.
+ * @param CounterPtr points to a memory location where the current packet
+ *        counter will be written.
+ * @param TimerPtr points to a memory location where the current waitbound
+ *        timer will be written.
+ *****************************************************************************/
+void XLlDma_BdRingGetCoalesce(XLlDma_BdRing * RingPtr,
+			      u32 *CounterPtr, u32 *TimerPtr)
+{
+	u32 Cr = XLlDma_mReadReg(RingPtr->ChanBase, XLLDMA_CR_OFFSET);
+
+	*CounterPtr =
+		((Cr & XLLDMA_CR_IRQ_COUNT_MASK) >> XLLDMA_CR_IRQ_COUNT_SHIFT);
+	*TimerPtr =
+		((Cr & XLLDMA_CR_IRQ_TIMEOUT_MASK) >>
+		 XLLDMA_CR_IRQ_TIMEOUT_SHIFT);
+}
+
+
+/*****************************************************************************/
+/**
+ * Reserve locations in the BD ring. The set of returned BDs may be modified in
+ * preparation for future DMA transactions). Once the BDs are ready to be
+ * submitted to hardware, the application must call XLlDma_BdRingToHw() in the
+ * same order which they were allocated here. Example:
+ *
+ * <pre>
+ *        NumBd = 2;
+ *        Status = XDsma_RingBdAlloc(MyRingPtr, NumBd, &MyBdSet);
+ *
+ *        if (Status != XST_SUCCESS)
+ *        {
+ *            // Not enough BDs available for the request
+ *        }
+ *
+ *        CurBd = MyBdSet;
+ *        for (i=0; i<NumBd; i++)
+ *        {
+ *            // Prepare CurBd.....
+ *
+ *            // Onto next BD
+ *            CurBd = XLlDma_mBdRingNext(MyRingPtr, CurBd);
+ *        }
+ *
+ *        // Give list to hardware
+ *        Status = XLlDma_BdRingToHw(MyRingPtr, NumBd, MyBdSet);
+ * </pre>
+ *
+ * A more advanced use of this function may allocate multiple sets of BDs.
+ * They must be allocated and given to hardware in the correct sequence:
+ * <pre>
+ *        // Legal
+ *        XLlDma_BdRingAlloc(MyRingPtr, NumBd1, &MySet1);
+ *        XLlDma_BdRingToHw(MyRingPtr, NumBd1, MySet1);
+ *
+ *        // Legal
+ *        XLlDma_BdRingAlloc(MyRingPtr, NumBd1, &MySet1);
+ *        XLlDma_BdRingAlloc(MyRingPtr, NumBd2, &MySet2);
+ *        XLlDma_BdRingToHw(MyRingPtr, NumBd1, MySet1);
+ *        XLlDma_BdRingToHw(MyRingPtr, NumBd2, MySet2);
+ *
+ *        // Not legal
+ *        XLlDma_BdRingAlloc(MyRingPtr, NumBd1, &MySet1);
+ *        XLlDma_BdRingAlloc(MyRingPtr, NumBd2, &MySet2);
+ *        XLlDma_BdRingToHw(MyRingPtr, NumBd2, MySet2);
+ *        XLlDma_BdRingToHw(MyRingPtr, NumBd1, MySet1);
+ * </pre>
+ *
+ * Use the API defined in xlldmabd.h to modify individual BDs. Traversal of the
+ * BD set can be done using XLlDma_mBdRingNext() and XLlDma_mBdRingPrev().
+ *
+ * @param RingPtr is a pointer to the descriptor ring instance to be worked on.
+ * @param NumBd is the number of BDs to allocate
+ * @param BdSetPtr is an output parameter, it points to the first BD available
+ *        for modification.
+ *
+ * @return
+ *   - XST_SUCCESS if the requested number of BDs was returned in the BdSetPtr
+ *     parameter.
+ *   - XST_FAILURE if there were not enough free BDs to satisfy the request.
+ *
+ * @note This function should not be preempted by another XLlDma_BdRing
+ *       function call that modifies the BD space. It is the caller's
+ *       responsibility to provide a mutual exclusion mechanism.
+ *
+ * @note Do not modify more BDs than the number requested with the NumBd
+ *       parameter. Doing so will lead to data corruption and system
+ *       instability.
+ *
+ *****************************************************************************/
+int XLlDma_BdRingAlloc(XLlDma_BdRing * RingPtr, unsigned NumBd,
+		       XLlDma_Bd ** BdSetPtr)
+{
+	/* Enough free BDs available for the request? */
+	if (RingPtr->FreeCnt < NumBd) {
+		return (XST_FAILURE);
+	}
+
+	/* Set the return argument and move FreeHead forward */
+	*BdSetPtr = RingPtr->FreeHead;
+	XLLDMA_RING_SEEKAHEAD(RingPtr, RingPtr->FreeHead, NumBd);
+	RingPtr->FreeCnt -= NumBd;
+	RingPtr->PreCnt += NumBd;
+
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * Fully or partially undo an XLlDma_BdRingAlloc() operation. Use this function
+ * if all the BDs allocated by XLlDma_BdRingAlloc() could not be transferred to
+ * hardware with XLlDma_BdRingToHw().
+ *
+ * This function helps out in situations when an unrelated error occurs after
+ * BDs have been allocated but before they have been given to hardware.
+ *
+ * This function is not the same as XLlDma_BdRingFree(). The Free function
+ * returns BDs to the free list after they have been processed by hardware,
+ * while UnAlloc returns them before being processed by hardware.
+ *
+ * There are two scenarios where this function can be used. Full UnAlloc or
+ * Partial UnAlloc. A Full UnAlloc means all the BDs Alloc'd will be returned:
+ *
+ * <pre>
+ *    Status = XLlDma_BdRingAlloc(MyRingPtr, 10, &BdPtr);
+ *        .
+ *        .
+ *    if (Error)
+ *    {
+ *        Status = XLlDma_BdRingUnAlloc(MyRingPtr, 10, &BdPtr);
+ *    }
+ * </pre>
+ *
+ * A partial UnAlloc means some of the BDs Alloc'd will be returned:
+ *
+ * <pre>
+ *    Status = XLlDma_BdRingAlloc(MyRingPtr, 10, &BdPtr);
+ *    BdsLeft = 10;
+ *    CurBdPtr = BdPtr;
+ *
+ *    while (BdsLeft)
+ *    {
+ *       if (Error)
+ *       {
+ *          Status = XLlDma_BdRingUnAlloc(MyRingPtr, BdsLeft, CurBdPtr);
+ *       }
+ *
+ *       CurBdPtr = XLlDma_mBdRingNext(MyRingPtr, CurBdPtr);
+ *       BdsLeft--;
+ *    }
+ * </pre>
+ *
+ * A partial UnAlloc must include the last BD in the list that was Alloc'd.
+ *
+ * @param RingPtr is a pointer to the descriptor ring instance to be worked on.
+ * @param NumBd is the number of BDs to unallocate
+ * @param BdSetPtr points to the first of the BDs to be returned.
+ *
+ * @return
+ *   - XST_SUCCESS if the BDs were unallocated.
+ *   - XST_FAILURE if NumBd parameter was greater that the number of BDs in the
+ *     preprocessing state.
+ *
+ * @note This function should not be preempted by another XLlDma ring function
+ *       call that modifies the BD space. It is the caller's responsibility to
+ *       provide a mutual exclusion mechanism.
+ *
+ *****************************************************************************/
+int XLlDma_BdRingUnAlloc(XLlDma_BdRing * RingPtr, unsigned NumBd,
+			 XLlDma_Bd * BdSetPtr)
+{
+	/* Enough BDs in the free state for the request? */
+	if (RingPtr->PreCnt < NumBd) {
+		return (XST_FAILURE);
+	}
+
+	/* Set the return argument and move FreeHead backward */
+	XLLDMA_RING_SEEKBACK(RingPtr, RingPtr->FreeHead, NumBd);
+	RingPtr->FreeCnt += NumBd;
+	RingPtr->PreCnt -= NumBd;
+
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * Enqueue a set of BDs to hardware that were previously allocated by
+ * XLlDma_BdRingAlloc(). Once this function returns, the argument BD set goes
+ * under hardware control. Any changes made to these BDs after this point will
+ * corrupt the BD list leading to data corruption and system instability.
+ *
+ * The set will be rejected if the last BD of the set does not mark the end of
+ * a packet.
+ *
+ * @param RingPtr is a pointer to the descriptor ring instance to be worked on.
+ * @param NumBd is the number of BDs in the set.
+ * @param BdSetPtr is the first BD of the set to commit to hardware.
+ *
+ * @return
+ *   - XST_SUCCESS if the set of BDs was accepted and enqueued to hardware
+ *   - XST_FAILURE if the set of BDs was rejected because the first BD
+ *     did not have its start-of-packet bit set, the last BD did not have
+ *     its end-of-packet bit set, or any one of the BD set has 0 as length
+ *     value
+ *   - XST_DMA_SG_LIST_ERROR if this function was called out of sequence with
+ *     XLlDma_BdRingAlloc()
+ *
+ * @note This function should not be preempted by another XLlDma ring function
+ *       call that modifies the BD space. It is the caller's responsibility to
+ *       provide a mutual exclusion mechanism.
+ *
+ *****************************************************************************/
+int XLlDma_BdRingToHw(XLlDma_BdRing * RingPtr, unsigned NumBd,
+		      XLlDma_Bd * BdSetPtr)
+{
+	XLlDma_Bd *CurBdPtr;
+	unsigned i;
+	u32 BdStsCr;
+
+	/* If the commit set is empty, do nothing */
+	if (NumBd == 0) {
+		return (XST_SUCCESS);
+	}
+
+	/* Make sure we are in sync with XLlDma_BdRingAlloc() */
+	if ((RingPtr->PreCnt < NumBd) || (RingPtr->PreHead != BdSetPtr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	CurBdPtr = BdSetPtr;
+	BdStsCr = XLlDma_mBdRead(CurBdPtr, XLLDMA_BD_STSCTRL_USR0_OFFSET);
+
+	/* The first BD should have been marked as start-of-packet */
+	if (!(BdStsCr & XLLDMA_BD_STSCTRL_SOP_MASK)) {
+		return (XST_FAILURE);
+	}
+
+	/* For each BD being submitted except the last one, clear the completed
+	 * bit and stop_on_end bit in the status word
+	 */
+	for (i = 0; i < NumBd - 1; i++) {
+
+		/* Make sure the length value in the BD is non-zero. */
+		if (XLlDma_mBdGetLength(CurBdPtr) == 0) {
+			return (XST_FAILURE);
+		}
+
+		BdStsCr &=
+			~(XLLDMA_BD_STSCTRL_COMPLETED_MASK |
+			  XLLDMA_BD_STSCTRL_SOE_MASK);
+		XLlDma_mBdWrite(CurBdPtr, XLLDMA_BD_STSCTRL_USR0_OFFSET,
+				BdStsCr);
+
+		/* In RX channel case, the current BD should have the
+		 * XLLDMA_USERIP_APPWORD_OFFSET initialized to
+		 * XLLDMA_USERIP_APPWORD_INITVALUE
+		 */
+		if (RingPtr->IsRxChannel) {
+			XLlDma_mBdWrite(CurBdPtr, XLLDMA_USERIP_APPWORD_OFFSET,
+					XLLDMA_USERIP_APPWORD_INITVALUE);
+		}
+
+		/* Flush the current BD so DMA core could see the updates */
+		XLLDMA_CACHE_FLUSH(CurBdPtr);
+
+		CurBdPtr = XLlDma_mBdRingNext(RingPtr, CurBdPtr);
+		BdStsCr =
+			XLlDma_mBdRead(CurBdPtr, XLLDMA_BD_STSCTRL_USR0_OFFSET);
+	}
+
+	/* The last BD should have end-of-packet bit set */
+	if (!(BdStsCr & XLLDMA_BD_STSCTRL_EOP_MASK)) {
+		return (XST_FAILURE);
+	}
+
+	/* Make sure the length value in the last BD is non-zero. */
+	if (XLlDma_mBdGetLength(CurBdPtr) == 0) {
+		return (XST_FAILURE);
+	}
+
+	/* The last BD should also have the completed and stop-on-end bits
+	 * cleared
+	 */
+	BdStsCr &=
+		~(XLLDMA_BD_STSCTRL_COMPLETED_MASK |
+		  XLLDMA_BD_STSCTRL_SOE_MASK);
+	XLlDma_mBdWrite(CurBdPtr, XLLDMA_BD_STSCTRL_USR0_OFFSET, BdStsCr);
+
+	/* In RX channel case, the last BD should have the
+	 * XLLDMA_USERIP_APPWORD_OFFSET initialized to
+	 * XLLDMA_USERIP_APPWORD_INITVALUE
+	 */
+	if (RingPtr->IsRxChannel) {
+		XLlDma_mBdWrite(CurBdPtr, XLLDMA_USERIP_APPWORD_OFFSET,
+				XLLDMA_USERIP_APPWORD_INITVALUE);
+	}
+
+	/* Flush the last BD so DMA core could see the updates */
+	XLLDMA_CACHE_FLUSH(CurBdPtr);
+
+	/* This set has completed pre-processing, adjust ring pointers and
+	 * counters
+	 */
+	XLLDMA_RING_SEEKAHEAD(RingPtr, RingPtr->PreHead, NumBd);
+	RingPtr->PreCnt -= NumBd;
+	RingPtr->HwTail = CurBdPtr;
+	RingPtr->HwCnt += NumBd;
+
+	/* If it was enabled, tell the engine to begin processing */
+	if (RingPtr->RunState == XST_DMA_SG_IS_STARTED) {
+		XLlDma_mWriteReg(RingPtr->ChanBase, XLLDMA_TDESC_OFFSET,
+				 XLLDMA_VIRT_TO_PHYS(RingPtr->HwTail));
+	}
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * Returns a set of BD(s) that have been processed by hardware. The returned
+ * BDs may be examined by the application to determine the outcome of the DMA
+ * transactions). Once the BDs have been examined, the application must call
+ * XLlDma_BdRingFree() in the same order which they were retrieved here.
+ *
+ * Example:
+ *
+ * <pre>
+ *        NumBd = XLlDma_BdRingFromHw(MyRingPtr, XLLDMA_ALL_BDS, &MyBdSet);
+ *
+ *        if (NumBd == 0)
+ *        {
+ *           // hardware has nothing ready for us yet
+ *        }
+ *
+ *        CurBd = MyBdSet;
+ *        for (i=0; i<NumBd; i++)
+ *        {
+ *           // Examine CurBd for post processing.....
+ *
+ *           // Onto next BD
+ *           CurBd = XLlDma_mBdRingNext(MyRingPtr, CurBd);
+ *        }
+ *
+ *        XLlDma_BdRingFree(MyRingPtr, NumBd, MyBdSet); // Return the list
+ * </pre>
+ *
+ * A more advanced use of this function may allocate multiple sets of BDs.
+ * They must be retrieved from hardware and freed in the correct sequence:
+ * <pre>
+ *        // Legal
+ *        XLlDma_BdRingFromHw(MyRingPtr, NumBd1, &MySet1);
+ *        XLlDma_BdRingFree(MyRingPtr, NumBd1, MySet1);
+ *
+ *        // Legal
+ *        XLlDma_BdRingFromHw(MyRingPtr, NumBd1, &MySet1);
+ *        XLlDma_BdRingFromHw(MyRingPtr, NumBd2, &MySet2);
+ *        XLlDma_BdRingFree(MyRingPtr, NumBd1, MySet1);
+ *        XLlDma_BdRingFree(MyRingPtr, NumBd2, MySet2);
+ *
+ *        // Not legal
+ *        XLlDma_BdRingFromHw(MyRingPtr, NumBd1, &MySet1);
+ *        XLlDma_BdRingFromHw(MyRingPtr, NumBd2, &MySet2);
+ *        XLlDma_BdRingFree(MyRingPtr, NumBd2, MySet2);
+ *        XLlDma_BdRingFree(MyRingPtr, NumBd1, MySet1);
+ * </pre>
+ *
+ * If hardware has partially completed a packet spanning multiple BDs, then
+ * none of the BDs for that packet will be included in the results.
+ *
+ * @param RingPtr is a pointer to the descriptor ring instance to be worked on.
+ * @param BdLimit is the maximum number of BDs to return in the set. Use
+ *        XLLDMA_ALL_BDS to return all BDs that have been processed.
+ * @param BdSetPtr is an output parameter, it points to the first BD available
+ *        for examination.
+ *
+ * @return
+ *   The number of BDs processed by hardware. A value of 0 indicates that no
+ *   data is available. No more than BdLimit BDs will be returned.
+ *
+ * @note Treat BDs returned by this function as read-only.
+ *
+ * @note This function should not be preempted by another XLlDma ring function
+ *       call that modifies the BD space. It is the caller's responsibility to
+ *       provide a mutual exclusion mechanism.
+ *
+ *****************************************************************************/
+unsigned XLlDma_BdRingFromHw(XLlDma_BdRing * RingPtr, unsigned BdLimit,
+			     XLlDma_Bd ** BdSetPtr)
+{
+	XLlDma_Bd *CurBdPtr;
+	unsigned BdCount;
+	unsigned BdPartialCount;
+	u32 BdStsCr;
+	u32 UserIpAppWord;
+
+	CurBdPtr = RingPtr->HwHead;
+	BdCount = 0;
+	BdPartialCount = 0;
+
+	/* If no BDs in work group, then there's nothing to search */
+	if (RingPtr->HwCnt == 0) {
+		*BdSetPtr = NULL;
+		return (0);
+	}
+
+	/* Starting at HwHead, keep moving forward in the list until:
+	 *  - A BD is encountered with its completed bit clear in the status
+	 *    word which means hardware has not completed processing of that
+	 *    BD.
+	 *  - A BD is encountered with its XLLDMA_USERIP_APPWORD_OFFSET field
+	 *    with value XLLDMA_USERIP_APPWORD_INITVALUE which means hardware
+	 *    has not completed updating the BD structure.
+	 *  - RingPtr->HwTail is reached
+	 *  - The number of requested BDs has been processed
+	 */
+	while (BdCount < BdLimit) {
+		/* Read the status */
+		XLLDMA_CACHE_INVALIDATE(CurBdPtr);
+		BdStsCr = XLlDma_mBdRead(CurBdPtr,
+					 XLLDMA_BD_STSCTRL_USR0_OFFSET);
+
+		/* If the hardware still hasn't processed this BD then we are
+		 * done
+		 */
+		if (!(BdStsCr & XLLDMA_BD_STSCTRL_COMPLETED_MASK)) {
+			break;
+		}
+
+		/* In RX channel case, check if XLLDMA_USERIP_APPWORD_OFFSET
+		 * field of the BD has been updated. If not, RX channel has
+		 * not completed updating the BD structure and we delay
+		 * the processing of this BD to next time
+		 */
+		if (RingPtr->IsRxChannel) {
+			UserIpAppWord = XLlDma_mBdRead(CurBdPtr,
+						       XLLDMA_USERIP_APPWORD_OFFSET);
+			if (UserIpAppWord == XLLDMA_USERIP_APPWORD_INITVALUE) {
+				break;
+			}
+		}
+
+
+		BdCount++;
+
+		/* Hardware has processed this BD so check the "last" bit. If
+		 * it is clear, then there are more BDs for the current packet.
+		 * Keep a count of these partial packet BDs.
+		 */
+		if (BdStsCr & XLLDMA_BD_STSCTRL_EOP_MASK) {
+			BdPartialCount = 0;
+		}
+		else {
+			BdPartialCount++;
+		}
+
+		/* Reached the end of the work group */
+		if (CurBdPtr == RingPtr->HwTail) {
+			break;
+		}
+
+		/* Move on to next BD in work group */
+		CurBdPtr = XLlDma_mBdRingNext(RingPtr, CurBdPtr);
+	}
+
+	/* Subtract off any partial packet BDs found */
+	BdCount -= BdPartialCount;
+
+	/* If BdCount is non-zero then BDs were found to return. Set return
+	 * parameters, update pointers and counters, return success
+	 */
+	if (BdCount) {
+		*BdSetPtr = RingPtr->HwHead;
+		RingPtr->HwCnt -= BdCount;
+		RingPtr->PostCnt += BdCount;
+		XLLDMA_RING_SEEKAHEAD(RingPtr, RingPtr->HwHead, BdCount);
+		return (BdCount);
+	}
+	else {
+		*BdSetPtr = NULL;
+		return (0);
+	}
+}
+
+
+/*****************************************************************************/
+/**
+ * Frees a set of BDs that had been previously retrieved with
+ * XLlDma_BdRingFromHw().
+ *
+ * @param RingPtr is a pointer to the descriptor ring instance to be worked on.
+ * @param NumBd is the number of BDs to free.
+ * @param BdSetPtr is the head of a list of BDs returned by
+ *        XLlDma_BdRingFromHw().
+ *
+ * @return
+ *   - XST_SUCCESS if the set of BDs was freed.
+ *   - XST_DMA_SG_LIST_ERROR if this function was called out of sequence with
+ *     XLlDma_BdRingFromHw().
+ *
+ * @note This function should not be preempted by another XLlDma function call
+ *       that modifies the BD space. It is the caller's responsibility to
+ *       provide a mutual exclusion mechanism.
+ *
+ * @internal
+ *          This Interrupt handler provided by application MUST clear pending
+ *          interrupts before handling them by calling the call back. Otherwise
+ *          the following corner case could raise some issue:
+ *
+ *           - A packet was transmitted and asserted an TX interrupt, and if
+ *             this interrupt handler calls the call back before clears the
+ *             interrupt, another packet could get transmitted (and assert the
+ *             interrupt) between when the call back function returned and when
+ *             the interrupt clearing operation begins, and the interrupt
+ *             clearing operation will clear the interrupt raised by the second
+ *             packet and won't never process its according buffer descriptors
+ *             until a new interrupt occurs.
+ *
+ *           Changing the sequence to "Clear interrupts, then handle" solve this
+ *           issue. If the interrupt raised by the second packet is before the
+ *           the interrupt clearing operation, the descriptors associated with
+ *           the second packet must have been finished by hardware and ready for
+ *           the handling by the call back; otherwise, the interrupt raised by
+ *           the second packet is after the interrupt clearing operation,
+ *           the packet's buffer descriptors will be handled by the call back in
+ *           current pass, if the descriptors are finished before the call back
+ *           is invoked, or next pass otherwise.
+ *
+ *           Please note that if the second packet is handled by the call back
+ *           in current pass, the next pass could find no buffer descriptor
+ *           finished by the hardware. (i.e., XLlDma_BdRingFromHw() returns 0).
+ *           As XLlDma_BdRingFromHw() and XLlDma_BdRingFree() are used in pair,
+ *           XLlDma_BdRingFree() covers this situation by checking if the BD
+ *           list to free is empty
+ *****************************************************************************/
+int XLlDma_BdRingFree(XLlDma_BdRing * RingPtr, unsigned NumBd,
+		      XLlDma_Bd * BdSetPtr)
+{
+	/* If the BD Set to free is empty, return immediately with value
+	 * XST_SUCCESS. See the @internal comment block above for detailed
+	 * information
+	 */
+	if (NumBd == 0) {
+		return XST_SUCCESS;
+	}
+
+	/* Make sure we are in sync with XLlDma_BdRingFromHw() */
+	if ((RingPtr->PostCnt < NumBd) || (RingPtr->PostHead != BdSetPtr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* Update pointers and counters */
+	RingPtr->FreeCnt += NumBd;
+	RingPtr->PostCnt -= NumBd;
+	XLLDMA_RING_SEEKAHEAD(RingPtr, RingPtr->PostHead, NumBd);
+
+	return (XST_SUCCESS);
+}
+
+
+/*****************************************************************************/
+/**
+ * Check the internal data structures of the BD ring for the provided channel.
+ * The following checks are made:
+ *
+ *   - Is the BD ring linked correctly in physical address space.
+ *   - Do the internal pointers point to BDs in the ring.
+ *   - Do the internal counters add up.
+ *
+ * The channel should be stopped prior to calling this function.
+ *
+ * @param RingPtr is a pointer to the descriptor ring to be worked on.
+ *
+ * @return
+ *   - XST_SUCCESS if no errors were found.
+ *   - XST_DMA_SG_NO_LIST if the ring has not been created.
+ *   - XST_IS_STARTED if the channel is not stopped.
+ *   - XST_DMA_SG_LIST_ERROR if a problem is found with the internal data
+ *     structures. If this value is returned, the channel should be reset to
+ *     avoid data corruption or system instability.
+ *
+ * @note This function should not be preempted by another XLlDma ring function
+ *       call that modifies the BD space. It is the caller's responsibility to
+ *       provide a mutual exclusion mechanism.
+ *
+ *****************************************************************************/
+int XLlDma_BdRingCheck(XLlDma_BdRing * RingPtr)
+{
+	u32 AddrV, AddrP;
+	unsigned i;
+
+	/* Is the list created */
+	if (RingPtr->AllCnt == 0) {
+		return (XST_DMA_SG_NO_LIST);
+	}
+
+	/* Can't check if channel is running */
+	if (RingPtr->RunState == XST_DMA_SG_IS_STARTED) {
+		return (XST_IS_STARTED);
+	}
+
+	/* RunState doesn't make sense */
+	else if (RingPtr->RunState != XST_DMA_SG_IS_STOPPED) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* Verify internal pointers point to correct memory space */
+	AddrV = (u32) RingPtr->FreeHead;
+	if ((AddrV < RingPtr->FirstBdAddr) || (AddrV > RingPtr->LastBdAddr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	AddrV = (u32) RingPtr->PreHead;
+	if ((AddrV < RingPtr->FirstBdAddr) || (AddrV > RingPtr->LastBdAddr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	AddrV = (u32) RingPtr->HwHead;
+	if ((AddrV < RingPtr->FirstBdAddr) || (AddrV > RingPtr->LastBdAddr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	AddrV = (u32) RingPtr->HwTail;
+	if ((AddrV < RingPtr->FirstBdAddr) || (AddrV > RingPtr->LastBdAddr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	AddrV = (u32) RingPtr->PostHead;
+	if ((AddrV < RingPtr->FirstBdAddr) || (AddrV > RingPtr->LastBdAddr)) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* Verify internal counters add up */
+	if ((RingPtr->HwCnt + RingPtr->PreCnt + RingPtr->FreeCnt +
+	     RingPtr->PostCnt) != RingPtr->AllCnt) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* Verify BDs are linked correctly */
+	AddrV = RingPtr->FirstBdAddr;
+	AddrP = RingPtr->FirstBdPhysAddr + RingPtr->Separation;
+	for (i = 1; i < RingPtr->AllCnt; i++) {
+		XLLDMA_CACHE_INVALIDATE(AddrV);
+		/* Check next pointer for this BD. It should equal to the
+		 * physical address of next BD
+		 */
+		if (XLlDma_mBdRead(AddrV, XLLDMA_BD_NDESC_OFFSET) != AddrP) {
+			return (XST_DMA_SG_LIST_ERROR);
+		}
+
+		/* Move on to next BD */
+		AddrV += RingPtr->Separation;
+		AddrP += RingPtr->Separation;
+	}
+
+	XLLDMA_CACHE_INVALIDATE(AddrV);
+	/* Last BD should point back to the beginning of ring */
+	if (XLlDma_mBdRead(AddrV, XLLDMA_BD_NDESC_OFFSET) !=
+	    RingPtr->FirstBdPhysAddr) {
+		return (XST_DMA_SG_LIST_ERROR);
+	}
+
+	/* No problems found */
+	return (XST_SUCCESS);
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xlldma_bdring.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma_bdring.h
--- linux-2.6.31.12/drivers/xilinx_common/xlldma_bdring.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma_bdring.h	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,434 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2007-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xlldma_bdring.h
+*
+* This file contains DMA channel related structure and constant definition
+* as well as function prototypes. Each DMA channel is managed by a Buffer
+* Descriptor ring, and so XLlDma_BdRing is chosen as the symbol prefix used in
+* this file. See xlldma.h for more information.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a xd   12/21/06 First release
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XLLDMA_BDRING_H		/* prevent circular inclusions */
+#define XLLDMA_BDRING_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "xbasic_types.h"
+#include "xstatus.h"
+#include "xlldma_hw.h"
+#include "xlldma_bd.h"
+
+/** Container structure for descriptor storage control. If address translation
+ * is enabled, then all addresses and pointers excluding FirstBdPhysAddr are
+ * expressed in terms of the virtual address.
+ */
+typedef struct {
+	u32 ChanBase;	       /**< Virtual base address of channel registers
+                                       */
+	u32 IsRxChannel;       /**< Is this a receive channel ? */
+	u32 FirstBdPhysAddr;   /**< Physical address of 1st BD in list */
+	u32 FirstBdAddr;       /**< Virtual address of 1st BD in list */
+	u32 LastBdAddr;	       /**< Virtual address of last BD in the list */
+	u32 Length;	       /**< Total size of ring in bytes */
+	u32 RunState;	       /**< Flag to indicate channel is started */
+	u32 Separation;	       /**< Number of bytes between the starting
+	                            address of adjacent BDs */
+	XLlDma_Bd *FreeHead;   /**< First BD in the free group */
+	XLlDma_Bd *PreHead;    /**< First BD in the pre-work group */
+	XLlDma_Bd *HwHead;     /**< First BD in the work group */
+	XLlDma_Bd *HwTail;     /**< Last BD in the work group */
+	XLlDma_Bd *PostHead;   /**< First BD in the post-work group */
+	XLlDma_Bd *BdaRestart; /**< BD to load when channel is started */
+	u32 FreeCnt;	       /**< Number of allocatable BDs in free group */
+	u32 PreCnt;	       /**< Number of BDs in pre-work group */
+	u32 HwCnt;	       /**< Number of BDs in work group */
+	u32 PostCnt;	       /**< Number of BDs in post-work group */
+	u32 AllCnt;	       /**< Total Number of BDs for channel */
+} XLlDma_BdRing;
+
+/*****************************************************************************/
+/**
+* Use this macro at initialization time to determine how many BDs will fit
+* within the given memory constraints.
+*
+* The results of this macro can be provided to XLlDma_BdRingCreate().
+*
+* @param Alignment specifies what byte alignment the BDs must fall on and
+*        must be a power of 2 to get an accurate calculation (32, 64, 126,...)
+* @param Bytes is the number of bytes to be used to store BDs.
+*
+* @return Number of BDs that can fit in the given memory area
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mBdRingCntCalc(u32 Alignment, u32 Bytes)
+*
+******************************************************************************/
+#define XLlDma_mBdRingCntCalc(Alignment, Bytes)                           \
+	(u32)((Bytes)/((sizeof(XLlDma_Bd)+((Alignment)-1))&~((Alignment)-1)))
+
+
+/*****************************************************************************/
+/**
+* Use this macro at initialization time to determine how many bytes of memory
+* are required to contain a given number of BDs at a given alignment.
+*
+* @param Alignment specifies what byte alignment the BDs must fall on. This
+*        parameter must be a power of 2 to get an accurate calculation (32, 64,
+*        128,...)
+* @param NumBd is the number of BDs to calculate memory size requirements for
+*
+* @return The number of bytes of memory required to create a BD list with the
+*         given memory constraints.
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mBdRingMemCalc(u32 Alignment, u32 NumBd)
+*
+******************************************************************************/
+#define XLlDma_mBdRingMemCalc(Alignment, NumBd)			\
+	(u32)((sizeof(XLlDma_Bd)+((Alignment)-1))&~((Alignment)-1))*(NumBd)
+
+
+/****************************************************************************/
+/**
+* Return the total number of BDs allocated by this channel with
+* XLlDma_BdRingCreate().
+*
+* @param  RingPtr is the BD ring to operate on.
+*
+* @return The total number of BDs allocated for this channel.
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mBdRingGetCnt(XLlDma_BdRing* RingPtr)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingGetCnt(RingPtr) ((RingPtr)->AllCnt)
+
+
+/****************************************************************************/
+/**
+* Return the number of BDs allocatable with XLlDma_BdRingAlloc() for pre-
+* processing.
+*
+* @param  RingPtr is the BD ring to operate on.
+*
+* @return The number of BDs currently allocatable.
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mBdRingGetFreeCnt(XLlDma_BdRing* RingPtr)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingGetFreeCnt(RingPtr)  ((RingPtr)->FreeCnt)
+
+
+/****************************************************************************/
+/**
+* Snap shot the latest BD a BD ring is processing.
+*
+* @param  RingPtr is the BD ring to operate on.
+*
+* @return None
+*
+* @note
+* C-style signature:
+*    void XLlDma_mBdRingSnapShotCurrBd(XLlDma_BdRing* RingPtr)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingSnapShotCurrBd(RingPtr)				  \
+	{								  \
+		(RingPtr)->BdaRestart = 				  \
+			(XLlDma_Bd *)XLlDma_mReadReg((RingPtr)->ChanBase, \
+					XLLDMA_CDESC_OFFSET);		  \
+	}
+
+
+/****************************************************************************/
+/**
+* Return the next BD in the ring.
+*
+* @param  RingPtr is the BD ring to operate on.
+* @param  BdPtr is the current BD.
+*
+* @return The next BD in the ring relative to the BdPtr parameter.
+*
+* @note
+* C-style signature:
+*    XLlDma_Bd *XLlDma_mBdRingNext(XLlDma_BdRing* RingPtr, XLlDma_Bd *BdPtr)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingNext(RingPtr, BdPtr)			\
+		(((u32)(BdPtr) >= (RingPtr)->LastBdAddr) ?	\
+			(XLlDma_Bd*)(RingPtr)->FirstBdAddr :	\
+			(XLlDma_Bd*)((u32)(BdPtr) + (RingPtr)->Separation))
+
+
+/****************************************************************************/
+/**
+* Return the previous BD in the ring.
+*
+* @param  InstancePtr is the DMA channel to operate on.
+* @param  BdPtr is the current BD.
+*
+* @return The previous BD in the ring relative to the BdPtr parameter.
+*
+* @note
+* C-style signature:
+*    XLlDma_Bd *XLlDma_mBdRingPrev(XLlDma_BdRing* RingPtr, XLlDma_Bd *BdPtr)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingPrev(RingPtr, BdPtr)				\
+		(((u32)(BdPtr) <= (RingPtr)->FirstBdAddr) ?		\
+			(XLlDma_Bd*)(RingPtr)->LastBdAddr :		\
+			(XLlDma_Bd*)((u32)(BdPtr) - (RingPtr)->Separation))
+
+/****************************************************************************/
+/**
+* Retrieve the contents of the channel status register XLLDMA_SR_OFFSET
+*
+* @param  RingPtr is the channel instance to operate on.
+*
+* @return Current contents of SR_OFFSET
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mBdRingGetSr(XLlDma_BdRing* RingPtr)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingGetSr(RingPtr)				\
+		XLlDma_mReadReg((RingPtr)->ChanBase, XLLDMA_SR_OFFSET)
+
+
+/****************************************************************************/
+/**
+* Retrieve the contents of the channel control register XLLDMA_CR_OFFSET
+*
+* @param  RingPtr is the channel instance to operate on.
+*
+* @return Current contents of CR_OFFSET
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mBdRingGetCr(XLlDma_BdRing* RingPtr)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingGetCr(RingPtr)				\
+		XLlDma_mReadReg((RingPtr)->ChanBase, XLLDMA_CR_OFFSET)
+
+
+/****************************************************************************/
+/**
+* Set the contents of the channel control register XLLDMA_CR_OFFSET. This
+* register does not affect the other DMA channel.
+*
+* @param  RingPtr is the channel instance to operate on.
+* @param  Data is the data to write to CR_OFFSET
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mBdRingSetCr(XLlDma_BdRing* RingPtr, u32 Data)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingSetCr(RingPtr, Data)				\
+		XLlDma_mWriteReg((RingPtr)->ChanBase, XLLDMA_CR_OFFSET, (Data))
+
+
+/****************************************************************************/
+/**
+* Check if the current DMA channel is busy with a DMA operation.
+*
+* @param  RingPtr is the channel instance to operate on.
+*
+* @return TRUE if the DMA is busy. FALSE otherwise
+*
+* @note
+* C-style signature:
+*    XBoolean XLlDma_mBdRingBusy(XLlDma_BdRing* RingPtr)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingBusy(RingPtr)					 \
+		((XLlDma_mReadReg((RingPtr)->ChanBase, XLLDMA_SR_OFFSET) \
+			& XLLDMA_SR_ENGINE_BUSY_MASK) ? TRUE : FALSE)
+
+
+/****************************************************************************/
+/**
+* Set interrupt enable bits for a channel. This operation will modify the
+* XLLDMA_CR_OFFSET register.
+*
+* @param  RingPtr is the channel instance to operate on.
+* @param  Mask consists of the interrupt signals to enable. They are formed by
+*         OR'ing one or more of the following bitmasks together:
+*         XLLDMA_CR_IRQ_EN_MASK, XLLDMA_CR_IRQ_ERROR_EN_MASK,
+*         XLLDMA_CR_IRQ_DELAY_EN_MASK, XLLDMA_CR_IRQ_COALESCE_EN_MASK and
+*         XLLDMA_CR_IRQ_ALL_EN_MASK. Bits not specified in the mask are not
+*         affected.
+*
+* @note
+* C-style signature:
+*    void XLlDma_mBdRingIntEnable(XLlDma_BdRing* RingPtr, u32 Mask)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingIntEnable(RingPtr, Mask)			\
+	{							\
+		u32 Reg = XLlDma_mReadReg((RingPtr)->ChanBase,	\
+				XLLDMA_CR_OFFSET);		\
+		Reg |= ((Mask) & XLLDMA_CR_IRQ_ALL_EN_MASK);	\
+		XLlDma_mWriteReg((RingPtr)->ChanBase, XLLDMA_CR_OFFSET, Reg);\
+	}
+
+
+/****************************************************************************/
+/**
+* Clear interrupt enable bits for a channel. This operation will modify the
+* XLLDMA_CR_OFFSET register.
+*
+* @param  RingPtr is the channel instance to operate on.
+* @param  Mask consists of the interrupt signals to disable. They are formed
+*         by OR'ing one or more of the following bitmasks together:
+*         XLLDMA_CR_IRQ_EN_MASK, XLLDMA_CR_IRQ_ERROR_EN_MASK,
+*         XLLDMA_CR_IRQ_DELAY_EN_MASK, XLLDMA_CR_IRQ_COALESCE_EN_MASK and
+*         XLLDMA_CR_IRQ_ALL_EN_MASK. Bits not specified in the mask are not
+*         affected.
+*
+* @note
+* C-style signature:
+*    void XLlDma_mBdRingIntDisable(XLlDma_BdRing* RingPtr, u32 Mask)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingIntDisable(RingPtr, Mask)				\
+	{								\
+		u32 Reg = XLlDma_mReadReg((RingPtr)->ChanBase,		\
+				XLLDMA_CR_OFFSET);			\
+		Reg &= ~((Mask) & XLLDMA_CR_IRQ_ALL_EN_MASK);		\
+		XLlDma_mWriteReg((RingPtr)->ChanBase, XLLDMA_CR_OFFSET, Reg);\
+	}
+
+
+/****************************************************************************/
+/**
+* Get enabled interrupts of a channel.
+*
+* @param  RingPtr is the channel instance to operate on.
+* @return Enabled interrupts of a channel. Use XLLDMA_CR_IRQ_* defined in
+*         xlldma_hw.h to interpret this returned value.
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mBdRingIntGetEnabled(XLlDma_BdRing* RingPtr)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingIntGetEnabled(RingPtr)				\
+		(XLlDma_mReadReg((RingPtr)->ChanBase, XLLDMA_CR_OFFSET) \
+			& XLLDMA_CR_IRQ_ALL_EN_MASK)
+
+
+/****************************************************************************/
+/**
+* Retrieve the contents of the channel's IRQ register XDMACR_IRQ_OFFSET. This
+* operation can be used to see which interrupts are pending.
+*
+* @param  RingPtr is the channel instance to operate on.
+*
+* @return Current contents of the IRQ_OFFSET register. Use XLLDMA_IRQ_***
+*         values defined in xlldma_hw.h to interpret the returned value.
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mBdRingGetIrq(XLlDma_BdRing* RingPtr)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingGetIrq(RingPtr)				\
+		XLlDma_mReadReg((RingPtr)->ChanBase, XLLDMA_IRQ_OFFSET)
+
+
+/****************************************************************************/
+/**
+* Acknowledge asserted interrupts.
+*
+* @param  RingPtr is the channel instance to operate on.
+* @param  Mask are the interrupt signals to acknowledge and are made by Or'ing
+*         one or more of the following bits: XLLDMA_IRQ_ERROR_MASK,
+*         XLLDMA_IRQ_DELAY_MASK, XLLDMA_IRQ_COALESCE_MASK, XLLDMA_IRQ_ALL_MASK.
+*         Any mask bit set for an unasserted interrupt has no effect.
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mBdRingAckIrq(XLlDma_BdRing* RingPtr)
+*
+*****************************************************************************/
+#define XLlDma_mBdRingAckIrq(RingPtr, Mask)				\
+		XLlDma_mWriteReg((RingPtr)->ChanBase, XLLDMA_IRQ_OFFSET,\
+			(Mask) & XLLDMA_IRQ_ALL_MASK)
+
+/************************* Function Prototypes ******************************/
+
+/*
+ * Descriptor ring functions xlldma_bdring.c
+ */
+int XLlDma_BdRingCreate(XLlDma_BdRing * RingPtr, u32 PhysAddr,
+			u32 VirtAddr, u32 Alignment, unsigned BdCount);
+int XLlDma_BdRingCheck(XLlDma_BdRing * RingPtr);
+int XLlDma_BdRingClone(XLlDma_BdRing * RingPtr, XLlDma_Bd * SrcBdPtr);
+int XLlDma_BdRingAlloc(XLlDma_BdRing * RingPtr, unsigned NumBd,
+		       XLlDma_Bd ** BdSetPtr);
+int XLlDma_BdRingUnAlloc(XLlDma_BdRing * RingPtr, unsigned NumBd,
+			 XLlDma_Bd * BdSetPtr);
+int XLlDma_BdRingToHw(XLlDma_BdRing * RingPtr, unsigned NumBd,
+		      XLlDma_Bd * BdSetPtr);
+unsigned XLlDma_BdRingFromHw(XLlDma_BdRing * RingPtr, unsigned BdLimit,
+			     XLlDma_Bd ** BdSetPtr);
+int XLlDma_BdRingFree(XLlDma_BdRing * RingPtr, unsigned NumBd,
+		      XLlDma_Bd * BdSetPtr);
+int XLlDma_BdRingStart(XLlDma_BdRing * RingPtr);
+int XLlDma_BdRingSetCoalesce(XLlDma_BdRing * RingPtr, u32 Counter, u32 Timer);
+void XLlDma_BdRingGetCoalesce(XLlDma_BdRing * RingPtr,
+			      u32 *CounterPtr, u32 *TimerPtr);
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xlldma.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma.c
--- linux-2.6.31.12/drivers/xilinx_common/xlldma.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma.c	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,252 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2007-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xlldma.c
+*
+* This file implements initialization and control related functions. For more
+* information on this driver, see xlldma.h.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a xd   12/21/06 First release
+* </pre>
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include <linux/string.h>
+
+#include "xlldma.h"
+#include "xenv.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+
+/************************** Variable Definitions *****************************/
+
+
+/*****************************************************************************/
+/**
+ * This function initializes a DMA engine.  This function must be called
+ * prior to using a DMA engine. Initialization of a engine includes setting
+ * up the register base address, setting up the instance data, and ensuring the
+ * hardware is in a quiescent state.
+ *
+ * @param  InstancePtr is a pointer to the DMA engine instance to be worked on.
+ * @param  BaseAddress is where the registers for this engine can be found.
+ *         If address translation is being used, then this parameter must
+ *         reflect the virtual base address.
+ * @return None.
+ *
+ *****************************************************************************/
+void XLlDma_Initialize(XLlDma * InstancePtr, u32 BaseAddress)
+{
+	/* Setup the instance */
+	memset(InstancePtr, 0, sizeof(XLlDma));
+	InstancePtr->RegBase = BaseAddress;
+
+	/* Initialize the ring structures */
+	InstancePtr->TxBdRing.RunState = XST_DMA_SG_IS_STOPPED;
+	InstancePtr->TxBdRing.ChanBase = BaseAddress + XLLDMA_TX_OFFSET;
+	InstancePtr->TxBdRing.IsRxChannel = 0;
+	InstancePtr->RxBdRing.RunState = XST_DMA_SG_IS_STOPPED;
+	InstancePtr->RxBdRing.ChanBase = BaseAddress + XLLDMA_RX_OFFSET;
+	InstancePtr->RxBdRing.IsRxChannel = 1;
+
+	/* Reset the device and return */
+	XLlDma_Reset(InstancePtr);
+}
+
+/*****************************************************************************/
+/**
+* Reset both TX and RX channels of a DMA engine.
+*
+* Any DMA transaction in progress aborts immediately. The DMA engine is in
+* stop state after the reset.
+*
+* @param  InstancePtr is a pointer to the DMA engine instance to be worked on.
+*
+* @return None.
+*
+* @note
+*         - If the hardware is not working properly, this function will enter
+*           infinite loop and never return.
+*         - After the reset, the Normal mode is enabled, and the overflow error
+*           for both TX/RX channels are disabled.
+*         - After the reset, the DMA engine is no longer in pausing state, if
+*           the DMA engine is paused before the reset operation.
+*         - After the reset, the coalescing count value and the delay timeout
+*           value are both set to 1 for TX and RX channels.
+*         - After the reset, all interrupts are disabled.
+*
+******************************************************************************/
+void XLlDma_Reset(XLlDma * InstancePtr)
+{
+	u32 IrqStatus;
+	XLlDma_BdRing *TxRingPtr, *RxRingPtr;
+
+	TxRingPtr = &XLlDma_mGetTxRing(InstancePtr);
+	RxRingPtr = &XLlDma_mGetRxRing(InstancePtr);
+
+	/* Save the locations of current BDs both rings are working on
+	 * before the reset so later we can resume the rings smoothly.
+	 */
+	XLlDma_mBdRingSnapShotCurrBd(TxRingPtr);
+	XLlDma_mBdRingSnapShotCurrBd(RxRingPtr);
+
+	/* Start reset process then wait for completion */
+	XLlDma_mSetCr(InstancePtr, XLLDMA_DMACR_SW_RESET_MASK);
+
+	/* Loop until the reset is done */
+	while ((XLlDma_mGetCr(InstancePtr) & XLLDMA_DMACR_SW_RESET_MASK)) {
+	}
+
+	/* Disable all interrupts after issue software reset */
+	XLlDma_mBdRingIntDisable(TxRingPtr, XLLDMA_CR_IRQ_ALL_EN_MASK);
+	XLlDma_mBdRingIntDisable(RxRingPtr, XLLDMA_CR_IRQ_ALL_EN_MASK);
+
+	/* Clear Interrupt registers of both channels, as the software reset
+	 * does not clear any register values. Not doing so will cause
+	 * interrupts asserted after the software reset if there is any
+	 * interrupt left over before.
+	 */
+	IrqStatus = XLlDma_mBdRingGetIrq(TxRingPtr);
+	XLlDma_mBdRingAckIrq(TxRingPtr, IrqStatus);
+	IrqStatus = XLlDma_mBdRingGetIrq(RxRingPtr);
+	XLlDma_mBdRingAckIrq(RxRingPtr, IrqStatus);
+
+	/* Enable Normal mode, and disable overflow errors for both channels */
+	XLlDma_mSetCr(InstancePtr, XLLDMA_DMACR_TAIL_PTR_EN_MASK |
+		      XLLDMA_DMACR_RX_OVERFLOW_ERR_DIS_MASK |
+		      XLLDMA_DMACR_TX_OVERFLOW_ERR_DIS_MASK);
+
+	/* Set TX/RX Channel coalescing setting */
+	XLlDma_BdRingSetCoalesce(TxRingPtr, 1, 1);
+	XLlDma_BdRingSetCoalesce(RxRingPtr, 1, 1);
+
+	TxRingPtr->RunState = XST_DMA_SG_IS_STOPPED;
+	RxRingPtr->RunState = XST_DMA_SG_IS_STOPPED;
+}
+
+/*****************************************************************************/
+/**
+* Pause DMA transactions on both channels. The DMA enters the pausing state
+* immediately. So if a DMA transaction is in progress, it will be left
+* unfinished and will be continued once the DMA engine is resumed
+* (see XLlDma_Resume()).
+*
+* @param  InstancePtr is a pointer to the DMA engine instance to be worked on.
+*
+* @return None.
+*
+* @note
+*       - If the hardware is not working properly, this function will enter
+*         infinite loop and never return.
+*       - After the DMA is paused, DMA channels still could accept more BDs
+*         from software (see XLlDma_BdRingToHw()), but new BDs will not be
+*         processed until the DMA is resumed (see XLlDma_Resume()).
+*
+*****************************************************************************/
+void XLlDma_Pause(XLlDma * InstancePtr)
+{
+	u32 RegValue;
+	XLlDma_BdRing *TxRingPtr, *RxRingPtr;
+
+	TxRingPtr = &XLlDma_mGetTxRing(InstancePtr);
+	RxRingPtr = &XLlDma_mGetRxRing(InstancePtr);
+
+	/* Do nothing if both channels already stopped */
+	if ((TxRingPtr->RunState == XST_DMA_SG_IS_STOPPED) &&
+	    (RxRingPtr->RunState == XST_DMA_SG_IS_STOPPED)) {
+		return;
+	}
+
+	/* Enable pause bits for both TX/ RX channels */
+	RegValue = XLlDma_mGetCr(InstancePtr);
+	XLlDma_mSetCr(InstancePtr, RegValue | XLLDMA_DMACR_TX_PAUSE_MASK |
+		      XLLDMA_DMACR_RX_PAUSE_MASK);
+
+	/* Loop until Write Command Queue of RX channel is empty, which
+	 * indicates that all the write data associated with the pending
+	 * commands has been flushed.*/
+	while (!(XLlDma_mBdRingGetIrq(RxRingPtr) | XLLDMA_IRQ_WRQ_EMPTY_MASK));
+
+	TxRingPtr->RunState = XST_DMA_SG_IS_STOPPED;
+	RxRingPtr->RunState = XST_DMA_SG_IS_STOPPED;
+}
+
+/*****************************************************************************/
+/**
+* Resume DMA transactions on both channels. Any interrupted DMA transaction
+* caused by DMA pause operation (see XLlDma_Pause()) and all committed
+* transactions after DMA is paused will be continued upon the return of this
+* function.
+*
+* @param  InstancePtr is a pointer to the DMA engine instance to be worked on.
+*
+* @return None.
+*
+*****************************************************************************/
+void XLlDma_Resume(XLlDma * InstancePtr)
+{
+	u32 RegValue;
+	XLlDma_BdRing *TxRingPtr, *RxRingPtr;
+
+	TxRingPtr = &XLlDma_mGetTxRing(InstancePtr);
+	RxRingPtr = &XLlDma_mGetRxRing(InstancePtr);
+
+	/* Do nothing if both channels already started */
+	if ((TxRingPtr->RunState == XST_DMA_SG_IS_STARTED) &&
+	    (RxRingPtr->RunState == XST_DMA_SG_IS_STARTED)) {
+		return;
+	}
+
+	/* Clear pause bits for both TX/ RX channels */
+	RegValue = XLlDma_mGetCr(InstancePtr);
+	XLlDma_mSetCr(InstancePtr, RegValue & ~(XLLDMA_DMACR_TX_PAUSE_MASK |
+						XLLDMA_DMACR_RX_PAUSE_MASK));
+
+	TxRingPtr->RunState = XST_DMA_SG_IS_STARTED;
+	RxRingPtr->RunState = XST_DMA_SG_IS_STARTED;
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xlldma.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma.h
--- linux-2.6.31.12/drivers/xilinx_common/xlldma.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma.h	2010-08-08 17:22:50.619989557 +0200
@@ -0,0 +1,579 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2007-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xlldma.h
+*
+* The Xilinx Local-Link Scatter Gather DMA driver. This driver supports Soft
+* DMA (SDMA) engines. Each SDMA engine contains two separate DMA channels (TX
+* and RX).
+*
+* This component is designed to be used as a basic building block for
+* designing a device driver. It provides registers accesses such that all
+* DMA processing can be maintained easier, but the device driver designer
+* must still understand all the details of the DMA channel.
+*
+* For a full description of DMA features, please see the hardware spec. This
+* driver supports the following features:
+*
+*   - Scatter-Gather DMA (SGDMA)
+*   - Interrupts
+*   - Programmable interrupt coalescing for SGDMA
+*   - Capable of using 32 bit addressing for buffer. (Hardware spec states
+*     36 Bit bus addressing, which includes Msb 4-bits of DMA address
+*     configurable on each channel through the Channel Control Registers)
+*   - APIs to manage Buffer Descriptors (BD) movement to and from the SGDMA
+*     engine
+*   - Virtual memory support
+*
+* <b>Transactions</b>
+*
+* To describe a DMA transaction in its simplest form, you need source address,
+* destination address, and the number of bytes to transfer. When using a DMA
+* receive channel, the source address is within some piece of IP Hardware and
+* doesn't require the application explicitly set it. Likewise with a transmit
+* channel and the destination address. So this leaves a application buffer
+* address and the number bytes to transfer as the primary transaction
+* attributes. Other attributes include:
+*
+*   - If the transaction occurs on a bus wider than 32 bits, what are the
+*     highest order address bits.
+*   - Does this transaction represent the start of a packet, or end of a
+*     packet.
+*
+* The object used to describe a transaction is referred to as a Buffer
+* Descriptor (BD). The format of a BD closely matches that of the DMA hardware.
+* Many fields within the BD correspond directly with the same fields within the
+* hardware registers. See xlldmabd.h for a detailed description of and the API
+* for manipulation of these objects.
+*
+* <b>Scatter-Gather DMA</b>
+*
+* SGDMA allows the application to define a list of transactions in memory which
+* the hardware will process without further application intervention. During
+* this time, the application is free to continue adding more work to keep the
+* Hardware busy.
+*
+* Notification of completed transactions can be done either by polling the
+* hardware, or using interrupts that signal a transaction has completed or a
+* series of transactions have been completed.
+*
+* SGDMA processes whole packets. A packet is defined as a series of
+* data bytes that represent a message. SGDMA allows a packet of data to be
+* broken up into one or more transactions. For example, take an Ethernet IP
+* packet which consists of a 14 byte header followed by a 1 or more byte
+* payload. With SGDMA, the application may point a BD to the header and another
+* BD to the payload, then transfer them as a single message. This strategy can
+* make a TCP/IP stack more efficient by allowing it to keep packet headers and
+* data in different memory regions instead of assembling packets into
+* contiguous blocks of memory.
+*
+* <b>SGDMA Ring Management</b>
+*
+* The hardware expects BDs to be setup as a singly linked list. As a BD is
+* completed, the DMA engine will dereference BD.Next and load the next BD to
+* process. This driver uses a fixed buffer ring where all BDs are linked to the
+* next BD in adjacent memory. The last BD in the ring is linked to the first.
+*
+* Within the ring, the driver maintains four groups of BDs. Each group consists
+* of 0 or more adjacent BDs:
+*
+*   - Free: Those BDs that can be allocated by the application with
+*     XLlDma_BdRingAlloc(). These BDs are under driver control and may not be
+*     modified by the application
+*
+*   - Pre-process: Those BDs that have been allocated with
+*     XLlDma_BdRingAlloc(). These BDs are under application control. The
+*     application modifies these BDs in preparation for future DMA
+*     transactions.
+*
+*   - Hardware: Those BDs that have been enqueued to hardware with
+*     XLlDma_BdRingToHw(). These BDs are under hardware control and may be in a
+*     state of awaiting hardware processing, in process, or processed by
+*     hardware. It is considered an error for the application to change BDs
+*     while they are in this group. Doing so can cause data corruption and lead
+*     to system instability.
+*
+*   - Post-process: Those BDs that have been processed by hardware and have
+*     been extracted from the work group with XLlDma_BdRingFromHw(). These BDs
+*     are under application control. The application may access these BDs to
+*     determine the result of DMA transactions. When the application is
+*     finished, XLlDma_BdRingFree() should be called to place them back into
+*     the Free group.
+*
+*
+* Normally BDs are moved in the following way:
+* <pre>
+*
+*         XLlDma_BdRingAlloc()                   XLlDma_BdRingToHw()
+*   Free ------------------------> Pre-process ----------------------> Hardware
+*                                                                      |
+*    /|\                                                               |
+*     |   XLlDma_BdRingFree()                    XLlDma_BdRingFromHw() |
+*     +--------------------------- Post-process <----------------------+
+*
+* </pre>
+*
+* The only exception to the flow above is that after BDs are moved from Free
+* group to Pre-process group, the application decide for whatever reason these
+* BDs are not ready and could not be given to hardware. In this case these BDs
+* could be moved back to Free group using XLlDma_BdRingUnAlloc() function to
+* help keep the BD ring in great shape and recover the error. See comments of
+* the function for details
+*
+* <pre>
+*
+*         XLlDma_BdRingUnAlloc()
+*   Free <----------------------- Pre-process
+*
+* </pre>
+*
+* The API provides macros that allow BD list traversal. These macros should be
+* used with care as they do not understand where one group ends and another
+* begins.
+*
+* The driver does not cache or keep copies of any BD. When the application
+* modifies BDs returned by XLlDma_BdRingAlloc() or XLlDma_BdRingFromHw(), they
+* are modifying the same BD that hardware accesses.
+*
+* Certain pairs of list modification functions have usage restrictions. See
+* the function headers for XLlDma_BdRingAlloc() and XLlDma_BdRingFromHw() for
+* more information.
+*
+* <b>SGDMA Descriptor Ring Creation</b>
+*
+* During initialization, the function XLlDma_BdRingCreate() is used to setup
+* a application supplied memory block to contain all BDs for the DMA channel.
+* This function takes as an argument the number of BDs to place in the list. To
+* arrive at this number, the application is given two methods of calculating
+* it.
+*
+* The first method assumes the application has a block of memory and they just
+* want to fit as many BDs as possible into it. The application must calculate
+* the number of BDs that will fit with XLlDma_mBdRingCntCalc(), then supply
+* that number into the list creation function.
+*
+* The second method allows the application to just supply the number directly.
+* The driver assumes the memory block is large enough to contain them all. To
+* double-check, the application should invoke XLlDma_mBdRingMemCalc() to verify
+* the memory block size is adequate.
+*
+* Once the list has been created, it can be used right away to perform DMA
+* transactions. However, there are optional steps that can be done to increase
+* throughput and decrease application code complexity by the use of
+* XLlDma_BdRingClone().
+*
+* BDs have several application accessible attributes that affect how DMA
+* transactions are carried out. Some of these attributes will probably be
+* constant at run-time. The cloning function can be used to copy a template BD
+* to every BD in the ring relieving the application of having to setup
+* transactions from scratch every time a BD is submitted to hardware.
+*
+* Ideally, the only transaction parameters that need to be set by application
+* should be: buffer address, bytes to transfer, and whether the BD is the
+* Start and/or End of a packet.
+*
+* <b>Interrupt Coalescing</b>
+*
+* SGDMA provides control over the frequency of interrupts. On a high speed link
+* significant processor overhead may be used servicing interrupts. Interrupt
+* coalescing provides two mechanisms that help control interrupt frequency:
+*
+* - The packet threshold counter will hold off interrupting the CPU until a
+*   programmable number of packets have been processed by the engine.
+* - The packet waitbound timer is used to interrupt the CPU if after a
+*   programmable amount of time after processing the last packet, no new
+*   packets were processed.
+*
+* <b>Interrupt Service </b>
+*
+* This driver does not service interrupts. This is done typically by a
+* interrupt handler within a higher level driver/application that uses DMA.
+* This driver does provide an API to enable or disable specific interrupts.
+*
+* This interrupt handler provided by the higher level driver/application
+* !!!MUST!!! clear pending interrupts before handling the BDs processed by the
+* DMA. Otherwise the following corner case could raise some issue:
+*
+* - A packet is transmitted(/received) and asserts a TX(/RX) interrupt, and if
+*   this interrupt handler deals with the BDs finished by the DMA before clears
+*   the interrupt, another packet could get transmitted(/received) and assert
+*   the interrupt between when the BDs are taken care  and when the interrupt
+*   clearing operation begins, and the interrupt clearing operation will clear
+*   the interrupt raised by the second packet and will never process its
+*   according BDs until a new interrupt occurs.
+*
+* Changing the sequence to "Clear interrupts before handle BDs" solves this
+* issue:
+*
+* - If the interrupt raised by the second packet is before the interrupt
+*   clearing operation, the descriptors associated with the second packet must
+*   have been finished by hardware and ready for the handler to deal with,
+*   and those descriptors will processed with those BDs of the first packet
+*   during the handling of the interrupt asserted by the first packet.
+*
+* - if the interrupt of the second packet is asserted after the interrupt
+*   clearing operation but its BDs are finished before the handler starts to
+*   deal with BDs, the packet's buffer descriptors will be handled with
+*   those of the first packet during the handling of the interrupt asserted
+*   by the first packet.
+*
+* - Otherwise, the BDs of the second packet is not ready when the interrupt
+*   handler starts to deal with the BDs of the first packet. Those BDs will
+*   be handled next time the interrupt handled gets invoked as the interrupt
+*   of the second packet is not cleared in current pass and thereby will
+*   cause the handler to get invoked again
+*
+* Please note if the second case above occurs, the handler will find
+* NO buffer descriptor is finished by the hardware (i.e.,
+* XLlDma_BdRingFromHw() returns 0) during the handling of the interrupt
+* asserted by the second packet. This is valid and the application should NOT
+* consider this is a hardware error and have no need to reset the hardware.
+*
+* <b> Software Initialization </b>
+*
+* The application needs to do following steps in order for preparing DMA engine
+* to be ready to process DMA transactions:
+*
+* - DMA Initialization using XLlDma_Initialize() function. This step
+*   initializes a driver instance for the given DMA engine and resets the
+*   engine.
+* - BD Ring creation. A BD ring is needed per channel and can be built by
+*   calling XLlDma_BdRingCreate(). A parameter passed to this function is the
+*   number of BD fit in a given memory range, and XLlDma_mBdRingCntCalc() helps
+*   calculate the value.
+* - (Optional) BD setup using a template. Once a BD ring is created, the
+*   application could populate a template BD and then invoke
+*   XLlDma_BdRingClone() to set the same attributes on all BDs on the BD ring.
+*   This saves the application some effort to populate all fixed attributes of
+*   each BD before passing it to the hardware.
+* - (RX channel only) Prepare BDs with attached data buffers and give them to
+*   RX channel. First allocate BDs using XLlDma_BdRingAlloc(), then populate
+*   data buffer address, data buffer size and the control word fields of each
+*   allocated BD with valid values. Last call XLlDma_BdRingToHw() to give the
+*   BDs to the channel.
+* - Enable interrupts if interrupt mode is chosen. The application is
+*   responsible for setting up the interrupt system, which includes providing
+*   and connecting interrupt handlers and call back functions, before
+*   the interrupts are enabled.
+* - Start DMA channels: Call XLlDma_BdRingStart() to start a channel
+*
+* <b> How to start DMA transactions </b>
+*
+* RX channel is ready to start RX transactions once the initialization (see
+* Initialization section above) is finished. The DMA transactions are triggered
+* by the user IP (like Local Link TEMAC).
+*
+* Starting TX transactions needs some work. The application calls
+* XLlDma_BdRingAlloc() to allocate a BD list, then populates necessary
+* attributes of each allocated BD including data buffer address, data size,
+* and control word, and last passes those BDs to the TX channel
+* (see XLlDma_BdRingToHw()). The added BDs will be processed as soon as the
+* TX channel reaches them.
+*
+* For both channels, If the DMA engine is currently paused (see
+* XLlDma_Pause()), the newly added BDs will be accepted but not processed
+* until the DMA engine is resumed (see XLlDma_Resume()).
+*
+* <b> Software Post-Processing on completed DMA transactions </b>
+*
+* Some software post-processing is needed after DMA transactions are finished.
+*
+* if interrupt system are set up and enabled, DMA channels notify the software
+* the finishing of DMA transactions using interrupts,  Otherwise the
+* application could poll the channels (see XLlDma_BdRingFromHw()).
+*
+* - Once BDs are finished by a channel, the application first needs to fetch
+*   them from the channel (see XLlDma_BdRingFromHw()).
+* - On TX side, the application now could free the data buffers attached to
+*   those BDs as the data in the buffers has been transmitted.
+* - On RX side, the application now could use the received data in the buffers
+*   attached to those BDs
+* - For both channels, those BDs need to be freed back to the Free group (see
+*   XLlDma_BdRingFree()) so they are allocatable for future transactions.
+* - On RX side, it is the application's responsibility for having BDs ready
+*   to receive data at any time. Otherwise the RX channel will refuse to
+*   accept any data once it runs out of RX BDs. As we just freed those hardware
+*   completed BDs in the previous step, it is good timing to allocate them
+*   back (see XLlDma_BdRingAlloc()), prepare them, and feed them to the RX
+*   channel again (see XLlDma_BdRingToHw())
+*
+* <b> Examples </b>
+*
+* Two examples are provided with this driver to demonstrate the driver usage:
+* One for interrupt mode and one for polling mode.
+*
+* <b>Address Translation</b>
+*
+* When the BD list is setup with XLlDma_BdRingCreate(), a physical and
+* virtual address is supplied for the segment of memory containing the
+* descriptors. The driver will handle any translations internally. Subsequent
+* access of descriptors by the application is done in terms of their virtual
+* address.
+*
+* Any application data buffer address attached to a BD must be physical
+* address. The application is responsible for calculating the physical address
+* before assigns it to the buffer address field in the BD.
+*
+* <b>Cache Coherency</b>
+*
+* This driver expects all application buffers attached to BDs to be in cache
+* coherent memory. Buffers for transmit MUST be flushed from the cache before
+* passing the associated BD to this driver. Buffers for receive MUST be
+* invalidated before passing the associated BD to this driver.
+*
+* <b>Alignment</b>
+*
+* For BDs:
+*
+* Minimum alignment is defined by the constant XLLDMA_BD_MINIMUM_ALIGNMENT.
+* This is the smallest alignment allowed by both hardware and software for them
+* to properly work. Other than XLLDMA_BD_MINIMUM_ALIGNMENT, multiples of the
+* constant are the only valid alignments for BDs.
+*
+* If the descriptor ring is to be placed in cached memory, alignment also MUST
+* be at least the processor's cache-line size. If this requirement is not met
+* then system instability will result. This is also true if the length of a BD
+* is longer than one cache-line, in which case multiple cache-lines are needed
+* to accommodate each BD.
+*
+* Aside from the initial creation of the descriptor ring (see
+* XLlDma_BdRingCreate()), there are no other run-time checks for proper
+* alignment.
+*
+* For application data buffers:
+*
+* Application data buffers may reside on any alignment.
+*
+* <b>Reset After Stopping</b>
+*
+* This driver is designed to allow for stop-reset-start cycles of the DMA
+* hardware while keeping the BD list intact. When restarted after a reset, this
+* driver will point the DMA engine to where it left off after stopping it.
+*
+* <b>Limitations</b>
+*
+* This driver only supports Normal mode (i.e., Tail Descriptor Pointer mode).
+* In this mode write of a Tail Descriptor Pointer register (which is done in
+* XLlDma_BdRingStart() and XLlDma_BdRingToHw()) starts DMA transactions.
+*
+* Legacy mode is NOT supported by this driver.
+*
+* This driver does not have any mechanism for mutual exclusion. It is up to the
+* application to provide this protection.
+*
+* <b>Hardware Defaults & Exclusive Use</b>
+*
+* During initialization, this driver will override the following hardware
+* default settings. If desired, the application may change these settings back
+* to their hardware defaults:
+*
+*   - Normal mode (Tail Descriptor Pointer mode) will be enabled.
+*   - Interrupt coalescing timer and counter overflow errors will be disabled
+*     (XLLDMA_DMACR_RX_OVERFLOW_ERR_DIS_MASK and TX_OVERFLOW_ERR_DIS_MASK will
+*     be set to 1). These two items control interrupt "overflow" behavior.
+*     When enabled, the hardware may signal an error if interrupts are not
+*     processed fast enough even though packets were correctly processed. This
+*     error is triggered when certain internal counters overflow. The driver
+*     disables this feature so no such error will be reported.
+*
+* The driver requires exclusive use of the following hardware features. If any
+* are changed by the application then the driver will not operate properly:
+*
+*   - XLLDMA_DMACR_TAIL_PTR_ENABLE_MASK. The driver controls this bit
+*     in the DMACR register.
+*   - XLLDMA_BD_STSCTRL_COMPLETED_MASK. The driver controls this bit in each BD
+*   - XLLDMA_NDESC_OFFSET. The driver controls this register
+*   - XLLDMA_DMACR_SW_RESET_MASK. The driver controls this bit in the DMACR
+*     register
+*
+* <b>BUS Interface</b>
+*
+* The constant CONFIG_XILINX_LLDMA_USE_DCR (see xlldma_hw.h) is used
+* to inform the driver the type of the BUS the DMA device is on. If
+* the DMA device is on DCR BUS, CONFIG_XILINX_LLDMA_USE_DCR must be
+* defined as a compiler option used in the Makefile BEFORE this driver
+* is compiled; Otherwise, the constant must NOT be defined.
+*
+* <b>User-IP Specific Definition</b>
+*
+* This driver relies on two User-IP (like Local-Link TEMAC) specific constants
+* (see xlldma_userip.h) to work properly:
+*
+*   - XLLDMA_USR_APPWORD_OFFSET defines a user word the User-IP always updates
+*     in the RX Buffer Descriptors (BD) during <b>ALL</b> Receive transactions.
+*     This driver uses XLLDMA_BD_USR4_OFFSET as the default value of this
+*     constant.
+*
+*   - XLLDMA_USR_APPWORD_INITVALUE defines the value the DMA driver uses to
+*     populate the XLLDMA_USR_APPWORD_OFFSET field in any RX BD before giving
+*     the BD to the RX channel for receive transaction. It must be ensured
+*     that the User-IP will always populates a different value into the
+*     XLLDMA_USR_APPWORD_OFFSET field during any receive transaction. Failing
+*     to do so will cause the DMA driver to work improperly. This driver uses
+*     0xFFFFFFFF as the default value of this constant.
+*
+* If the User-IP uses different setting, the correct setting must be defined as
+* compiler options used in the Makefile BEFORE this driver is compiled. In
+* either case the default definition of the constants in this driver will be
+* discarded.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a xd   12/21/06 First release
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XLLDMA_H		/* prevent circular inclusions */
+#define XLLDMA_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xlldma_bd.h"
+#include "xlldma_bdring.h"
+#include "xlldma_userip.h"
+#include "xstatus.h"
+
+/************************** Constant Definitions *****************************/
+
+#define XLLDMA_NO_CHANGE            0xFFFF	/* Used as API argument */
+#define XLLDMA_ALL_BDS              0xFFFFFFFF	/* Used as API argument */
+
+/**************************** Type Definitions *******************************/
+
+
+/**
+ * The XLlDma driver instance data. An instance must be allocated for each DMA
+ * engine in use. Each DMA engine includes a TX channel and a RX channel.
+ */
+typedef struct XLlDma {
+	u32 RegBase;		/**< Virtual base address of DMA engine */
+	XLlDma_BdRing TxBdRing;	/**< BD container management for TX channel */
+	XLlDma_BdRing RxBdRing;	/**< BD container management for RX channel */
+
+} XLlDma;
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/****************************************************************************/
+/**
+* Retrieve the TX ring object. This object can be used in the various Ring
+* API functions.
+*
+* @param  InstancePtr is the DMA engine to operate on.
+*
+* @return TxBdRing object
+*
+* @note
+* C-style signature:
+*    XLlDma_BdRing XLlDma_mGetTxRing(XLlDma* InstancePtr)
+*
+*****************************************************************************/
+#define XLlDma_mGetTxRing(InstancePtr) ((InstancePtr)->TxBdRing)
+
+
+/****************************************************************************/
+/**
+* Retrieve the RX ring object. This object can be used in the various Ring
+* API functions.
+*
+* @param  InstancePtr is the DMA engine to operate on.
+*
+* @return RxBdRing object
+*
+* @note
+* C-style signature:
+*    XLlDma_BdRing XLlDma_mGetRxRing(XLlDma* InstancePtr)
+*
+*****************************************************************************/
+#define XLlDma_mGetRxRing(InstancePtr) ((InstancePtr)->RxBdRing)
+
+
+/****************************************************************************/
+/**
+* Retrieve the contents of the DMA engine control register
+* (XLLDMA_DMACR_OFFSET).
+*
+* @param  InstancePtr is the DMA engine instance to operate on.
+*
+* @return Current contents of the DMA engine control register.
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mGetCr(XLlDma* InstancePtr)
+*
+*****************************************************************************/
+#define XLlDma_mGetCr(InstancePtr)                                      \
+	XLlDma_mReadReg((InstancePtr)->RegBase, XLLDMA_DMACR_OFFSET)
+
+
+/****************************************************************************/
+/**
+* Set the contents of the DMA engine control register (XLLDMA_DMACR_OFFSET).
+* This control register affects both DMA channels.
+*
+* @param  InstancePtr is the DMA engine instance to operate on.
+* @param  Data is the data to write to the DMA engine control register.
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mSetCr(XLlDma* InstancePtr, u32 Data)
+*
+*****************************************************************************/
+#define XLlDma_mSetCr(InstancePtr, Data)                                \
+	XLlDma_mWriteReg((InstancePtr)->RegBase, XLLDMA_DMACR_OFFSET, (Data))
+
+
+/************************** Function Prototypes ******************************/
+
+/*
+ * Initialization and control functions in xlldma.c
+ */
+void XLlDma_Initialize(XLlDma * InstancePtr, u32 BaseAddress);
+void XLlDma_Reset(XLlDma * InstancePtr);
+void XLlDma_Pause(XLlDma * InstancePtr);
+void XLlDma_Resume(XLlDma * InstancePtr);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xlldma_hw.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma_hw.h
--- linux-2.6.31.12/drivers/xilinx_common/xlldma_hw.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma_hw.h	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,373 @@
+/* $Id: */
+
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2007 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+
+/*****************************************************************************/
+/**
+*
+* @file xlldma_hw.h
+*
+* This header file contains identifiers and register-level driver functions (or
+* macros) that can be used to access the Local-Link Scatter-gather Direct
+* Memory Access Gather (LLDMA) device.
+*
+* For more information about the operation of this device, see the hardware
+* specification and documentation in the higher level driver xlldma.h source
+* code file.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a xd   12/21/06 First release
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XLLDMA_HW_H		/* prevent circular inclusions */
+#define XLLDMA_HW_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+
+/** @name Device Bus Type definition The constant
+ * CONFIG_XILINX_LLDMA_USE_DCR is used to inform this driver the type
+ * of the BUS the DMA device is on. If the DMA core is on DCR BUS
+ * using indirect addressing, which currently only happens on V5FX,
+ * then this option must be set.  On other architectures where dma
+ * ports are accessed through memory mapped io, this must not be set.
+ *@{
+ */
+#ifdef CONFIG_XILINX_LLDMA_USE_DCR
+#include "xio_dcr.h"
+#else
+#include "xio.h"
+#endif
+/*@}*/
+
+/************************** Constant Definitions *****************************/
+
+/** @name Buffer Descriptor Alignment
+ *  @{
+ */
+#define XLLDMA_BD_MINIMUM_ALIGNMENT 0x40  /**< Minimum byte alignment
+                                               requirement for descriptors to
+                                               satisfy both hardware/software
+                                               needs */
+/*@}*/
+
+
+/* Register offset definitions. Unless otherwise noted, register access is
+ * 32 bit.
+ */
+
+#ifdef CONFIG_XILINX_LLDMA_USE_DCR
+
+/* DMA core is on DCR BUS */
+
+/** @name Device registers for DCR based systems.
+ *  Offsets defined in DCR address space. TX and RX channels consist of
+ *  identical registers
+ *  @{
+ */
+#define XLLDMA_TX_OFFSET    0x00000000	/**< TX channel registers base
+                                             offset [0..7] */
+#define XLLDMA_RX_OFFSET    0x00000008	/**< RX channel registers base
+                                             offset [8..F] */
+#define XLLDMA_DMACR_OFFSET 0x00000010	/**< DMA control register */
+
+/* This set of registers are applicable for both channels. Add
+ * XLLDMA_TX_OFFSET to get to TX channel, and XLLDMA_RX_OFFSET to get to RX
+ * channel
+ */
+#define XLLDMA_NDESC_OFFSET 0x00000000	/**< Next descriptor pointer */
+#define XLLDMA_BUFA_OFFSET  0x00000001	/**< Current buffer address */
+#define XLLDMA_BUFL_OFFSET  0x00000002	/**< Current buffer length */
+#define XLLDMA_CDESC_OFFSET 0x00000003	/**< Current descriptor pointer */
+#define XLLDMA_TDESC_OFFSET 0x00000004	/**< Tail descriptor pointer */
+#define XLLDMA_CR_OFFSET    0x00000005	/**< Channel control */
+#define XLLDMA_IRQ_OFFSET   0x00000006	/**< Interrupt register */
+#define XLLDMA_SR_OFFSET    0x00000007	/**< Status */
+/*@}*/
+
+#else /* Non-DCR interface is used */
+
+/** @name Device registers for Non-DCR based systems.
+ *  Offsets defined in Non-DCR address space. TX and RX channels consist of
+ *  identical registers
+ *  @{
+ */
+#define XLLDMA_TX_OFFSET    0x00000000	/**< TX channel registers base
+                                             offset */
+#define XLLDMA_RX_OFFSET    0x00000020	/**< RX channel registers base
+                                             offset */
+#define XLLDMA_DMACR_OFFSET 0x00000040	/**< DMA control register */
+
+/* This set of registers are applicable for both channels. Add
+ * XLLDMA_TX_OFFSET to get to TX channel, and XLLDMA_RX_OFFSET to get to RX
+ * channel
+ */
+#define XLLDMA_NDESC_OFFSET 0x00000000	/**< Next descriptor pointer */
+#define XLLDMA_BUFA_OFFSET  0x00000004	/**< Current buffer address */
+#define XLLDMA_BUFL_OFFSET  0x00000008	/**< Current buffer length */
+#define XLLDMA_CDESC_OFFSET 0x0000000C	/**< Current descriptor pointer */
+#define XLLDMA_TDESC_OFFSET 0x00000010	/**< Tail descriptor pointer */
+#define XLLDMA_CR_OFFSET    0x00000014	/**< Channel control */
+#define XLLDMA_IRQ_OFFSET   0x00000018	/**< Interrupt register */
+#define XLLDMA_SR_OFFSET    0x0000001C	/**< Status */
+
+/*@}*/
+
+#endif /* #ifdef CONFIG_XILINX_LLDMA_USE_DCR */
+
+/** @name Buffer Descriptor register offsets
+ *  USR fields are defined by higher level IP. For example, checksum offload
+ *  setup for EMAC type devices. The 1st 8 words are utilized by hardware. Any
+ *  words after the 8th are for software use only.
+ *  @{
+ */
+#define XLLDMA_BD_NDESC_OFFSET        0x00  /**< Next descriptor pointer */
+#define XLLDMA_BD_BUFA_OFFSET         0x04  /**< Buffer address */
+#define XLLDMA_BD_BUFL_OFFSET         0x08  /**< Buffer length */
+#define XLLDMA_BD_STSCTRL_USR0_OFFSET 0x0C  /**< Status and Control and
+                                                 hardware implementation
+                                                 specific */
+#define XLLDMA_BD_USR1_OFFSET         0x10  /**< Hardware implementation
+                                                 specific */
+#define XLLDMA_BD_USR2_OFFSET         0x14  /**< Hardware implementation
+                                                 specific */
+#define XLLDMA_BD_USR3_OFFSET         0x18  /**< Hardware implementation
+                                                 specific */
+#define XLLDMA_BD_USR4_OFFSET         0x1C  /**< Hardware implementation
+                                                 specific */
+#define XLLDMA_BD_ID_OFFSET           0x20  /**< Software application use */
+
+#define XLLDMA_BD_NUM_WORDS              9  /**< Number of 32-bit words that
+                                                 make up a full BD */
+#define XLLDMA_BD_HW_NUM_WORDS           8  /**< Number of 32-bit words that
+                                                 make up the hardware
+                                                 accessible portion of a BD */
+#define XLLDMA_BD_HW_NUM_BYTES          32  /**< Number of bytes that make up
+                                                 the hardware accessible
+                                                 portion of a BD */
+/*@}*/
+
+
+/* Register masks. The following constants define bit locations of various
+ * control bits in the registers. Constants are not defined for those registers
+ * that have a single bit field representing all 32 bits. For further
+ * information on the meaning of the various bit masks, refer to the hardware
+ * spec.
+ */
+
+
+/** @name Bitmasks of XLLDMA_TX_CR_OFFSET and XLLDMA_RX_CR_OFFSET registers
+ * @{
+ */
+#define XLLDMA_CR_IRQ_TIMEOUT_MASK      0xFF000000 /**< Interrupt coalesce
+                                                        waitbound timeout */
+#define XLLDMA_CR_IRQ_COUNT_MASK        0x00FF0000 /**< Interrupt coalesce
+                                                        count threshold */
+#define XLLDMA_CR_MSB_ADDR_MASK         0x0000F000 /**< MSB address of DMA
+                                                        buffers and descriptors
+                                                        for 36 bit
+                                                        addressing */
+#define XLLDMA_CR_APP_EN_MASK           0x00000800 /**< Application data mask
+                                                        enable */
+#define XLLDMA_CR_USE_1_BIT_CNT_MASK    0x00000400 /**< Turn 4 and 2 bit
+                                                        interrupt counters into
+                                                        1 bit counters */
+#define XLLDMA_CR_USE_INT_ON_END_MASK   0x00000200 /**< Use interrupt-on-end */
+#define XLLDMA_CR_LD_IRQ_CNT_MASK       0x00000100 /**< Load IRQ_COUNT */
+#define XLLDMA_CR_IRQ_EN_MASK           0x00000080 /**< Master interrupt
+                                                        enable */
+#define XLLDMA_CR_IRQ_ERROR_EN_MASK     0x00000004 /**< Enable error
+                                                        interrupt */
+#define XLLDMA_CR_IRQ_DELAY_EN_MASK     0x00000002 /**< Enable coalesce delay
+                                                        interrupt */
+#define XLLDMA_CR_IRQ_COALESCE_EN_MASK  0x00000001 /**< Enable coalesce count
+                                                        interrupt */
+#define XLLDMA_CR_IRQ_ALL_EN_MASK       0x00000087 /**< All interrupt enable
+                                                        bits */
+
+/* Shift constants for selected masks */
+#define XLLDMA_CR_IRQ_TIMEOUT_SHIFT     24
+#define XLLDMA_CR_IRQ_COUNT_SHIFT       16
+#define XLLDMA_CR_MSB_ADDR_SHIFT        12
+
+/*@}*/
+
+
+/** @name Bitmasks of XLLDMA_TX_IRQ_OFFSET & XLLDMA_RX_IRQ_OFFSET registers
+ * @{
+ */
+#define XLLDMA_IRQ_WRQ_EMPTY_MASK        0x00004000 /**< Write Command Queue
+                                                         Empty -- RX channel
+                                                         Only */
+#define XLLDMA_IRQ_COALESCE_COUNTER_MASK 0x00003C00 /**< Coalesce IRQ 4 bit
+                                                         counter */
+#define XLLDMA_IRQ_DELAY_COUNTER_MASK    0x00000300 /**< Coalesce delay IRQ 2
+                                                         bit counter */
+#define XLLDMA_IRQ_PLB_RD_ERROR_MASK     0x00000010 /**< PLB Read Error IRQ */
+#define XLLDMA_IRQ_PLB_WR_ERROR_MASK     0x00000008 /**< PLB Write Error IRQ */
+#define XLLDMA_IRQ_ERROR_MASK            0x00000004 /**< Error IRQ */
+#define XLLDMA_IRQ_DELAY_MASK            0x00000002 /**< Coalesce delay IRQ */
+#define XLLDMA_IRQ_COALESCE_MASK         0x00000001 /**< Coalesce threshold
+                                                         IRQ */
+#define XLLDMA_IRQ_ALL_ERR_MASK          0x0000001C /**< All error interrupt */
+#define XLLDMA_IRQ_ALL_MASK              0x0000001F /**< All interrupt bits */
+
+/* Shift constants for selected masks */
+#define XLLDMA_IRQ_COALESCE_COUNTER_SHIFT 10
+#define XLLDMA_IRQ_DELAY_COUNTER_SHIFT     8
+
+/*@}*/
+
+
+/** @name Bitmasks of XLLDMA_TX_SR_OFFSET and XLLDMA_RX_SR_OFFSET registers
+ * @{
+ */
+#define XLLDMA_SR_IRQ_ON_END_MASK   0x00000040 /**< IRQ on end has occurred */
+#define XLLDMA_SR_STOP_ON_END_MASK  0x00000020 /**< Stop on end has occurred */
+#define XLLDMA_SR_COMPLETED_MASK    0x00000010 /**< BD completed */
+#define XLLDMA_SR_SOP_MASK          0x00000008 /**< Current BD has SOP set */
+#define XLLDMA_SR_EOP_MASK          0x00000004 /**< Current BD has EOP set */
+#define XLLDMA_SR_ENGINE_BUSY_MASK  0x00000002 /**< Channel is busy */
+/*@}*/
+
+
+/** @name Bitmasks associated with XLLDMA_DMACR_OFFSET register
+ * @{
+ */
+#define XLLDMA_DMACR_TX_PAUSE_MASK             0x20000000 /**< Pause TX channel
+                                                                  */
+#define XLLDMA_DMACR_RX_PAUSE_MASK             0x10000000 /**< Pause RX channel
+                                                                  */
+#define XLLDMA_DMACR_PLB_ERR_DIS_MASK          0x00000020 /**< Disable PLB
+                                                               error detection
+                                                                  */
+#define XLLDMA_DMACR_RX_OVERFLOW_ERR_DIS_MASK  0x00000010 /**< Disable error
+                                                               when 2 or 4 bit
+                                                               coalesce counter
+                                                               overflows */
+#define XLLDMA_DMACR_TX_OVERFLOW_ERR_DIS_MASK  0x00000008 /**< Disable error
+                                                               when 2 or 4 bit
+                                                               coalesce counter
+                                                               overflows */
+#define XLLDMA_DMACR_TAIL_PTR_EN_MASK          0x00000004 /**< Enable use of
+                                                               tail pointer
+                                                               register */
+#define XLLDMA_DMACR_EN_ARB_HOLD_MASK          0x00000002 /**< Enable
+                                                               arbitration
+                                                               hold */
+#define XLLDMA_DMACR_SW_RESET_MASK             0x00000001 /**< Assert Software
+                                                               reset for both
+                                                               channels */
+/*@}*/
+
+
+/** @name Bitmasks of XLLDMA_BD_STSCTRL_USR0_OFFSET descriptor word
+ *  @{
+ */
+#define XLLDMA_BD_STSCTRL_ERROR_MASK      0x80000000  /**< DMA error */
+#define XLLDMA_BD_STSCTRL_IOE_MASK        0x40000000  /**< Interrupt on end */
+#define XLLDMA_BD_STSCTRL_SOE_MASK        0x20000000  /**< Stop on end */
+#define XLLDMA_BD_STSCTRL_COMPLETED_MASK  0x10000000  /**< DMA completed */
+#define XLLDMA_BD_STSCTRL_SOP_MASK        0x08000000  /**< Start of packet */
+#define XLLDMA_BD_STSCTRL_EOP_MASK        0x04000000  /**< End of packet */
+#define XLLDMA_BD_STSCTRL_BUSY_MASK       0x02000000  /**< DMA channel busy */
+
+#define XLLDMA_BD_STSCTRL_MASK            0xFF000000  /**< Status/Control field
+                                                               */
+#define XLLDMA_BD_STSCTRL_USR0_MASK       0x00FFFFFF  /**< User field #0 */
+/*@}*/
+
+/**************************** Type Definitions *******************************/
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+#ifdef CONFIG_XILINX_LLDMA_USE_DCR
+
+/* DCR interface is used */
+
+#define XLlDma_In32  XIo_DcrIn
+#define XLlDma_Out32 XIo_DcrOut
+
+#else
+
+/* Non-DCR interface is used */
+
+#define XLlDma_In32  XIo_In32
+#define XLlDma_Out32 XIo_Out32
+
+#endif
+
+/*****************************************************************************/
+/**
+*
+* Read the given register.
+*
+* @param    BaseAddress is the base address of the device
+* @param    RegOffset is the register offset to be read
+*
+* @return   The 32-bit value of the register
+*
+* @note
+* C-style signature:
+*    u32 XLlDma_mReadReg(u32 BaseAddress, u32 RegOffset)
+*
+******************************************************************************/
+#define XLlDma_mReadReg(BaseAddress, RegOffset)             \
+    XLlDma_In32((BaseAddress) + (RegOffset))
+
+/*****************************************************************************/
+/**
+*
+* Write the given register.
+*
+* @param    BaseAddress is the base address of the device
+* @param    RegOffset is the register offset to be written
+* @param    Data is the 32-bit value to write to the register
+*
+* @return   None.
+*
+* @note
+* C-style signature:
+*    void XLlDma_mWriteReg(u32 BaseAddress, u32 RegOffset, u32 Data)
+*
+******************************************************************************/
+#define XLlDma_mWriteReg(BaseAddress, RegOffset, Data)          \
+    XLlDma_Out32((BaseAddress) + (RegOffset), (Data))
+
+/************************** Function Prototypes ******************************/
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xlldma_userip.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma_userip.h
--- linux-2.6.31.12/drivers/xilinx_common/xlldma_userip.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xlldma_userip.h	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,106 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2007 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xlldma_userip.h
+*
+* This file is for the User-IP core (like Local-Link TEMAC) to define constants
+* that are the User-IP core specific. DMA driver requires the constants to work
+* correctly. Two constants must be defined in this file:
+*
+*   - XLLDMA_USR_APPWORD_OFFSET:
+*
+*     This constant defines a user word the User-IP always updates in the RX
+*     Buffer Descriptors (BD) during any Receive transaction.
+*
+*     The DMA driver initializes this chosen user word of any RX BD to the
+*     pre-defined value (see XLLDMA_USR_APPWORD_INITVALUE below) before
+*     giving it to the RX channel. The DMA relies on its updation (by the
+*     User-IP) to ensure the BD has been completed by the RX channel besides
+*     checking the COMPLETE bit in XLLDMA_BD_STSCTRL_USR0_OFFSET field (see
+*     xlldma_hw.h).
+*
+*     The only valid options for this constant are XLLDMA_BD_USR1_OFFSET,
+*     XLLDMA_BD_USR2_OFFSET, XLLDMA_BD_USR3_OFFSET and XLLDMA_BD_USR4_OFFSET.
+*
+*     If the User-IP does not update any of the option fields above, the DMA
+*     driver will not work properly.
+*
+*   - XLLDMA_USR_APPWORD_INITVALUE:
+*
+*     This constant defines the value the DMA driver uses to populate the
+*     XLLDMA_USR_APPWORD_OFFSET field (see above) in any RX BD before giving
+*     the BD to the RX channel for receive transaction.
+*
+*     It must be ensured that the User-IP will always populates a different
+*     value from this constant into the XLLDMA_USR_APPWORD_OFFSET field at
+*     the end of any receive transaction. Failing to do so will cause the
+*     DMA driver to work improperly.
+*
+* If the User-IP uses different setting, the correct setting must be defined as
+* a compiler options used in the Makefile. In either case the default
+* definition of the constants in this file will be discarded.
+*
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a xd   02/21/07 First release
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XLLDMA_USERIP_H		/* prevent circular inclusions */
+#define XLLDMA_USERIP_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xlldma_hw.h"
+
+/************************** Constant Definitions *****************************/
+
+#ifndef XLLDMA_USERIP_APPWORD_OFFSET
+#define XLLDMA_USERIP_APPWORD_OFFSET    XLLDMA_BD_USR4_OFFSET
+#endif
+
+#ifndef XLLDMA_USERIP_APPWORD_INITVALUE
+#define XLLDMA_USERIP_APPWORD_INITVALUE 0xFFFFFFFF
+#endif
+
+/**************************** Type Definitions *******************************/
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/************************** Function Prototypes ******************************/
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xllfifo.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xllfifo.c
--- linux-2.6.31.12/drivers/xilinx_common/xllfifo.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xllfifo.c	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,393 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2005-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+ *
+ * @file llfifo.c
+ *
+ * The Xilinx local link FIFO driver component. This driver supports the
+ * Xilinx xps_ll_fifo core.
+ *
+ * <pre>
+ * MODIFICATION HISTORY:
+ *
+ * Ver   Who  Date     Changes
+ * ----- ---- -------- -------------------------------------------------------
+ * 1.00a jvb  10/13/06 First release
+ * </pre>
+ ******************************************************************************/
+
+
+/***************************** Include Files *********************************/
+
+#include <linux/string.h>
+
+#include "xllfifo_hw.h"
+#include "xllfifo.h"
+#include "xstatus.h"
+
+/************************** Constant Definitions *****************************/
+
+#define FIFO_WIDTH_BYTES 4
+
+/*
+ * Implementation Notes:
+ *
+ * This Fifo driver makes use of a byte streamer driver (xstreamer.h). The code
+ * is structured like so:
+ *
+ * +--------------------+
+ * |     llfifo         |
+ * |   +----------------+
+ * |   | +--------------+
+ * |   | |  xstreamer   |
+ * |   | +--------------+
+ * |   +----------------+
+ * |                    |
+ * +--------------------+
+ *
+ * Initialization
+ * At initialization time this driver (llfifo) sets up the streamer objects to
+ * use routines in this driver (llfifo) to perform the actual I/O to the H/W
+ * FIFO core.
+ *
+ * Operation
+ * Once the streamer objects are set up, the API routines in this driver, just
+ * call through to the streamer driver to perform the read/write operations.
+ * The streamer driver will eventually make calls back into the routines (which
+ * reside in this driver) given at initialization to peform the actual I/O.
+ *
+ * Interrupts
+ * Interrupts are handled in the OS/Application layer above this driver.
+ */
+
+xdbg_stmnt(u32 _xllfifo_rr_value;)
+xdbg_stmnt(u32 _xllfifo_ipie_value;)
+xdbg_stmnt(u32 _xllfifo_ipis_value;)
+
+/****************************************************************************/
+/*
+*
+* XLlFifo_RxGetWord reads one 32 bit word from the FIFO specified by
+* <i>InstancePtr</i>.
+*
+* XLlFifo_RxGetLen or XLlFifo_iRxGetLen must be called before calling
+* XLlFifo_RxGetWord. Otherwise, the hardware will raise an <i>Over Read
+* Exception</i>.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XLlFifo_RxGetWord returns the 32 bit word read from the FIFO.
+*
+* @note
+* C-style signature:
+*    u32 XLlFifo_RxGetWord(XLlFifo *InstancePtr)
+*
+*****************************************************************************/
+#define XLlFifo_RxGetWord(InstancePtr) \
+	XLlFifo_ReadReg((InstancePtr)->BaseAddress, XLLF_RDFD_OFFSET)
+
+/****************************************************************************/
+/*
+*
+* XLlFifo_TxPutWord writes the 32 bit word, <i>Word</i> to the FIFO specified by
+* <i>InstancePtr</i>.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   N/A
+*
+* @note
+* C-style signature:
+*    void XLlFifo_TxPutWord(XLlFifo *InstancePtr, u32 Word)
+*
+*****************************************************************************/
+#define XLlFifo_TxPutWord(InstancePtr, Word) \
+	XLlFifo_WriteReg((InstancePtr)->BaseAddress, XLLF_TDFD_OFFSET, \
+			(Word))
+
+/*****************************************************************************/
+/*
+*
+* XLlFifo_iRxOccupancy returns the number of 32-bit words available (occupancy)
+* to be read from the receive channel of the FIFO, specified by
+* <i>InstancePtr</i>.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XLlFifo_iRxOccupancy returns the occupancy count in 32-bit words for
+*           the specified FIFO.
+*
+******************************************************************************/
+static u32 XLlFifo_iRxOccupancy(XLlFifo *InstancePtr)
+{
+	XASSERT_NONVOID(InstancePtr);
+
+	return XLlFifo_ReadReg(InstancePtr->BaseAddress,
+			XLLF_RDFO_OFFSET);
+}
+
+/*****************************************************************************/
+/*
+*
+* XLlFifo_iRxGetLen notifies the hardware that the program is ready to receive the
+* next frame from the receive channel of the FIFO specified by <i>InstancePtr</i>.
+*
+* Note that the program must first call XLlFifo_iRxGetLen before pulling data
+* out of the receive channel of the FIFO with XLlFifo_Read.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XLlFifo_iRxGetLen returns the number of bytes available in the next
+*           frame.
+*
+******************************************************************************/
+static u32 XLlFifo_iRxGetLen(XLlFifo *InstancePtr)
+{
+	XASSERT_NONVOID(InstancePtr);
+
+	return XLlFifo_ReadReg(InstancePtr->BaseAddress,
+		XLLF_RLF_OFFSET);
+}
+
+/*****************************************************************************/
+/*
+*
+* XLlFifo_iRead_Aligned reads, <i>WordCount</i>, words from the FIFO referenced by
+* <i>InstancePtr</i> to the block of memory, referenced by <i>BufPtr</i>.
+*
+* XLlFifo_iRead_Aligned assumes that <i>BufPtr</i> is already aligned according
+* to the following hardware limitations:
+*    ppc        - aligned on 32 bit boundaries to avoid performance penalties
+*                 from unaligned exception handling.
+*    microblaze - aligned on 32 bit boundaries as microblaze does not handle
+*                 unaligned transfers.
+*
+* Care must be taken to ensure that the number of words read with one or more
+* calls to XLlFifo_Read() does not exceed the number of bytes (rounded up to
+* the nearest whole 32 bit word) available given from the last call to
+* XLlFifo_RxGetLen().
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @param    BufPtr specifies the memory address to place the data read.
+*
+* @param    WordCount specifies the number of 32 bit words to read.
+*
+* @return   XLlFifo_iRead_Aligned always returns XST_SUCCESS. Error handling is
+*           otherwise handled through hardware exceptions and interrupts.
+*
+* @note
+*
+* C Signature: int XLlFifo_iRead_Aligned(XLlFifo *InstancePtr,
+*                      void *BufPtr, unsigned WordCount);
+*
+******************************************************************************/
+/* static */ int XLlFifo_iRead_Aligned(XLlFifo *InstancePtr, void *BufPtr,
+			     unsigned WordCount)
+{
+	unsigned WordsRemaining = WordCount;
+	u32 *BufPtrIdx = BufPtr;
+
+	xdbg_printf(XDBG_DEBUG_FIFO_RX, "XLlFifo_iRead_Aligned: start\n");
+	XASSERT_NONVOID(InstancePtr);
+	XASSERT_NONVOID(BufPtr);
+	/* assert bufer is 32 bit aligned */
+	XASSERT_NONVOID(((unsigned)BufPtr & 0x3) == 0x0);
+	xdbg_printf(XDBG_DEBUG_FIFO_RX, "XLlFifo_iRead_Aligned: after asserts\n");
+
+	while (WordsRemaining) {
+/*		xdbg_printf(XDBG_DEBUG_FIFO_RX,
+			    "XLlFifo_iRead_Aligned: WordsRemaining: %d\n",
+			    WordsRemaining);
+*/
+		*BufPtrIdx = XLlFifo_RxGetWord(InstancePtr);
+		BufPtrIdx++;
+		WordsRemaining--;
+	}
+	xdbg_printf(XDBG_DEBUG_FIFO_RX,
+		    "XLlFifo_iRead_Aligned: returning SUCCESS\n");
+	return XST_SUCCESS;
+}
+
+/****************************************************************************/
+/*
+*
+* XLlFifo_iTxVacancy returns the number of unused 32 bit words available
+* (vacancy) in the send channel of the FIFO, specified by <i>InstancePtr</i>.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XLlFifo_iTxVacancy returns the vacancy count in 32-bit words for
+*           the specified FIFO.
+*
+*****************************************************************************/
+static u32 XLlFifo_iTxVacancy(XLlFifo *InstancePtr)
+{
+	XASSERT_NONVOID(InstancePtr);
+
+	return XLlFifo_ReadReg(InstancePtr->BaseAddress,
+			XLLF_TDFV_OFFSET);
+}
+
+/*****************************************************************************/
+/*
+*
+* XLlFifo_iTxSetLen begins a hardware transfer of data out of the transmit
+* channel of the FIFO, specified by <i>InstancePtr</i>. <i>Bytes</i> specifies the number
+* of bytes in the frame to transmit.
+*
+* Note that <i>Bytes</i> (rounded up to the nearest whole 32 bit word) must be same
+* number of words just written using one or more calls to
+* XLlFifo_iWrite_Aligned()
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @param    Bytes specifies the number of bytes to transmit.
+*
+* @return   N/A
+*
+******************************************************************************/
+static void XLlFifo_iTxSetLen(XLlFifo *InstancePtr, u32 Bytes)
+{
+	XASSERT_VOID(InstancePtr);
+
+	XLlFifo_WriteReg(InstancePtr->BaseAddress, XLLF_TLF_OFFSET,
+			Bytes);
+}
+
+/*****************************************************************************/
+/*
+*
+* XLlFifo_iWrite_Aligned writes, <i>WordCount</i>, words to the FIFO referenced by
+* <i>InstancePtr</i> from the block of memory, referenced by <i>BufPtr</i>.
+*
+* XLlFifo_iWrite_Aligned assumes that <i>BufPtr</i> is already aligned according
+* to the following hardware limitations:
+*    ppc        - aligned on 32 bit boundaries to avoid performance penalties
+*                 from unaligned exception handling.
+*    microblaze - aligned on 32 bit boundaries as microblaze does not handle
+*                 unaligned transfers.
+*
+* Care must be taken to ensure that the number of words written with one or
+* more calls to XLlFifo_iWrite_Aligned() matches the number of bytes (rounded up
+* to the nearest whole 32 bit word) given in the next call to
+* XLlFifo_iTxSetLen().
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @param    BufPtr specifies the memory address to place the data read.
+*
+* @param    WordCount specifies the number of 32 bit words to read.
+*
+* @return   XLlFifo_iWrite_Aligned always returns XST_SUCCESS. Error handling is
+*           otherwise handled through hardware exceptions and interrupts.
+*
+* @note
+*
+* C Signature: int XLlFifo_iWrite_Aligned(XLlFifo *InstancePtr,
+*                      void *BufPtr, unsigned WordCount);
+*
+******************************************************************************/
+/* static */ int XLlFifo_iWrite_Aligned(XLlFifo *InstancePtr, void *BufPtr,
+			      unsigned WordCount)
+{
+	unsigned WordsRemaining = WordCount;
+	u32 *BufPtrIdx = BufPtr;
+
+	xdbg_printf(XDBG_DEBUG_FIFO_TX,
+		    "XLlFifo_iWrite_Aligned: Inst: %p; Buff: %p; Count: %d\n",
+		    InstancePtr, BufPtr, WordCount);
+	XASSERT_NONVOID(InstancePtr);
+	XASSERT_NONVOID(BufPtr);
+	/* assert bufer is 32 bit aligned */
+	XASSERT_NONVOID(((unsigned)BufPtr & 0x3) == 0x0);
+
+	xdbg_printf(XDBG_DEBUG_FIFO_TX,
+		    "XLlFifo_iWrite_Aligned: WordsRemaining: %d\n",
+		    WordsRemaining);
+	while (WordsRemaining) {
+		XLlFifo_TxPutWord(InstancePtr, *BufPtrIdx);
+		BufPtrIdx++;
+		WordsRemaining--;
+	}
+	
+	xdbg_printf(XDBG_DEBUG_FIFO_TX,
+		    "XLlFifo_iWrite_Aligned: returning SUCCESS\n");
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************/
+/**
+*
+* XLlFifo_Initialize initializes an XPS_ll_Fifo device along with the
+* <i>InstancePtr</i> that references it.
+*
+* @param    InstancePtr references the memory instance to be associated with
+*           the FIFO device upon initialization.
+*
+* @param    BaseAddress is the processor address used to access the
+*           base address of the Fifo device.
+*
+* @return   N/A
+*
+******************************************************************************/
+void XLlFifo_Initialize(XLlFifo *InstancePtr, u32 BaseAddress)
+{
+	XASSERT_VOID(InstancePtr);
+	XASSERT_VOID(BaseAddress);
+
+	/* Clear instance memory */
+	memset(InstancePtr, 0, sizeof(XLlFifo));
+
+	/*
+	 * We don't care about the physical base address, just copy the
+	 * processor address over it.
+	 */
+	InstancePtr->BaseAddress = BaseAddress;
+
+	InstancePtr->IsReady = XCOMPONENT_IS_READY;
+
+	XLlFifo_TxReset(InstancePtr);
+	XLlFifo_RxReset(InstancePtr);
+
+	XStrm_RxInitialize(&(InstancePtr->RxStreamer), FIFO_WIDTH_BYTES,
+			(void *)InstancePtr,
+                        (XStrm_XferFnType)XLlFifo_iRead_Aligned,
+                        (XStrm_GetLenFnType)XLlFifo_iRxGetLen,
+                        (XStrm_GetOccupancyFnType)XLlFifo_iRxOccupancy);
+
+	XStrm_TxInitialize(&(InstancePtr->TxStreamer), FIFO_WIDTH_BYTES,
+			(void *)InstancePtr,
+                        (XStrm_XferFnType)XLlFifo_iWrite_Aligned,
+                        (XStrm_SetLenFnType)XLlFifo_iTxSetLen,
+                        (XStrm_GetVacancyFnType)XLlFifo_iTxVacancy);
+}
+
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xllfifo.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xllfifo.h
--- linux-2.6.31.12/drivers/xilinx_common/xllfifo.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xllfifo.h	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,575 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2005-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+ *
+ * @file llfifo.h
+ *
+ * The Xilinx Dual Channel Fifo driver component. This driver supports the
+ * Virtex-5(TM) and Virtex-4(TM) XPS_ll_Fifo.
+ *
+ * For a full description of the bridge features, please see the HW spec. This driver
+ * supports the following features:
+ *   - Memory mapped access to host interface registers
+ *   - API for polled frame transfers
+ *   - API for interrupt driven frame transfers
+ *   - Virtual memory support
+ *   - Full duplex operation
+ *
+ * <h2>Driver Description</h2>
+ *
+ * This driver enables higher layer software to access the XPS_llFifo core
+ * using any alignment in the data buffers.
+ * 
+ * This driver supports send and receive channels in the same instance
+ * structure in the same fashion as the hardware core.
+ * 
+ * <h2>Initialization</h2>
+ *
+ * An instance of this driver is initialized using a call to Initialize().
+ * 
+ * <h2>Usage</h2>
+ * 
+ * It is fairly simple to use the API provided by this FIFO driver. The
+ * only somewhat tricky part is that the calling code must correctly call
+ * a couple routines in the right sequence for receive and transmit.
+ *
+ * This sequence is described here. Check the routine functional 
+ * descriptions for information on how to use a specific API routine.
+ *
+ * <h3>Receive</h3>
+ *
+ * A frame is received by using the following sequence:<br>
+ * 1) call XLlFifo_RxGetLen() to get the length of the next incoming frame<br>
+ * 2) call XLlFifo_Read() one or more times to read the number of bytes
+ *    reported by XLlFifo_RxGetLen().<br>
+ *
+ * For example:
+ * <pre>
+ * 	frame_len = XLlFifo_RxGetLen(&RxInstance);
+ * 	while (frame_len) {
+ * 		unsigned bytes = min(sizeof(buffer), frame_len);
+ * 		XLlFifo_Read(&RxInstance, buffer, bytes);
+ * 		// ********
+ * 		// do something with buffer here
+ * 		// ********
+ * 		frame_len -= bytes;
+ * 	}
+ * </pre>
+ *
+ * This FIFO hardware core does <b>not</b> support a sequence where the
+ * calling code calls RxGetLen() twice in a row and then receive the data
+ * for two frames. Each frame must be read in by calling RxGetLen() just
+ * prior to reading the data.
+ *
+ * <h3>Transmit</h3>
+ * A frame is transmittted by using the following sequence:<br>
+ * 1) call XLlFifo_Write() one or more times to write all the of bytes in
+ *    the next frame.<br>
+ * 2) call XLlFifo_TxSetLen() to begin the transmission of frame just
+ *    written.<br>
+ *
+ * For example:
+ * <pre>
+ * 	frame_left = frame_len;
+ * 	while (frame_left) {
+ * 		unsigned bytes = min(sizeof(buffer), frame_left);
+ * 		XLlFifo_Write(&TxInstance, buffer, bytes);
+ * 		// ********
+ * 		// do something here to refill buffer
+ * 		// ********
+ * 	}
+ * 	XLlFifo_TxSetLen(&RxInstance, frame_len);
+ * </pre>
+ *
+ * This FIFO hardware core does <b>not</b> support a sequence where the
+ * calling code writes the data for two frames and then calls TxSetLen()
+ * twice in a row. Each frame must be written by writting the data for one
+ * frame and then calling TxSetLen().
+ * 
+ * <h2>Interrupts</h2>
+ * This driver does not handle interrupts from the FIFO hardware. The
+ * software layer above may make use of the interrupts by setting up its
+ * own handlers for the interrupts.
+ *
+ * <pre>
+ * MODIFICATION HISTORY:
+ *
+ * Ver   Who  Date     Changes
+ * ----- ---- -------- -------------------------------------------------------
+ * 1.00a jvb  10/12/06 First release
+ * </pre>
+ *
+ *****************************************************************************/
+#ifndef XLLFIFO_H		/* prevent circular inclusions */
+#define XLLFIFO_H		/* by using preprocessor symbols */
+
+/* force C linkage */
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xllfifo_hw.h"
+#include "xstreamer.h"
+
+/**************************** Type Definitions *******************************/
+
+/**
+ * This typedef defines a run-time instance of an XLlFifo device.
+ */
+typedef struct XLlFifo {
+	u32 BaseAddress;  /**< BaseAddress is the physical base address of the
+	                   *   device's registers
+	                   */
+
+	u32 IsReady;           /**< IsReady is non-zero if the driver instance
+	                        *   has been initialized.
+	                        */
+	XStrm_RxFifoStreamer RxStreamer; /**< RxStreamer is the byte streamer
+	                                  *   instance for the receive channel.
+	                                  */
+	XStrm_TxFifoStreamer TxStreamer; /**< TxStreamer is the byte streamer
+	                                  *   instance for the transmit channel.
+	                                  */
+} XLlFifo;
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_Reset resets both the Tx and Rx channels and the local link interface
+* the FIFO specified by <i>InstancePtr</i>. XLlFifo_TxReset resets also sends a
+* reset pulse to the downstream device (e.g. TEMAC). XLlFifo_Reset drops any
+* bytes in the FIFO not yet retrieved. XLlFifo_Reset drops any bytes in the FIFO
+* not yet transmitted.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   N/A
+*
+* @note
+* C-style signature:
+*    void XLlFifo_Reset(XLlFifo *InstancePtr)
+*
+*****************************************************************************/
+#define XLlFifo_Reset(InstancePtr) \
+	XLlFifo_WriteReg((InstancePtr)->BaseAddress, XLLF_LLR_OFFSET, \
+			XLLF_LLR_RESET_MASK)
+
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_Status returns a bit mask of the interrupt status register (ISR)
+* for the FIFO specified by <i>InstancePtr</i>. XLlFifo_Status can be used
+* to query the status of the FIFO without having to have interrupts enabled.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XLlFifo_IntStatus returns a bit mask of the status conditions.
+*           The mask will be a set of bitwise or'd values from the
+*           <code>XLLF_INT_*_MASK</code> preprocessor symbols.
+*
+* @note
+* C-style signature:
+*    u32 XLlFifo_IntStatus(XLlFifo *InstancePtr)
+*
+*****************************************************************************/
+#define XLlFifo_Status(InstancePtr) \
+	 XLlFifo_ReadReg((InstancePtr)->BaseAddress, XLLF_ISR_OFFSET)
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_IntEnable enables the interrupts specified in <i>Mask</i> for the
+* FIFO specified by <i>InstancePtr</i>. The corresponding interrupt for each bit
+* set to 1 in <i>Mask</i>, will be enabled.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @param    Mask contains a bit mask of the interrupts to enable. The mask
+*           can be formed using a set of bitwise or'd values from the
+*           <code>XLLF_INT_*_MASK</code> preprocessor symbols.
+*
+* @return   N/A
+*
+* @note
+* C-style signature:
+*    void XLlFifo_IntEnable(XLlFifo *InstancePtr, u32 Mask)
+*
+*****************************************************************************/
+#define XLlFifo_IntEnable(InstancePtr, Mask) \
+{ \
+	u32 Reg = XLlFifo_ReadReg((InstancePtr)->BaseAddress, \
+			XLLF_IER_OFFSET); \
+	Reg |= ((Mask) & XLLF_INT_ALL_MASK);                    \
+	XLlFifo_WriteReg((InstancePtr)->BaseAddress, XLLF_IER_OFFSET, \
+			Reg); \
+}
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_IntDisable disables the interrupts specified in <i>Mask</i> for the
+* FIFO specified by <i>InstancePtr</i>. The corresponding interrupt for each bit
+* set to 1 in <i>Mask</i>, will be disabled. In other words, XLlFifo_IntDisable
+* uses the "set a bit to clear it" scheme.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @param    Mask contains a bit mask of the interrupts to disable. The mask
+*           can be formed using a set of bitwise or'd values from the
+*           <code>XLLF_INT_*_MASK</code> preprocessor symbols.
+*
+* @return   N/A
+*
+* @note
+* C-style signature:
+*    void XLlFifo_IntDisable(XLlFifo *InstancePtr, u32 Mask)
+*
+*****************************************************************************/
+#define XLlFifo_IntDisable(InstancePtr, Mask) \
+{ \
+	u32 Reg = XLlFifo_ReadReg((InstancePtr)->BaseAddress, \
+			XLLF_IER_OFFSET); \
+	Reg &= ~((Mask) & XLLF_INT_ALL_MASK);  \
+	XLlFifo_WriteReg((InstancePtr)->BaseAddress, XLLF_IER_OFFSET, \
+			Reg); \
+}
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_IntPending returns a bit mask of the pending interrupts for the
+* FIFO specified by <i>InstancePtr</i>. Each bit set to 1 in the return value
+* represents a pending interrupt.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XLlFifo_IntPending returns a bit mask of the interrupts that are
+*           pending. The mask will be a set of bitwise or'd values from the
+*           <code>XLLF_INT_*_MASK</code> preprocessor symbols.
+*
+* @note
+* C-style signature:
+*    u32 XLlFifo_IntPending(XLlFifo *InstancePtr)
+*
+*****************************************************************************/
+#ifdef DEBUG
+extern u32 _xllfifo_ipie_value;
+extern u32 _xllfifo_ipis_value;
+#define XLlFifo_IntPending(InstancePtr) \
+	(_xllfifo_ipie_value = XLlFifo_ReadReg( \
+		(InstancePtr)->BaseAddress, XLLF_IER_OFFSET),  \
+	_xllfifo_ipis_value = XLlFifo_ReadReg( \
+		(InstancePtr)->BaseAddress, XLLF_ISR_OFFSET),  \
+	(_xllfifo_ipie_value & _xllfifo_ipis_value))
+#else
+#define XLlFifo_IntPending(InstancePtr) \
+	(XLlFifo_ReadReg((InstancePtr)->BaseAddress, XLLF_IER_OFFSET) &  \
+	 XLlFifo_ReadReg((InstancePtr)->BaseAddress, XLLF_ISR_OFFSET))
+#endif
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_IntClear clears pending interrupts specified in <i>Mask</i> for the
+* FIFO specified by <i>InstancePtr</i>. The corresponding pending interrupt for
+* each bit set to 1 in <i>Mask</i>, will be cleared. In other words,
+* XLlFifo_IntClear uses the "set a bit to clear it" scheme.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @param    Mask contains a bit mask of the pending interrupts to clear. The
+*           mask can be formed using a set of bitwise or'd values from the
+*           <code>XLLF_INT_*_MASK</code> preprocessor symbols.
+*
+* @note
+* C-style signature:
+*    void XLlFifo_IntClear(XLlFifo *InstancePtr, u32 Mask)
+*
+*****************************************************************************/
+#define XLlFifo_IntClear(InstancePtr, Mask) \
+	XLlFifo_WriteReg((InstancePtr)->BaseAddress, XLLF_ISR_OFFSET, \
+			((Mask) & XLLF_INT_ALL_MASK))
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_RxReset resets the receive channel of the FIFO specified by
+* <i>InstancePtr</i>. XLlFifo_RxReset drops any bytes in the FIFO not yet
+* retrieved.
+*
+* The calling software may want to test for the completion of the reset by
+* reading the interrupt status (IS) register and testing for the Rx Reset
+* complete (RRC) bit.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   N/A
+*
+* @note
+* C-style signature:
+*    void XLlFifo_RxReset(XLlFifo *InstancePtr)
+*
+*****************************************************************************/
+#define XLlFifo_RxReset(InstancePtr) \
+	XLlFifo_WriteReg((InstancePtr)->BaseAddress, XLLF_RDFR_OFFSET, \
+			XLLF_RDFR_RESET_MASK)
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_IsRxEmpty returns true if the receive channel of the FIFO, specified
+* by <i>InstancePtr</i>, is empty.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XLlFifo_IsRxEmpty returns TRUE when the receive channel of the
+*           FIFO is empty. Otherwise, XLlFifo_IsRxEmpty returns FALSE.
+*
+* @note
+* C-style signature:
+*    int XLlFifo_IsRxEmpty(XLlFifo *InstancePtr)
+*
+*****************************************************************************/
+#define XLlFifo_IsRxEmpty(InstancePtr) \
+	((XStrm_IsRxInternalEmpty(&((InstancePtr)->RxStreamer)) && \
+	((XLlFifo_ReadReg((InstancePtr)->BaseAddress, \
+			XLLF_RDFO_OFFSET) == 0))) \
+			? TRUE : FALSE)
+
+
+/*****************************************************************************/
+/**
+*
+* XLlFifo_RxOccupancy returns the number of 32-bit words available (occupancy) to
+* be read from the receive channel of the FIFO, specified by <i>InstancePtr</i>.
+*
+* The xps_ll_fifo core uses the same fifo to store data values and frame length
+* values. Upon initialization, the XLlFifo_RxOccupancy will give the value of
+* 1, which means one length value (a reserved fifo location) and no data
+* values.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XLlFifo_RxOccupancy returns the occupancy count for the specified
+*           packet FIFO.
+*
+* @note
+*
+* C Signature: u32 XLlFifo_RxOccupancy(XLlFifo *InstancePtr)
+*
+******************************************************************************/
+#define XLlFifo_RxOccupancy(InstancePtr) \
+	XStrm_RxOccupancy(&((InstancePtr)->RxStreamer))
+
+/*****************************************************************************/
+/**
+*
+* XLlFifo_RxGetLen notifies the hardware that the program is ready to receive
+* the next frame from the receive channel of the FIFO, specified by
+* <i>InstancePtr</i>.
+*
+* Note that the program must first call XLlFifo_RxGetLen before pulling data
+* out of the receive channel of the FIFO with XLlFifo_Read.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XLlFifo_RxGetLen returns the number of bytes available in the next
+*           frame.
+*
+* @note
+*
+* C Signature: u32 XLlFifo_RxGetLen(XLlFifo *InstancePtr)
+*
+******************************************************************************/
+#define XLlFifo_RxGetLen(InstancePtr) \
+	XStrm_RxGetLen(&((InstancePtr)->RxStreamer))
+
+/*****************************************************************************/
+/**
+*
+* XLlFifo_Read reads <i>Bytes</i> bytes from the receive channel of the FIFO
+* referenced by <i>InstancePtr</i> to the block of memory, referenced by
+* <i>BufPtr</i>. 
+*
+* Care must be taken to ensure that the number of bytes read with one or more
+* calls to XLlFifo_Read() does not exceed the number of bytes available given
+* from the last call to XLlFifo_RxGetLen().
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @param    BufPtr specifies the memory address to place the data read.
+*
+* @param    Bytes specifies the number of bytes to read.
+*
+* @return   N/A
+*
+* @note
+* Error handling is handled through hardware exceptions and interrupts.
+*
+* C Signature: void XLlFifo_Read(XLlFifo *InstancePtr, void *BufPtr, unsigned Bytes)
+*
+******************************************************************************/
+#define XLlFifo_Read(InstancePtr, BufPtr, Bytes) \
+	XStrm_Read(&((InstancePtr)->RxStreamer), (BufPtr), (Bytes))
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_TxReset resets the transmit channel of the FIFO specified by
+* <i>InstancePtr</i>. XLlFifo_TxReset drops any bytes in the FIFO not yet
+* transmitted.
+*
+* The calling software may want to test for the completion of the reset by
+* reading the interrupt status (IS) register and testing for the Tx Reset
+* complete (TRC) bit.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   N/A
+*
+* @note
+* C-style signature:
+*    void XLlFifo_TxReset(XLlFifo *InstancePtr)
+*
+*****************************************************************************/
+#define XLlFifo_TxReset(InstancePtr) \
+	XLlFifo_WriteReg((InstancePtr)->BaseAddress, XLLF_TDFR_OFFSET, \
+			XLLF_TDFR_RESET_MASK)
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_IsTxDone returns true if the transmission in the transmit channel
+* of the FIFO, specified by <i>InstancePtr</i>, is complete. XLlFifo_IsTxDone
+* works only if the TC bit in the IS register is cleared before sending a
+* frame.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XLlFifo_IsTxDone returns TRUE when the transmit channel of the
+*           FIFO is complete. Otherwise, XLlFifo_IsTxDone returns FALSE.
+*
+* @note
+* C-style signature:
+*    int XLlFifo_IsTxDone(XLlFifo *InstancePtr)
+*
+*****************************************************************************/
+#define XLlFifo_IsTxDone(InstancePtr) \
+	((XLlFifo_ReadReg((InstancePtr)->BaseAddress, XLLF_ISR_OFFSET) & \
+		XLLF_INT_TC_MASK) \
+		? TRUE : FALSE)
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_TxVacancy returns the number of unused 32 bit words available
+* (vacancy) in the send channel of the FIFO specified by <i>InstancePtr</i>.
+*
+* The xps_ll_fifo core uses tXLLF_he same fifo to store data values and frame length
+* values. Upon initialization, the XLlFifo_TxVacancy will give the value of
+* FIFO_WIDTH - 1, which means one length value used (a reserved fifo location)
+* and no data values yet present.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XLlFifo_TxVacancy returns the vacancy count in 32-bit words for
+*           the specified FIFO.
+*
+* @note
+* C-style signature:
+*    u32 XLlFifo_TxVacancy(XLlFifo *InstancePtr)
+*
+*****************************************************************************/
+#define XLlFifo_TxVacancy(InstancePtr) \
+	XStrm_TxVacancy(&((InstancePtr)->TxStreamer))
+
+/*****************************************************************************/
+/**
+*
+* XLlFifo_TxSetLen begins a hardware transfer of <i>Bytes</i> bytes out of the
+* transmit channel of the FIFO specified by <i>InstancePtr</i>.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @param    Bytes specifies the frame length in bytes.
+*
+* @return   N/A
+*
+* @note
+*
+* C Signature: void XLlFifo_TxSetLen(XLlFifo *InstancePtr, u32 Bytes)
+*
+******************************************************************************/
+#define XLlFifo_TxSetLen(InstancePtr, Bytes) \
+	XStrm_TxSetLen(&((InstancePtr)->TxStreamer), (Bytes))
+
+/*****************************************************************************/
+/**
+*
+* XLlFifo_Write writes <i>Bytes</i> bytes of the block of memory, referenced by
+* <i>BufPtr</i>, to the transmit channel of the FIFO referenced by
+* <i>InstancePtr</i>. 
+*
+* Care must be taken to ensure that the number of bytes written with one or
+* more calls to XLlFifo_Write() matches the number of bytes given in the next
+* call to XLlFifo_TxSetLen().
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @param    BufPtr specifies the memory address of data to write.
+*
+* @param    Bytes specifies the number of bytes to write.
+*
+* @return   N/A
+*
+* @note
+* Error handling is handled through hardware exceptions and interrupts.
+*
+* C Signature: void XLlFifo_Write(XLlFifo *InstancePtr, void *BufPtr, unsigned Bytes)
+*
+******************************************************************************/
+#define XLlFifo_Write(InstancePtr, BufPtr, Bytes) \
+	XStrm_Write(&((InstancePtr)->TxStreamer), (BufPtr), (Bytes))
+	
+ 
+/************************** Function Prototypes ******************************/
+/*
+ * Initialization functions in xtemac_sinit.c
+ */
+void XLlFifo_Initialize(XLlFifo *InstancePtr, u32 BaseAddress);
+
+#ifdef __cplusplus
+}
+#endif
+#endif				/* XLLFIFO_H  end of preprocessor protection symbols */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xllfifo_hw.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xllfifo_hw.h
--- linux-2.6.31.12/drivers/xilinx_common/xllfifo_hw.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xllfifo_hw.h	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,211 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2004-2006 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+
+/*****************************************************************************/
+/**
+*
+* @file llfifo_hw.h
+*
+* This header file contains identifiers and low-level driver functions (or
+* macros) that can be used to access the xps_ll_fifo core.
+* High-level driver functions are defined in xpfifo.h.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a jvb  10/16/06 First release.
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XLLFIFO_HW_H		/* prevent circular inclusions */
+#define XLLFIFO_HW_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xio.h"
+#include "xdebug.h"
+			 
+/************************** Constant Definitions *****************************/
+
+/* Register offset definitions. Unless otherwise noted, register access is
+ * 32 bit.
+ */
+
+/** @name Registers
+ *  @{
+ */
+#define XLLF_ISR_OFFSET  0x00000000  /**< Interrupt Status */
+#define XLLF_IER_OFFSET  0x00000004 /**< Interrupt Enable */
+
+#define XLLF_TDFR_OFFSET 0x00000008  /**< Transmit Reset */
+#define XLLF_TDFV_OFFSET 0x0000000c  /**< Transmit Vacancy */
+#define XLLF_TDFD_OFFSET 0x00000010  /**< Transmit Data */
+#define XLLF_TLF_OFFSET  0x00000014  /**< Transmit Length */
+
+#define XLLF_RDFR_OFFSET 0x00000018  /**< Receive Reset */
+#define XLLF_RDFO_OFFSET 0x0000001c  /**< Receive Occupancy */
+#define XLLF_RDFD_OFFSET 0x00000020  /**< Receive Data */
+#define XLLF_RLF_OFFSET  0x00000024  /**< Receive Length */
+#define XLLF_LLR_OFFSET  0x00000028  /**< Local Link Reset */
+
+/*@}*/
+
+/* Register masks. The following constants define bit locations of various
+ * control bits in the registers. Constants are not defined for those registers
+ * that have a single bit field representing all 32 bits. For further
+ * information on the meaning of the various bit masks, refer to the HW spec.
+ */
+
+/** @name Interrupt bits
+ *  These bits are associated with the XLLF_IER_OFFSET and XLLF_ISR_OFFSET
+ *  registers.
+ * @{
+ */
+#define XLLF_INT_RPURE_MASK       0x80000000 /**< Receive under-read */
+#define XLLF_INT_RPORE_MASK       0x40000000 /**< Receive over-read */
+#define XLLF_INT_RPUE_MASK        0x20000000 /**< Receive underrun (empty) */
+#define XLLF_INT_TPOE_MASK        0x10000000 /**< Transmit overrun */
+#define XLLF_INT_TC_MASK          0x08000000 /**< Transmit complete */
+#define XLLF_INT_RC_MASK          0x04000000 /**< Receive complete */
+#define XLLF_INT_TSE_MASK         0x02000000 /**< Transmit length mismatch */
+#define XLLF_INT_TRC_MASK         0x01000000 /**< Transmit reset complete */
+#define XLLF_INT_RRC_MASK         0x00800000 /**< Receive reset complete */
+#define XLLF_INT_ALL_MASK         0xff800000 /**< All the ints */
+#define XLLF_INT_ERROR_MASK       0xf2000000 /**< Error status ints */
+#define XLLF_INT_RXERROR_MASK     0xe0000000 /**< Receive Error status ints */
+#define XLLF_INT_TXERROR_MASK     0x12000000 /**< Transmit Error status ints */
+/*@}*/
+
+/** @name Reset register values
+ *  These bits are associated with the XLLF_TDFR_OFFSET and XLLF_RDFR_OFFSET
+ *  reset registers.
+ * @{
+ */
+#define XLLF_RDFR_RESET_MASK        0x000000a5 /**< receive reset value */
+#define XLLF_TDFR_RESET_MASK        0x000000a5 /**< Transmit reset value */
+#define XLLF_LLR_RESET_MASK        0x000000a5 /**< Local Link reset value */
+/*@}*/
+
+/**************************** Type Definitions *******************************/
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/**** debug macros ****/
+#define XLlFifo_reg_name(RegOffset) \
+	(((RegOffset) == XLLF_ISR_OFFSET) ? "ISR": \
+	((RegOffset) == XLLF_IER_OFFSET) ? "IER": \
+	((RegOffset) == XLLF_TDFR_OFFSET) ? "TDFR {tx reset}": \
+	((RegOffset) == XLLF_TDFV_OFFSET) ? "TDFV {tx vacancy}": \
+	((RegOffset) == XLLF_TDFD_OFFSET) ? "TDFD {tx data}": \
+	((RegOffset) == XLLF_TLF_OFFSET) ? "TLF {tx length}": \
+	((RegOffset) == XLLF_RDFR_OFFSET) ? "RDFR {rx reset}": \
+	((RegOffset) == XLLF_RDFO_OFFSET) ? "RDFO {rx occupancy}": \
+	((RegOffset) == XLLF_RDFD_OFFSET) ? "RDFD {rx data}": \
+	((RegOffset) == XLLF_RLF_OFFSET) ? "RLF {rx length}": \
+	"unknown")
+
+#define XLlFifo_print_reg_o(BaseAddress, RegOffset, Value) \
+	 xdbg_printf(XDBG_DEBUG_FIFO_REG, "0x%08x -> %s(0x%08x)\n", (Value), \
+			  XLlFifo_reg_name(RegOffset), \
+			 (RegOffset) + (BaseAddress))
+
+#define XLlFifo_print_reg_i(BaseAddress, RegOffset, Value) \
+	xdbg_printf(XDBG_DEBUG_FIFO_REG, "%s(0x%08x) -> 0x%08x\n", \
+			 XLlFifo_reg_name(RegOffset), \
+			(RegOffset) + (BaseAddress), (Value))
+/**** end debug macros ****/
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_ReadReg returns the value of the register at the offet,
+* <i>RegOffset</i>, from the memory mapped base address, <i>BaseAddress</i>.
+*
+* @param    BaseAddress specifies the base address of the device.
+*
+* @param    RegOffset specifies the offset from BaseAddress.
+*
+* @return   XLlFifo_ReadReg returns the value of the specified register.
+*
+* @note
+* C-style signature:
+*    u32 XLlFifo_ReadReg(u32 BaseAddress, u32 RegOffset)
+*
+*****************************************************************************/
+#ifdef DEBUG
+extern u32 _xllfifo_rr_value;
+#define XLlFifo_ReadReg(BaseAddress, RegOffset) \
+	((((RegOffset) > 0x24) ? xdbg_printf(XDBG_DEBUG_ERROR, \
+		"XLlFifo_WriteReg: Woah! wrong reg addr: 0x%08x\n", \
+		(RegOffset)) : 0), \
+	_xllfifo_rr_value = XIo_In32((BaseAddress) + (RegOffset)), \
+	XLlFifo_print_reg_i((BaseAddress), (RegOffset), _xllfifo_rr_value), \
+	_xllfifo_rr_value)
+#else
+#define XLlFifo_ReadReg(BaseAddress, RegOffset) \
+	(XIo_In32((BaseAddress) + (RegOffset)))
+#endif
+
+/****************************************************************************/
+/**
+*
+* XLlFifo_WriteReg writes the value, <i>Value</i>, to the register at the
+* offet, <i>RegOffset</i>, from the memory mapped base address,
+* <i>BaseAddress</i>.
+*
+* @param    BaseAddress specifies the base address of the device.
+*
+* @param    RegOffset specifies the offset from BaseAddress.
+*
+* @param    Value is value to write to the register.
+*
+* @return   N/A
+*
+* @note
+* C-style signature:
+*    void XLlFifo_WriteReg(u32 BaseAddress, u32 RegOffset, u32 Value)
+*
+*****************************************************************************/
+#ifdef DEBUG
+#define XLlFifo_WriteReg(BaseAddress, RegOffset, Value) \
+	(((RegOffset) > 0x24) ? xdbg_printf(XDBG_DEBUG_ERROR, \
+		"XLlFifo_WriteReg: Woah! wrong reg addr: 0x%08x\n", \
+		(RegOffset)) : 0), \
+	XLlFifo_print_reg_o((BaseAddress), (RegOffset), (Value)), \
+	(XIo_Out32((BaseAddress) + (RegOffset), (Value)))
+#else
+#define XLlFifo_WriteReg(BaseAddress, RegOffset, Value) \
+	((XIo_Out32((BaseAddress) + (RegOffset), (Value))))
+#endif
+
+#ifdef __cplusplus
+}
+#endif
+#endif				/* XLLFIFO_HW_H  end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xpacket_fifo_l_v2_00_a.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xpacket_fifo_l_v2_00_a.c
--- linux-2.6.31.12/drivers/xilinx_common/xpacket_fifo_l_v2_00_a.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xpacket_fifo_l_v2_00_a.c	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,852 @@
+/* $Id: xpacket_fifo_l_v2_00_a.c,v 1.1 2006/12/13 14:22:53 imanuilov Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2003-2004 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xpacket_fifo_l_v2_00_a.c
+*
+* Contains low-level (Level 0) functions for the XPacketFifoV200a driver.
+* See xpacket_fifo_v2_00_a.h for information about the high-level (Level 1)
+* driver.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- ------------------------------------------------------
+* 2.00a rpm  10/22/03  First release. Moved most of Level 1 driver functions
+*                      into this layer.
+* 2.00a rmm  02/24/04  Added L0WriteDRE function.
+* 2.00a xd   10/27/04  Changed comments to support doxygen for API
+*                      documentation.
+* </pre>
+*
+*****************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xio.h"
+#include "xpacket_fifo_l_v2_00_a.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************* Variable Definitions ******************************/
+
+
+/************************** Function Prototypes ******************************/
+
+static int Write32(u32 RegBaseAddress, u32 DataBaseAddress,
+		   u8 *BufferPtr, u32 ByteCount);
+
+static int Write64(u32 RegBaseAddress, u32 DataBaseAddress,
+		   u8 *BufferPtr, u32 ByteCount);
+
+static int Read32(u32 RegBaseAddress, u32 DataBaseAddress,
+		  u8 *BufferPtr, u32 ByteCount);
+
+static int Read64(u32 RegBaseAddress, u32 DataBaseAddress,
+		  u8 *BufferPtr, u32 ByteCount);
+
+
+/*****************************************************************************/
+/**
+*
+* Read data from a FIFO and puts it into a specified buffer. The packet FIFO is
+* currently 32 or 64 bits wide such that an input buffer which is a series of
+* bytes is filled from the FIFO a word at a time. If the requested byte count
+* is not a multiple of 32/64 bit words, it is necessary for this function to
+* format the remaining 32/64 bit word from the FIFO into a series of bytes in
+* the buffer. There may be up to 3/7 extra bytes which must be extracted from
+* the last word of the FIFO and put into the buffer.
+*
+* @param RegBaseAddress is the base address of the FIFO registers.
+*
+* @param DataBaseAddress is the base address of the FIFO keyhole.
+*
+* @param BufferPtr points to the memory buffer to write the data into. This
+*        buffer must be 32 bit aligned or an alignment exception could be
+*        generated. Since this buffer is a byte buffer, the data is assumed to
+*        be endian independent.
+*
+* @param ByteCount contains the number of bytes to read from the FIFO. This
+*        number of bytes must be present in the FIFO or an error will be
+*        returned.
+*
+* @return
+*
+* XST_SUCCESS indicates the operation was successful.  If the number of
+* bytes specified by the byte count is not present in the FIFO
+* XST_PFIFO_LACK_OF_DATA is returned.
+* <br><br>
+* If the function was successful, the specified buffer is modified to contain
+* the bytes which were removed from the FIFO.
+*
+* @note
+*
+* Note that the exact number of bytes which are present in the FIFO is
+* not known by this function.  It can only check for a number of 32/64 bit
+* words such that if the byte count specified is incorrect, but is still
+* possible based on the number of words in the FIFO, up to 3/7 garbage bytes
+* may be present at the end of the buffer.
+* <br><br>
+* This function assumes that if the device consuming data from the FIFO is
+* a byte device, the order of the bytes to be consumed is from the most
+* significant byte to the least significant byte of a 32/64 bit word removed
+* from the FIFO.
+*
+******************************************************************************/
+int XPacketFifoV200a_L0Read(u32 RegBaseAddress, u32 DataBaseAddress,
+			    u8 *BufferPtr, u32 ByteCount)
+{
+	u32 Width;
+	int Result = XST_FIFO_ERROR;
+
+	/* determine the width of the FIFO
+	 */
+	Width = XIo_In32(RegBaseAddress + XPF_V200A_COUNT_STATUS_REG_OFFSET) &
+		XPF_V200A_FIFO_WIDTH_MASK;
+
+	if ((Width == XPF_V200A_FIFO_WIDTH_LEGACY_TYPE) ||
+	    (Width == XPF_V200A_FIFO_WIDTH_32BITS_TYPE)) {
+		Result = Read32(RegBaseAddress, DataBaseAddress, BufferPtr,
+				ByteCount);
+	}
+	else if (Width == XPF_V200A_FIFO_WIDTH_64BITS_TYPE) {
+		Result = Read64(RegBaseAddress, DataBaseAddress, BufferPtr,
+				ByteCount);
+	}
+
+	return Result;
+
+}
+
+/*****************************************************************************/
+/**
+*
+* Write data into a packet FIFO. The packet FIFO is currently 32 or 64 bits
+* wide such that an input buffer which is a series of bytes must be written
+* into the FIFO a word at a time. If the buffer is not a multiple of 32 bit
+* words, it is necessary for this function to format the remaining bytes into
+* a single 32 bit word to be inserted into the FIFO. This is necessary to
+* avoid any accesses past the end of the buffer.
+*
+* @param RegBaseAddress is the base address of the FIFO registers.
+*
+* @param DataBaseAddress is the base address of the FIFO keyhole.
+*
+* @param BufferPtr points to the memory buffer that data is to be read from
+*        and written into the FIFO. Since this buffer is a byte buffer, the
+*        data is assumed to be endian independent. This buffer must be 32 bit
+*        aligned or an alignment exception could be generated.
+*
+* @param ByteCount contains the number of bytes to read from the buffer and to
+*        write to the FIFO.
+*
+* @return
+*
+* XST_SUCCESS is returned if the operation succeeded.  If there is not enough
+* room in the FIFO to hold the specified bytes, XST_PFIFO_NO_ROOM is
+* returned.
+*
+* @note
+*
+* This function assumes that if the device inserting data into the FIFO is
+* a byte device, the order of the bytes in each 32/64 bit word is from the most
+* significant byte to the least significant byte.
+*
+******************************************************************************/
+int XPacketFifoV200a_L0Write(u32 RegBaseAddress,
+			     u32 DataBaseAddress, u8 *BufferPtr, u32 ByteCount)
+{
+	u32 Width;
+	int Result = XST_FIFO_ERROR;
+
+
+	/* determine the width of the FIFO
+	 */
+	Width = XIo_In32(RegBaseAddress + XPF_V200A_COUNT_STATUS_REG_OFFSET) &
+		XPF_V200A_FIFO_WIDTH_MASK;
+
+	if ((Width == XPF_V200A_FIFO_WIDTH_LEGACY_TYPE) ||
+	    (Width == XPF_V200A_FIFO_WIDTH_32BITS_TYPE)) {
+		Result = Write32(RegBaseAddress, DataBaseAddress, BufferPtr,
+				 ByteCount);
+	}
+	else if (Width == XPF_V200A_FIFO_WIDTH_64BITS_TYPE) {
+		Result = Write64(RegBaseAddress, DataBaseAddress, BufferPtr,
+				 ByteCount);
+	}
+
+	return Result;
+
+}
+
+/*****************************************************************************/
+/**
+*
+* Write data into a packet FIFO configured for the Data Realignment Engine
+* (DRE). A packet FIFO channel configured in this way will accept any
+* combination of byte, half-word, or word writes. The DRE will shift the data
+* into the correct byte lane.
+*
+* @param RegBaseAddress is the base address of the FIFO registers.
+*
+* @param DataBaseAddress is the base address of the FIFO keyhole.
+*
+* @param BufferPtr points to the memory buffer that data is to be read from
+*        and written into the FIFO. Since this buffer is a byte buffer, the
+*        data is assumed to be endian independent. There are no alignment
+*        restrictions.
+*
+* @param ByteCount contains the number of bytes to read from the buffer and to
+*        write to the FIFO.
+*
+* @return
+*
+* XST_SUCCESS is returned if the operation succeeded.  If there is not enough
+* room in the FIFO to hold the specified bytes, XST_PFIFO_NO_ROOM is
+* returned.
+*
+* @note
+*
+* This function assumes that if the device inserting data into the FIFO is
+* a byte device, the order of the bytes in each 32/64 bit word is from the most
+* significant byte to the least significant byte.
+*
+******************************************************************************/
+int XPacketFifoV200a_L0WriteDre(u32 RegBaseAddress,
+				u32 DataBaseAddress,
+				u8 *BufferPtr, u32 ByteCount)
+{
+	u32 FifoRoomLeft;
+	u32 BytesLeft;
+	u32 Width;
+
+	/* calculate how many slots are left in the FIFO
+	 */
+	FifoRoomLeft =
+		XIo_In32(RegBaseAddress + XPF_V200A_COUNT_STATUS_REG_OFFSET)
+		& XPF_V200A_COUNT_MASK;
+
+	/* determine the width of the FIFO
+	 */
+	Width = XIo_In32(RegBaseAddress + XPF_V200A_COUNT_STATUS_REG_OFFSET) &
+		XPF_V200A_FIFO_WIDTH_MASK;
+
+	/* from the width, determine how many bytes can be written to the FIFO
+	 */
+	if ((Width == XPF_V200A_FIFO_WIDTH_LEGACY_TYPE) ||
+	    (Width == XPF_V200A_FIFO_WIDTH_32BITS_TYPE)) {
+		FifoRoomLeft *= 4;
+	}
+	else if (Width == XPF_V200A_FIFO_WIDTH_64BITS_TYPE) {
+		FifoRoomLeft *= 8;
+	}
+
+	/* Make sure there's enough room in the FIFO */
+	if (FifoRoomLeft < ByteCount) {
+		return XST_PFIFO_NO_ROOM;
+	}
+
+	/* Determine the number of bytes to write until 32 bit alignment is
+	 * reached, then write those bytes to the FIFO one byte at a time
+	 */
+	BytesLeft = (unsigned) BufferPtr % sizeof(u32);
+	ByteCount -= BytesLeft;
+	while (BytesLeft--) {
+		XIo_Out8(DataBaseAddress, *BufferPtr++);
+	}
+
+	/* Write as many 32 bit words as we can */
+	BytesLeft = ByteCount;
+	while (BytesLeft >= sizeof(u32)) {
+		XIo_Out32(DataBaseAddress, *(u32 *) BufferPtr);
+		BufferPtr += sizeof(u32);
+		BytesLeft -= sizeof(u32);
+	}
+
+	/* Write remaining bytes */
+	while (BytesLeft--) {
+		XIo_Out8(DataBaseAddress, *BufferPtr++);
+	}
+
+	return XST_SUCCESS;
+
+}
+
+/*****************************************************************************/
+/**
+*
+* Read data from a FIFO and puts it into a specified buffer. The packet FIFO
+* is 32 bits wide such that an input buffer which is a series of bytes is
+* filled from the FIFO a word at a time. If the requested byte count is not
+* a multiple of 32 bit words, it is necessary for this function to format the
+* remaining 32 bit word from the FIFO into a series of bytes in the buffer.
+* There may be up to 3 extra bytes which must be extracted from the last word
+* of the FIFO and put into the buffer.
+*
+* @param RegBaseAddress is the base address of the FIFO registers.
+*
+* @param DataBaseAddress is the base address of the FIFO keyhole.
+*
+* @param BufferPtr points to the memory buffer to write the data into. This
+*        buffer must be 32 bit aligned or an alignment exception could be
+*        generated. Since this buffer is a byte buffer, the data is assumed to
+*        be endian independent.
+*
+* @param ByteCount contains the number of bytes to read from the FIFO. This
+*        number of bytes must be present in the FIFO or an error will be
+*        returned.
+*
+* @return
+*
+* XST_SUCCESS indicates the operation was successful.  If the number of
+* bytes specified by the byte count is not present in the FIFO
+* XST_PFIFO_LACK_OF_DATA is returned.
+* <br><br>
+* If the function was successful, the specified buffer is modified to contain
+* the bytes which were removed from the FIFO.
+*
+* @note
+*
+* Note that the exact number of bytes which are present in the FIFO is
+* not known by this function.  It can only check for a number of 32 bit
+* words such that if the byte count specified is incorrect, but is still
+* possible based on the number of words in the FIFO, up to 3 garbage bytes
+* may be present at the end of the buffer.
+* <br><br>
+* This function assumes that if the device consuming data from the FIFO is
+* a byte device, the order of the bytes to be consumed is from the most
+* significant byte to the least significant byte of a 32 bit word removed
+* from the FIFO.
+*
+******************************************************************************/
+static int Read32(u32 RegBaseAddress, u32 DataBaseAddress,
+		  u8 *BufferPtr, u32 ByteCount)
+{
+	u32 FifoCount;
+	u32 WordCount;
+	u32 ExtraByteCount;
+	u32 *WordBuffer = (u32 *) BufferPtr;
+
+	/* get the count of how many 32 bit words are in the FIFO, if there
+	 * aren't enough words to satisfy the request, return an error
+	 */
+
+	FifoCount =
+		XIo_In32(RegBaseAddress +
+			 XPF_V200A_COUNT_STATUS_REG_OFFSET) &
+		XPF_V200A_COUNT_MASK;
+
+	if ((FifoCount * XPF_V200A_32BIT_FIFO_WIDTH_BYTE_COUNT) < ByteCount) {
+		return XST_PFIFO_LACK_OF_DATA;
+	}
+
+	/* calculate the number of words to read from the FIFO before the word
+	 * containing the extra bytes, and calculate the number of extra bytes
+	 * the extra bytes are defined as those at the end of the buffer when
+	 * the buffer does not end on a 32 bit boundary
+	 */
+	WordCount = ByteCount / XPF_V200A_32BIT_FIFO_WIDTH_BYTE_COUNT;
+	ExtraByteCount = ByteCount % XPF_V200A_32BIT_FIFO_WIDTH_BYTE_COUNT;
+
+	/* Read the 32 bit words from the FIFO for all the buffer except the
+	 * last word which contains the extra bytes, the following code assumes
+	 * that the buffer is 32 bit aligned, otherwise an alignment exception
+	 * could be generated
+	 */
+	for (FifoCount = 0; FifoCount < WordCount; FifoCount++) {
+		WordBuffer[FifoCount] = XIo_In32(DataBaseAddress);
+	}
+
+	/* if there are extra bytes to handle, read the last word from the FIFO
+	 * and insert the extra bytes into the buffer
+	 */
+	if (ExtraByteCount > 0) {
+		u32 LastWord;
+		u8 *WordPtr;
+		u8 *ExtraBytesBuffer = (u8 *) (WordBuffer + WordCount);
+
+		/* get the last word from the FIFO for the extra bytes */
+
+		LastWord = XIo_In32(DataBaseAddress);
+
+		/* one extra byte in the last word, put the byte into the next
+		 * location of the buffer, bytes in a word of the FIFO are ordered
+		 * from most significant byte to least
+		 */
+		WordPtr = (u8 *) &LastWord;
+		if (ExtraByteCount == 1) {
+			ExtraBytesBuffer[0] = WordPtr[0];
+		}
+
+		/* two extra bytes in the last word, put each byte into the next
+		 * two locations of the buffer
+		 */
+		else if (ExtraByteCount == 2) {
+			ExtraBytesBuffer[0] = WordPtr[0];
+			ExtraBytesBuffer[1] = WordPtr[1];
+		}
+		/* three extra bytes in the last word, put each byte into the next
+		 * three locations of the buffer
+		 */
+		else if (ExtraByteCount == 3) {
+			ExtraBytesBuffer[0] = WordPtr[0];
+			ExtraBytesBuffer[1] = WordPtr[1];
+			ExtraBytesBuffer[2] = WordPtr[2];
+		}
+	}
+
+	return XST_SUCCESS;
+}
+
+
+/*****************************************************************************/
+/**
+*
+* Read data from a FIFO and puts it into a specified buffer. The packet FIFO
+* is 64 bits wide such that an input buffer which is a series of bytes is
+* filled from the FIFO a word at a time. If the requested byte count is not
+* a multiple of 64 bit words, it is necessary for this function to format the
+* remaining 64 bit word from the FIFO into a series of bytes in the buffer.
+* There may be up to 7 extra bytes which must be extracted from the last word
+* of the FIFO and put into the buffer.
+*
+* @param RegBaseAddress is the base address of the FIFO registers.
+*
+* @param DataBaseAddress is the base address of the FIFO keyhole.
+*
+* @param BufferPtr points to the memory buffer to write the data into. This
+*        buffer must be 32 bit aligned or an alignment exception could be
+*        generated. Since this buffer is a byte buffer, the data is assumed to
+*        be endian independent.
+*
+* @param ByteCount contains the number of bytes to read from the FIFO. This
+*        number of bytes must be present in the FIFO or an error will be
+*        returned.
+*
+* @return
+*
+* XST_SUCCESS indicates the operation was successful.  If the number of
+* bytes specified by the byte count is not present in the FIFO
+* XST_PFIFO_LACK_OF_DATA is returned.
+* <br><br>
+* If the function was successful, the specified buffer is modified to contain
+* the bytes which were removed from the FIFO.
+*
+* @note
+*
+* Note that the exact number of bytes which are present in the FIFO is
+* not known by this function.  It can only check for a number of 64 bit
+* words such that if the byte count specified is incorrect, but is still
+* possible based on the number of words in the FIFO, up to 7 garbage bytes
+* may be present at the end of the buffer.
+* <br><br>
+* This function assumes that if the device consuming data from the FIFO is
+* a byte device, the order of the bytes to be consumed is from the most
+* significant byte to the least significant byte of a 64 bit word removed
+* from the FIFO.
+*
+******************************************************************************/
+static int Read64(u32 RegBaseAddress, u32 DataBaseAddress,
+		  u8 *BufferPtr, u32 ByteCount)
+{
+	u32 FifoCount;
+	u32 WordCount;
+	u32 ExtraByteCount;
+	u32 *WordBuffer = (u32 *) BufferPtr;
+
+	/* get the count of how many 64 bit words are in the FIFO, if there
+	 * aren't enough words to satisfy the request, return an error
+	 */
+
+	FifoCount =
+		XIo_In32(RegBaseAddress +
+			 XPF_V200A_COUNT_STATUS_REG_OFFSET) &
+		XPF_V200A_COUNT_MASK;
+
+	if ((FifoCount * XPF_V200A_64BIT_FIFO_WIDTH_BYTE_COUNT) < ByteCount) {
+		return XST_PFIFO_LACK_OF_DATA;
+	}
+
+	/* calculate the number of words to read from the FIFO before the word
+	 * containing the extra bytes, and calculate the number of extra bytes
+	 * the extra bytes are defined as those at the end of the buffer when
+	 * the buffer does not end on a 32 bit boundary
+	 */
+	WordCount = ByteCount / XPF_V200A_64BIT_FIFO_WIDTH_BYTE_COUNT;
+	ExtraByteCount = ByteCount % XPF_V200A_64BIT_FIFO_WIDTH_BYTE_COUNT;
+
+	/* Read the 64 bit words from the FIFO for all the buffer except the
+	 * last word which contains the extra bytes, the following code assumes
+	 * that the buffer is 32 bit aligned, otherwise an alignment exception
+	 * could be generated. The MSWord must be read first followed by the
+	 * LSWord
+	 */
+	for (FifoCount = 0; FifoCount < WordCount; FifoCount++) {
+		WordBuffer[(FifoCount * 2)] = XIo_In32(DataBaseAddress);
+		WordBuffer[(FifoCount * 2) + 1] = XIo_In32(DataBaseAddress + 4);
+	}
+
+	/* if there are extra bytes to handle, read the last word from the FIFO
+	 * and insert the extra bytes into the buffer
+	 */
+	if (ExtraByteCount > 0) {
+		u32 MSLastWord;
+		u32 LSLastWord;
+		u8 *WordPtr;
+		u8 *ExtraBytesBuffer = (u8 *) (WordBuffer + (WordCount * 2));
+		u8 Index = 0;
+
+		/* get the last word from the FIFO for the extra bytes */
+
+		MSLastWord = XIo_In32(DataBaseAddress);
+		LSLastWord = XIo_In32(DataBaseAddress + 4);
+
+		/* four or more extra bytes in the last word, put the byte into
+		 * the next location of the buffer, bytes in a word of the FIFO
+		 * are ordered from most significant byte to least
+		 */
+		WordPtr = (u8 *) &MSLastWord;
+		if (ExtraByteCount >= 4) {
+			ExtraBytesBuffer[Index] = WordPtr[0];
+			ExtraBytesBuffer[Index + 1] = WordPtr[1];
+			ExtraBytesBuffer[Index + 2] = WordPtr[2];
+			ExtraBytesBuffer[Index + 3] = WordPtr[3];
+			ExtraByteCount = ExtraByteCount - 4;
+			MSLastWord = LSLastWord;
+			Index = 4;
+		}
+
+		/* one extra byte in the last word, put the byte into the next
+		 * location of the buffer, bytes in a word of the FIFO are
+		 * ordered from most significant byte to least
+		 */
+		if (ExtraByteCount == 1) {
+			ExtraBytesBuffer[Index] = WordPtr[0];
+		}
+
+		/* two extra bytes in the last word, put each byte into the next
+		 * two locations of the buffer
+		 */
+		else if (ExtraByteCount == 2) {
+			ExtraBytesBuffer[Index] = WordPtr[0];
+			ExtraBytesBuffer[Index + 1] = WordPtr[1];
+		}
+		/* three extra bytes in the last word, put each byte into the next
+		 * three locations of the buffer
+		 */
+		else if (ExtraByteCount == 3) {
+			ExtraBytesBuffer[Index] = WordPtr[0];
+			ExtraBytesBuffer[Index + 1] = WordPtr[1];
+			ExtraBytesBuffer[Index + 2] = WordPtr[2];
+		}
+	}
+
+	return XST_SUCCESS;
+}
+
+
+/*****************************************************************************/
+/**
+*
+* Write data into a 32 bit packet FIFO. The packet FIFO is 32 bits wide in this
+* function call such that an input buffer which is a series of bytes must be
+* written into the FIFO a word at a time. If the buffer is not a multiple of
+* 32 bit words, it is necessary for this function to format the remaining bytes
+* into a single 32 bit word to be inserted into the FIFO. This is necessary to
+* avoid any accesses past the end of the buffer.
+*
+* @param RegBaseAddress is the base address of the FIFO registers.
+*
+* @param DataBaseAddress is the base address of the FIFO keyhole.
+*
+* @param BufferPtr points to the memory buffer that data is to be read from
+*        and written into the FIFO. Since this buffer is a byte buffer, the
+*        data is assumed to be endian independent. This buffer must be 32 bit
+*        aligned or an alignment exception could be generated.
+* @param ByteCount contains the number of bytes to read from the buffer and to
+*        write to the FIFO.
+*
+* @return
+*
+* XST_SUCCESS is returned if the operation succeeded.  If there is not enough
+* room in the FIFO to hold the specified bytes, XST_PFIFO_NO_ROOM is
+* returned.
+*
+* @note
+*
+* This function assumes that if the device inserting data into the FIFO is
+* a byte device, the order of the bytes in each 32 bit word is from the most
+* significant byte to the least significant byte.
+*
+******************************************************************************/
+static int Write32(u32 RegBaseAddress, u32 DataBaseAddress,
+		   u8 *BufferPtr, u32 ByteCount)
+{
+	u32 FifoCount;
+	u32 WordCount;
+	u32 ExtraByteCount;
+	u32 *WordBuffer = (u32 *) BufferPtr;
+
+	/* get the count of how many words may be inserted into the FIFO */
+
+	FifoCount =
+		XIo_In32(RegBaseAddress +
+			 XPF_V200A_COUNT_STATUS_REG_OFFSET) &
+		XPF_V200A_COUNT_MASK;
+
+	/* Calculate the number of 32 bit words required to insert the
+	 * specified number of bytes in the FIFO and determine the number
+	 * of extra bytes if the buffer length is not a multiple of 32 bit
+	 * words
+	 */
+
+	WordCount = ByteCount / XPF_V200A_32BIT_FIFO_WIDTH_BYTE_COUNT;
+	ExtraByteCount = ByteCount % XPF_V200A_32BIT_FIFO_WIDTH_BYTE_COUNT;
+
+	/* take into account the extra bytes in the total word count */
+
+	if (ExtraByteCount > 0) {
+		WordCount++;
+	}
+
+	/* if there's not enough room in the FIFO to hold the specified
+	 * number of bytes, then indicate an error,
+	 */
+	if (FifoCount < WordCount) {
+		return XST_PFIFO_NO_ROOM;
+	}
+
+	/* readjust the word count to not take into account the extra bytes */
+
+	if (ExtraByteCount > 0) {
+		WordCount--;
+	}
+
+	/* Write all the bytes of the buffer which can be written as 32 bit
+	 * words into the FIFO, waiting to handle the extra bytes separately
+	 */
+	for (FifoCount = 0; FifoCount < WordCount; FifoCount++) {
+		XIo_Out32(DataBaseAddress, WordBuffer[FifoCount]);
+	}
+
+	/* if there are extra bytes to handle, extract them from the buffer
+	 * and create a 32 bit word and write it to the FIFO
+	 */
+	if (ExtraByteCount > 0) {
+		u32 LastWord = 0;
+		u8 *WordPtr;
+		u8 *ExtraBytesBuffer = (u8 *) (WordBuffer + WordCount);
+
+		/* one extra byte in the buffer, put the byte into the last word
+		 * to be inserted into the FIFO, perform this processing inline
+		 * rather than in a loop to help performance
+		 */
+		WordPtr = (u8 *) &LastWord;
+		if (ExtraByteCount == 1) {
+			WordPtr[0] = ExtraBytesBuffer[0];
+		}
+
+		/* two extra bytes in the buffer, put each byte into the last word
+		 * to be inserted into the FIFO
+		 */
+		else if (ExtraByteCount == 2) {
+			WordPtr[0] = ExtraBytesBuffer[0];
+			WordPtr[1] = ExtraBytesBuffer[1];
+		}
+
+		/* three extra bytes in the buffer, put each byte into the last
+		 * word to be inserted into the FIFO
+		 */
+		else if (ExtraByteCount == 3) {
+			WordPtr[0] = ExtraBytesBuffer[0];
+			WordPtr[1] = ExtraBytesBuffer[1];
+			WordPtr[2] = ExtraBytesBuffer[2];
+		}
+
+		/* write the last 32 bit word to the FIFO and return with
+		 * no errors
+		 */
+
+		XIo_Out32(DataBaseAddress, LastWord);
+	}
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************/
+/**
+*
+* Write data into a 64 bit packet FIFO. The packet FIFO is 64 bits wide in this
+* function call such that an input buffer which is a series of bytes must be
+* written into the FIFO a word at a time. If the buffer is not a multiple of
+* 64 bit words, it is necessary for this function to format the remaining bytes
+* into two 32 bit words to be inserted into the FIFO. This is necessary to
+* avoid any accesses past the end of the buffer.
+*
+* @param RegBaseAddress is the base address of the FIFO registers.
+*
+* @param DataBaseAddress is the base address of the FIFO keyhole.
+*
+* @param BufferPtr points to the memory buffer that data is to be read from
+*        and written into the FIFO. Since this buffer is a byte buffer, the
+*        data is assumed to be endian independent. This buffer must be 32 bit
+*        aligned or an alignment exception could be generated.
+*
+* @param ByteCount contains the number of bytes to read from the buffer and to
+*        write to the FIFO.
+*
+* @return
+*
+* XST_SUCCESS is returned if the operation succeeded.  If there is not enough
+* room in the FIFO to hold the specified bytes, XST_PFIFO_NO_ROOM is
+* returned.
+*
+* @note
+*
+* This function assumes that if the device inserting data into the FIFO is
+* a byte device, the order of the bytes in each 64 bit word is from the most
+* significant byte to the least significant byte.
+*
+******************************************************************************/
+static int Write64(u32 RegBaseAddress, u32 DataBaseAddress,
+		   u8 *BufferPtr, u32 ByteCount)
+{
+	u32 FifoCount;
+	u32 WordCount;
+	u32 ExtraByteCount;
+	u32 *WordBuffer = (u32 *) BufferPtr;
+
+	/* get the count of how many words may be inserted into the FIFO */
+
+	FifoCount =
+		XIo_In32(RegBaseAddress +
+			 XPF_V200A_COUNT_STATUS_REG_OFFSET) &
+		XPF_V200A_COUNT_MASK;
+
+	/* Calculate the number of 64 bit words required to insert the
+	 * specified number of bytes in the FIFO and determine the number
+	 * of extra bytes if the buffer length is not a multiple of 64 bit
+	 * words
+	 */
+
+	WordCount = ByteCount / XPF_V200A_64BIT_FIFO_WIDTH_BYTE_COUNT;
+	ExtraByteCount = ByteCount % XPF_V200A_64BIT_FIFO_WIDTH_BYTE_COUNT;
+
+	/* take into account the extra bytes in the total word count */
+
+	if (ExtraByteCount > 0) {
+		WordCount++;
+	}
+
+	/* if there's not enough room in the FIFO to hold the specified
+	 * number of bytes, then indicate an error,
+	 */
+	if (FifoCount < WordCount) {
+		return XST_PFIFO_NO_ROOM;
+	}
+
+	/* readjust the word count to not take into account the extra bytes */
+
+	if (ExtraByteCount > 0) {
+		WordCount--;
+	}
+
+	/* Write all the bytes of the buffer which can be written as 32 bit
+	 * words into the FIFO, waiting to handle the extra bytes separately
+	 * The MSWord must be written first followed by the LSWord
+	 */
+	for (FifoCount = 0; FifoCount < WordCount; FifoCount++) {
+		XIo_Out32(DataBaseAddress, WordBuffer[(FifoCount * 2)]);
+		XIo_Out32(DataBaseAddress + 4, WordBuffer[(FifoCount * 2) + 1]);
+	}
+
+	/* if there are extra bytes to handle, extract them from the buffer
+	 * and create two 32 bit words and write to the FIFO
+	 */
+	if (ExtraByteCount > 0) {
+
+		u32 MSLastWord = 0;
+		u32 LSLastWord = 0;
+		u8 Index = 0;
+		u8 *WordPtr;
+		u8 *ExtraBytesBuffer = (u8 *) (WordBuffer + (WordCount * 2));
+
+		/* four extra bytes in the buffer, put the bytes into the last word
+		 * to be inserted into the FIFO, perform this processing inline
+		 * rather than in a loop to help performance
+		 */
+		WordPtr = (u8 *) &MSLastWord;
+
+		if (ExtraByteCount >= 4) {
+			WordPtr[0] = ExtraBytesBuffer[Index];
+			WordPtr[1] = ExtraBytesBuffer[Index + 1];
+			WordPtr[2] = ExtraBytesBuffer[Index + 2];
+			WordPtr[3] = ExtraBytesBuffer[Index + 3];
+			ExtraByteCount = ExtraByteCount - 4;
+			WordPtr = (u8 *) &LSLastWord;
+			Index = 4;
+		}
+
+		/* one extra byte in the buffer, put the byte into the last word
+		 * to be inserted into the FIFO, perform this processing inline
+		 * rather than in a loop to help performance
+		 */
+		if (ExtraByteCount == 1) {
+			WordPtr[0] = ExtraBytesBuffer[Index];
+		}
+
+		/* two extra bytes in the buffer, put each byte into the last word
+		 * to be inserted into the FIFO
+		 */
+		else if (ExtraByteCount == 2) {
+			WordPtr[0] = ExtraBytesBuffer[Index];
+			WordPtr[1] = ExtraBytesBuffer[Index + 1];
+		}
+
+		/* three extra bytes in the buffer, put each byte into the last
+		 * word to be inserted into the FIFO
+		 */
+		else if (ExtraByteCount == 3) {
+			WordPtr[0] = ExtraBytesBuffer[Index];
+			WordPtr[1] = ExtraBytesBuffer[Index + 1];
+			WordPtr[2] = ExtraBytesBuffer[Index + 2];
+		}
+
+		/* write the last 64 bit word to the FIFO and return with no errors
+		 * The MSWord must be written first followed by the LSWord
+		 */
+		XIo_Out32(DataBaseAddress, MSLastWord);
+		XIo_Out32(DataBaseAddress + 4, LSLastWord);
+	}
+
+	return XST_SUCCESS;
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xpacket_fifo_l_v2_00_a.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xpacket_fifo_l_v2_00_a.h
--- linux-2.6.31.12/drivers/xilinx_common/xpacket_fifo_l_v2_00_a.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xpacket_fifo_l_v2_00_a.h	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,145 @@
+/* $Id: xpacket_fifo_l_v2_00_a.h,v 1.1 2006/12/13 14:23:01 imanuilov Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2003-2004 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xpacket_fifo_l_v2_00_a.h
+*
+* This header file contains identifiers and low-level (Level 0) driver
+* functions (or macros) that can be used to access the FIFO.  High-level driver
+* (Level 1) functions are defined in xpacket_fifo_v2_00_a.h.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- ------------------------------------------------------
+* 2.00a rpm  10/22/03  First release. Moved most of Level 1 driver functions
+*                      into this layer.
+* 2.00a rmm  02/24/04  Added L0WriteDre function.
+* 2.00a xd   10/27/04  Changed comments to support doxygen for API
+*                      documentation.
+* </pre>
+*
+*****************************************************************************/
+#ifndef XPACKET_FIFO_L_V200A_H	/* prevent circular inclusions */
+#define XPACKET_FIFO_L_V200A_H	/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xstatus.h"
+
+/************************** Constant Definitions *****************************/
+
+/** @name FIFO types
+ *
+ * These constants specify the FIFO type and are mutually exclusive
+ * @{
+ */
+#define XPF_V200A_READ_FIFO_TYPE      0	    /**< a read FIFO */
+#define XPF_V200A_WRITE_FIFO_TYPE     1	    /**< a write FIFO */
+/* @} */
+
+/** @name Register offsets
+ *
+ * These constants define the offsets to each of the registers from the
+ * register base address, each of the constants are a number of bytes
+ * @{
+ */
+#define XPF_V200A_RESET_REG_OFFSET            0UL /**< Reset register */
+#define XPF_V200A_MODULE_INFO_REG_OFFSET      0UL /**< MIR register */
+#define XPF_V200A_COUNT_STATUS_REG_OFFSET     4UL /**< Count/Status register */
+/* @} */
+
+/**
+ * This constant is used with the Reset Register
+ */
+#define XPF_V200A_RESET_FIFO_MASK             0x0000000A
+
+/** @name Occupancy/Vacancy Count Register constants
+ * @{
+ */
+/** Constant used with the Occupancy/Vacancy Count Register. This
+ *  register also contains FIFO status
+ */
+#define XPF_V200A_COUNT_MASK                  0x00FFFFFF
+#define XPF_V200A_DEADLOCK_MASK               0x20000000
+#define XPF_V200A_ALMOST_EMPTY_FULL_MASK      0x40000000
+#define XPF_V200A_EMPTY_FULL_MASK             0x80000000
+#define XPF_V200A_VACANCY_SCALED_MASK         0x10000000
+/* @} */
+
+/**
+ * This constant is used to mask the Width field
+ */
+#define XPF_V200A_FIFO_WIDTH_MASK             0x0E000000
+
+/** @name Width field
+ * @{
+ */
+/** Constant used with the Width field */
+#define XPF_V200A_FIFO_WIDTH_LEGACY_TYPE      0x00000000
+#define XPF_V200A_FIFO_WIDTH_8BITS_TYPE       0x02000000
+#define XPF_V200A_FIFO_WIDTH_16BITS_TYPE      0x04000000
+#define XPF_V200A_FIFO_WIDTH_32BITS_TYPE      0x06000000
+#define XPF_V200A_FIFO_WIDTH_64BITS_TYPE      0x08000000
+#define XPF_V200A_FIFO_WIDTH_128BITS_TYPE     0x0A000000
+#define XPF_V200A_FIFO_WIDTH_256BITS_TYPE     0x0C000000
+#define XPF_V200A_FIFO_WIDTH_512BITS_TYPE     0x0E000000
+/* @} */
+
+/** @name FIFO word width
+ * @{
+ */
+/** Width of a FIFO word */
+#define XPF_V200A_32BIT_FIFO_WIDTH_BYTE_COUNT       4
+#define XPF_V200A_64BIT_FIFO_WIDTH_BYTE_COUNT       8
+/* @} */
+
+/**************************** Type Definitions *******************************/
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/************************** Function Prototypes ******************************/
+
+int XPacketFifoV200a_L0Read(u32 RegBaseAddress,
+			    u32 DataBaseAddress,
+			    u8 *ReadBufferPtr, u32 ByteCount);
+
+int XPacketFifoV200a_L0Write(u32 RegBaseAddress,
+			     u32 DataBaseAddress,
+			     u8 *WriteBufferPtr, u32 ByteCount);
+
+int XPacketFifoV200a_L0WriteDre(u32 RegBaseAddress,
+				u32 DataBaseAddress,
+				u8 *BufferPtr, u32 ByteCount);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xpacket_fifo_v2_00_a.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xpacket_fifo_v2_00_a.c
--- linux-2.6.31.12/drivers/xilinx_common/xpacket_fifo_v2_00_a.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xpacket_fifo_v2_00_a.c	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,329 @@
+/* $Id: xpacket_fifo_v2_00_a.c,v 1.1 2006/12/13 14:23:11 imanuilov Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002-2003 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xpacket_fifo_v2_00_a.c
+*
+* Contains functions for the XPacketFifoV200a component. See
+* xpacket_fifo_v2_00_a.h for more information about the component.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 2.00a ecm 12/30/02  First release
+* 2.00a rmm 05/14/03  Fixed diab compiler warnings
+* 2.00a rpm 10/22/03  Created and made use of Level 0 driver
+* 2.00a rmm 02/24/04  Added WriteDRE function.
+* 2.00a xd  10/27/04  Changed comments to support doxygen for API
+*                     documentation.
+* </pre>
+*
+*****************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xio.h"
+#include "xstatus.h"
+#include "xpacket_fifo_v2_00_a.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************* Variable Definitions ******************************/
+
+
+/************************** Function Prototypes ******************************/
+
+
+/*****************************************************************************/
+/**
+*
+* This function initializes a packet FIFO.  Initialization resets the
+* FIFO such that it's empty and ready to use.
+*
+* @param    InstancePtr contains a pointer to the FIFO to operate on.
+*
+* @param    RegBaseAddress contains the base address of the registers for
+*           the packet FIFO.
+*
+* @param    DataBaseAddress contains the base address of the data for
+*           the packet FIFO.
+*
+* @return   Always returns XST_SUCCESS.
+*
+* @note     None.
+*
+******************************************************************************/
+int XPacketFifoV200a_Initialize(XPacketFifoV200a * InstancePtr,
+				u32 RegBaseAddress, u32 DataBaseAddress)
+{
+	/* assert to verify input argument are valid */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+
+	/* initialize the component variables to the specified state */
+
+	InstancePtr->RegBaseAddress = RegBaseAddress;
+	InstancePtr->DataBaseAddress = DataBaseAddress;
+	InstancePtr->IsReady = XCOMPONENT_IS_READY;
+
+	/* reset the FIFO such that it's empty and ready to use and indicate the
+	 * initialization was successful, note that the is ready variable must be
+	 * set prior to calling the reset function to prevent an assert
+	 */
+	XPF_V200A_RESET(InstancePtr);
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************/
+/**
+*
+* This function performs a self-test on the specified packet FIFO.  The self
+* test resets the FIFO and reads a register to determine if it is the correct
+* reset value.  This test is destructive in that any data in the FIFO will
+* be lost.
+*
+* @param InstancePtr is a pointer to the packet FIFO to be operated on.
+*
+* @param FifoType specifies the type of FIFO, read or write, for the self test.
+*        The FIFO type is specified by the values XPF_V200A_READ_FIFO_TYPE or
+*        XPF_V200A_WRITE_FIFO_TYPE.
+*
+* @return
+*
+* XST_SUCCESS is returned if the selftest is successful, or
+* XST_PFIFO_BAD_REG_VALUE indicating that the value read back from the
+* occupancy/vacancy count register after a reset does not match the
+* specified reset value.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+int XPacketFifoV200a_SelfTest(XPacketFifoV200a * InstancePtr, u32 FifoType)
+{
+	u32 Register;
+
+	/* assert to verify valid input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID((FifoType == XPF_V200A_READ_FIFO_TYPE) ||
+			(FifoType == XPF_V200A_WRITE_FIFO_TYPE));
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	/* reset the FIFO and then check to make sure the occupancy/vacancy
+	 * register contents are correct for a reset condition
+	 */
+	XPF_V200A_RESET(InstancePtr);
+
+	Register = XIo_In32(InstancePtr->RegBaseAddress +
+			    XPF_V200A_COUNT_STATUS_REG_OFFSET);
+
+	/* check the value of the register to ensure that it's correct for the
+	 * specified FIFO type since both FIFO types reset to empty, but a bit
+	 * in the register changes definition based upon FIFO type
+	 */
+
+	if (FifoType == XPF_V200A_READ_FIFO_TYPE) {
+		/* check the register value for a read FIFO which should be empty */
+
+		if ((Register & ~(XPF_V200A_FIFO_WIDTH_MASK)) !=
+		    XPF_V200A_EMPTY_FULL_MASK) {
+			return XST_PFIFO_BAD_REG_VALUE;
+		}
+	}
+	else {
+		/* check the register value for a write FIFO which should not be full
+		 * on reset
+		 */
+		if (((Register & ~(XPF_V200A_FIFO_WIDTH_MASK) &
+		      XPF_V200A_EMPTY_FULL_MASK)) != 0) {
+			return XST_PFIFO_BAD_REG_VALUE;
+		}
+	}
+
+	/* check the register value for the proper FIFO width */
+
+	Register &= ~XPF_V200A_EMPTY_FULL_MASK;
+
+	if (((Register & XPF_V200A_FIFO_WIDTH_MASK) !=
+	     XPF_V200A_FIFO_WIDTH_LEGACY_TYPE) &&
+	    ((Register & XPF_V200A_FIFO_WIDTH_MASK) !=
+	     XPF_V200A_FIFO_WIDTH_32BITS_TYPE) &&
+	    ((Register & XPF_V200A_FIFO_WIDTH_MASK) !=
+	     XPF_V200A_FIFO_WIDTH_64BITS_TYPE)) {
+		return XST_PFIFO_BAD_REG_VALUE;
+	}
+
+	/* the test was successful */
+
+	return XST_SUCCESS;
+}
+
+
+/*****************************************************************************/
+/**
+*
+* Read data from a FIFO and puts it into a specified buffer. This function
+* invokes the Level 0 driver function to read the FIFO.
+*
+* @param InstancePtr contains a pointer to the FIFO to operate on.
+*
+* @param BufferPtr points to the memory buffer to write the data into. This
+*        buffer must be 32 bit aligned or an alignment exception could be
+*        generated. Since this buffer is a byte buffer, the data is assumed to
+*        be endian independent.
+*
+* @param ByteCount contains the number of bytes to read from the FIFO. This
+*        number of bytes must be present in the FIFO or an error will be
+*        returned.
+*
+* @return
+* - XST_SUCCESS if the operation was successful
+*   <br><br>
+* - XST_PFIFO_LACK_OF_DATA if the number of bytes specified by the byte count
+*   is not present in the FIFO.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+int XPacketFifoV200a_Read(XPacketFifoV200a * InstancePtr,
+			  u8 *BufferPtr, u32 ByteCount)
+{
+	/* assert to verify valid input arguments including 32 bit alignment of
+	 * the buffer pointer
+	 */
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(BufferPtr != NULL);
+	XASSERT_NONVOID(((u32) BufferPtr &
+			 (XPF_V200A_32BIT_FIFO_WIDTH_BYTE_COUNT - 1)) == 0);
+	XASSERT_NONVOID(ByteCount != 0);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	return XPacketFifoV200a_L0Read(InstancePtr->RegBaseAddress,
+				       InstancePtr->DataBaseAddress,
+				       BufferPtr, ByteCount);
+}
+
+/*****************************************************************************/
+/**
+*
+* Write data into a packet FIFO. This function invokes the Level 0 driver
+* function to read the FIFO.
+*
+* @param InstancePtr contains a pointer to the FIFO to operate on.
+*
+* @param BufferPtr points to the memory buffer that data is to be read from
+*        and written into the FIFO. Since this buffer is a byte buffer, the
+*        data is assumed to be endian independent. This buffer must be 32 bit
+*        aligned or an alignment exception could be generated.
+*
+* @param ByteCount contains the number of bytes to read from the buffer and to
+*        write to the FIFO.
+*
+* @return
+* - XST_SUCCESS is returned if the operation succeeded.
+*   <br><br>
+* - XST_PFIFO_NO_ROOM is returned if there is not enough room in the FIFO to
+*   hold the specified bytes.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+int XPacketFifoV200a_Write(XPacketFifoV200a * InstancePtr,
+			   u8 *BufferPtr, u32 ByteCount)
+{
+	/* assert to verify valid input arguments including 32 bit alignment of
+	 * the buffer pointer
+	 */
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(BufferPtr != NULL);
+	XASSERT_NONVOID(((u32) BufferPtr &
+			 (XPF_V200A_32BIT_FIFO_WIDTH_BYTE_COUNT - 1)) == 0);
+	XASSERT_NONVOID(ByteCount != 0);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+
+	return XPacketFifoV200a_L0Write(InstancePtr->RegBaseAddress,
+					InstancePtr->DataBaseAddress,
+					BufferPtr, ByteCount);
+}
+
+
+/*****************************************************************************/
+/**
+*
+* Write data into a packet FIFO configured with the Data Realignment engine
+* (DRE). There are no alignment restrictions. The FIFO can be written on any
+* byte boundary. The FIFO must be at least 32 bits wide.
+*
+* @param InstancePtr contains a pointer to the FIFO to operate on.
+*
+* @param BufferPtr points to the memory buffer that data is to be read from
+*        and written into the FIFO. Since this buffer is a byte buffer, the
+*        data is assumed to be endian independent.
+*
+* @param ByteCount contains the number of bytes to read from the buffer and to
+*        write to the FIFO.
+*
+* @return
+*
+* XST_SUCCESS is returned if the operation succeeded.  If there is not enough
+* room in the FIFO to hold the specified bytes, XST_PFIFO_NO_ROOM is
+* returned.
+*
+* @note
+*
+* This function assumes that if the device inserting data into the FIFO is
+* a byte device, the order of the bytes in each 32/64 bit word is from the most
+* significant byte to the least significant byte.
+*
+******************************************************************************/
+int XPacketFifoV200a_WriteDre(XPacketFifoV200a * InstancePtr,
+			      u8 *BufferPtr, u32 ByteCount)
+{
+	/* assert to verify valid input arguments */
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(BufferPtr != NULL);
+	XASSERT_NONVOID(ByteCount != 0);
+	XASSERT_NONVOID(InstancePtr->IsReady == XCOMPONENT_IS_READY);
+
+	return XPacketFifoV200a_L0WriteDre(InstancePtr->RegBaseAddress,
+					   InstancePtr->DataBaseAddress,
+					   BufferPtr, ByteCount);
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xpacket_fifo_v2_00_a.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xpacket_fifo_v2_00_a.h
--- linux-2.6.31.12/drivers/xilinx_common/xpacket_fifo_v2_00_a.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xpacket_fifo_v2_00_a.h	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,281 @@
+/* $Id: xpacket_fifo_v2_00_a.h,v 1.1 2006/12/13 14:23:19 imanuilov Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002-2004 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xpacket_fifo_v2_00_a.h
+*
+* This component is a common component because it's primary purpose is to
+* prevent code duplication in drivers. A driver which must handle a packet
+* FIFO uses this component rather than directly manipulating a packet FIFO.
+*
+* A FIFO is a device which has dual port memory such that one user may be
+* inserting data into the FIFO while another is consuming data from the FIFO.
+* A packet FIFO is designed for use with packet protocols such as Ethernet and
+* ATM.  It is typically only used with devices when DMA and/or Scatter Gather
+* is used.  It differs from a nonpacket FIFO in that it does not provide any
+* interrupts for thresholds of the FIFO such that it is less useful without
+* DMA.
+*
+* @note
+*
+* This component has the capability to generate an interrupt when an error
+* condition occurs.  It is the user's responsibility to provide the interrupt
+* processing to handle the interrupt. This component provides the ability to
+* determine if that interrupt is active, a deadlock condition, and the ability
+* to reset the FIFO to clear the condition. In this condition, the device which
+* is using the FIFO should also be reset to prevent other problems. This error
+* condition could occur as a normal part of operation if the size of the FIFO
+* is not setup correctly.  See the hardware IP specification for more details.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -----------------------------------------------
+* 2.00a ecm 12/30/02  First release
+* 2.00a rpm 10/22/03  Created and made use of Level 0 driver
+* 2.00a rmm 02/24/04  Added WriteDre function.
+* 2.00a xd  10/27/04  Changed comments to support doxygen for API
+*                     documentation.
+* </pre>
+*
+*****************************************************************************/
+#ifndef XPACKET_FIFO_V200A_H	/* prevent circular inclusions */
+#define XPACKET_FIFO_V200A_H	/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xstatus.h"
+#include "xpacket_fifo_l_v2_00_a.h"
+
+/************************** Constant Definitions *****************************/
+
+/* See the low-level header file for constant definitions */
+
+/**************************** Type Definitions *******************************/
+
+/**
+ * The XPacketFifo driver instance data. The driver is required to allocate a
+ * variable of this type for every packet FIFO in the device.
+ */
+typedef struct {
+	u32 RegBaseAddress; /**< Base address of registers */
+	u32 IsReady;	    /**< Device is initialized and ready */
+	u32 DataBaseAddress;/**< Base address of data for FIFOs */
+} XPacketFifoV200a;
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+/*****************************************************************************/
+/**
+*
+* Reset the specified packet FIFO.  Resetting a FIFO will cause any data
+* contained in the FIFO to be lost.
+*
+* @param    InstancePtr contains a pointer to the FIFO to operate on.
+*
+* @return   None.
+*
+* @note     C Signature: void XPF_V200A_RESET(XPacketFifoV200a *InstancePtr)
+*
+******************************************************************************/
+#define XPF_V200A_RESET(InstancePtr) \
+    XIo_Out32((InstancePtr)->RegBaseAddress + XPF_V200A_RESET_REG_OFFSET, XPF_V200A_RESET_FIFO_MASK);
+
+
+/*****************************************************************************/
+/**
+*
+* Get the occupancy count for a read packet FIFO and the vacancy count for a
+* write packet FIFO. These counts indicate the number of 32-bit words
+* contained (occupancy) in the FIFO or the number of 32-bit words available
+* to write (vacancy) in the FIFO.
+*
+* @param    InstancePtr contains a pointer to the FIFO to operate on.
+*
+* @return   The occupancy or vacancy count for the specified packet FIFO.
+*
+* @note
+*
+* C Signature: u32 XPF_V200A_GET_COUNT(XPacketFifoV200a *InstancePtr)
+*
+******************************************************************************/
+#define XPF_V200A_GET_COUNT(InstancePtr) \
+    (XIo_In32((InstancePtr)->RegBaseAddress + XPF_V200A_COUNT_STATUS_REG_OFFSET) & \
+    XPF_V200A_COUNT_MASK)
+
+
+/*****************************************************************************/
+/**
+*
+* Determine if the specified packet FIFO is almost empty. Almost empty is
+* defined for a read FIFO when there is only one data word in the FIFO.
+*
+* @param InstancePtr contains a pointer to the FIFO to operate on.
+*
+* @return
+*
+* TRUE if the packet FIFO is almost empty, FALSE otherwise.
+*
+* @note
+*
+* C Signature: u32 XPF_V200A_IS_ALMOST_EMPTY(XPacketFifoV200a *InstancePtr)
+*
+******************************************************************************/
+#define XPF_V200A_IS_ALMOST_EMPTY(InstancePtr) \
+    (XIo_In32((InstancePtr)->RegBaseAddress + XPF_V200A_COUNT_STATUS_REG_OFFSET) & \
+    XPF_V200A_ALMOST_EMPTY_FULL_MASK)
+
+
+/*****************************************************************************/
+/**
+*
+* Determine if the specified packet FIFO is almost full. Almost full is
+* defined for a write FIFO when there is only one available data word in the
+* FIFO.
+*
+* @param InstancePtr contains a pointer to the FIFO to operate on.
+*
+* @return
+*
+* TRUE if the packet FIFO is almost full, FALSE otherwise.
+*
+* @note
+*
+* C Signature: u32 XPF_V200A_IS_ALMOST_FULL(XPacketFifoV200a *InstancePtr)
+*
+******************************************************************************/
+#define XPF_V200A_IS_ALMOST_FULL(InstancePtr) \
+    (XIo_In32((InstancePtr)->RegBaseAddress + XPF_V200A_COUNT_STATUS_REG_OFFSET) & \
+    XPF_V200A_ALMOST_EMPTY_FULL_MASK)
+
+
+/*****************************************************************************/
+/**
+*
+* Determine if the specified packet FIFO is empty. This applies only to a
+* read FIFO.
+*
+* @param InstancePtr contains a pointer to the FIFO to operate on.
+*
+* @return
+*
+* TRUE if the packet FIFO is empty, FALSE otherwise.
+*
+* @note
+*
+* C Signature: u32 XPF_V200A_IS_EMPTY(XPacketFifoV200a *InstancePtr)
+*
+******************************************************************************/
+#define XPF_V200A_IS_EMPTY(InstancePtr) \
+    (XIo_In32((InstancePtr)->RegBaseAddress + XPF_V200A_COUNT_STATUS_REG_OFFSET) & \
+    XPF_V200A_EMPTY_FULL_MASK)
+
+
+/*****************************************************************************/
+/**
+*
+* Determine if the specified packet FIFO is full. This applies only to a
+* write FIFO.
+*
+* @param InstancePtr contains a pointer to the FIFO to operate on.
+*
+* @return
+*
+* TRUE if the packet FIFO is full, FALSE otherwise.
+*
+* @note
+*
+* C Signature: u32 XPF_V200A_IS_FULL(XPacketFifoV200a *InstancePtr)
+*
+******************************************************************************/
+#define XPF_V200A_IS_FULL(InstancePtr) \
+    (XIo_In32((InstancePtr)->RegBaseAddress + XPF_V200A_COUNT_STATUS_REG_OFFSET) & \
+    XPF_V200A_EMPTY_FULL_MASK)
+
+
+/*****************************************************************************/
+/**
+*
+* Determine if the specified packet FIFO is deadlocked.  This condition occurs
+* when the FIFO is full and empty at the same time and is caused by a packet
+* being written to the FIFO which exceeds the total data capacity of the FIFO.
+* It occurs because of the mark/restore features of the packet FIFO which allow
+* retransmission of a packet. The software should reset the FIFO and any devices
+* using the FIFO when this condition occurs.
+*
+* @param InstancePtr contains a pointer to the FIFO to operate on.
+*
+* @return
+*
+* TRUE if the packet FIFO is deadlocked, FALSE otherwise.
+*
+* @note
+*
+* This component has the capability to generate an interrupt when an error
+* condition occurs.  It is the user's responsibility to provide the interrupt
+* processing to handle the interrupt. This function provides the ability to
+* determine if a deadlock condition, and the ability to reset the FIFO to
+* clear the condition.
+* <br><br>
+* In this condition, the device which is using the FIFO should also be reset
+* to prevent other problems. This error condition could occur as a normal part
+* of operation if the size of the FIFO is not setup correctly.
+* <br><br>
+* C Signature: u32 XPF_V200A_IS_DEADLOCKED(XPacketFifoV200a *InstancePtr)
+*
+******************************************************************************/
+#define XPF_V200A_IS_DEADLOCKED(InstancePtr) \
+    (XIo_In32((InstancePtr)->RegBaseAddress + XPF_V200A_COUNT_STATUS_REG_OFFSET) & \
+    XPF_V200A_DEADLOCK_MASK)
+
+
+/************************** Function Prototypes ******************************/
+
+/**
+ * Standard functions
+ */
+int XPacketFifoV200a_Initialize(XPacketFifoV200a * InstancePtr,
+				u32 RegBaseAddress, u32 DataBaseAddress);
+int XPacketFifoV200a_SelfTest(XPacketFifoV200a * InstancePtr, u32 FifoType);
+
+/**
+ * Data functions
+ */
+int XPacketFifoV200a_Read(XPacketFifoV200a * InstancePtr,
+			  u8 *ReadBufferPtr, u32 ByteCount);
+int XPacketFifoV200a_Write(XPacketFifoV200a * InstancePtr,
+			   u8 *WriteBufferPtr, u32 ByteCount);
+int XPacketFifoV200a_WriteDre(XPacketFifoV200a * InstancePtr,
+			      u8 *WriteBufferPtr, u32 ByteCount);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xstatus.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xstatus.h
--- linux-2.6.31.12/drivers/xilinx_common/xstatus.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xstatus.h	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,357 @@
+/* $Id: xstatus.h,v 1.1 2006/12/13 14:23:26 imanuilov Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xstatus.h
+*
+* This file contains Xilinx software status codes.  Status codes have their
+* own data type called int.  These codes are used throughout the Xilinx
+* device drivers.
+*
+******************************************************************************/
+
+#ifndef XSTATUS_H		/* prevent circular inclusions */
+#define XSTATUS_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+/************************** Constant Definitions *****************************/
+
+/*********************** Common statuses 0 - 500 *****************************/
+
+#define XST_SUCCESS                     0L
+#define XST_FAILURE                     1L
+#define XST_DEVICE_NOT_FOUND            2L
+#define XST_DEVICE_BLOCK_NOT_FOUND      3L
+#define XST_INVALID_VERSION             4L
+#define XST_DEVICE_IS_STARTED           5L
+#define XST_DEVICE_IS_STOPPED           6L
+#define XST_FIFO_ERROR                  7L	/* an error occurred during an
+						   operation with a FIFO such as
+						   an underrun or overrun, this
+						   error requires the device to
+						   be reset */
+#define XST_RESET_ERROR                 8L	/* an error occurred which requires
+						   the device to be reset */
+#define XST_DMA_ERROR                   9L	/* a DMA error occurred, this error
+						   typically requires the device
+						   using the DMA to be reset */
+#define XST_NOT_POLLED                  10L	/* the device is not configured for
+						   polled mode operation */
+#define XST_FIFO_NO_ROOM                11L	/* a FIFO did not have room to put
+						   the specified data into */
+#define XST_BUFFER_TOO_SMALL            12L	/* the buffer is not large enough
+						   to hold the expected data */
+#define XST_NO_DATA                     13L	/* there was no data available */
+#define XST_REGISTER_ERROR              14L	/* a register did not contain the
+						   expected value */
+#define XST_INVALID_PARAM               15L	/* an invalid parameter was passed
+						   into the function */
+#define XST_NOT_SGDMA                   16L	/* the device is not configured for
+						   scatter-gather DMA operation */
+#define XST_LOOPBACK_ERROR              17L	/* a loopback test failed */
+#define XST_NO_CALLBACK                 18L	/* a callback has not yet been
+						   registered */
+#define XST_NO_FEATURE                  19L	/* device is not configured with
+						   the requested feature */
+#define XST_NOT_INTERRUPT               20L	/* device is not configured for
+						   interrupt mode operation */
+#define XST_DEVICE_BUSY                 21L	/* device is busy */
+#define XST_ERROR_COUNT_MAX             22L	/* the error counters of a device
+						   have maxed out */
+#define XST_IS_STARTED                  23L	/* used when part of device is
+						   already started i.e.
+						   sub channel */
+#define XST_IS_STOPPED                  24L	/* used when part of device is
+						   already stopped i.e.
+						   sub channel */
+#define XST_DATA_LOST                   26L	/* driver defined error */
+#define XST_RECV_ERROR                  27L	/* generic receive error */
+#define XST_SEND_ERROR                  28L	/* generic transmit error */
+#define XST_NOT_ENABLED                 29L	/* a requested service is not
+						   available because it has not
+						   been enabled */
+
+/***************** Utility Component statuses 401 - 500  *********************/
+
+#define XST_MEMTEST_FAILED              401L	/* memory test failed */
+
+
+/***************** Common Components statuses 501 - 1000 *********************/
+
+/********************* Packet Fifo statuses 501 - 510 ************************/
+
+#define XST_PFIFO_LACK_OF_DATA          501L	/* not enough data in FIFO   */
+#define XST_PFIFO_NO_ROOM               502L	/* not enough room in FIFO   */
+#define XST_PFIFO_BAD_REG_VALUE         503L	/* self test, a register value
+						   was invalid after reset */
+#define XST_PFIFO_ERROR                 504L	/* generic packet FIFO error */
+#define XST_PFIFO_DEADLOCK              505L	/* packet FIFO is reporting
+						 * empty and full simultaneously
+						 */
+
+/************************** DMA statuses 511 - 530 ***************************/
+
+#define XST_DMA_TRANSFER_ERROR          511L	/* self test, DMA transfer
+						   failed */
+#define XST_DMA_RESET_REGISTER_ERROR    512L	/* self test, a register value
+						   was invalid after reset */
+#define XST_DMA_SG_LIST_EMPTY           513L	/* scatter gather list contains
+						   no buffer descriptors ready
+						   to be processed */
+#define XST_DMA_SG_IS_STARTED           514L	/* scatter gather not stopped */
+#define XST_DMA_SG_IS_STOPPED           515L	/* scatter gather not running */
+#define XST_DMA_SG_LIST_FULL            517L	/* all the buffer desciptors of
+						   the scatter gather list are
+						   being used */
+#define XST_DMA_SG_BD_LOCKED            518L	/* the scatter gather buffer
+						   descriptor which is to be
+						   copied over in the scatter
+						   list is locked */
+#define XST_DMA_SG_NOTHING_TO_COMMIT    519L	/* no buffer descriptors have been
+						   put into the scatter gather
+						   list to be commited */
+#define XST_DMA_SG_COUNT_EXCEEDED       521L	/* the packet count threshold
+						   specified was larger than the
+						   total # of buffer descriptors
+						   in the scatter gather list */
+#define XST_DMA_SG_LIST_EXISTS          522L	/* the scatter gather list has
+						   already been created */
+#define XST_DMA_SG_NO_LIST              523L	/* no scatter gather list has
+						   been created */
+#define XST_DMA_SG_BD_NOT_COMMITTED     524L	/* the buffer descriptor which was
+						   being started was not committed
+						   to the list */
+#define XST_DMA_SG_NO_DATA              525L	/* the buffer descriptor to start
+						   has already been used by the
+						   hardware so it can't be reused
+						 */
+#define XST_DMA_SG_LIST_ERROR           526L	/* general purpose list access
+						   error */
+#define XST_DMA_BD_ERROR                527L	/* general buffer descriptor
+						   error */
+
+/************************** IPIF statuses 531 - 550 ***************************/
+
+#define XST_IPIF_REG_WIDTH_ERROR        531L	/* an invalid register width
+						   was passed into the function */
+#define XST_IPIF_RESET_REGISTER_ERROR   532L	/* the value of a register at
+						   reset was not valid */
+#define XST_IPIF_DEVICE_STATUS_ERROR    533L	/* a write to the device interrupt
+						   status register did not read
+						   back correctly */
+#define XST_IPIF_DEVICE_ACK_ERROR       534L	/* the device interrupt status
+						   register did not reset when
+						   acked */
+#define XST_IPIF_DEVICE_ENABLE_ERROR    535L	/* the device interrupt enable
+						   register was not updated when
+						   other registers changed */
+#define XST_IPIF_IP_STATUS_ERROR        536L	/* a write to the IP interrupt
+						   status register did not read
+						   back correctly */
+#define XST_IPIF_IP_ACK_ERROR           537L	/* the IP interrupt status register
+						   did not reset when acked */
+#define XST_IPIF_IP_ENABLE_ERROR        538L	/* IP interrupt enable register was
+						   not updated correctly when other
+						   registers changed */
+#define XST_IPIF_DEVICE_PENDING_ERROR   539L	/* The device interrupt pending
+						   register did not indicate the
+						   expected value */
+#define XST_IPIF_DEVICE_ID_ERROR        540L	/* The device interrupt ID register
+						   did not indicate the expected
+						   value */
+#define XST_IPIF_ERROR                  541L	/* generic ipif error */
+
+/****************** Device specific statuses 1001 - 4095 *********************/
+
+/********************* Ethernet statuses 1001 - 1050 *************************/
+
+#define XST_EMAC_MEMORY_SIZE_ERROR  1001L	/* Memory space is not big enough
+						 * to hold the minimum number of
+						 * buffers or descriptors */
+#define XST_EMAC_MEMORY_ALLOC_ERROR 1002L	/* Memory allocation failed */
+#define XST_EMAC_MII_READ_ERROR     1003L	/* MII read error */
+#define XST_EMAC_MII_BUSY           1004L	/* An MII operation is in progress */
+#define XST_EMAC_OUT_OF_BUFFERS     1005L	/* Adapter is out of buffers */
+#define XST_EMAC_PARSE_ERROR        1006L	/* Invalid adapter init string */
+#define XST_EMAC_COLLISION_ERROR    1007L	/* Excess deferral or late
+						 * collision on polled send */
+
+/*********************** UART statuses 1051 - 1075 ***************************/
+#define XST_UART
+
+#define XST_UART_INIT_ERROR         1051L
+#define XST_UART_START_ERROR        1052L
+#define XST_UART_CONFIG_ERROR       1053L
+#define XST_UART_TEST_FAIL          1054L
+#define XST_UART_BAUD_ERROR         1055L
+#define XST_UART_BAUD_RANGE         1056L
+
+
+/************************ IIC statuses 1076 - 1100 ***************************/
+
+#define XST_IIC_SELFTEST_FAILED         1076	/* self test failed            */
+#define XST_IIC_BUS_BUSY                1077	/* bus found busy              */
+#define XST_IIC_GENERAL_CALL_ADDRESS    1078	/* mastersend attempted with   */
+					     /* general call address        */
+#define XST_IIC_STAND_REG_RESET_ERROR   1079	/* A non parameterizable reg   */
+					     /* value after reset not valid */
+#define XST_IIC_TX_FIFO_REG_RESET_ERROR 1080	/* Tx fifo included in design  */
+					     /* value after reset not valid */
+#define XST_IIC_RX_FIFO_REG_RESET_ERROR 1081	/* Rx fifo included in design  */
+					     /* value after reset not valid */
+#define XST_IIC_TBA_REG_RESET_ERROR     1082	/* 10 bit addr incl in design  */
+					     /* value after reset not valid */
+#define XST_IIC_CR_READBACK_ERROR       1083	/* Read of the control register */
+					     /* didn't return value written */
+#define XST_IIC_DTR_READBACK_ERROR      1084	/* Read of the data Tx reg     */
+					     /* didn't return value written */
+#define XST_IIC_DRR_READBACK_ERROR      1085	/* Read of the data Receive reg */
+					     /* didn't return value written */
+#define XST_IIC_ADR_READBACK_ERROR      1086	/* Read of the data Tx reg     */
+					     /* didn't return value written */
+#define XST_IIC_TBA_READBACK_ERROR      1087	/* Read of the 10 bit addr reg */
+					     /* didn't return written value */
+#define XST_IIC_NOT_SLAVE               1088	/* The device isn't a slave    */
+
+/*********************** ATMC statuses 1101 - 1125 ***************************/
+
+#define XST_ATMC_ERROR_COUNT_MAX    1101L	/* the error counters in the ATM
+						   controller hit the max value
+						   which requires the statistics
+						   to be cleared */
+
+/*********************** Flash statuses 1126 - 1150 **************************/
+
+#define XST_FLASH_BUSY                1126L	/* Flash is erasing or programming */
+#define XST_FLASH_READY               1127L	/* Flash is ready for commands */
+#define XST_FLASH_ERROR               1128L	/* Flash had detected an internal
+						   error. Use XFlash_DeviceControl
+						   to retrieve device specific codes */
+#define XST_FLASH_ERASE_SUSPENDED     1129L	/* Flash is in suspended erase state */
+#define XST_FLASH_WRITE_SUSPENDED     1130L	/* Flash is in suspended write state */
+#define XST_FLASH_PART_NOT_SUPPORTED  1131L	/* Flash type not supported by
+						   driver */
+#define XST_FLASH_NOT_SUPPORTED       1132L	/* Operation not supported */
+#define XST_FLASH_TOO_MANY_REGIONS    1133L	/* Too many erase regions */
+#define XST_FLASH_TIMEOUT_ERROR       1134L	/* Programming or erase operation
+						   aborted due to a timeout */
+#define XST_FLASH_ADDRESS_ERROR       1135L	/* Accessed flash outside its
+						   addressible range */
+#define XST_FLASH_ALIGNMENT_ERROR     1136L	/* Write alignment error */
+#define XST_FLASH_BLOCKING_CALL_ERROR 1137L	/* Couldn't return immediately from
+						   write/erase function with
+						   XFL_NON_BLOCKING_WRITE/ERASE
+						   option cleared */
+#define XST_FLASH_CFI_QUERY_ERROR     1138L	/* Failed to query the device */
+
+/*********************** SPI statuses 1151 - 1175 ****************************/
+
+#define XST_SPI_MODE_FAULT          1151	/* master was selected as slave */
+#define XST_SPI_TRANSFER_DONE       1152	/* data transfer is complete */
+#define XST_SPI_TRANSMIT_UNDERRUN   1153	/* slave underruns transmit register */
+#define XST_SPI_RECEIVE_OVERRUN     1154	/* device overruns receive register */
+#define XST_SPI_NO_SLAVE            1155	/* no slave has been selected yet */
+#define XST_SPI_TOO_MANY_SLAVES     1156	/* more than one slave is being
+						 * selected */
+#define XST_SPI_NOT_MASTER          1157	/* operation is valid only as master */
+#define XST_SPI_SLAVE_ONLY          1158	/* device is configured as slave-only */
+#define XST_SPI_SLAVE_MODE_FAULT    1159	/* slave was selected while disabled */
+
+/********************** OPB Arbiter statuses 1176 - 1200 *********************/
+
+#define XST_OPBARB_INVALID_PRIORITY  1176	/* the priority registers have either
+						 * one master assigned to two or more
+						 * priorities, or one master not
+						 * assigned to any priority
+						 */
+#define XST_OPBARB_NOT_SUSPENDED     1177	/* an attempt was made to modify the
+						 * priority levels without first
+						 * suspending the use of priority
+						 * levels
+						 */
+#define XST_OPBARB_PARK_NOT_ENABLED  1178	/* bus parking by id was enabled but
+						 * bus parking was not enabled
+						 */
+#define XST_OPBARB_NOT_FIXED_PRIORITY 1179	/* the arbiter must be in fixed
+						 * priority mode to allow the
+						 * priorities to be changed
+						 */
+
+/************************ Intc statuses 1201 - 1225 **************************/
+
+#define XST_INTC_FAIL_SELFTEST      1201	/* self test failed */
+#define XST_INTC_CONNECT_ERROR      1202	/* interrupt already in use */
+
+/********************** TmrCtr statuses 1226 - 1250 **************************/
+
+#define XST_TMRCTR_TIMER_FAILED     1226	/* self test failed */
+
+/********************** WdtTb statuses 1251 - 1275 ***************************/
+
+#define XST_WDTTB_TIMER_FAILED      1251L
+
+/********************** PlbArb statuses 1276 - 1300 **************************/
+
+#define XST_PLBARB_FAIL_SELFTEST    1276L
+
+/********************** Plb2Opb statuses 1301 - 1325 *************************/
+
+#define XST_PLB2OPB_FAIL_SELFTEST   1301L
+
+/********************** Opb2Plb statuses 1326 - 1350 *************************/
+
+#define XST_OPB2PLB_FAIL_SELFTEST   1326L
+
+/********************** SysAce statuses 1351 - 1360 **************************/
+
+#define XST_SYSACE_NO_LOCK          1351L	/* No MPU lock has been granted */
+
+/********************** PCI Bridge statuses 1361 - 1375 **********************/
+
+#define XST_PCI_INVALID_ADDRESS     1361L
+
+/**************************** Type Definitions *******************************/
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xstreamer.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xstreamer.c
--- linux-2.6.31.12/drivers/xilinx_common/xstreamer.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xstreamer.c	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,512 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2005-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/*
+* @file xstreamer.c
+*
+* See xtreamer.h for a description on how to use this driver.
+*
+* <pre>
+* MODIFICATION HISTORY:
+*
+* Ver   Who  Date     Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a jvb  10/13/06 First release - based on Robert McGee's streaming packet
+*                     fifo driver.
+* </pre>
+******************************************************************************/
+
+/***************************** Include Files *********************************/
+
+#include "xstreamer.h"
+
+/*
+ * Implementation Notes
+ *
+ * --- Receive ---
+ *
+ * The basic algorithm for receiving bytes through this byte streamer copies a
+ * fifo key-hole width chunk from the fifo into a holding buffer and then doles
+ * out the bytes from the holding buffer. In some cases, when the buffer given
+ * happens to already be aligned in memory, this algorithm will bypass the
+ * holding buffer.
+ *
+ * Here is a picture to depict this process:
+ *
+ * Initial state:                 holding buffer
+ *                                +--------------+
+ *                                |   <empty>    |
+ *                                +--------------+
+ *                                               ^
+ *                                               |
+ *                                             index
+ *
+ * during XStrm_Read():
+ * first holding buffer fill:     holding buffer
+ *                                +--------------+
+ *                                |////<full>////|
+ *                                +--------------+
+ *                                ^
+ *                                |
+ *                              index
+ *
+ * first holding buffer read:     holding buffer
+ *                                 read   unread
+ *                                +--------------+
+ *                                |      |///////|
+ *                                +--------------+
+ *                                       ^
+ *                                       |
+ *                                     index
+ *
+ * ...
+ *
+ * last holding buffer read:     holding buffer
+ *                                +--------------+
+ *                                |   <empty>    |
+ *                                +--------------+
+ *                                               ^
+ *                                               |
+ *                                             index
+ *
+ * repeat this process ^^^
+ *
+ *
+ * --- Transmit ---
+ *
+ * The basic algorithm for transmitting bytes through this byte streamer copies
+ * bytes into a holding buffer and then writes the holding buffer into the fifo
+ * when it is full.  In some cases, when the buffer given happens to already be
+ * aligned in memory, this algorithm will bypass the holding buffer.
+ *
+ * Here is a picture to depict this process:
+ *
+ * Initial state:                 holding buffer
+ *                                +--------------+
+ *                                |   <empty>    |
+ *                                +--------------+
+ *                                ^
+ *                                |
+ *                              index
+ *
+ * during XStrm_Write():
+ * first holding buffer write:    holding buffer
+ *                                 writen  empty
+ *                                +--------------+
+ *                                |//////|       |
+ *                                +--------------+
+ *                                       ^
+ *                                       |
+ *                                     index
+ *
+ * ...
+ * last holding buffer write:     holding buffer
+ *                                +--------------+
+ *                                |////<full>////|
+ *                                +--------------+
+ *                                               ^
+ *                                               |
+ *                                             index
+ *
+ * holding buffer flush:          holding buffer
+ *                                +--------------+
+ *                                |   <empty>    |
+ *                                +--------------+
+ *                                ^
+ *                                |
+ *                              index
+ *
+ * repeat this process ^^^
+ */
+
+#ifndef min
+#define min(x, y) (((x) < (y)) ? (x) : (y))
+#endif
+
+/*****************************************************************************/
+/*
+*
+* XStrm_RxInitialize initializes the XStrm_RxFifoStreamer object referenced by
+* <i>InstancePtr</i>.
+*
+* @param    InstancePtr references the tx streamer on which to operate.
+*
+* @param    FifoWidth specifies the FIFO keyhole size in bytes.
+*
+* @param    FifoInstance references the FIFO driver instance that this streamer
+*           object should use to transfer data into the the actual fifo.
+*
+* @param    ReadFn specifies a routine to use to read data from the actual
+*           FIFO. It is assumed that this read routine will handle only reads
+*           from an aligned buffer. (Otherwise, why are we using this streamer
+*           driver?)
+*
+* @param    GetLenFn specifies a routine to use to initiate a receive on the
+*           actual FIFO.
+*
+* @param    GetOccupancyFn specifies a routine to use to retrieve the occupancy
+*           in the actual FIFO. The true occupancy value needs to come through
+*           this streamer driver becuase it holds some of the bytes.
+*
+* @return   N/A
+*
+******************************************************************************/
+void XStrm_RxInitialize(XStrm_RxFifoStreamer * InstancePtr,
+			unsigned FifoWidth, void *FifoInstance,
+			XStrm_XferFnType ReadFn,
+			XStrm_GetLenFnType GetLenFn,
+			XStrm_GetOccupancyFnType GetOccupancyFn)
+{
+	/* Verify arguments */
+	XASSERT_VOID(InstancePtr != NULL);
+
+	InstancePtr->HeadIndex = FifoWidth;
+	InstancePtr->FifoWidth = FifoWidth;
+	InstancePtr->FifoInstance = FifoInstance;
+	InstancePtr->ReadFn = ReadFn;
+	InstancePtr->GetLenFn = GetLenFn;
+	InstancePtr->GetOccupancyFn = GetOccupancyFn;
+}
+
+/*****************************************************************************/
+/*
+*
+* XStrm_TxInitialize initializes the XStrm_TxFifoStreamer object referenced by
+* <i>InstancePtr</i>.
+*
+* @param    InstancePtr references the tx streamer on which to operate.
+*
+* @param    FifoWidth specifies the FIFO keyhole size in bytes.
+*
+* @param    FifoInstance references the FIFO driver instance that this streamer
+*           object should use to transfer data into the the actual fifo.
+*
+* @param    WriteFn specifies a routine to use to write data into the actual
+*           FIFO. It is assumed that this write routine will handle only writes
+*           from an aligned buffer. (Otherwise, why are we using this streamer
+*           driver?)
+*
+* @param    SetLenFn specifies a routine to use to initiate a transmit on the
+*           actual FIFO.
+*
+* @param    GetVacancyFn specifies a routine to use to retrieve the vacancy in
+*           the actual FIFO. The true vacancy value needs to come through this
+*           streamer driver becuase it holds some of the bytes.
+*
+* @return   N/A
+*
+******************************************************************************/
+void XStrm_TxInitialize(XStrm_TxFifoStreamer * InstancePtr, unsigned FifoWidth,
+			void *FifoInstance, XStrm_XferFnType WriteFn,
+			XStrm_SetLenFnType SetLenFn,
+			XStrm_GetVacancyFnType GetVacancyFn)
+{
+	/* Verify arguments */
+	XASSERT_VOID(InstancePtr != NULL);
+
+	InstancePtr->TailIndex = 0;
+	InstancePtr->FifoWidth = FifoWidth;
+	InstancePtr->FifoInstance = FifoInstance;
+	InstancePtr->WriteFn = WriteFn;
+	InstancePtr->SetLenFn = SetLenFn;
+	InstancePtr->GetVacancyFn = GetVacancyFn;
+}
+
+/*****************************************************************************/
+/*
+*
+* XStrm_RxGetLen notifies the hardware that the program is ready to receive the
+* next frame from the receive channel of the FIFO, specified by
+* <i>InstancePtr</i>.
+*
+* Note that the program must first call XStrm_RxGetLen before pulling data
+* out of the receive channel of the FIFO with XStrm_Read.
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @return   XStrm_RxGetLen returns the number of bytes available in the next
+*           frame.
+*
+******************************************************************************/
+u32 XStrm_RxGetLen(XStrm_RxFifoStreamer * InstancePtr)
+{
+	u32 len;
+
+	InstancePtr->HeadIndex = InstancePtr->FifoWidth;
+	len = (*InstancePtr->GetLenFn) (InstancePtr->FifoInstance);
+	InstancePtr->FrmByteCnt = len;
+	return len;
+}
+
+/*****************************************************************************/
+/*
+*
+* XStrm_Read reads <i>Bytes</i> bytes from the FIFO specified by
+* <i>InstancePtr</i> to the block of memory, referenced by <i>BufPtr</i>. 
+*
+* Care must be taken to ensure that the number of bytes read with one or more
+* calls to XStrm_Read() does not exceed the number of bytes available given
+* from the last call to XStrm_RxGetLen().
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @param    BufPtr specifies the memory address to place the data read.
+*
+* @param    Bytes specifies the number of bytes to read.
+*
+* @return   N/A
+*
+******************************************************************************/
+void XStrm_Read(XStrm_RxFifoStreamer * InstancePtr, void *BufPtr,
+		unsigned Bytes)
+{
+	u8 *DestPtr = (u8 *) BufPtr;
+	unsigned BytesRemaining = Bytes;
+	unsigned FifoWordsToXfer;
+	unsigned PartialBytes;
+	unsigned i;
+
+	while (BytesRemaining) {
+		xdbg_printf(XDBG_DEBUG_FIFO_RX,
+			    "XStrm_Read: BytesRemaining: %d\n", BytesRemaining);
+		/* Case 1: There are bytes in the holding buffer
+		 * 
+		 *   1) Read the bytes from the holding buffer to the target buffer.
+		 *   2) Loop back around and handle the rest of the transfer.
+		 */
+		if (InstancePtr->HeadIndex != InstancePtr->FifoWidth) {
+			xdbg_printf(XDBG_DEBUG_FIFO_RX,
+				    "XStrm_Read: Case 1: InstancePtr->HeadIndex [%d] != InstancePtr->FifoWidth [%d]\n",
+				    InstancePtr->HeadIndex,
+				    InstancePtr->FifoWidth);
+			i = InstancePtr->HeadIndex;
+
+			PartialBytes = min(BytesRemaining,
+					   InstancePtr->FifoWidth -
+					   InstancePtr->HeadIndex);
+			InstancePtr->HeadIndex += PartialBytes;
+			BytesRemaining -= PartialBytes;
+			InstancePtr->FrmByteCnt -= PartialBytes;
+			while (PartialBytes--) {
+				*DestPtr = InstancePtr->AlignedBuffer.bytes[i];
+				i++;
+				DestPtr++;
+			}
+		}
+		/* Case 2: There are no more bytes in the holding buffer and
+		 *         the target buffer is 32 bit aligned and
+		 *         the number of bytes remaining to transfer is greater
+		 *         than or equal to the fifo width.
+		 *
+		 *   1) We can go fast by reading a long string of fifo words right out
+		 *      of the fifo into the target buffer.
+		 *   2) Loop back around to transfer the last few bytes.
+		 */
+		else if ((((unsigned) DestPtr & 3) == 0) &&
+			 (BytesRemaining >= InstancePtr->FifoWidth)) {
+			xdbg_printf(XDBG_DEBUG_FIFO_RX,
+				    "XStrm_Read: Case 2: DestPtr: %p, BytesRemaining: %d, InstancePtr->FifoWidth: %d\n",
+				    DestPtr, BytesRemaining,
+				    InstancePtr->FifoWidth);
+			FifoWordsToXfer =
+				BytesRemaining / InstancePtr->FifoWidth;
+
+			(*(InstancePtr->ReadFn)) (InstancePtr->FifoInstance,
+						  DestPtr, FifoWordsToXfer);
+			DestPtr += FifoWordsToXfer * InstancePtr->FifoWidth;
+			BytesRemaining -=
+				FifoWordsToXfer * InstancePtr->FifoWidth;
+			InstancePtr->FrmByteCnt -=
+				FifoWordsToXfer * InstancePtr->FifoWidth;
+		}
+		/* Case 3: There are no more bytes in the holding buffer and
+		 *         the number of bytes remaining to transfer is less than
+		 *         the fifo width or
+		 *         things just don't line up.
+		 *
+		 *   1) Fill the holding buffer.
+		 *   2) Loop back around and handle the rest of the transfer.
+		 */
+		else {
+			xdbg_printf(XDBG_DEBUG_FIFO_RX, "XStrm_Read: Case 3\n");
+			/*
+			 * At the tail end, read one fifo word into the local holding
+			 * buffer and loop back around to take care of the transfer.
+			 */
+			(*InstancePtr->ReadFn) (InstancePtr->FifoInstance,
+						&(InstancePtr->AlignedBuffer.
+						  bytes[0]), 1);
+			InstancePtr->HeadIndex = 0;
+		}
+	}
+}
+
+/*****************************************************************************/
+/*
+*
+* XStrm_TxSetLen flushes to the FIFO, specified by <i>InstancePtr</i>, any
+* bytes remaining in internal buffers and begins a hardware transfer of data
+* out of the transmit channel of the FIFO. <i>Bytes</i> specifies the number
+* of bytes in the frame to transmit.
+*
+* @param    InstancePtr references the FIFO Streamer on which to operate.
+*
+* @param    Bytes specifies the frame length in bytes.
+*
+* @return   N/A
+*
+******************************************************************************/
+void XStrm_TxSetLen(XStrm_TxFifoStreamer * InstancePtr, u32 Bytes)
+{
+	/*
+	 * First flush what's in the holding buffer
+	 */
+	if (InstancePtr->TailIndex != 0) {
+		(*InstancePtr->WriteFn) (InstancePtr->FifoInstance,
+					 &(InstancePtr->AlignedBuffer.bytes[0]),
+					 1);
+		InstancePtr->TailIndex = 0;
+	}
+
+	/*
+	 * Kick off the hw write
+	 */
+	(*(InstancePtr)->SetLenFn) (InstancePtr->FifoInstance, Bytes);
+}
+
+/*****************************************************************************/
+/*
+*
+* XStrm_Write writes <i>Bytes</i> bytes of the block of memory, referenced by
+* <i>BufPtr</i>, to the transmit channel of the FIFO referenced by
+* <i>InstancePtr</i>. 
+*
+* Care must be taken to ensure that the number of bytes written with one or
+* more calls to XStrm_Write() matches the number of bytes given in the next
+* call to XStrm_TxSetLen().
+*
+* @param    InstancePtr references the FIFO on which to operate.
+*
+* @param    BufPtr specifies the memory address of data to write.
+*
+* @param    Bytes specifies the number of bytes to write.
+*
+* @return   N/A
+*
+******************************************************************************/
+void XStrm_Write(XStrm_TxFifoStreamer * InstancePtr, void *BufPtr,
+		 unsigned Bytes)
+{
+	u8 *SrcPtr = (u8 *) BufPtr;
+	unsigned BytesRemaining = Bytes;
+	unsigned FifoWordsToXfer;
+	unsigned PartialBytes;
+	unsigned i;
+
+	while (BytesRemaining) {
+		xdbg_printf(XDBG_DEBUG_FIFO_TX,
+			    "XStrm_Write: BytesRemaining: %d\n",
+			    BytesRemaining);
+		/* Case 1: The holding buffer is full
+		 * 
+		 *   1) Write it to the fifo.
+		 *   2) Fall through to transfer more bytes in this iteration.
+		 */
+		if (InstancePtr->TailIndex == InstancePtr->FifoWidth) {
+			xdbg_printf(XDBG_DEBUG_FIFO_TX,
+				    "XStrm_Write: (case 1) TailIndex: %d; FifoWidth: %d; WriteFn: %p\n",
+				    InstancePtr->TailIndex,
+				    InstancePtr->FifoWidth,
+				    InstancePtr->WriteFn);
+			(*InstancePtr->WriteFn) (InstancePtr->FifoInstance,
+						 &(InstancePtr->AlignedBuffer.
+						   bytes[0]), 1);
+			InstancePtr->TailIndex = 0;
+		}
+		/* Case 2: There are no bytes in the holding buffer and
+		 *         the target buffer is 32 bit aligned and
+		 *         the number of bytes remaining to transfer is greater
+		 *         than or equal to the fifo width.
+		 *
+		 *   1) We can go fast by writing a long string of fifo words right out
+		 *      of the source buffer into the fifo.
+		 *   2) Loop back around to transfer the last few bytes.
+		 */
+		if ((InstancePtr->TailIndex == 0) &&
+		    (BytesRemaining >= InstancePtr->FifoWidth) &&
+		    (((unsigned) SrcPtr & 3) == 0)) {
+			FifoWordsToXfer =
+				BytesRemaining / InstancePtr->FifoWidth;
+
+			xdbg_printf(XDBG_DEBUG_FIFO_TX,
+				    "XStrm_Write: (case 2) TailIndex: %d; BytesRemaining: %d; FifoWidth: %d; SrcPtr: %p;\n InstancePtr: %p; WriteFn: %p (XLlFifo_iWrite_Aligned: %p),\nFifoWordsToXfer: %d (BytesRemaining: %d)\n",
+				    InstancePtr->TailIndex, BytesRemaining,
+				    InstancePtr->FifoWidth, SrcPtr, InstancePtr,
+				    InstancePtr->WriteFn,
+				    XLlFifo_iWrite_Aligned, FifoWordsToXfer,
+				    BytesRemaining);
+
+			(*InstancePtr->WriteFn) (InstancePtr->FifoInstance,
+						 SrcPtr, FifoWordsToXfer);
+			SrcPtr += FifoWordsToXfer * InstancePtr->FifoWidth;
+			BytesRemaining -=
+				FifoWordsToXfer * InstancePtr->FifoWidth;
+			xdbg_printf(XDBG_DEBUG_FIFO_TX,
+				    "XStrm_Write: (end case 2) TailIndex: %d; BytesRemaining: %d; SrcPtr: %p\n",
+				    InstancePtr->TailIndex, BytesRemaining,
+				    SrcPtr);
+		}
+		/* Case 3: The alignment of the "galaxies" didn't occur in
+		 *         Case 2 above, so we must pump the bytes through the
+		 *         holding buffer.
+		 * 
+		 *   1) Write bytes from the source buffer to the holding buffer
+		 *   2) Loop back around and handle the rest of the transfer.
+		 */
+		else {
+			i = InstancePtr->TailIndex;
+
+			PartialBytes =
+				min(BytesRemaining,
+				    InstancePtr->FifoWidth -
+				    InstancePtr->TailIndex);
+			BytesRemaining -= PartialBytes;
+			InstancePtr->TailIndex += PartialBytes;
+			while (PartialBytes--) {
+				xdbg_printf(XDBG_DEBUG_FIFO_TX,
+					    "XStrm_Write: (case 3) PartialBytes: %d\n",
+					    PartialBytes);
+				InstancePtr->AlignedBuffer.bytes[i] = *SrcPtr;
+				i++;
+				SrcPtr++;
+			}
+		}
+	}
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xstreamer.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xstreamer.h
--- linux-2.6.31.12/drivers/xilinx_common/xstreamer.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xstreamer.h	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,325 @@
+/* $Id: */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2005-2008 Xilinx Inc.
+*       All rights reserved.
+* This program is free software; you can redistribute it and/or modify it
+* under the terms of the GNU General Public License as published by the
+* Free Software Foundation; either version 2 of the License, or (at your
+* option) any later version.
+*
+* You should have received a copy of the GNU General Public License
+* along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+*
+******************************************************************************/
+/*****************************************************************************/
+/*
+ *
+ * @file xstreamer.h
+ *
+ * The Xilinx byte streamer for packet FIFOs.
+ *
+ * <h2>Driver Description</h2>
+ *
+ * This driver enables higher layer software to access a hardware FIFO using
+ * any alignment in the data buffers while preserving alignment for the hardware
+ * FIFO access.
+ * 
+ * This driver treats send and receive channels separately, using different
+ * types of instance objects for each.
+ * 
+ * This driver makes use of another FIFO driver to access the specific FIFO
+ * hardware through use of the routines passed into the Tx/RxInitialize
+ * routines.
+ * 
+ * <h2>Initialization</h2>
+ *
+ * Send and receive channels are intialized separately. The receive channel is
+ * initiailzed using XStrm_RxInitialize(). The send channel is initialized
+ * using XStrm_TxInitialize().
+ *
+ * 
+ * <h2>Usage</h2>
+ * It is fairly simple to use the API provided by this byte streamer
+ * driver. The only somewhat tricky part is that the calling code must
+ * correctly call a couple routines in the right sequence for receive and
+ * transmit.
+ *
+ * 	This sequence is described here. Check the routine functional 
+ * descriptions for information on how to use a specific API routine.
+ *
+ * <h3>Receive</h3>
+ * A frame is received by using the following sequence:<br>
+ * 1) call XStrm_RxGetLen() to get the length of the next incoming frame.<br>
+ * 2) call XStrm_Read() one or more times to read the number of bytes
+ * 	   reported by XStrm_RxGetLen().<br>
+ *
+ * For example:
+ * <pre>
+ * 	frame_len = XStrm_RxGetLen(&RxInstance);
+ * 	while (frame_len) {
+ * 		unsigned bytes = min(sizeof(buffer), frame_len);
+ * 		XStrm_Read(&RxInstance, buffer, bytes);
+ * 		// do something with buffer here
+ * 		frame_len -= bytes;
+ * 	}
+ * </pre>
+ *
+ * Other restrictions on the sequence of API calls may apply depending on
+ * the specific FIFO driver used by this byte streamer driver.
+ *
+ * <h3>Transmit</h3>
+ * A frame is transmittted by using the following sequence:<br>
+ * 1) call XStrm_Write() one or more times to write all the of bytes in
+ *    the next frame.<br>
+ * 2) call XStrm_TxSetLen() to begin the transmission of frame just
+ *    written.<br>
+ *
+ * For example:
+ * <pre>
+ * 	frame_left = frame_len;
+ * 	while (frame_left) {
+ * 		unsigned bytes = min(sizeof(buffer), frame_left);
+ * 		XStrm_Write(&TxInstance, buffer, bytes);
+ * 		// do something here to refill buffer
+ * 	}
+ * 	XStrm_TxSetLen(&RxInstance, frame_len);
+ * </pre>
+ *
+ * Other restrictions on the sequence of API calls may apply depending on
+ * the specific FIFO driver used by this byte streamer driver.
+ *
+ * <pre>
+ * MODIFICATION HISTORY:
+ *
+ * Ver   Who  Date     Changes
+ * ----- ---- -------- -------------------------------------------------------
+ * 1.00a jvb  10/12/06 First release
+ * </pre>
+ *
+ *****************************************************************************/
+#ifndef XSTREAMER_H		/* prevent circular inclusions */
+#define XSTREAMER_H		/* by using preprocessor symbols */
+
+/* force C linkage */
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "xbasic_types.h"
+#include "xstatus.h"
+#include "xdebug.h"
+
+/*
+ * key hole size in 32 bit words
+ */
+#define LARGEST_FIFO_KEYHOLE_SIZE_WORDS 4
+
+/*
+ * This union is used simply to force a 32bit alignment on the
+ * buffer. Only the 'bytes' member is really used.
+ */
+union XStrm_AlignedBufferType {
+	u32 _words[LARGEST_FIFO_KEYHOLE_SIZE_WORDS];
+	char bytes[LARGEST_FIFO_KEYHOLE_SIZE_WORDS * 4];
+};
+
+typedef int(*XStrm_XferFnType) (void *FifoInstance, void *BufPtr,
+                                    unsigned WordCount);
+typedef u32 (*XStrm_GetLenFnType) (void *FifoInstance);
+typedef void (*XStrm_SetLenFnType) (void *FifoInstance,
+                                    u32 ByteCount);
+typedef u32 (*XStrm_GetOccupancyFnType) (void *FifoInstance);
+typedef u32 (*XStrm_GetVacancyFnType) (void *FifoInstance);
+
+/**
+ * This typedef defines a run-time instance of a receive byte-streamer.
+ */
+typedef struct XStrm_RxFifoStreamer {
+	union XStrm_AlignedBufferType AlignedBuffer;
+	unsigned HeadIndex;  /**< HeadIndex is the index to the AlignedBuffer
+	                      *   as bytes.
+                              */
+	unsigned FifoWidth;  /**< FifoWidth is the FIFO key hole width in bytes.
+	                      */
+	unsigned FrmByteCnt; /**< FrmByteCnt is the number of bytes in the next
+			      *   Frame.
+			      */
+	void *FifoInstance;  /**< FifoInstance is the FIFO driver instance to
+	                      *   pass to ReadFn, GetLenFn, and GetOccupancyFn
+	                      *   routines.
+	                      */
+	XStrm_XferFnType ReadFn;     /**< ReadFn is the routine the streamer
+	                              *   uses to receive bytes from the Fifo.
+	                              */
+	XStrm_GetLenFnType GetLenFn; /**< GetLenFn is the routine the streamer
+	                              *   uses to initiate receive operations
+	                              *   on the FIFO.
+                                      */
+	XStrm_GetOccupancyFnType GetOccupancyFn; /**< GetOccupancyFn is the
+	                                          *   routine the streamer uses
+	                                          *   to get the occupancy from
+	                                          *   the FIFO.
+	                                          */
+} XStrm_RxFifoStreamer;
+
+/**
+ * This typedef defines a run-time instance of a transmit byte-streamer.
+ */
+typedef struct XStrm_TxFifoStreamer {
+	union XStrm_AlignedBufferType AlignedBuffer;
+	unsigned TailIndex; /**< TailIndex is the index to the AlignedBuffer
+	                     *   as bytes
+                             */
+	unsigned FifoWidth; /**< FifoWidth is the FIFO key hole width in bytes.
+	                     */
+
+	void *FifoInstance; /**< FifoInstance is the FIFO driver instance to
+	                     *   pass to WriteFn, SetLenFn, and GetVacancyFn
+	                     *   routines.
+	                     */
+	XStrm_XferFnType WriteFn; /**< WriteFn is the routine the streamer
+	                           *   uses to transmit bytes to the Fifo.
+	                           */
+	XStrm_SetLenFnType SetLenFn; /**< SetLenFn is the routine the streamer
+	                              *   uses to initiate transmit operations
+	                              *   on the FIFO.
+                                      */
+	XStrm_GetVacancyFnType GetVacancyFn; /**< GetVaccancyFn is the routine
+	                                      *   the streamer uses to get the
+	                                      *   vacancy from the FIFO.
+	                                      */
+} XStrm_TxFifoStreamer;
+
+/*****************************************************************************/
+/*
+*
+* XStrm_TxVacancy returns the number of unused 32-bit words available (vacancy)
+* between the streamer, specified by <i>InstancePtr</i>, and the FIFO this
+* streamer is using.
+*
+* @param    InstancePtr references the streamer on which to operate.
+*
+* @return   XStrm_TxVacancy returns the vacancy count in number of 32 bit words.
+*
+* @note
+*
+* C Signature: u32 XStrm_TxVacancy(XStrm_TxFifoStreamer *InstancePtr)
+*
+* The amount of bytes in the holding buffer (rounded up to whole 32-bit words)
+* is subtracted from the vacancy value of FIFO this streamer is using. This is
+* to ensure the caller can write the number words given in the return value and
+* not overflow the FIFO.
+*
+******************************************************************************/
+#define XStrm_TxVacancy(InstancePtr) \
+	(((*(InstancePtr)->GetVacancyFn)((InstancePtr)->FifoInstance)) - \
+			(((InstancePtr)->TailIndex + 3) / 4))
+
+/*****************************************************************************/
+/*
+*
+* XStrm_RxOccupancy returns the number of 32-bit words available (occupancy) to
+* be read from the streamer, specified by <i>InstancePtr</i>, and FIFO this
+* steamer is using.
+*
+* @param    InstancePtr references the streamer on which to operate.
+*
+* @return   XStrm_RxOccupancy returns the occupancy count in number of 32 bit
+*           words.
+*
+* @note
+*
+* C Signature: u32 XStrm_RxOccupancy(XStrm_RxFifoStreamer *InstancePtr)
+*
+* The amount of bytes in the holding buffer (rounded up to whole 32-bit words)
+* is added to the occupancy value of FIFO this streamer is using. This is to
+* ensure the caller will get a little more accurate occupancy value.
+*
+******************************************************************************/
+#ifdef DEBUG
+extern u32 _xstrm_ro_value;
+extern u32 _xstrm_buffered;
+#define XStrm_RxOccupancy(InstancePtr) \
+        (_xstrm_ro_value = ((*(InstancePtr)->GetOccupancyFn)((InstancePtr)->FifoInstance)), \
+	xdbg_printf(XDBG_DEBUG_FIFO_RX, "reg: %d; frmbytecnt: %d\n", \
+		_xstrm_ro_value, (InstancePtr)->FrmByteCnt), \
+	(((InstancePtr)->FrmByteCnt) ? \
+		_xstrm_buffered = ((InstancePtr)->FifoWidth - (InstancePtr)->HeadIndex) : \
+		0), \
+	xdbg_printf(XDBG_DEBUG_FIFO_RX, "buffered_bytes: %d\n", _xstrm_buffered), \
+	xdbg_printf(XDBG_DEBUG_FIFO_RX, "buffered (rounded): %d\n", _xstrm_buffered), \
+	(_xstrm_ro_value + _xstrm_buffered))
+#else
+#define XStrm_RxOccupancy(InstancePtr) \
+	( \
+	  ((*(InstancePtr)->GetOccupancyFn)((InstancePtr)->FifoInstance)) + \
+	  ( \
+	    ((InstancePtr)->FrmByteCnt) ? \
+	      ((InstancePtr)->FifoWidth - (InstancePtr)->HeadIndex) : \
+	      0 \
+	  ) \
+	)
+#endif
+
+/****************************************************************************/
+/*
+*
+* XStrm_IsRxInternalEmpty returns true if the streamer, specified by
+* <i>InstancePtr</i>, is not holding any bytes in it's  internal buffers. Note
+* that this routine does not reflect information about the state of the
+* FIFO used by this streamer.
+*
+* @param    InstancePtr references the streamer on which to operate.
+*
+* @return   XStrm_IsRxInternalEmpty returns TRUE when the streamer is not
+*           holding any bytes in it's internal buffers. Otherwise,
+*           XStrm_IsRxInternalEmpty returns FALSE.
+*
+* @note
+* C-style signature:
+*    int XStrm_IsRxInternalEmpty(XStrm_RxFifoStreamer *InstancePtr)
+*
+*****************************************************************************/
+#define XStrm_IsRxInternalEmpty(InstancePtr) \
+	(((InstancePtr)->HeadIndex == (InstancePtr)->FifoWidth) ? TRUE : FALSE)
+
+void XStrm_RxInitialize(XStrm_RxFifoStreamer *InstancePtr,
+                        unsigned FifoWidth, void *FifoInstance,
+                        XStrm_XferFnType ReadFn,
+                        XStrm_GetLenFnType GetLenFn,
+                        XStrm_GetOccupancyFnType GetOccupancyFn);
+
+void XStrm_TxInitialize(XStrm_TxFifoStreamer *InstancePtr,
+                        unsigned FifoWidth, void *FifoInstance,
+                        XStrm_XferFnType WriteFn,
+                        XStrm_SetLenFnType SetLenFn,
+                        XStrm_GetVacancyFnType GetVacancyFn);
+
+void XStrm_TxSetLen(XStrm_TxFifoStreamer *InstancePtr, u32 Bytes);
+void XStrm_Write(XStrm_TxFifoStreamer *InstancePtr, void *BufPtr,
+                    unsigned bytes);
+
+u32 XStrm_RxGetLen(XStrm_RxFifoStreamer *InstancePtr);
+void XStrm_Read(XStrm_RxFifoStreamer *InstancePtr, void *BufPtr,
+                   unsigned bytes);
+
+#ifdef __cplusplus
+}
+#endif
+#endif				/* XSTREAMER_H  end of preprocessor protection symbols */
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xversion.c linux-2.6.31.12-petalinux/drivers/xilinx_common/xversion.c
--- linux-2.6.31.12/drivers/xilinx_common/xversion.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xversion.c	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,341 @@
+/* $Id: xversion.c,v 1.1 2006/12/13 14:23:34 imanuilov Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+*
+* @file xversion.c
+*
+* This file contains the implementation of the XVersion component. This
+* component represents a version ID.  It is encapsulated within a component
+* so that it's type and implementation can change without affecting users of
+* it.
+*
+* The version is formatted as X.YYZ where X = 0 - 9, Y = 00 - 99, Z = a - z
+* X is the major revision, YY is the minor revision, and Z is the
+* compatability revision.
+*
+* Packed versions are also utilized for the configuration ROM such that
+* memory is minimized. A packed version consumes only 16 bits and is
+* formatted as follows.
+*
+* <pre>
+* Revision                  Range       Bit Positions
+*
+* Major Revision            0 - 9       Bits 15 - 12
+* Minor Revision            0 - 99      Bits 11 - 5
+* Compatability Revision    a - z       Bits 4 - 0
+*
+* MODIFICATION HISTORY:
+*
+* Ver   Who    Date   Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a xd   11/03/04 Improved support for doxygen.
+</pre>
+*
+******************************************************************************/
+
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xversion.h"
+
+/************************** Constant Definitions *****************************/
+
+/* the following constants define the masks and shift values to allow the
+ * revisions to be packed and unpacked, a packed version is packed into a 16
+ * bit value in the following format, XXXXYYYYYYYZZZZZ, where XXXX is the
+ * major revision, YYYYYYY is the minor revision, and ZZZZZ is the compatability
+ * revision
+ */
+#define XVE_MAJOR_SHIFT_VALUE       12
+#define XVE_MINOR_ONLY_MASK         0x0FE0
+#define XVE_MINOR_SHIFT_VALUE       5
+#define XVE_COMP_ONLY_MASK          0x001F
+
+/* the following constants define the specific characters of a version string
+ * for each character of the revision, a version string is in the following
+ * format, "X.YYZ" where X is the major revision (0 - 9), YY is the minor
+ * revision (00 - 99), and Z is the compatability revision (a - z)
+ */
+#define XVE_MAJOR_CHAR      0	/* major revision 0 - 9 */
+#define XVE_MINOR_TENS_CHAR 2	/* minor revision tens 0 - 9 */
+#define XVE_MINOR_ONES_CHAR 3	/* minor revision ones 0 - 9 */
+#define XVE_COMP_CHAR       4	/* compatability revision a - z */
+#define XVE_END_STRING_CHAR 5
+
+/**************************** Type Definitions *******************************/
+
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+static u32 IsVersionStringValid(s8 *StringPtr);
+
+/*****************************************************************************/
+/**
+*
+* Unpacks a packed version into the specified version. Versions are packed
+* into the configuration ROM to reduce the amount storage. A packed version
+* is a binary format as oppossed to a non-packed version which is implemented
+* as a string.
+*
+* @param    InstancePtr points to the version to unpack the packed version into.
+* @param    PackedVersion contains the packed version to unpack.
+*
+* @return   None.
+*
+* @note     None.
+*
+******************************************************************************/
+void XVersion_UnPack(XVersion * InstancePtr, u16 PackedVersion)
+{
+	/* not implemented yet since CROM related */
+}
+
+/*****************************************************************************/
+/**
+*
+* Packs a version into the specified packed version. Versions are packed into
+* the configuration ROM to reduce the amount storage.
+*
+* @param    InstancePtr points to the version to pack.
+* @param    PackedVersionPtr points to the packed version which will receive
+*           the new packed version.
+*
+* @return
+*
+* A status, XST_SUCCESS, indicating the packing was accomplished
+* successfully, or an error, XST_INVALID_VERSION, indicating the specified
+* input version was not valid such that the pack did not occur
+* <br><br>
+* The packed version pointed to by PackedVersionPtr is modified with the new
+* packed version if the status indicates success.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+int XVersion_Pack(XVersion * InstancePtr, u16 *PackedVersionPtr)
+{
+	/* not implemented yet since CROM related */
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************/
+/**
+*
+* Determines if two versions are equal.
+*
+* @param    InstancePtr points to the first version to be compared.
+* @param    VersionPtr points to a second version to be compared.
+*
+* @return
+*
+* TRUE if the versions are equal, FALSE otherwise.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+u32 XVersion_IsEqual(XVersion * InstancePtr, XVersion * VersionPtr)
+{
+	u8 *Version1 = (u8 *) InstancePtr;
+	u8 *Version2 = (u8 *) VersionPtr;
+	int Index;
+
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(VersionPtr != NULL);
+
+	/* check each byte of the versions to see if they are the same,
+	 * return at any point a byte differs between them
+	 */
+	for (Index = 0; Index < sizeof(XVersion); Index++) {
+		if (Version1[Index] != Version2[Index]) {
+			return FALSE;
+		}
+	}
+
+	/* No byte was found to be different between the versions, so indicate
+	 * the versions are equal
+	 */
+	return TRUE;
+}
+
+/*****************************************************************************/
+/**
+*
+* Converts a version to a null terminated string.
+*
+* @param    InstancePtr points to the version to convert.
+* @param    StringPtr points to the string which will be the result of the
+*           conversion. This does not need to point to a null terminated
+*           string as an input, but must point to storage which is an adequate
+*           amount to hold the result string.
+*
+* @return
+*
+* The null terminated string is inserted at the location pointed to by
+* StringPtr if the status indicates success.
+*
+* @note
+*
+* It is necessary for the caller to have already allocated the storage to
+* contain the string.  The amount of memory necessary for the string is
+* specified in the version header file.
+*
+******************************************************************************/
+void XVersion_ToString(XVersion * InstancePtr, s8 *StringPtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(StringPtr != NULL);
+
+	/* since version is implemented as a string, just copy the specified
+	 * input into the specified output
+	 */
+	XVersion_Copy(InstancePtr, (XVersion *) StringPtr);
+}
+
+/*****************************************************************************/
+/**
+*
+* Initializes a version from a null terminated string. Since the string may not
+* be a format which is compatible with the version, an error could occur.
+*
+* @param    InstancePtr points to the version which is to be initialized.
+* @param    StringPtr points to a null terminated string which will be
+*           converted to a version.  The format of the string must match the
+*           version string format which is X.YYX where X = 0 - 9, YY = 00 - 99,
+*           Z = a - z.
+*
+* @return
+*
+* A status, XST_SUCCESS, indicating the conversion was accomplished
+* successfully, or XST_INVALID_VERSION indicating the version string format
+* was not valid.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+int XVersion_FromString(XVersion * InstancePtr, s8 *StringPtr)
+{
+	/* assert to verify input arguments */
+
+	XASSERT_NONVOID(InstancePtr != NULL);
+	XASSERT_NONVOID(StringPtr != NULL);
+
+	/* if the version string specified is not valid, return an error */
+
+	if (!IsVersionStringValid(StringPtr)) {
+		return XST_INVALID_VERSION;
+	}
+
+	/* copy the specified string into the specified version and indicate the
+	 * conversion was successful
+	 */
+	XVersion_Copy((XVersion *) StringPtr, InstancePtr);
+
+	return XST_SUCCESS;
+}
+
+/*****************************************************************************/
+/**
+*
+* Copies the contents of a version to another version.
+*
+* @param    InstancePtr points to the version which is the source of data for
+*           the copy operation.
+* @param    VersionPtr points to another version which is the destination of
+*           the copy operation.
+*
+* @return
+*
+* None.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+void XVersion_Copy(XVersion * InstancePtr, XVersion * VersionPtr)
+{
+	u8 *Source = (u8 *) InstancePtr;
+	u8 *Destination = (u8 *) VersionPtr;
+	int Index;
+
+	/* assert to verify input arguments */
+
+	XASSERT_VOID(InstancePtr != NULL);
+	XASSERT_VOID(VersionPtr != NULL);
+
+	/* copy each byte of the source version to the destination version */
+
+	for (Index = 0; Index < sizeof(XVersion); Index++) {
+		Destination[Index] = Source[Index];
+	}
+}
+
+/*****************************************************************************/
+/**
+*
+* Determines if the specified version is valid.
+*
+* @param    StringPtr points to the string to be validated.
+*
+* @return
+*
+* TRUE if the version string is a valid format, FALSE otherwise.
+*
+* @note
+*
+* None.
+*
+******************************************************************************/
+static u32 IsVersionStringValid(s8 *StringPtr)
+{
+	/* if the input string is not a valid format, "X.YYZ" where X = 0 - 9,
+	 * YY = 00 - 99, and Z = a - z, then indicate it's not valid
+	 */
+	if ((StringPtr[XVE_MAJOR_CHAR] < '0') ||
+	    (StringPtr[XVE_MAJOR_CHAR] > '9') ||
+	    (StringPtr[XVE_MINOR_TENS_CHAR] < '0') ||
+	    (StringPtr[XVE_MINOR_TENS_CHAR] > '9') ||
+	    (StringPtr[XVE_MINOR_ONES_CHAR] < '0') ||
+	    (StringPtr[XVE_MINOR_ONES_CHAR] > '9') ||
+	    (StringPtr[XVE_COMP_CHAR] < 'a') ||
+	    (StringPtr[XVE_COMP_CHAR] > 'z')) {
+		return FALSE;
+	}
+
+	return TRUE;
+}
diff -purN --exclude=.git linux-2.6.31.12/drivers/xilinx_common/xversion.h linux-2.6.31.12-petalinux/drivers/xilinx_common/xversion.h
--- linux-2.6.31.12/drivers/xilinx_common/xversion.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/drivers/xilinx_common/xversion.h	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,98 @@
+/* $Id: xversion.h,v 1.1 2006/12/13 14:23:41 imanuilov Exp $ */
+/******************************************************************************
+*
+*       XILINX IS PROVIDING THIS DESIGN, CODE, OR INFORMATION "AS IS"
+*       AS A COURTESY TO YOU, SOLELY FOR USE IN DEVELOPING PROGRAMS AND
+*       SOLUTIONS FOR XILINX DEVICES.  BY PROVIDING THIS DESIGN, CODE,
+*       OR INFORMATION AS ONE POSSIBLE IMPLEMENTATION OF THIS FEATURE,
+*       APPLICATION OR STANDARD, XILINX IS MAKING NO REPRESENTATION
+*       THAT THIS IMPLEMENTATION IS FREE FROM ANY CLAIMS OF INFRINGEMENT,
+*       AND YOU ARE RESPONSIBLE FOR OBTAINING ANY RIGHTS YOU MAY REQUIRE
+*       FOR YOUR IMPLEMENTATION.  XILINX EXPRESSLY DISCLAIMS ANY
+*       WARRANTY WHATSOEVER WITH RESPECT TO THE ADEQUACY OF THE
+*       IMPLEMENTATION, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OR
+*       REPRESENTATIONS THAT THIS IMPLEMENTATION IS FREE FROM CLAIMS OF
+*       INFRINGEMENT, IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+*       FOR A PARTICULAR PURPOSE.
+*
+*       (c) Copyright 2002 Xilinx Inc.
+*       All rights reserved.
+*
+******************************************************************************/
+/*****************************************************************************/
+/**
+* @file xversion.h
+*
+* This file contains the interface for the XVersion component. This
+* component represents a version ID.  It is encapsulated within a component
+* so that it's type and implementation can change without affecting users of
+* it.
+*
+* The version is formatted as X.YYZ where X = 0 - 9, Y = 00 - 99, Z = a - z
+* X is the major revision, YY is the minor revision, and Z is the
+* compatability revision.
+*
+* Packed versions are also utilized for the configuration ROM such that
+* memory is minimized. A packed version consumes only 16 bits and is
+* formatted as follows.
+*
+* <pre>
+* Revision                  Range       Bit Positions
+*
+* Major Revision            0 - 9       Bits 15 - 12
+* Minor Revision            0 - 99      Bits 11 - 5
+* Compatability Revision    a - z       Bits 4 - 0
+*
+* MODIFICATION HISTORY:
+*
+* Ver   Who    Date   Changes
+* ----- ---- -------- -------------------------------------------------------
+* 1.00a xd   11/03/04 Improved support for doxygen.
+* </pre>
+*
+******************************************************************************/
+
+#ifndef XVERSION_H		/* prevent circular inclusions */
+#define XVERSION_H		/* by using protection macros */
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/***************************** Include Files *********************************/
+
+#include "xbasic_types.h"
+#include "xstatus.h"
+
+/************************** Constant Definitions *****************************/
+
+
+/**************************** Type Definitions *******************************/
+
+/* the following data type is used to hold a null terminated version string
+ * consisting of the following format, "X.YYX"
+ */
+typedef s8 XVersion[6];
+
+/***************** Macros (Inline Functions) Definitions *********************/
+
+
+/************************** Function Prototypes ******************************/
+
+void XVersion_UnPack(XVersion * InstancePtr, u16 PackedVersion);
+
+int XVersion_Pack(XVersion * InstancePtr, u16 *PackedVersion);
+
+u32 XVersion_IsEqual(XVersion * InstancePtr, XVersion * VersionPtr);
+
+void XVersion_ToString(XVersion * InstancePtr, s8 *StringPtr);
+
+int XVersion_FromString(XVersion * InstancePtr, s8 *StringPtr);
+
+void XVersion_Copy(XVersion * InstancePtr, XVersion * VersionPtr);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* end of protection macro */
diff -purN --exclude=.git linux-2.6.31.12/include/asm-generic/atomic.h linux-2.6.31.12-petalinux/include/asm-generic/atomic.h
--- linux-2.6.31.12/include/asm-generic/atomic.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/include/asm-generic/atomic.h	2010-08-08 17:40:18.256172933 +0200
@@ -60,11 +60,11 @@ static inline int atomic_add_return(int 
 	unsigned long flags;
 	int temp;
 
-	local_irq_save(flags);
+	raw_local_irq_save(flags);
 	temp = v->counter;
 	temp += i;
 	v->counter = temp;
-	local_irq_restore(flags);
+	raw_local_irq_restore(flags);
 
 	return temp;
 }
@@ -82,11 +82,11 @@ static inline int atomic_sub_return(int 
 	unsigned long flags;
 	int temp;
 
-	local_irq_save(flags);
+	raw_local_irq_save(flags);
 	temp = v->counter;
 	temp -= i;
 	v->counter = temp;
-	local_irq_restore(flags);
+	raw_local_irq_restore(flags);
 
 	return temp;
 }
@@ -139,9 +139,9 @@ static inline void atomic_clear_mask(uns
 	unsigned long flags;
 
 	mask = ~mask;
-	local_irq_save(flags);
+	raw_local_irq_save(flags);
 	*addr &= mask;
-	local_irq_restore(flags);
+	raw_local_irq_restore(flags);
 }
 
 #define atomic_xchg(ptr, v)		(xchg(&(ptr)->counter, (v)))
diff -purN --exclude=.git linux-2.6.31.12/include/asm-generic/dma-mapping-common.h linux-2.6.31.12-petalinux/include/asm-generic/dma-mapping-common.h
--- linux-2.6.31.12/include/asm-generic/dma-mapping-common.h	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/include/asm-generic/dma-mapping-common.h	2010-08-08 17:40:18.256172933 +0200
@@ -103,7 +103,6 @@ static inline void dma_sync_single_for_c
 	if (ops->sync_single_for_cpu)
 		ops->sync_single_for_cpu(dev, addr, size, dir);
 	debug_dma_sync_single_for_cpu(dev, addr, size, dir);
-	flush_write_buffers();
 }
 
 static inline void dma_sync_single_for_device(struct device *dev,
@@ -116,7 +115,6 @@ static inline void dma_sync_single_for_d
 	if (ops->sync_single_for_device)
 		ops->sync_single_for_device(dev, addr, size, dir);
 	debug_dma_sync_single_for_device(dev, addr, size, dir);
-	flush_write_buffers();
 }
 
 static inline void dma_sync_single_range_for_cpu(struct device *dev,
@@ -132,7 +130,6 @@ static inline void dma_sync_single_range
 		ops->sync_single_range_for_cpu(dev, addr, offset, size, dir);
 		debug_dma_sync_single_range_for_cpu(dev, addr, offset, size, dir);
 
-		flush_write_buffers();
 	} else
 		dma_sync_single_for_cpu(dev, addr, size, dir);
 }
@@ -150,7 +147,6 @@ static inline void dma_sync_single_range
 		ops->sync_single_range_for_device(dev, addr, offset, size, dir);
 		debug_dma_sync_single_range_for_device(dev, addr, offset, size, dir);
 
-		flush_write_buffers();
 	} else
 		dma_sync_single_for_device(dev, addr, size, dir);
 }
@@ -165,7 +161,6 @@ dma_sync_sg_for_cpu(struct device *dev, 
 	if (ops->sync_sg_for_cpu)
 		ops->sync_sg_for_cpu(dev, sg, nelems, dir);
 	debug_dma_sync_sg_for_cpu(dev, sg, nelems, dir);
-	flush_write_buffers();
 }
 
 static inline void
@@ -179,7 +174,6 @@ dma_sync_sg_for_device(struct device *de
 		ops->sync_sg_for_device(dev, sg, nelems, dir);
 	debug_dma_sync_sg_for_device(dev, sg, nelems, dir);
 
-	flush_write_buffers();
 }
 
 #define dma_map_single(d, a, s, r) dma_map_single_attrs(d, a, s, r, NULL)
diff -purN --exclude=.git linux-2.6.31.12/include/linux/uio_pdrv_genirq.h linux-2.6.31.12-petalinux/include/linux/uio_pdrv_genirq.h
--- linux-2.6.31.12/include/linux/uio_pdrv_genirq.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/include/linux/uio_pdrv_genirq.h	2010-08-08 17:40:18.279759310 +0200
@@ -0,0 +1,13 @@
+#ifndef _LINUX_UIO_PDRV_GENIRQ_H
+#define _LINUX_UIO_PDRV_GENIRQ_H
+
+struct uio_pdrv_genirq_platdata {
+	struct uio_info *uioinfo;
+	spinlock_t lock;
+	unsigned long flags;
+};
+
+extern int __uio_pdrv_genirq_probe(struct device *dev, struct uio_info *uioinfo,
+	struct resource *resources, unsigned int num_resources);
+
+#endif
diff -purN --exclude=.git linux-2.6.31.12/include/linux/xilinx_devices.h linux-2.6.31.12-petalinux/include/linux/xilinx_devices.h
--- linux-2.6.31.12/include/linux/xilinx_devices.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.31.12-petalinux/include/linux/xilinx_devices.h	2010-08-08 17:22:50.623938732 +0200
@@ -0,0 +1,111 @@
+/*
+ * include/linux/xilinx_devices.h
+ *
+ * Definitions for any platform device related flags or structures for
+ * Xilinx EDK IPs
+ *
+ * Author: MontaVista Software, Inc.
+ *         source@mvista.com
+ *
+ * 2002-2005 (c) MontaVista Software, Inc.  This file is licensed under the
+ * terms of the GNU General Public License version 2.  This program is licensed
+ * "as is" without any warranty of any kind, whether express or implied.
+ */
+
+#ifdef __KERNEL__
+#ifndef _XILINX_DEVICE_H_
+#define _XILINX_DEVICE_H_
+
+#include <linux/types.h>
+#include <linux/version.h>
+#include <linux/platform_device.h>
+
+/*- 10/100 Mb Ethernet Controller IP (XEMAC) -*/
+
+struct xemac_platform_data {
+	u32 device_flags;
+	u32 dma_mode;
+	u32 has_mii;
+	u32 has_err_cnt;
+	u32 has_cam;
+	u32 has_jumbo;
+	u32 tx_dre;
+	u32 rx_dre;
+	u32 tx_hw_csum;
+	u32 rx_hw_csum;
+	u8 mac_addr[6];
+};
+
+/* Flags related to XEMAC device features */
+#define XEMAC_HAS_ERR_COUNT	0x00000001
+#define XEMAC_HAS_MII		0x00000002
+#define XEMAC_HAS_CAM		0x00000004
+#define XEMAC_HAS_JUMBO		0x00000008
+
+/* Possible DMA modes supported by XEMAC */
+#define XEMAC_DMA_NONE		1
+#define XEMAC_DMA_SIMPLE	2	/* simple 2 channel DMA */
+#define XEMAC_DMA_SGDMA		3	/* scatter gather DMA */
+
+/*- 10/100 Mb Ethernet Controller IP (XEMACLITE) -*/
+struct xemaclite_platform_data {
+	u32 tx_ping_pong;
+	u32 rx_ping_pong;
+	u8 mac_addr[6];
+};
+
+/*- 10/100/1000 Mb Ethernet Controller IP (XTEMAC) -*/
+
+struct xtemac_platform_data {
+#ifdef XPAR_TEMAC_0_INCLUDE_RX_CSUM
+	u8 tx_dre;
+	u8 rx_dre;
+	u8 tx_csum;
+	u8 rx_csum;
+	u8 phy_type;
+#endif
+	u8 dma_mode;
+	u32 rx_pkt_fifo_depth;
+	u32 tx_pkt_fifo_depth;
+	u16 mac_fifo_depth;
+	u8 dcr_host;
+	u8 dre;
+
+	u8 mac_addr[6];
+};
+
+/* Possible DMA modes supported by XTEMAC */
+#define XTEMAC_DMA_NONE		1
+#define XTEMAC_DMA_SIMPLE	2	/* simple 2 channel DMA */
+#define XTEMAC_DMA_SGDMA	3	/* scatter gather DMA */
+
+
+/* LLTEMAC platform data */
+struct xlltemac_platform_data {
+	u8 tx_csum;
+	u8 rx_csum;
+	u8 phy_type;
+	u8 dcr_host;
+	u8 ll_dev_type;
+	u32 ll_dev_baseaddress;
+	u32 ll_dev_dma_rx_irq;
+	u32 ll_dev_dma_tx_irq;
+	u32 ll_dev_fifo_irq;
+
+	u8 mac_addr[6];
+};
+
+/* SPI Controller IP */
+struct xspi_platform_data {
+	s16 bus_num;
+	u16 num_chipselect;
+	u32 speed_hz;
+};
+
+/*- GPIO -*/
+
+/* Flags related to XGPIO device features */
+#define XGPIO_IS_DUAL		0x00000001
+
+#endif /* _XILINX_DEVICE_H_ */
+#endif /* __KERNEL__ */
diff -purN --exclude=.git linux-2.6.31.12/lib/checksum.c linux-2.6.31.12-petalinux/lib/checksum.c
--- linux-2.6.31.12/lib/checksum.c	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/lib/checksum.c	2010-08-08 17:40:18.305471793 +0200
@@ -37,7 +37,8 @@
 
 #include <asm/byteorder.h>
 
-static inline unsigned short from32to16(unsigned long x)
+#ifndef do_csum
+static inline unsigned short from32to16(unsigned int x)
 {
 	/* add up 16-bit and 16-bit for 16+c bit */
 	x = (x & 0xffff) + (x >> 16);
@@ -49,16 +50,16 @@ static inline unsigned short from32to16(
 static unsigned int do_csum(const unsigned char *buff, int len)
 {
 	int odd, count;
-	unsigned long result = 0;
+	unsigned int result = 0;
 
 	if (len <= 0)
 		goto out;
 	odd = 1 & (unsigned long) buff;
 	if (odd) {
 #ifdef __LITTLE_ENDIAN
-		result = *buff;
-#else
 		result += (*buff << 8);
+#else
+		result = *buff;
 #endif
 		len--;
 		buff++;
@@ -73,9 +74,9 @@ static unsigned int do_csum(const unsign
 		}
 		count >>= 1;		/* nr of 32-bit words.. */
 		if (count) {
-			unsigned long carry = 0;
+			unsigned int carry = 0;
 			do {
-				unsigned long w = *(unsigned int *) buff;
+				unsigned int w = *(unsigned int *) buff;
 				count--;
 				buff += 4;
 				result += carry;
@@ -102,6 +103,7 @@ static unsigned int do_csum(const unsign
 out:
 	return result;
 }
+#endif
 
 /*
  *	This is a version of ip_compute_csum() optimized for IP headers,
diff -purN --exclude=.git linux-2.6.31.12/Makefile linux-2.6.31.12-petalinux/Makefile
--- linux-2.6.31.12/Makefile	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/Makefile	2010-08-08 17:40:15.843755287 +0200
@@ -1013,8 +1013,8 @@ define create-symlink
 endef
 
 include/asm: FORCE
-	$(Q)$(check-symlink)
-	$(Q)$(create-symlink)
+	$(Q)@$(check-symlink)
+	$(Q)@$(create-symlink)
 
 # Generate some files
 # ---------------------------------------------------------------------------
diff -purN --exclude=.git linux-2.6.31.12/scripts/recordmcount.pl linux-2.6.31.12-petalinux/scripts/recordmcount.pl
--- linux-2.6.31.12/scripts/recordmcount.pl	2010-01-18 19:30:45.000000000 +0100
+++ linux-2.6.31.12-petalinux/scripts/recordmcount.pl	2010-08-08 17:40:18.333069992 +0200
@@ -246,6 +246,9 @@ if ($arch eq "x86_64") {
     $ld .= " -m elf64_sparc";
     $cc .= " -m64";
     $objcopy .= " -O elf64-sparc";
+} elsif ($arch eq "microblaze") {
+    # Microblaze calls '_mcount' instead of plain 'mcount'.
+    $mcount_regex = "^\\s*([0-9a-fA-F]+):.*\\s_mcount\$";
 } else {
     die "Arch $arch is not supported with CONFIG_FTRACE_MCOUNT_RECORD";
 }
